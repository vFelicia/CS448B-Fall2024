hey this is andrew brown your cloud instructor at exam pro bringing you another complete study course and this time it's the hashicorp terraform associate certification made available to you here on freecodecamp so this course is designed to help you pass and achieve hashicorp issued certification and the way we're going to do that is by going through lectures follow alongs cheat sheets and even a practice exam so you can prove on your resume and linkedin you got that terraform knowledge so you can go get that devops job or get that promotion you've been looking for to tell you a bit about me i'm previously the cto of multiple edtech companies 15 years industry experience five years specializing cloud i'm it was community hero i published multiple free cloud courses and if you ever want to buy me a drink coconut water is what i drink uh if you i just want to take a moment here to thank viewers like you because it's you that make these free courses possible if you want to know how you can support more free courses like this the best ways to buy our additional study materials at exam pro dot co forward slash terraform for this particular course so this is where you'll get study notes flash cards quizlets downloadable lectures downloadable cheat sheets practice exams ask questions get learning support and so if you want to access the free practice exam cheat sheets you do have to sign up but there is no credit card required there's no trial limit and you're not going to get spammed okay if there are course updates they are going to appear within a link within the youtube and also on the exam pro platform and just make sure that you have access to these corrections additions modifications uh before you start this course so you're making sure you are consuming the latest version so that you have the best chance of passing if you want to keep up to date on uh new courses that i'm working on the best places to follow me on twitter at andrew brown and i'd love to hear if you passed your exam what courses you'd like to see next and there you go so let's go jump into the course now hey this is andrew brown from exam pro and we're at the start of our journey asking the most important questions first which is what is the terraform associate so the hashicorp terraform associate is a specialty certification in terraform and it is an infrastructure as a code tool that is both declarative and cloud agnostic so you might be considering getting the certification if you are seeking a devops engineer role if you enjoy automating infrastructure or writing scripts if you have knowledge uh working with multiple cloud service providers like aws gcp azure or you enjoy designing and entering on endtoend infrastructure life cycles so terraform is the third most uh cloud skill that is in demand for devops roles so it goes aws azure terraform and kubernetes so terraform is the industry standard for infrastructure as a code i know aws really likes cloud formation but you know when you're using more than one provider and most companies are they're going to be turning to terraform this is not a difficult exam however grasping terraform requires a bit of patience since uh it requires a bit of uh silic uh circular learning to fully understand certain concepts so when i say that it's like you'll go over something you'll kind of get it then you'll go put it into practice and you'll come back to the original lecture content and then it will all make sense so you just have to kind of work through it with having partial information it's kind of like doing math back in the day for high school so terraform is easy to learn but it definitely is hard to master so just because you pass this terraform associate doesn't mean you're an expert in it but definitely means that you're gonna have the skills to meet the job requirements for junior devops roles or you know if you're upskilling okay so there are multiple ways that we can look at this i call it the multicloud roadmap because everything that hashicorp does is all about uh multicloud workloads and a prerequisite of doing this kind of stuff is actually having base knowledge in uh different providers so if we're looking at certifications you have the google cloud engineer you could have any any sort of um aws certification could be the solutions architect could be the developer but generally the sysops is probably the most aligned and then you have your azure administrator or maybe your azure developer the az204 and then there's also kubernetes because kubernetes workloads can come in there so that's the ckad so very common is you'll pick up one or two certs in your associate tier for one of the csps and then you're going to move on to your terraform associate certification uh hashicorp while i'm making this video does not have that many certifications beyond the associate track as you can see they only have a single professional up here and it's for vault would they make a terraform professional i don't know um but you know that'd be interesting to see if you wanted to know where to go after your associate i would probably go over to console because that is uh like cloud networking or multicloud networking that is agnostic and then maybe you might want to go over to vaults if you are uh interested to go the vault route and again this is outside of the terraform roadmap but you could just take one of those associates and move to vaults and then go to the take the professional if you're doing the kubernetes track then you you would probably want to go over to console there but really we're focused on here is this over here okay so how long does it take to pass uh this exam so here i have kind of a scale here we're going to look at beginner and then experience so i i describe a beginner as someone who's never written infrastructure as a code uh has not previously focused on automating infrastructure and doesn't hold an associate level certification if this is you you're looking at a 30 hour study time you really should go obtain a cloud service provider associate before you take this exam you don't have to but it's generally recommended for the experienced person this is someone who is written infrastructure's code maybe it's been cloud formation maybe it's been armed templates but maybe it's just not terraform they are already working in a devops role automating infrastructure writing scripts and they hold an associate level they probably have professionals too so they're looking at 12 hours study time okay so there's a large window of time but my recommendation is that you spread it out across 14 days study one to two hours obviously it's going to vary based on uh what you're doing here but that will pretty much get you there okay what does it take to pass this example you're going to have to watch the lecture materials and memorize key information you absolutely need to do handson labs it's really going to cement your knowledge here when i made this course i did all the lecture content first and then when i did my follow alongs i just had so many misconceptions because the um the actual documentation did not exactly match what was in practice so it's very important that you do that and i would strongly recommend some practice exams and the great thing is i have practice exams for you on our platform and not only that i have a full free practice exam for for you with 57 questions like that's a full set just like the real exam so i strongly recommend that you go redeem it uh you could probably pass just with the free one but you know if you want to help support the platform then go pay to unlock all the rest of the study material content okay um in terms of the content outline there is a lot of domains here so we have understand infrastructures of code understand terraform purpose under stand terraform basics use terraform cli interact with terraform modules navigate the terraform workflow implement uh and maintain terraform state regenerate modify configuration understand terraform cloud enterprise capabilities and the interesting thing is that they don't give a a distribution in terms of the weighting so it's my assumption that um and when we look at the exam guide outline you'll see that they'll have sub domains under each one so i would imagine that if you know if there's like five questions under or five sub domains under 1.0 then that kind of tells you the waiting for that section uh but we'll talk about that when we get the exam guide because there's some interesting stuff there okay where do you take the exam well you can take an inperson test center or online from the convenience of your own home and it's only with one test center and this is with psi when i say test center i mean like uh they're a network of test centers around the world and this is a project experience so there is a supervisor who monitors students during the examination so uh you know to make sure that it's legit okay in terms of grading you have to get a 70 percent to pass around that just like every other exam out there it probably uses scaled scoring so it's not always exact if you get exactly on the dot seven percent doesn't necessarily mean you pass so make sure you aim for 75 percent for your exam okay there are 57 questions that affords about 17 questions that you can get wrong there's no penalty for wrong questions so absolutely make sure that you always take a guess the format of the questions are multiple choice multiple answer and this last one's interesting but there's fill in the blank and this is where you type a single word answer so they might ask you like what is the name of the terraform save file and you just write in terraform.tf state so you know it could be as simple as that the duration of the exam is one hour but that is plenty of time you get one minute per question a little bit more than just a minute so your exam time is 60 minutes but your seat times 90 minutes see time is meaning that you show up 30 minutes early and you make sure you're ready so you can review the instructions if you have to work with your online proctor to make sure your workspace is secure accept and read the nda complete the exam provide feedback of the exam so make sure you get paid for that time this exam is valid for 24 months so that means two years before recertification one little thing i want to note here is about terraform version considerations when i designed this course it was designed around the 1.0 specification of terraform so terraform is always incrementing inversion so for your studies you may always need to look at the feature set of versions that go back three minor versions from the current stable version so if it's 1.0 like uh which the exams at least when i sat it wasn't even at 1.0 it's probably like point 15 or 0.14 but my point is that i designed this kind of be like a bit future proof so it's this course is not going to go stale for a couple years but i do want you to tell you that like you know if the exam is based around let's say like the terraform version that's out is one point uh you know six uh that doesn't like the exam is always a bit behind it so you know the exam might be 1.0 and then that means that the content exam would cover these three things okay so throughout this course i will cover older stuff but i'll also cover newer stuff and i'll give more emphasis on and you'll see me do that throughout the course okay so for terraform certification is heavily dependent on practical knowledge so as as long as you take the time to apply the knowledge uh you'll have a good chance of passing regardless of the differences in versioning and uh more than half of this course is handson okay so the bulk of it is handson um you could pass just doing lecture content so like when i sat the exam i had done a i like like a very simple walkthrough and then i made all my lecture content and i was able to pass no problem uh but again i have a background in devops and i understand how this stuff works so it was easy for me to translate that if you are new or you're not confident you should really do all those practice exams so there you go and let's take a look at the actual exam guide okay hey this is andrew brown from exam pro and we are on the hashicorp certification website looking at terraform associate and we're going to take a look here at the exam guide because i have some commentary that i want to share with you about it and what i found really interesting with the way they design their courses is that everything that you see pretty much shows up on the exam so there is 57 questions on the exam and but down below here there is just shy of 57 subdomains and so the great thing here is that pretty much every single question will map to one of these and you're not going to be worried about having to figure out things outside of this pool so that really is going to narrow what you need to study for uh it creates a lot of less like confusion or guesswork or over study and i really appreciate that and i did not until i actually finished like i got certified and made the lectures in the labs and my practice exams and i realized wow that makes it a lot easier from a study perspective but when i came into this i thought the exam was going to be something like aws where what they do is they have all these domains and subdomains and subtopics and then besides that then they also have like appendix and then the service and features list and so basically more than half like half of more than half of the stuff that they say here you might not even experience an exam and that's really frustrating because you're really over studying here and i really like hashicorp's approach here so if you really do want to know what you know just go down the list here and say do i know what all of these things are and if you can checkbox those off you're very likely to pass okay um i do want to say that this is uh dated even like right now as we talk because this is not based off of terraform 1.0 this exam guide outline and we can tell because we see terraform taint if you look up terraform taint this is a deprecated command um so it has been replaced with terraform apply with the hyphen replace but do not worry i've taken care of all of that for you in the exam so you do not have to worry about any kind of confusion we are going to cover things outside of just this exam guide outline because after talking to da's their technical writers product marketers i feel that there's going to be additional content coming in the update like terraform cloud because i feel like that needs a lot more attention here and so i was i was sure to pack this course with a lot of extra stuff so that the lifespan of this course is gonna be a lot longer than what is being shown here okay so yeah uh hopefully that gives you kind of an idea and some confidence going into this exam uh but let's jump into the real content okay hey this is andrew brown from exam pro and what i want to do is walk you through a few of our practice exam questions just to give you an idea of what it will be like on the real exam and where we might have had to make some adjustments to help your study so what you'd have to do to access this practice exam is you'd have to be signed up and logged in to the exam pro platform make your way over to the hashicorp terraform course accept the free tier or pay for full access but once you go there you'll scroll all the way down to the bottom and you should see three or four practice exams at the time of writing this we're still writing the questions so that's why they're not shown in the video here but what i want you to do is to go to the first practice exam and notice that there are 57 questions you get an hour on on the exam here and we have a breakdown based on domain now the percentage is not something that uh terraform or hashicorp provides so we just had to break it down based on the coverage of questions that we saw in the exam guide outline and so that should be accurate enough and that's kind of what it felt like on the exam so i don't think that's going to be a problem if we click into here we're just going to look at some of the questions i'll talk around them so the first one here is we have how do you create a workspace and it's showing us a bunch of cli commands and so on the exam you do need to know um uh you know cli commands and the difference of them and the questions can be as simple as this where you're just choosing the option and some are obvious distractors like there isn't there is no one called terraform workspace branch okay so just understand that you not just need to know the conceptual ideas behind terraform but also it in practice okay another one here would be the terraform registry can search based on the following search terms we have an option to choose multiple uh questions and so this is something that you will see on the exam where you're choosing multiples of something i didn't get a lot on my exam but i cannot say for certain like how many questions would show up like this um but you know they're not really that hard to figure out okay and this question is about um a tool or sorry uh the public terraform registry website and that is just a uh a publicfacing website if we go to registry.terraform.io here it's this website here so it's not just the tooling of terraform itself but it's the ecosystem around it's a terraform cloud the terraform registry things like that another type of question you will see and i think it's over here is what they will do is they'll ask you to fill in the blank now we don't have that support in our platform just as of yet but the idea is they'll say like okay uh we'll ask you a question or we'll even give you um maybe they'll have like underscores and they'll say fill in this thing and you'll literally have to type the answer in but the answer is gonna be like a word answer so on the exam i literally had a question which was like where is the api stored and it was actually terraformed at tf state but i did not know i could not recall the name of it which is kind of embarrassing but uh you know that is the level of fillins that you'll have to do and you're very likely to see some code on the on the clut exam too so if i just click through here really quickly you may see a code block okay and you might have to decipher it so that's the difficulty of the exam i would not say this is a hard exam but you just have to understand the scope of those kind of questions and make sure that you have wellrounded study in both practical and conceptual concepts of terraform so hopefully that helps you out okay hey this is andrew brown from exam pro and we are looking at what is infrastructure is code and before we talk about that we need to talk about the problem with manual configuration so manually configuring your cloud infrastructure allows you to easily start using new cloud service offerings to quickly prototype architectures however it comes with a few downsides so it's easy to misconfigure a service through human error it's hard to manage the expected state of the configuration for compliance it's hard to transfer configuration knowledge to other team members and so this is why uh infrastructure code is going to really help us out so um infrastructure is code commonly abbreviated to iac and you'll see that a lot in this course allows you to write a configuration script to automate creating updating or destroying cloud infrastructure notice i gave great emphasis on automate or automation because that is really key to infrastructure's code iec can also be thought of as a blueprint of your infrastructure ic allows you to easily share version or inventory your cloud infrastructure and just to kind of give you a visualization imagine you write a script and that's going to uh provision uh and launch a bunch of cloud services that are all interconnected okay all right so we're taking a look at popular iac tools and so of course this course is about terraform but by understanding all the options out there you understand why we're using terraform and one thing that is very important to understand is the difference between declarative and imperative iec tools those are the broad categories that we see for iac so let's start with declarative so the idea here is what you see is what you get everything's explicit it's more verbose but there's zero chance of misconfiguration and this all relies on the fact that they use a scripting language such as json yaml xml in the case of terraform they have their own language called hcl but the way these languages are structured is that they're very verbose and there's not a lot of programming logic involved so for azure we have arm templates and azure blueprints for aws we have cloudformation for google we have cloud deployment manager and then there is of course terraform which has many cloud service providers such as aws azure gcp kubernetes and a lot more but these are all in the declarative category on the right hand side we have imperative so you say what you want and the rest is filled in everything here is implicit uh it's less verbose but you could end up with misconfiguration and when i say that it's that like if you were to find um let's say a virtual machine you might not have to provide every single uh option that you would normally do and it would fill in the rest but if you weren't aware of what it was doing that's where you could end up with misconfiguration though i would say that imperative tools generally try to always have their defaults as best practices so you're not usually in a bad position uh but you know you might end up with something you don't expect uh imperative can do more than declarative so there's just some very hard limitations with declarative languages uh so there's just cases where you want to do imperative uh and the idea here is imperative languages use programming language you know like python ruby javascript golang you know whatever it is uh there's likely an sdk for it and so it's just a lot more programmer friendly a lot of developers like imperative tools so aws has their own called cloud development kit cdk and it technically only supports aws i say technically because hashicorp has a very cool library that allows you to generate out uh terraform hcl files which allows you to work with anything but when we're just talking about cdk on its own it's just for aws then you have plumi it supports aws azure tcp and kubernetes um so it can do a lot so why would you choose with your team to use declarative over imperative well it just really depends on your um your team right so like if they're all used to if they're all administrators and they're used to using jason yaml and they're not good programming languages uh that is one reason why you might want to use declarative over imperative um the other thing is just you know you prefer to know exactly every single thing that was defined right you don't want anything left up to a chance and so that is another reason why you might want to use declarative but both are great options it just really depends on your team's knowledge and what your goals are okay so we just looked at imperative and declarative but i just want to clarify that terraform even though it's a declarative language it has imperative like features so i've coined the phrase declarative plus and so terraform kind of gives you the best of both worlds so you have declarative and imperative and then the three types so our yaml json xml we have terraform language which actually utilizes hcl underneath and then you have programming languages on the right hand side like ruby python javascript uh what have you right so when we're looking at yaml or json these are very limited languages or scripting languages where you know you don't really have any kind of complex data types you probably don't have a whole lot of robust functions but in some cases you can extend that base behavior so in the case of cloud formation which uses yaml or json files they have a concept called macros so you can extend it a bit but again it's very inflexible and so a lot of people are led to go and use cdk so terraform is great because it kind of has a lot of stuff you'd see in programming languages like for loops dynamic blocks locals it also has complex data structures and a lot of functions around using those data structures and so it allows you to stay in that declarative world but having the stuff that you generally need when you're in the paradive world when you're in the imperative side the idea is that the language is what you're utilizing so you can do anything that the programming language allows you to do but i just wanted to kind of show you that terraform sits in the middle okay hey it's andrew brown from exam pro and we are looking at infrastructure life cycle so what is infrastructure lifecycle it's the idea of having clearly defined and distinct work phases which are used by devops engineers to plan design build test deliver maintain and retire cloud infrastructure when we're talking about like sdlc so software development life cycle there's usually a really great visual that i can show for you but for infrastructure life cycle especially cloud infrastructure life cycle there isn't something that is well defined which is weird by the definition but i think that there's just nobody's agreed upon one yet or nobody's made the graphic yet so i just don't have anything to show you for that but i just want you to get familiar with the term infrastructure life cycle because you're likely to hear it again but one particular infrastructure life cycle that is pretty common is ones that talk about day zero day one and day two so the idea here is this is a simplified way to describe phases of infrastructure life cycle so when we say we are on day zero we are planning and designing our infrastructure on day one we are developing and iterating it so we might be uh you know deploying or provisioning it and actually testing it in the cloud and then day two is actually when we go live with real production users and maintain it and the idea of mentioning day zero one and two is to say well when does iac start and the idea is it starts on day zero okay the days do not literally mean a 24hour day uh it's just a broad way of defining where in the infrastructure project we would be okay so after defining what infrastructure life cycle is what advantage or what advancement are we going to have when we add iac to our infrastructure life cycle well the first thing we're going to get is reliability so ic makes changes impotent consistent repeatable and predictable i'm going to give extra attention here to impotent because it is a very strange english word but no matter how many times you run your ic you will always end up with the same state that is expected that is a very important concept of iec whereas if you use configuration management there's no guarantee of that that's why you use a terraform over something like ansible okay you have manageability so enable mutation via code revise with minimal changes and then you have sensibility so avoid financial and reputational losses to even loss of life when considering government and military dependencies on infrastructure so there you go okay so it impodent is a very important concept to infrastructure as code and so we're going to give it a little bit more attention i wouldn't stress out about the pronunciation uh there's more than one way to pronounce it in english and i've probably even said it wrong uh in the previous slide so just be uh forgiving on that part okay but the idea is that let's stage a scenario between a nonedipotent example and an independent example so when i deploy my iac config file it will provision and launch two virtual machines that is what i'm expecting okay and that is what i get but what happens when i go and i update this infrastructure code file saying maybe i want to increase the size of the vms or some of the configuration i deploy that again when it's nonindependent what will end up happening is i will end up with two additional virtual machines with the new configuration and the old ones will be there and so this is something you might not want because you just want to have a file that says exactly the state that you expect okay so when we have something that is idepotent the idea is we will go and we will define our two virtual machines and we will get our two virtual machines but we go and we update that file and we deploy again and what happens this time is it just ends up modifying the original virtual machines or if it really can't and it has to it might delete them and recreate them but the idea is that we end up in a state of exactly what we want so in the first case we expected two but we ended up with four but with the inopponent uh case we expected two and we always end up with two so hopefully that makes that very clear okay hey this is andrew brown from exam pro and what i want to do here is concretely define the difference between provisioning deployment and orchestration now in practice sometimes these have overlapping responsibilities so you might say provisioning when you really mean deployment or vice versa it's not a big deal we all get kind of mixed up about it but i did want to just take the time to make sure that we understand what these things are supposed to mean okay so the first on our list here is provisioning so to prepare a server with systems data and software and to make it ready for network operation if you're using a configuration management tool you are most likely provisioning because that's what these tools do so puppet ansible chef bash scripts powershell or cloudnit so you can provision a server when you launch a cloud service and configure it you are provisioning it okay then you have deployment so deployment is the act of delivering a version of your application to run a provision server deployment could be performed via a bus code pipeline harness which is a thirdparty deployment tool jenkins github actions circle ci there's a lot more other providers out there then you have orchestration so orchestration is the act of coordinating multiple systems or services orchestration is a common term when working with micro services containers and kubernetes so orchestration could be done with kubernetes salt or fabric so if you're working with containers uh generally like you use the word orchestration especially with kubernetes because you're working with thousands of uh microservices okay so you know hopefully that helps you know the difference between those three again it's not a big deal if you don't perfectly know them but there you go hey this is andrew brown from exam pro and we are taking a look at configuration drift so this is when provision infrastructure has an unexpected configuration change due to team members manually adjusting configuration options malicious actors so maybe they're trying to cause downtime or breach data or side effects from apis sdks or cli so you've written some code that uses a cli in the bash script and it does something you did not expect to happen so here an example could be imagine you have a server like a database and a junior developer turns off delete on termination for your production database this could be a problem where let's say there's an accidental deletion of the database this feature would protect the database from deletion but if it's turned off you don't have that right so configuration drift going unnoticed could be a loss or breach of cloud services and residing data or result in interruption of services or unexpected downtime so there's a lot of downsides to uh neglecting or not noticing configuration drift so what can we do about this so how to detect so there's three things detect um we can fix it and then prevent it okay so to detect configuration drift if you have a compliance tool uh it can detect misconfiguration so aws config can do that azure policies can do that gcp security health analytics can do that some of these are constrained to security things not just configuration general but there are tools there for all the cloud service providers there is builtin support for drift detection for it was cloud formation it's called confirmation drift detection other providers don't necessarily have that if you're using terraform which is this which is all this course is about you have the terraform state files which says what the state of things should be so that's how you could detect configuration drift how to correct configuration drift well compliance tools can remediate so again abs config you can create a custom lambda to say hey when this happens then do this so set the configuration back into place with terraform you can use the refresh and plan commands which we'll look at in detail in this course or you can manually correct it so if the option was changed you could do that not recommended to do that another thing would be tearing down and setting up the infrastructure again because that would bring it back into its original state that could be a risky thing to do um depending on how you have things set up or it could be it could be fine right then there's prevention so this is a the important thing and kind of why we're talking about configuration drift which is all about immutable infrastructure so always create and just destroy never reuse so that might be bluegreen deployment strategies um servers are never modified they are all they're just always deployed with a new version uh the way you would do that would be baking ami images or containers via aws image builder or hashicorp packer or a build server like gcp cloud run or code build like aws but the idea is that you're not modifying after they're deployed you'd have that image already ready to go another thing you could use is git ops so uh you would version control your iac like within github or something like that and you would peer review every single uh um change via a pull request to the infrastructure so hopefully that gives you an idea of things we can do to tackle configuration drift okay we were just talking about immutable infrastructure but i just want to give it a bit more attention here so the idea is um we are going to first develop our infrastructure as a code file terraform cloudformation what have you and then we're going to go ahead and deploy that so we'll end up with our own virtual machine and that virtual machine needs to be configured so you need to install packages and things like that that's where cloud in it would come into play ansible puppet chef salt whatever configuration management tool you want to use the problem here is that there's no guarantee that that configuration is going to stay in place so that's where immutable infrastructure comes into play so we develop our infrastructure as a code file terraform cloudformation and then we're going to go ahead and do our configuration by building a virtual machine or building a container so we can use something like packer and then the idea is once we are happy with our configuration what we're going to do is bake that image and put it in an image repository and then that image is going to be referenced when we do our deploy and so that's going to make sure that our infrastructure is always immutable okay hey this is andrew brown from exam pro and we are taking a look at the concept or methodology of git ops so this is when you take infrastructure as code and you use a git repository to introduce a formal process to review and accept changes to infrastructure code and once that code is accepted it automatically triggers a deploy and changes that infrastructure so here's my illustration through it so the idea is you would have a terraform file and you would place that in something like github you would apply your commits and when you're ready you'd make a pull request you would merge that pull request into the main branch or whichever branch is set up for production and that could trigger something like github actions and github actions would then trigger a terraform uh plan and and accept it or maybe you have to manually intervene to say okay i accept these changes but then it would roll out those changes now terraform does have their own and it's pretty darn similar but i thought mine was a bit easier to read but the idea is you have your git repository uh you have your pull request uh this is pulling from terraform cloud because you can uh have files and state managed there uh so that is another means to do it but that's generally how it works okay so we were just looking at immutable infrastructure but what i want to do is just kind of cement in your head things that you should be asking yourself as a devops engineer so that you kind of lean towards uh that immutable uh kind of way of thinking and so this is mostly gonna be applicable for virtual machines but let's just ask some questions of things we should be thinking about so what's gonna happen if we deploy our virtual machine and there is a physical failure of the hardware by the provider so this can sometimes happen on aws where they have two status checks that have to complete before a virtual machine is ready sometimes they fail and so you know your infrastructure is not raised degraded or damaged right then you have application failure so you have this post installation script maybe to install your application and there's either a bug so introduced by developer or maybe there's just a dependency and it's changed and so it's breaking your app what happens when you need to deploy in a hurry what happens in worst case scenarios where you have accidental deletion compromised by a malicious actor need to change regions maybe there's a region outage and so the thing is is that when you look at these things what happens when multiples of these happen at the same time because that's the problem where you know it's like okay i have something wrong with my application code but i also have uh you know now we also have a region down and so you don't want to be dealing with more than one problem at the same time and so that's we're going to have an issue of agility in terms of deployment another thing that is overlooked is there's no guarantee of one to one if you are configuring your code after deployment because if you um were to deploy a virtual machine and installed all the dependencies and then you to were to deploy a virtual machine literally a minute later one of those dependencies could have a minor revision and so that would be deployed with that one minor revision so they would look very similar but they aren't onetoone so by introducing golding images which is an immutable infrastructure idea you get a guarantee of one one to one with your fleet you have increased assurance of consistency security you have uh you can speed up your deployments the reason why you have an improvement of security is because at that stage you could um you could perform kind of security checks and things like that there on that image before you roll it out so i don't know i would just say that i would recommend that you go with the immutable infrastructure or baking your images when you can if you're using bms okay hey this is andrew brown from exam pro and we're going to take a look here what is hashicorp so hashicorp is who creates terraform and they are companies specializing in managed open source tools used to support the deployment and development of largescale service oriented software installations and they have their own uh cloud platform called the hashicorp cloud platform hcp and it's a unified platform to access hashicorp various products so uh the main thing is that it's cloud agnostic so hashicorp makes it really easy to build crosscloud and they have support for all the three main providers so aws gcp azure i'm sure they have more support like kubernetes and things like that they're highly suited for multicloud workloads or crosscloud workloads and they have a lot of products that will help you out there so let's go through them quickly so first we have boundary this is secure remote access to systems based on trusted identity this is console this is a full featured service mesh for secure service segmentation across any cloud or runtime environment you have nomad this is scheduling and deployment of tasks across worker nodes in a cluster you have packer which is a tool for building virtual machine images that will be later deployed or they will place them in a image repository then you have terraform which is infrastructure as code software which enables provisioning and adapting virtual infrastructure across all major providers then you have terraform cloud and this is just a place to store and manage your iac state files and things like that with a team or just in the cloud by yourself we have vagrant so building and building and maintenance of reproducible software development environments via virtualization technology we have vault so secrets management identity based access encrypting application data auditing of secrets for application systems and users and lastly we have waypoint a modern workflow to build deploy and release across multiple platforms so there you go hey this is andrew brown from exam pro and we are looking at what is terraform so terraform is an open source and cloud agnostic infrastructure is a code tool and terraform uses declarative configuration files and the configuration files are written in the hashicorp configuration language hcl and so that's what you can see on the right hand side we'll generally call it the terraform language which we'll talk about later but notable features of terraform are installable modules plan and predict changes dependency graphing state management and provisioning infrastructure in familiar languages that's something you could do via aws cdk so i wouldn't say it's core to terraform but that's what they listed on their websites that's what i put in there and terraform registry which has over 1 000 plus providers okay so there we go so we were just looking at terraform but what is terraform cloud well it's a software as a service offering for remote state storage version control integrations flexible workflows and allows you to collaborate on infrastructure changes within a single unified web portal and this is all accessible via terraform.io and the first thing you'll have to do is create yourself an account on terraformio but it's free to start with and they actually have a very generous free tier that allows for team collaboration for the first five users of your organization that's not part of the team's plan that's part of the free plan and in the majority of cases you really should be using terraform cloud as your remote back end even if you are an individual just because you know it makes experience so much better the only case that you might not want to use terraform cloud is if you have a very large company that's trying to meet particular regulatory requirements and it's not that terraform cloud does not meet them but sometimes there's just a long procurement process so in the meantime you'd have to use something like standard remote backend or atlantis or maybe you need to investigate terraform enterprise i do want to note that uh terraform cloud and terraform enterprise is the underlying software known as terraform platform it's not something you're going to ever have direct access to but just to clarify that terminology okay so what i want to do is just set you up with understanding the terraform life cycle this is not necessarily described in the documentation anywhere but it's something that is inherently known when you're working with terraform and it's definitely not inclusive of every single command that can be ran but the ones that you're going to counter most often so at the start you're going to be writing or updating your terraform configuration file okay and from there the first thing you'll want to do is initialize your projects and or if you need to pull the latest providers and modules you're going to use terraforming it to do that as well from there you're going to use plan so plan allows you to speculate what will change or generate a saved execution plan that you could use later on when you run plan validate happens automatically but you could also run this separately and ensures types and values are valid ensures the required attributes are present within your configuration file from there if everything is good you're going to execute your execution plan by running terraform apply uh you can also from this point use terror from apply to destroy infrastructure so if you have things set up there's actually a flag for it or you can use the alias the terraform destroy command and then you know as you work you're just going to keep updating your code and that is the terraform life cycle so you know hopefully this gives you kind of a a snapshot of what the workflow will be and i mean we'll be covering it tons and tons of times over in this course okay hey this is andrew brown from exam pro and we are taking a look at change automation but to understand that we need to first talk about change management so this is a standard approach to apply change and resolving conflicts brought about by change in the context of iac change management is the procedure that will be followed when resources are modified and applied via configuration scripts so what is change automation then it is a way of automatically creating a consistent systematic and predictable way of managing change requests via control and policies notice and i should have probably emphasized this is change requests saying i'm going to change these resources terraform uses change automation in the form of execution plans and resource graphs which will look at detail those two things in upcoming slides and apply review complex change sets so a change set is a collection of commits that represents changes made to a versioning repository and for iec uses change sets so you can see what has changed by who over time so when i say versioning repository that doesn't necessarily mean git uh and if you're using git ops i suppose you could consider your change sets being committed to that but something like cloud formation when you apply a change you actually have to accept a change set uh and so the virgin repository is part of aws and so you know terraform you just kind of accept it in place it's not necessarily on your local machine but it gets reflected in your state file okay so change automation allows you to know exactly what terraform will change and in what order avoiding many possible human errors a change automation is essential to any iac tool they all have it okay so there we go hey this is andrew brown from exam pro and we are taking a look at execution plans so this is a manual review of what will add change or destroy before you apply changes and so let's say you type in terraform apply it's not just going to go ahead and do that it's going to have you uh type in yes or accept the value but what you can do is see the resources or configuration settings that will be added change or destroyed and it will summarize them at the bottom and then you'll have to type something like yes in order to accept the changes okay something else i want to show you is that you can actually visualize your execution plans by using the terraform graph command and terraform will output a graphviz file you'll have to have graphviz installed but graphis is an open source tool for drawing graphs specified in the dot language scripts having the file name extension of gv so i believe this is cross platform it's open source but once it's installed in your machine you can run terraform graph and here this is linux so we're using a pipe to say okay pass it over to graphis which is dot and that is going to then create an svg file you can just open that in your browser and the idea is you're going to get this graph which kind of shows you the relationship of the resources uh here but we'll talk about the these relationships in the next slide here which is a resource graph okay let's take a look here at the resource graph so terraform builds a dependency graph from the terraform configurations and walks this graph to generate plans refresh state and more when you use terraform graph this is a visual representation or presentation of the dependency graph if you're wondering what a dependency graph is in mathematics it's a directed graph representing dependencies of several objects towards each other so it's pretty much like nodes with relationships between other nodes so that is one that i generated out from terraform and so there's a few different types here we have a resource node that represents a single resource a resource meta node represents a group of resources but does not represent any action on its own and provider configuration node so represents the time to fully configure a provider uh will you need to know this for the exam probably not do you need to know this in great detail probably not because there's a lot to the resource graph but the idea here is just kind of like terraform saying just so you know we're using a graph database and graph databases are very well suited for this kind of stuff and that's why terraform is very good at figuring out conflicts uh and things like that okay hey this is andrew brown from exam pro and we're taking a look at terraform use cases and the idea here is not necessarily because it's going to show up in the exam but the idea is to give you a business use case or to highlight the features as to why you'd want to be using terraform and the first one here is that it has exotic providers so terraform supports a variety of providers outside of gcp awesome azure and sometimes is the only provider terraform is open source and extendable so any api can be used to create iec tooling of any kind of cloud platform or technology so you can make your own provider there's some interesting ones that they have like heroku or even spotify playlists i have my own platform called teacher seat and i want to have iac um for my platform and so this is what i'm going to be using terraform for for multitier applications terraform by default makes it easy to divide large and complex applications into isolate configuration script modules you'll notice in this course that uh when you have a bunch of terraform files they're all treated as one so that makes it really easy to split up your uh your projects uh or your your infrastructure so it has a complexity advantage over cloud native ise tools for its flexibility while retaining simplicity over imperative tools then we have disposable environments this is not unique to terraform it's any kind of ise tool but easily stand up an environment for a software demo or a temporary developer environment resource schedulers so terraform is not just defined to infrastructure of cloud resources but can be used to set dynamic schedules for docker containers hadoop spark and other software tools you can provision your own scheduling grid on the last one here is multicloud deployment terraform is cloud agnostic and allows a single configuration to be used to manage multiple riders and to even handle crosscloud dependencies and that is a big deal uh and is a very unique offering to terraform okay let's take a look here at terraform core and terraform plugins so terraform is logically split into two main parts terraform core which uses remote procedure calls rpc to communicate with terraform plugins and terraform plugins so expose an implementation for a specific service or provisioner uh something that's interesting to know is just terraform core is written in go um you know you probably won't ever encounter it but it's just a fact okay and so here's the graphic that terraform uses to kind of like explain uh terraform core uh versus terraform plugins and how they all relate um so here's the terraform core and here are the plugins notice we have uh providers here which will cover provisioners uh and they're just this is the group for plugins overall um but yeah that's about it um will it show up in the exam probably not but it's good to understand from a top level view the split between these two things okay if you are new to terraform i just wanted you to be aware of an additional resource that you can use beyond this course which is called terraform up and running so it's a a book and it has a deep dive into the internal workings of terraform and this is really great if you want to go beyond this course beyond certification beyond the basics because what we'll do is teach you about testing with terraform cloud zero downtime deployment common terraform gotchas and compositions of production grade terraform code there's a lot more to it and this book in particular is written by jim who's the cofounder of grunt work and we do have a whole section just on grunt work um and the thing is i just wanted you to know about this resource you definitely don't need it to pass a certification or to have a good understanding or working of terraform but you know at some point if you want more i just want to point you to that resource okay there's one other resource i want you to check out for terraform this one is free and just online and it's the terraform best practices so it's an open book it's a get book uh so it's essentially a wiki and it basically covers the best practices that are being used in the industry and so this is stuff that is separate from the terraform documentation it's just good practices you know if you're going to be using terraform professionally within the industry so i just wanted to make you aware of this resource and to go check it out okay hey it's andrew brown from exam pro and it's time to begin our follow along for terraform and the first thing we need to do is actually install terraform so what i've done uh and this is in the terraform associate folder this will all be hosted on github so you can access it later but what we're going to have to do is make our way over to the hashicorp learn website to get to the tutorials terraform install cli because that's the first thing we're going to need and then once we make our way there we're going to need to choose our installation method so we have manual install homebrew os 10 chocolation on windows or linux so it's just going to vary based on your installation i'm not going to walk through them all but i'm going to definitely do the one that is for me so i'm on windows 10. it's very common to use the windows subsystem of linux and so the way i would go ahead and install this i would open up my terminal and vs code and by the way i recommend you probably follow with vs code through all these tutorials just because vs code has a very good extension for terraform okay but once we are there what we can do is make our way over here and because linux the linux variant i'm using is ubuntu um i can go ahead here and just go and start going through this process so we would grab the first url here and again it's going to vary based on how you want to install um so we'll go there and i already have it installed so i'm just installing it again all right after short wait that line finished there so we'll just proceed to the next so we'll grab the gpg key that's just going to verify that we are grabbing from who we say we're grabbing our code from so that takes two seconds we'll go ahead and this will go and uh add that repository so that we can install from there i believe this takes a second just as well okay that took a little bit more extra time there but no big deal and so now we are ready to actually install the cli so we can now do our sudo aptget install terraform so just copy and we'll go ahead and paste that in there after a short little wait there the installation is finished and so what i would just suggest is type in terraform to make sure the command works and then just type in terraform hyphen version and just see what version you are using as of this tutorial i'm using version 1.07 there's one other thing i want to get set up for installation here and that's going to be going over to the extensions in vs code and making sure that this extension is installed because it's going to give us a bunch of options here i don't know what they all are but i definitely know that it's going to start format and do a bunch of nice things for us okay so once you have those two things installed our installation step is over and what we can do is begin on the getting started section here okay all right so now that we have terraform installed we're ready to uh go through our first basic terraform tutorial and the idea is to try to touch a bit of everything going through a very basic workflow um and the reason i want to do this early on with you it's not important for you to know what all these things do and remember them because we're going to cover them multiple times throughout this course but just to give you kind of an endtoend experience so you have a point of reference because it's really hard to learn terraform because you have to kind of go back a lot to uh remember information okay so we'll just start at the top here and what i want to do is enter my getting started folder i'm going to make a new file called main.tf um the way terraform works is you can name them files whatever you want but generally the standard practices use main tf when you just have a single file or the entry point file but i'm pretty sure the terraform will read anything that starts with tf and treat all the files as one single file okay so once we have our main tf we're going to need to add ourselves a provider so what i'll do is make my way over to my browser here and i want to go to the terraform registry so just type in terraform registry and what we'll do here is go and look at providers and since we're going to start with aws we'll click that in the top left corner we have this use provider and we can just go ahead and grab this code okay and so we'll go ahead and paste that in and so now what you'll see here is we have this terraform block that is our terraform settings configuration we need to have a provider at least a single one and so we're using aws here notice that the source is hashicorp aws because this provider is provided by hashicorp not abs themselves but it is an official one so it is in pretty good shape okay uh notice the version is 03.580 um i don't know much about the versions in terms of how they matter um but i would just say you probably want to stay up to date to the latest okay uh so down below we have provider aws and this is where we're going to configure our additional options so this is where we would do like our aws credentials but before we do that let's go uh find whatever could we need to provision ourselves a virtual machine because that would probably be the easiest thing that we could do so what i want you to do is go back to the terraform registry and we'll click on the documentation because this is where we're going to find all our information for anything we want to provision okay so if we want to provision ec2 instance which is a virtual machine aws we'll expand that uh there and i know that it's called aws instance so i'm just going to scroll on down here and click on itabus instance and right away we have ourselves a a very easy example i'm just going to scroll down here and just see what else we have so this all looks okay but you know what i think that i'd rather go grab one from the terraform um tutorial here because i believe that they have a much nicer one here for aws so i'm just going to scroll on down here yeah this one's a lot simpler so what we'll do so just grab this code here and we'll make our way back okay and i think it's probably good to set our region so i'm going to do us east one because that's where i like to deploy things uh and for profile we can set it as default that's totally fine for now and so notice here we have a bus instance that's going to be the type of resource we want to provision which is an ec2 instance and then we're going to name it whatever you want app server my server i'm going to name it something else here tt micro is pretty standard this would be the name so i'm just say my server okay and then we need to get our ami i'm just going to clear that out so that's pretty much all it takes to set up a resource for aws but we're going to have to go get the ami instance and we're also going to need to go get our credentials so let's go do that next all right so what i've done here is i've logged into my aws account you are going to have to create your own abyss account and if you're looking for how to do that just go to the readme here and just go to aws and just go and create an account it doesn't take that long to do you will need a credit card that's just like with any cloud service provider you have to have a credit card to activate the account doesn't necessarily mean they're going to charge you anything but you know there's the possibility in the future that if you do use resources it's possible to uh have it spend okay so what i want to do is make my way over to iam and i'm going to go to users oops over here and i have a user here but what i'm going to do is go ahead and delete this user just because this is an old one for me i'm just going to start the process over and create a new one now this is considered a machine user because i'm never going to use this user to log into aws i'm only going to use it to generate out pragmatic keys so i'm typing my name in here andrew brown uh and if you wanted to you could really just type in terraform as well actually that's what i'm going to do i only want to give it pragmatic access so i generated an access id and secret um i'm going to give it admin access so what i've done here is i've created an admin rule but let's just make a new group we're going to call terraform and we're going to give admin access this gives you 100 access to all of aws uh if you are uncomfortable that you can try power user but um it used to be called power user anyway if we can't find it that way we can drop it down here and say um it must manage policies and there should be or there should be like role based ones here ah job functions there it is and so you know if admin access is too much you can do power user and that usually prevents people from creating users and groups uh so that might be more uh or or less of a problem but i just want everything to work for this tutorial so i'm gonna do what everybody does and we're gonna give admin access okay and so now we have that new group um it says no policies are attached not sure why maybe i forgot to attach them so i'll just go back in here oh no it's there okay not sure why i didn't say it was there but we'll go back and i'll just check box on terraform i guess it needed a refresher i will just hit next next create user and so now i have an access id in secret so this is going to vanish after i leave this page so i want to leave it open and what i'll do is go down below here i'm going to open up my um aws credentials so i'm not sure how to open this in uh vs code so i'm just going to type in buy or vim and i'm going to go to tilde that's your home directory forward slash dot aws and this is going to be in credentials okay and so here i can add that so we want to have a default profile so i'll make square braces type in default um and then i need to put in these keys so i don't remember i mean should be just like aws you know key something but i always forget what it is so what we'll do is just look it up say it was credentials and it should just tell us here there they are so this is generally what we're looking for so i'll just copy that and i'm going to go ahead and paste that in there and i'll just clear out these keys because these are not my real keys i also like setting the region here so i'm just going to set it to us east one that is the uh the default region for aws and has the most stuff well technically your default region is going to be whatever's near you but that's where all new services are launched so we're not going to run into any problems if we use usc 1 and i'll go ahead and grab my key okay and we will go ahead and paste that in and i will go ahead and grab this secret okay and we'll paste that in and i'm just going to double check if that ends actually with a tilde i don't think it does i think i introduced that by accident so i'll just delete that out and just double check because once you leave this page you're not going to see it again so a k i e p m k one that is for me and of course don't ever show these to anybody um for me i will i will be uh regenerating these so uh by the time this is published you won't have these and you can't compromise my sandbox account which wouldn't be a big deal anyway so i'm just going to go ahead and save this file and probably be smart to have the aws cli installed so if you're wondering about that able cli i already have it installed on this machine but let's go take a look um and see how it gets installed oh this looks like something new developer preview it with shell that looks cool about cli install oh it's over here so download unzip and then run the linux installer so if we wanted to do for linux i'd go in here and i would just go ahead and start grabbing this stuff so we'll just go and curl that file it's probably a good idea to install the cli here after a short wait that finished there so we'll go grab the next line here which is to unzip it all right so after waiting a little while there it finally unzipped and so we can go ahead and run the last command which is pseudo period aws install and so that shouldn't take too long okay and so here it's just saying found preexisting cli because i already have it please rerun install script with the update flag so you would not have to do this but i'm going to do this because you know i'm just trying to get it up to date so that i'm on the latest while doing this tutorial with you i'll just give it a second to see if it executes there i think we'll just wait okay great so now it is using the latest so if i just type in a bus version i have uh 2.2.38 what i will also do is just go ahead and delete this uh zip here that it placed in my directory and also this aws directory just to make sure that it's working if i delete it just assuming that it didn't install it in this directory here and it's i mean it does say it's in user local bin but just as a sanity check there okay so we'll type in version again okay great and so now what we'll do is just type in aws s3 list just to see if there's anything there um so it has an issue let's just type in adris i think it's ada's credentials to authenticate i haven't done it in a while so let's just take a look at what we can do to check that out because we did set up the credentials file but sometimes sometimes you might have to run a command here so i'm just going to find that okay i'll be back in a second all right so i didn't have to look far i just went to configuring to configuration basis it's aws configure not credentials i'm not configuring new cli's all the time here so what we'll do is just type in database configure and so here it has that key i still have my uh my im open here so i e so that is correct and then that is forward slash y h that looks correct default region is uscs um default output you know json sounds good to me so uh you know if i do it list that should work because the signature you provided does not match check your signing method so just give me a second figure that out okay all right so i just tried another command that i know that should just work and it's just saying that they're not valid at access credentials so if it's having problems with those then that generally means that we need to go and fix our credentials so maybe there's like a hidden character we pasted by accident or something you might not be having this problem but i'm just going to go ahead and double check so what i'll do is go back over here and i'm going to go back to my users or i am and we will go to users and we will go into terraform here and we will go to our security credentials i'm going to delete those ones you have to deactivate them first and then i'm going to delete it and we'll create new ones we'll give this another go it really likes to put that tilde in there and that uh doesn't end with a one so you're saying i'm getting like weird characters as i do this but just double check to make sure they are correct ak the start eu on the end okay this is default that looks correct to me the region looks fine to me so we'll go ahead and quit this and we will try this again great and so it works and i do have a few uh s3 buckets there uh prior in the sandbox here so you might not might not get anything but as long as you're not getting the error that's saying does not match signature or validation doesn't work so now that's all set up if we go back to main tf that means that this here is going to use the default profile so that's going to make it easy so the last thing we need to do to set up this virtual machine is provided an ami and the reason why is that an ami is a required field so what i want to do is just go back over to the documentation here and if you scroll on down to attribute references you can see uh what is required so um well ami should be required i guess the only thing that's required is the instance type here maybe uh am i in it yeah i am so i might have went too far down here oh instant type is optional huh off they're both optional okay maybe it's just like one or the other but i think that if we didn't have the ami there we probably run into an issue so let's go ahead and make our way over to ec2 and we're going to go ahead and grab ourselves that ami id so we'll go and make sure we're in north virginia which is usc 1 we'll go ahead and launch a new instance and i want the amazon linux 2 so i'm going to go ahead and grab this x 68 ami ami id and it's really important that you watch which region you're in because different regions these ids are going to be different okay so again go ahead there and save that and so technically we should be ready to be able to do a plan and apply to provision this but before we do that there's a couple things that we should do which is to try out doing format and validate okay before we do format and validate what i want to do is actually initialize this project so go up and create yourselves a new terminal if it's closed or not so i actually have two open here so i'll just close the other one and i'm just going to type in clear here and what i want to do is type in terraform init and before i do that i just want to show you that right now there's only main tf in here and so if i hit enter it's going to say terraform initialize an empty directory oh you know what i did it in the terraform associate by accident so we're going to go into getting started here and typing clear and type in terraform and it again and so what it's going to do it's going to pull whatever providers and modules are defined so all we have is a aws provider so that is what it's pulling right now so i'll just give that a bit of time to do that okay all right so after a short little wait there you'll notice that we have this dot terraform directory and we also have this terraform lock hcl so this is a dependency lock file it's going to tell us uh what version of modules or providers that we are using um so because in the main tf you know we have 3.580 so that's going to match exactly that but if we said something like greater than or equals to this could be a different version right so whatever version is set here it's going to make sure that it stays with that version as long as we're not changing it okay so there's that if we open up the terraform file this has information about our provider so the provider is actually downloaded here and this is a binary file so there's not there's not anything to look at when we open it up okay so now that init is done what i want to do is go ahead and show you format and validate okay all right let's take a look here at format and validate so format is just a way of making the files syntax consistent and this is going to really help you reduce arguments within your team because there's only gonna be one way to write a terraform file and if you don't write it the the way to the standard format is going to correct it or complain about it okay so one thing we can do is change the indentation level here uh and what i'll do is run and run terraform format and notice that it fixed the indentation so that's all there really is to it it's just dealing with the uh styling of the actual file um i'm not sure if it would do anything for double lines let's see if that would take it out i'm not sure it doesn't so you know it's pretty much just indentation and a few other things besides indentation i don't know what else it would do then you have terraform validate and this is really useful to make sure that you have particular fields required so i'm going to go ahead and comment these out i'm going to type in terraform validate and it's going to tell me if my file is valid and it's saying here missing required so it wants an aws instance to have a instance type or launch template right so remember it said it was optional but one or the other is required so if we add this back in okay and type in validate we'll see if it works and now it's saying if you specify an instance type you have to also have an ami so we'll take that out there and type in validate okay another thing i want to show you is let's imagine that we just specified an ami that doesn't exist something like uh this doesn't exist i just want to show you what validate will do and what it will not do so we type in terraform validate that says it's valid because it's checking you know do you have the required attributes and is it the right type so this is a string but it doesn't know the contents of that string whether this is actually a valid one and doesn't match up to usc's one so just consider that validate doesn't take care of everything for you okay so yeah that's all there is to format and validate and so we'll move on to actually setting up a plan okay all right so now what i want you to do is just give yourself a lot of room in your terminal and type in terraform plan and what this is going to do it's going to generate a speculative plan of what it would deploy and so if we just scroll the top here uh what you're going to notice here is going to say this is what it's going to create so see the green plus sign and it's saying we're going to create a new aws instance or resource here and this is all the configurations that we're adding to it and down below it's going to say one added zero change zero destroy and so it's speculative in the sense that it's not generating out a a plan you can actually generate the plan to be used by a terraform apply so notice it says hyphen out option to save this plan so you know we don't need to generally save out our plans but that is an option if we want to do that for some pragmatic use but now that plan has been shown here and we're happy with it what we can do is go ahead and type in terror from apply and it's going to do the exact same thing it's going to show us a speculative plan um exactly the same thing so it's running basically terraform plan and then we're going to review it and if we're happy with it we're going to write the word yes okay and so what that's going to do it's going to go ahead and start creating uh some uh some adress infrastructure there and in particular it's just a single ableist instance so if we make our way over to aws and we go to ec2 okay i can just close these other tabs here uh you'll notice that we have the server and it's starting to spin up but if you're familiar with aws you're probably also familiar with cloud formation cloudformation is what uh aws uses for infrastructure as code it's their native tooling for it i just want to show you that there are no stacks like these are for aurora serverless i just couldn't delete them out but notice that there is no underlying stack the terraform is setting up so terraform is responsible for managing the state and uh it's not using cloud formation underneath just so you're aware if we make our way back here it says that it is uh completed provisioning okay and so what we'll do is make our way over here and give it a refresh and notice that uh even though it says that it's complete it technically isn't because the status checks aren't done so if you use cloud formation it would not be considered done until we had a status check one and two um i'm sure there's some way to check that with terraform to consider it actually complete i'm not really sure at this point in time how to do that but i'm just pointing that out okay so we'll just wait here for this to complete to move on to the next step okay all right so after a long wait there our two statistics are complete so what i want to show you is how we would go and update that infrastructure okay because uh you know in the course we say that um infrastructure code is independent meaning that if you define something you know like a resource and you run this again it's not going to create an additional resource it's just going to only have what you define which is you expect there to be this single resource here so what i'm going to do is just change the c2 micro to a t2 nano and then we'll go down below and type in terraform apply and we're just waiting for it to refresh the state and by the way any time you run terraform plan or terraform apply it actually runs validate every single time so you don't have to run terraform validate you can just do it as part of your terraform plan or if you're doing tearful reply you'll it'll be it'll also run there as well okay so notice this time we get this little uh tilde squiggly here and it's showing what it's going to change and so this is doing an update in place or um yep and so that means that yeah update in place and so that means that it's not going to destroy and recreate that instance it's just going to keep it in place and modify it so we'll go ahead and type in yes and we'll let that perform there and so if we just make our way back over here it should show us that we have a t2 micro and so if i refresh here and we take a look here shouldn't take too long and it is stopping the instance okay but it's not destroying it okay all right so after a short little wait there it's now a t2 nano coming back over here you can see that it's still a lapsing time it's checking to make sure that it's possible probably because it's in the initializing state and uh yeah there we go so now it is complete but you know like just because it says update in place doesn't mean that your instance or your service is not going to be interrupted uh so that's another consideration uh that updating place does not mean that there's no interruption of service okay um yep all right so um we were able to change the parameter of t2 nano but let's imagine that we wanted to make that a little bit more configurable so that we could provide a instance type uh pragmatically via a variable uh so so we'll do next so what i want you to do is make your way back over here to your main.tf and what we're going to do is define ourselves a new variable uh so it's like variable t2 oops sorry instance type and just to look it up in the documentation we'll just type in variable terraform i'm just trying to show you where you can find this stuff very easily so if we scroll on down notice here that we need to define a type so this is just going to be a string so we'll go ahead and grab that okay and we can just make that a type string and then when we want to reference this what we do is just type in var and then the name of the variable name which is instance type and so instead of setting it um you know through here what we can do is we can create like a tfrs files or we can provide it as a a flag so what i'll do first i'll just do a plan to just show you how we can do it a few different ways but i'm going to type in var and i'm going to put the name of the the variable so it's like instance type equals and i think i do double quotations here t2 micro and we'll see what we get as a plan here okay so notice that it's using the t2 micro i could do this at like with a medium as well here okay so that's just one way of changing it another thing we can do is create ourselves a terraform.tf vars file that allows us to set a bunch of variables so i'm going to go ahead and do that so what we'll do is just create a new file here until type in terraform dot tf vars and we'll say instance type equals t2 large again i'm not going to execute this i just want to show you in the plan that's going to show up okay and see that says a t2 large so i'm going to go back here and just change this to a t2 t2 micro because that's what's on the free tier for aws tt nano even though it's smaller and more inexpensive it's not so if you are in the free tier i want to keep you in that so you save any money or have no spend uh notice over here on the left hand side that we have this tf state file this has been generated out and notice that it's version four because every time we've ran this it has a new iteration okay and this is basically defining the current state of our infrastructure so if you go through here notice that it says type aws instance my server what provider it's using what its schema version is the ami here the reference to the ami and all the properties and these are all the properties we basically saw here uh like if we scroll up notice all these things here they're pretty much all defined in here exactly how it's going to be defined you aren't ever supposed to manually modify this file but it is something visible you can look at and when we do deploy it is going to show us the a backup here so if we if we ever happen to lose our tf state file or we want to go uh we can always grab that backup file okay um but uh yeah so what i want to do here is now that i have that tfr is in place i'm just going to go ahead and actually run apply and actually i'm going to run plan first sorry so let's see this is t2 micro okay it says t2 micro and what we can do is just do terraform apply and this time we're just going to do hyphen auto approve you probably really want to do this but if you just want to skip that yes process you're like you know it's going to be fine you can use the auto approved flag to do that okay so serious is the tt micro and it's just starting to modify it okay so uh now that we've done that i guess we'll take a look at locals here but we'll just let this finish updating and then we'll move on to that okay all right so now let's take a look at local values which seems very similar locals which seems very similar to variables but it's slightly different so what i'm going to do actually it's right here in the documentation so we'll go down to local values and this is kind of a way to dry up your code and so if i just go grab this block here it's different from variables because you know they generally are hard coded but i go to here and say locals and then if i had like a generic name i could say name and i could just say you know andrew or yeah andrew is fine just say project name and so if i wanted to use that somewhere else if it says my server i could uh use enter string interpolation i believe it's this yep and if we have locals it's just going to be local dot project underscore name okay and so now if i just do a terraform plan oops i have to type it right in uh whoops let's do uh terraform validate i think i'm using the syntax incorrectly local is not a valid template control keyword um it should be because if we go back over here yeah see how it's referencing is local and that's exactly what i'm doing it's just that i'm using interpolation and i might be using it incorrectly so what we'll do is make our way over to template strings terraform and if we go down here we have interpolation so i want the one that is for literals oh yeah this is for directives and so we want interpolation so it's a dollar sign just to show you like i've done this whole course i've passed the exam i've used terraform and i i can't remember so it's not a big deal if you have to look things up okay so type in tariff or validate here to see if that is correct good and so if we do terraform plan okay now you'll see that our tag would change over to that so that's basically what locals are it's just like a way of having some local variables that are in line with your code okay let's take a look at outputs so i'm going to go back to terraform here and i think it's actually right here but yeah variables and outputs and we'll go output values and this is just a way to get an outputted value and this is actually a really good example where we might want the private id or the public id so we'll scroll on down below here and this has its own section so we'll paste that there and this is private id and that is fine but i might want to get something a little bit more fun so we'll go here and just kind of see what we can get so we saw private id ip um argument reference right so we have private id maybe we want public id here public id ip oops yeah so let's give that a go instead i think i'd prefer to get the public ip because this is it is a publicfacing server okay and notice that this is not the name right name we're gonna have to call this my server right and so outputs is gonna allow us to uh see those values so what we'll do uh i'm gonna run terraform plan and see if there is any required change i'm not sure if we have to deploy to get that output working so we'll just run here from plan first and notice it says changes to outputs and then it adds this as a plus so if i was to type in terraform outputs there is commands for this i don't seem to remember off the top of my head so we'll just look at it up here really quickly output uh here it is so oh it's terraform output okay sorry it's not the plural so we'll go here and type in terraform output i just want to see if it'll actually output it without us doing it so it says warning no outputs found so what we'll have to do so the state file either has no outputs defined or all the defined outputs are empty please define and open your configuration with output or run terraform refresh to become available so we don't need to run terraform apply i don't think we probably just run terraform refresh so let's give that a go and see what happens whoops might be a good example of using terraform refresh terraform refresh is a command that is going to make the state file match whatever the the remote instance is so we already have an instance up there and so that's what it did it's probably a better example to use output so now if we type in terraform output we should be able to get that value there only if you type it right though okay so there it is and if we really want it to be in particular we could say instance ip address i really don't like the name of that i might just change this here so we'll just say um public ip okay i'm not sure if we can just change on the fly there let's see what happens if we do that yeah see it's still the old one so in that case i'll just type in terraform refresh and see what happens okay and notice the old one is still there so i think in that case we'd have to do because this doesn't exist in our output files anymore so i think it because refresh just adds i don't think it's going to remove anything uh well actually it would if the server was gone it would do that so but anyway if we type in terraform outputs we get do we get both of them we do and so in that case i think we would want to do a terraform plan and see if there's any differences here yeah notice it's going to remove it there and so then that's how we'd have to get rid of it so we just say terraform apply and we'll just say yes and that's our opportunity to update our tags and also get rid of this output so you can see refresh doesn't work in all cases and so now if we type in terraform output you should get a list there i just want to say like public id just to get the exact one there uh ip okay cool so that that works great so that's outputs so we've seen providers let's go take a look at modules so what i want you to do is go back to the internet here and i want to go back to the terraform registry in this case i want to go grab some modules so providers uh you know providers are basically onetoone mappings to the underlining api so like anything in cloud formation is pretty much mapped up here and modules are basically um they're like conveniences because they allow you to configure a bunch of resources using a more uh short form dsl okay so like if we open up here the vpc this is a very easy way for us to define an entire vpc without having to create like each of these resources individually so we had to do this by hand to be a lot of work so we'll do is go ahead and copy this and we're just going to expand this a little bit here that's a bit hard because my fonts are really large but you know of course you'd probably be using a smaller font and so what i want you to notice that it starts with a module block and we're providing it a source so terraform aws modules vpc aws and that's how it knows to map over to this one over here on the terraform registry and this is just defining a new vpc as long as we don't have any conflicts with this block it should deploy no problem so i'm going to go ahead and give that a go so we'll just type in terraform apply or plan and actually before we even do a terraform planner apply notice that the module isn't installed so this is where we'd have to type our terraform in it and that's going to go ahead and grab that module great and so once we have that we can now do our terraform plan and we'll give it a moment here and notice that it's going to generate a lot of stuff out that's fine so we will say terraform apply i just want to auto approve that save myself some trouble that's going to go set us us up a um a module i want to point out that actually uh when you're writing files out here and we're going to find this later in the course that even even when you write a single file like main tf you are creating yourself a terraform module because everything is based off of modules so you'll see that later on in the course but we'll just wait here until this is uh finished here okay so after a short little wait there i actually ran into an issue um here so i probably i was a bit too too quick to just copy this over because it is having some issues i think it's because our provider is in us east one and we're trying to specify something in u.s west so that's probably our problem so or this is actually europe which is no surprise because anton who made this is actually over in europe so it makes sense that he might set it to that so i'm going to do u.s east uh here right and so that's something that you have to understand that if you have a provider it's going to be mapped to that one actually if we wanted to keep it in uh er eu west this is a great opportunity to kind of show you how to make another provider as a reference so i'm just going to go here and paste this in and we'll change this to eu west was it one or two it's one and so in here what we can do is set ourselves up an alias okay and we could just say like this is called uh you uh we'll just say this this is eu or a to you and i actually might not remember how to do this exactly so i'm going to just type in terraform resource alias because that's what this is called it's a meta argument google europe okay so i just wanted to know if i had to type in google or something like that in front of it so if we make our way back over here and we go back to the top here we don't need to put the word adabas that's just redundant so we'll just say eu and if we go down to our vpc here and type in provider we'll say aws eu okay and so that should allow us to have both i'm not sure if we have to run terraforming it so we'll run tear from plan first it might say hey you got to run terraform in it maybe an argument provider is not expected here let's just make our way back over here oh because that's the within the resource and i put it in the module block so we'll just cut that out here and it doesn't uh doesn't have that so actually i wonder how you'd set a provider for module maybe you don't i'll be back here in a second okay all right so i just pulled up the documentation here and here's a module and it has this little provider's block so let's give that a go and see if that fixes their problem here so i'll just paste this in providers aws and we'll say eu okay and see if that works you know again it's not hard like if you get stuck you pretty much google anything and so that did not error out and so if i was to do a terraform apply auto approve that should work and so i'll see you back here in a bit okay all right so i have one little uh error here i actually typed in uh eu as uh instead of us there and so again my point is is that terraform validates not going to catch these things you're only going to find these uh when you actually run them so we'll run this one more time and i think it's going to work and i'll see you back here when this module is finished deploying okay all right so after waiting there it looks like our vpc is ready so if we make our way over to aws go to vpcs of course this is in the european region there so what we'll have to do is just switch over there in a moment but i just want to show you that it's not here but if we go over and find eu west one which is apparently ireland uh there it is so there's my vpc the one we created there okay so yeah what we'll do next is we'll just kind of break up these files and make things a little bit easier to work with okay all right so let's make it a little bit easier to work with our terraform file here and what's really nice is that you know we have this main tf but anything that's named.tf is going to be treated as a single file and so it's pretty common to break these up into individual files here so what i'm going to do is call this one providers dot tf and i found out that you can only have one terraform block and one required provider block so if you're thinking about making like uh one for each provider and then the resources within it that's just not possible so we'll name that there um and i guess we'll bring these over as well probably a good idea to do that okay and we have a variable pretty common to make a variables.tf so we'll say variables.tf here and we'll grab our single one there okay and uh so if we wanted to oh yeah probably in outputs would be good too so we'll say a new file here we'll say outputs.tf and i think when we get to module development i'm pretty sure this is like the standard if i just it's in my slides here we'll say like uh modules if i go over to that there for a second yeah it's in this section here but yeah when we get over to this yeah it's pretty common to have an outputs a variables a main okay and so we'll put our output there you know the rest is up to you so we can leave this in maine or we could try and take this and put this into one called aws resources maybe that's what i'll do i'll just rename this to aws okay and maybe we'll just keep a main around and i'm not sure if locals is i mean it treats it as one file so it must work that way but i'm just go ahead and paste that in there i was thinking maybe it's like bound to the file but it's probably just bound to the module and so i just want to make sure that this all works i'm going to do terraform plan here and see what happens here i'm just seeing if there's gonna be any kind of errors or just in general what are we gonna see uh no changes so it read all the files no problem so this is all good to go but yeah you can break it up however you like it's it's that easy okay okay so so far uh you know we said all this infrastructure but what if we wanted to go ahead and destroy it so what we could do is type in terraform uh apply and i think it's destroy i can't remember the flag off the top of my head so let's go take a look here just type in terraform apply and go down to our flags and it is called should be in here destroy oh it's not showing it i know that this flag exists so we'll go over here i just want to show you uh how that flag works maybe it's like terraform destroy probably better example here well um i know that there's a another flag that we can write here it's like destroy delete well that's fine because you're not really ever going to be doing it that way you're always going to be writing terraform destroy so that's what we're going to do you know what maybe it's under the plan that i'm thinking of terraform plan because maybe you make it in the plan and then it gets moved along yeah destroy mode here it is so i want you to understand that um you know that's how it would set it so active destroy mode using hyphen destroy so i think when you use plan or apply we could have done hyphen destroy and that is equivalent to this destroy command so i'll clear it out i'm just going to try that there destroy because i just want to show you that that's an alias of destroy okay or of apply and yep so that would destroy all of our resources and so i don't think it's really essential to show you that but i just wanted to show you how you'd run the terraform destroy command and that would tear down all your infrastructure okay but i want to keep it up because we're going to move this infrastructure over to terraform cloud and then we'll do a destroy soon enough okay all right so now that we have successfully created a resource organized their files learned the basics of getting started up to you know this point the next thing is to create a terraform cloud workspace and migrate our local backend to our remote workspace and the reason we want to do this is because we have this terraform dot tf state file and this is what contains all of our information about the state of our infrastructure and if we want to collaborate with other people we need to have it in shared space and so terraform cloud is one of the options and i would say the best option out there and so i want to show you how to use terraform cloud which by the way is free um and so before we do that i just want to show you uh uh what workspace we're in so if you type in terraform workspace list what you're going to see is a single workspace called default so this is a special workspace which every project comes with a default workspace and you cannot delete it so here you could create multiple workspaces like development production to have different variables for your infrastructure if you're deploying to different um uh different environments but for the purpose of getting started we're just going to work with the default but the thing is right now these day files are here locally and so what we need to do is define a back end and so far uh the back end that we're using is the local back end and that would be defined we had put it in our um providers probably been smarter to just call this like terraform this is the main you know this is what i'm going to do i'm going to take this here cut this and i'm going to put this in main because i think it makes more sense over here there's not like a true science to putting things places you're just going to have to feel them out so in this terraform settings block this is where we would specify our back end okay and so right now we are using local whether you specified or not you are okay and so we want to swap that out to remote which will use terraform cloud so what i will do is we'll just say terraform local migrate uh because they have a nice tutorial here for this but i just want the code from it so this is pretty close to what we want this is for multiple workspaces we're just doing local so this is what i want okay so what i'm going to do whoops is just bring this back on over and i just want to copy this interior part and it doesn't matter if you put it above or below providers but we'll have a back end we're going to specify the hostname we're going to need to set our organization and we're going to need to set our workspace name so now what we're going to do is make our way over to terraform dot io and what i want you to do is create yourself a new account it does not require a credit card or anything it's very easy to set up you just have to confirm your email and then once you have done that go ahead and sign in and what you'll need to do is create yourself an organization it'll probably prompt you right away so it's very easy just go here and give your organization name and provide an email it's pretty much those two options and once you have your organization you can go ahead and start creating workspaces and so i'm going to create a new workspace here and we're going to be presented with three options version control workflow cli driven workflow api driven workflow version control workflow is let's say every time we push to commit to our repository then it would trigger to do a terraform apply to execute the code but we don't want to do that we just want to use the cli which is what we've been doing all along so here i'm just going to say terraform um terraform example well maybe i'll just say getting started here actually getting started and we will go ahead and create this workspace and now that we have the name of the workspace and the organization so we'll put those in here so my workspace is called getting started and i just want to make sure i have the right name for this organization here i think it just would be called whatever it is so for mine it looks like it's just called exam pro i think you'd match it whatever's up here or okay it doesn't work we'll find out in a second though so we will paste that in there and so all we need to do to move from our local to a remote is type in terraform init to migrate it over and actually we probably need to log in first so before we do that well i can't stop it that's fine um so i'm just going to say no i don't want to migrate just yet so i'm going to type in terraform login first because we want to authenticate with terraform cloud so i've already done this previously so it already has a file saved over here okay but what i'm going to do i'm just going to delete mine you don't have to do this i'm just going to delete mine so you you can see a similar experience okay so i do terraform login and it's going to say if successful terraform will store in plain text in this area do you want to do this say yes and all this is doing is generating out an api token for a user so it's going over here and choose the description to help identify the token later and this is just for pro let's just say like terraform associate maybe because we're actually creating the token okay so your token we can copy it out um click on the token to copy and paste it into your terraform login prompt to continue so i'll hit copy and we will go back to terraform here and then we will paste in the value i know you couldn't see it but i definitely pasted it in and so it's now been pasted in there i'm going to go back here and hit done and i'm going to go ahead and delete my old tokens this is the one i made a month ago so i'll go ahead and delete that and again you don't want to share these tokens with anybody just make sure um you know you keep those secret because then they'll have access to your terraform account so now that we have that ready to go it's actually kind of cool to have a little getting started project here i didn't even notice about it but uh so now what we can do is type in terraformingnet because now that we have a local api key and it's just going to say hey you have a preexisting state that was found while migrating the previous local backend to the newly configured remote no existing state was found in the newly configured remote backend do you want to copy the state to the remote backend before we do that i just want to go over to our workspace and click into it just to show you that we have nothing under runs nothing under states nothing under variables there's nothing in there okay and so what i'm going to do here is just type yes and that's going to take the terraform state file and move it to your workspace so it's finished that was pretty quick so what i'm going to do is go back over here and we're going to just click on here and refresh it looks like we also have the instructions here which we could do so if we go over to states here is our state file so we open it up and it's all the same contents of the terraform.tf state so what we can do now is go over here and we can go ahead and delete this normally you wouldn't want to delete your backup but i just want to see if when we run terraform apply if it'll actually produce another backup backup locally here okay and so now that we have our infrastructure there all we could all we need to do is now run terraform apply so that's what i'm going to do next i'm going to go here and type in tara from apply and we'll see what it changes like there's no infrastructure changes so nothing should change but let's see what happens the fact that we moved our remote state over okay so right away it say it says no value for required variable so the thing is we have it set in our tf bars over here but the problem is is that the workspace does not have it because what's going to be running terraform is actually a run environment there's actually a server that's part of terraform cloud that executes your code and so these variables are on a local machine there's no way for them to get up there so we have to go set them under variables we have two options here so there's terraform variables so these are settings used as the terraform.tfrs to use a nonstring variable okay and then we have environment variables so we have two different ways to set it the way i'm going to set it is a terraform variable so we have a key and a value this is generally how you'd want to do it so we have our instance type so we will go and put the name in there and this is going to be a t2 micro okay and i'm just simply copying them over notice over here we have a checkbox for hcl so parse the field as the hcl language that's if we wanted to do something a bit more advanced mark it as sensitive if we need to and that's not something to do so this is going to be the size and this is optional but i'm just putting it the size of the ec2 instance okay and we'll go ahead and set that variable great and so what we'll do is now try to run this again so now it's saying um it's not saying no credential provider so no val providers in the chain and so we did specify in our providers that we want to use our profile default but the problem is is that this is not going to work for this is not going to work for our our workspace here because we actually have to set it in here in the environment variables so what i'm going to do is just go look up the terraform provider oh sorry so we'll go to terraform provider aws i want to do this on the registry and what we'll do is try to look for authentication um i'm just making sure that this is what this says github so if you just click back here in the top left corner go to providers go to aws go to documentation usually in the beginning they'll have like information in the guides that explain like how to configure it and so that's what i'm just looking for here maybe just click on aws provider so yeah here's the section on authentication so he would say like access key access a secret secret key but what we want to do is set these environment variables because that's the way we're going to have to do with terraform cloud so we'll do is go here and specify this key here so we'll say aws access key id and we're gonna have to go get those credentials so i'm gonna just type in by aws credentials and there's my key so let's go ahead and copy that again that's secret don't ever share it with anybody and this is definitely sensitive so we're going to mark that as sensitive and we'll save that and the other one's going to be called aws secret access key just making sure i spelt that right i'm just looking off screen here to see if i spelt it right and we'll go ahead and copy that paste that in just make sure there's no uh trailing spaces we're going to say that is also sensitive we also want the region so aws default region and i'm going to set mine as us east one that's not sensitive it's not a big deal and so this should give us enough to be able to execute that command now again there is no new infrastructure to create but just to get it to run is what we're trying to do here i'm just going to write and quit and we will try terraform apply again and now see if we get better luck this time around okay great so notice it says no changes your infrastructure matches the configuration so there hasn't been anything that has changed so what i'm going to do is i'm just going to do a terraform destroy because i want to tear this all down and then i want to maybe change uh the variable within terraform cloud and we'll do terraform apply just to make sure that it does work with terraform cloud and indeed we aren't losing our old state file okay so yeah again i just ran here from destroy for real and i said yes so we're just going to wait a while here until all the infrastructure is destroyed and i'll see you back here in a moment okay all right so it took a little bit time to actually just generate out the uh delete plan so i'm just going to go ahead and type yes and that should proceed to destroy all the resources we'll just give it a moment here there we go and so it's deleting everything so i'll see you back here when this is complete okay all right so now that we destroyed our infrastructure what i want to do is just go ahead to our a to bus one here i just want to comment out the module for the time being just because we do not need it uh there are three types of comments in terraform i believe we have this one so we have this is the like javascript multiline one but you could also be doing this or this it's up to you and so what we'll do now is do a terraform apply and we'll notice that it's just going to provision that ec2 instance so i'm just waiting for it to show me the option yes there we go so we'll type in yes and i'm going to go back to terraform cloud wherever i put it so i might have to go back to terraform.io here i might have closed it on my own okay so here you can see that it's applying right now we can even see it as it's running so it did the plan over here and now it's doing the apply i could even cancel it from here if i really wanted to i just want to show you that you have your previous states here so every time you do a deploy it's going to store a state file so it's technically versioned notice that if we open up our backups there's no longer a terraform backup file i suppose there's really no need for one because if we have all these states in here these are technically our backups so in the slides i might contradict that and say that the file remains but apparently it does not okay and i'll see you here when this is done okay all right so after a short little wait there it says it's complete again we'll just go over here to our overview we'll see that it has been applied we can see the resources under here and so this is our aws resource we can even see our outputs as well and that's pretty much all i wanted to cover in the getting started so now it's all just about clean up so what i want you to do is go back here and we're going to go type in terraform destroy to tear down all this infrastructure which is a single server right now and actually i'm just going to oops i'm trying to stop it here i want to do i think we can do auto proof here auto approve and actually if we wanted to do it the other way we do destroy auto approve and i'll see you back here in a moment when this infrastructure has been destroyed okay all right so this is finished destroying our infrastructure so now what i'm going to do is just go back to my workspace here and i just want to go ahead and delete it so we'll go down below and we'll delete this terraform cloud workspace so i will type in uh the name of it so this would be getting started like you can keep it around it's not a big deal also notice that it allowed destroy plan so when enabled the setting allows the destroy plan okay so that's just a way of disabling it um so we'll say getting started great and so now that workspace is gone and so we are done are you first getting started we can get back to the main course hey this is andrew brown from exam pro and we are taking a look at terraform provisioners so provisioners install software edit files and provision machines created with terraform and terraform allows you to work with two different provisioners we have cloud in it and packer so cloud init is an industry standard for crossplatform cloud instance initialization when you launch a vm on a cloud service provider you'll provide either a yaml or bash script uh and so for the case of aws what you'll have is this box called user data and so you can either put your yaml or bash script in there it's the same if you're using google or azure they both have this box it might just not be called user data but that is using cloud init underneath then you have packer this is an automated image builder service you provide a configuration file to create and provision the machine image and the image is then delivered to repository for use if you've ever heard of ec2 image builder it's a very similar service except that one's just for aws i suppose for google you could use google cloud run and even on database you could use um code build but packer is great because it's cloud agnostic so you're going to just build the image and then you can deliver it to any provider provisioners should be used as a last resort for the mo for more common situations there are better alternatives this is a warning that hashnote puts out in their terraform provisioner section and so i wasn't really sure why they were saying this so i reached out to anton and anton uh if you don't know him he's an abe's community hero just like myself and so he specializes in terraform like he wrote so many modules for the terraform aws so he knows it pretty well and he says here the main reason is that provisioners will do something that won't be reflected in the terraform state and the better alternative for that one is to use cloud provider features like cloud init scripts i think this comes back to immutability when we're looking at uh the fact that we want to um lean towards doing an approach with packer right we want to um bake our baker machines or virtual machines and then deploy because that's going to be probably the better alternative so if we wanted to use cloud init uh the idea is we'd have to provide a cloudant yaml file which is a a very particular format you can find them on the cloudant website uh and the idea here is we have these run commands so let's just like bash commands here to start and stop apache we can install our packages here do an update do an upgrade we'll have to pass along our ssh key here that's a very important component to that once we have that file configured we can reference it as a template file over here call it user data and then we're going to pass it on to this section here for user data so that when we launch up this vm and this one in particular is for aws that's going to pass it to that user data okay now you might be asking well where's all these other provisioners because there's a lot of other tools out there so terraform used to directly support thirdparty provisioning tools in the terraform language but they were deprecated uh because it was considered to be poor practice suggesting better alternatives as we were just talking about so you might be asking where is chef where is puppet where is salt and the thing is is that you can technically still use chef and puppet through cloudinet because cloudnit actually supports uh some dsls in there i've never used this before myself but it doesn't look too complicated but the idea is that there's just not direct support so you're not going to use it directly in the language you can use it through cloud in it if you really need it one thing i didn't see mentioned anywhere was ansible and this one's a little bit confusing because there's a lot of videos online about terraform and ansible working very well together and they're complementary uh technologies so ansible is a little bit different than these other ones because it does more than just configuration management so maybe that's the reason there um but anyway the point is is that there's no direct support for these anymore you've got to use cloud in it and generally if you can use packer instead when you're working with virtual machines okay hey this is andrew brown from exam pro and we are taking a look at local exec which allows you to execute local commands after resource is provisioned so the machine that is executing terraform so what's doing the terraform apply is where the command will execute in a local environment could be your local machine so your laptop or workstation a build server like gcp cloud build abs code builder jenkins or terraform cloud run environment so that is a single use linux virtual machine so just an example and there's a lot of cases where you might want to automate but the idea here is after you provision a vm you need to supply the public ip to a third party security service to add the vm ip address and you could accomplish this by using locally installed third party cli on your build server and so there is a bit of overlapping responsibility between terraform outputs versus local exec because the idea is that by getting um uh by getting data out after something is provisioned or something like that you can do something pragmatic but the idea here is terraform outputs allow you to output results after running terraform apply local exec allows you to run any arbitrary commands on your local machine commonly used to trigger configuration management like ansible chef or puppet okay let's take a look at some example code for a local exec so here we have a bunch of examples on the right hand side and so i just kind of want to walk through some of the commands that we can use but before we do that just let's take a quicker look here at the code so notice we have a resource like about instance in web and then we are specifying a provisioner being a local exec and then we have a command that is being executed under there okay so hopefully that makes it pretty clear but let's just kind of work through the options we have available to us so the first is we have a command and this is required and this is the command you want to execute so notice that we are doing an echo there so it's whatever is possible there and i think by default it's using bash okay so if you're using linux that's what it would be using uh we could also set a working directory we don't see an example there on the right hand side but if you wanted to say where the command will be executed that's something you could do so maybe you want it over here another thing is the interpreter so this is the entry point for the command i think by default again it would probably use bash if your linux machine but you could say use bash ruby it was cli powershell whatever you want okay if you needed to pass environment variables in maybe you need a key and secret so the example here is you know we are printing out those keys and then putting them into a credentials yaml file so that could be an example there okay hey this is andrew brown from exam pro and we're taking a look at remote execs so this allows you to execute commands on a target resource after a resources provision so the idea is you have a local machine executing terraform and so the idea is that when remote exec happens it has a script and it's sending that off to the target so this case it could be a provision virtual machine and this is where the command is going to run so a remote execute is useful for provisioning a virtual machine with a simple set of commands for more complex tasks it's recommended to use cloud init and strongly recommend it in all cases to bake golden images via packer or ec2 image builder if you want to use something more complex like ansible or something let's take a look at an example of a remote exact script so here we have a couple and just to quickly go through it the idea is you define your resource so here it's just a virtual machine on aws and we are provisioning our provisioner is going to be remote exact and so we're able to put these inline commands and say okay let's run puppet apply and then we'll use console join which is the cli for hashicorp console so there are three different modes for remote exec the first is inline list of command strings which is what we are seeing over here and then the other option is we can provide a script or scripts so the idea is that you would um well you just specify those locations and it would run it what's interesting here is that it doesn't say um like because we saw with local exec that we could use an interpreter and so it's my assumption that it's just going to use bash or it's going to use a script that is executable right where you have a shebang on the top there and so that's something you know i might test out it's not something that's going to be on the exam but maybe we'll just test out that theory because it's not in the documentation as of the time i'm recording this let's take a look at the file provisioner and this is used to copy files or directories from our local machine to the newly created resource so here we have some on the right as an example so again we have a virtual machine that we're deploying to aws we've set the provisioner as file and we are specifying a source file and a destination so source is going to be uh the file that's on your local machine or whoever is uh the considered the local that you might also want to provide content directly so in this example here you see that we're literally just giving it a string and then there's the destination where you want that file to be i don't have it shown in the code example here but there's a high chance that you would have to provide a connection block so that you could say okay i need to use ssh or winrm to gain access to that machine okay so we just mentioned that there's a connection block so it tells the provisioner or resource how to establish a connection so here is a big example on the right hand side so this is using the example for a provisioner file and here we are specifying our connection block and this one in particular is for ssh as you can see and there's a bunch of different parameters like the user the password the host you could also use a bastion host i don't i'm not showing it here but if you're using ssh you could specify a bunch of keys in order to do that because maybe you need to go through a bastion first for uh windows remote management you also have that option down below okay hey this is andrew brown from exam pro and we are taking a look at null resources so this is a placeholder for resources that have no specific association to a provider it's a bit confusing but it makes sense once you run into some use cases for it so here is a big example where we have an aws instance and we're defining a cluster and so we need a null resource here because we want to run this trigger and that's generally why you're going to be using all resources is to trigger a resource so triggers is a map of values which should cause this set of provisioners to rerun so values are meant to be interpolated references to variables or attributes of other resources and uh triggers are interesting because i think we also see them in terraform cloud i'm not sure if this is the same kind of functionality but um yeah that's in all resources okay hey this is andrew brown from exam pro and in this follow along we're going to be um learning all about provision or so what i want you to do is make sure you have a new folder and cd into that folder and we are going to create ourselves a new main.tf file and we're going to go set up a new workspace in terraform cloud so i'm going to choose the cli driven way of doing it i'm going to call this workspace provisioners okay and we're going to get some default uh code here that we can copy in so i'll just paste that into my main tf that's just going to set up that workspace we want to set up our environment variables or terraform variables again so we'll need to set up that for aws so i'm going to just go to the registry here registry.terraform.com or dot io and we'll go to aws here documentation aws providers scroll on down just because i can never seem to remember these key names and so we will put in this one here and i will need to actually get my credentials again these are secrets so you should not share these with anybody again i'm going to get rid of mine eventually here especially before i publish this course and i should be able to paste that in there didn't get it it's very finicky the um the copy paste here with uh vs code so we'll mark that as sensitive we'll add another one here and in this case it is called secret access key okay and we will save that and so we're all set up for aws with the exception that we need to define our actual required providers again we're going to go back to well we don't actually have to we could just go grab it from here if we go back here and grab the required provider there and so that needs to go just after back end here doesn't matter the order as long as it's in the first level of the terraform settings and we'll also want to specify the provider and i'm just going to set the region here as us east one and it's double quotations i don't think terraform supports single quotations and then i just need an aws instance so what i'm going to do here is go up to my getting started here and in here we're going to grab it from the aws code and we'll just scroll up and we'll grab this okay but we'll have to make some modifications because we don't have a local here so we'll take that out and i'm just going to hard code this value for the time being so t2 micro uh and that looks good to me i'm just going to double check here that is all good so we'll go down below type in terraform init great and that's just going to start setting up that for us there so the thing is is that we're going to want to ssh into this me machine and so we're going to want to set up like a data key okay and so the way we're going to do that is we're going to need to use um it's called aws key pair so what i'm going to do is make my way over to the documentation here and i'm just going to type in database key pair okay and this is pretty much what i'm looking for so i will go ahead and paste this in if you're familiar with aws you can uh you know associate keys but this is the easiest way so we're going to need to generate our own key and attach it there once we have our key in there we can just reference it so i'm just going to go down here and add it right now so we'll go key underscore name and i think what we'd want to do is use an interpolation there or directive and we want to do aws key pair dot deployer dot key name okay and i'm just looking at that to see if that is correct the coloring is not right here but um i don't think that's why like that is the problem because the syntax definitely looks correct to me here so i guess i'm just not going to worry about that right now another thing we're going to need is the public id so again with the outputs we will just type in output and do public id ip sorry i like to say id and we'll set our value here adabus instance my server okay so we're going to need some kind of ssh key so we're going to go ahead and generate ourselves a new one um there is a s or a linux command called ssh keygen it's basically the standard for generating keys and so i'll just hit enter here and i'm just going to call it terraform and i'm going to hit enter and enter again and notice that it has generated out in the root.ssh directory actually it might have dumped it right here and that's no good i'm going to delete that the reason i i can't have it in this folder is that i'm right now mounted to a windows directory and so chamod which is what we need to modify the permissions won't work if we do that so i'll have to do this again and i'll have to type the full path okay and so this will generate it out in the correct directory i'm going to do a chamod on that 400. the reason why we're doing that is that whenever you launch an instance i'll show you later but uh when you in sessions manager but aws will not accept um a uh like a key unless it has uh it's only readable okay so we will go here and do ssh terraform and put on the 400 we don't need to do it on the the public key there and we need that public key so we'll do root dot ssh terraform dot pub we're going to copy the contents there this might take more than one go because the paste and vs code is not great double check the ends here make sure there's no spaces that causes a lot of issues check the front here ssh that looks good to me okay and so when we deploy this instance it's going to take that ssh key and and install it on the server for us which is really nice um so we need to now set up a secure security group because we're going to need a way of accessing port 80 and 22. so back on aws here we go the top here and if we just type in security groups i never remember if it's under ec2 or aws if we go down here there is the security group and so here is where we have an example so i'm going to go ahead and copy this in here and we're just going to go ahead and modify that okay so i'll just paste it right here and i don't need any tag on that and so we have our egress rule we have our ingress rule and so for ingress rule we want one for http because we're going to install apache and just have it running on port 80 here okay we're going to be using our default vpc and so that doesn't have an ipv6 so i'm just removing it out of there and we're going to have to reference some kind of vpc so for the time being like we're going to use a external data source we'll have to change that but this will be um we'll call this sgmyserver sgmyserver we're going to have to set our description here so this will be my security group my my server security group notice that we are explicitly setting an egress port if you're familiar with aws this is usually set for you by default but when you're using terraform you have to explicitly set it because if you don't it won't be there when you deploy it um so we're going to need to have that vpc and so we just need the id and we could technically just open aws and grab that key so if we go over to aws here and go to the vpc and go to vpc ids we could just technically grab it that's the default vpc but the problem is we're going to probably have to refer to this vpc in other places so we can't just grab the id and put it in here that's not going to be good enough so what we'll need to do is we'll need to actually reference the existing we don't want to set up a new vpc which might use the default one so that's where data sources come into play data sources allow us to uh externally reference resources um and so like if i wanted to figure out how to reference a vpc i would just say terraform data source vpc okay and then i should be able to easily find an example here so here's an exact example that i want so i will go ahead and grab that it's very simple i'm just going to call my main because that other one was called main and this is where we would want to actually place the id so i'll go back here and grab my vpc id okay so now uh this actually acts as a resource and we can access all of its attributes so that's going to be very useful like notice how we're referencing cider block if we had just hard coded vpncid we wouldn't be able to do this which is what we need um so let's make sure the egress we don't need an ipv well we can just leave that alone that's fine so what we need is um to reference this here so we'll say data dot aws vpc notice that we're using data dot in the front because it's a data source that's how we always reference them and we'll just do dot id down below this has to be data because it's not a standard resource it's a it's from a data source all right and that is good so we have our data source so that looks pretty good to me oh but we have to reference the security group actually down below here otherwise it's not going to work so i think for that it is vpc security um group ids and then there that's where we'd have to reference that so our resource up here is called absolute group sdg my server so we'll just have to type that in again down below here so we'll say aws security group dot s g my server dot id and that should apply we didn't actually create a port 22 here so we'll go here and copy this and uh we do not need uh we don't want the cider block of the vpc this is what we if we want this we want this to be the internet so we're going to say 0.0 uh i'll just copy the one down below here just so i don't make any mistakes but this just means from anywhere okay and we only want rip to work so what we'll do is go to the internet here and type in what's my ip and so that is my current ip i'm going to go here and make a cider block forward slash 32 just means use a single address and i actually put that in the wrong block here so i'm just going to go ahead and paste it up there and we're going to go and clear that out and so that will give us access well i think i messed that up sorry so one is supposed to be one's supposed to be down here so we want the ssh to be our ip address here so sorry we'll say ssh port 22 port 22 and i'm going to go back and copy this one here because i just cleared it out by accident okay and so we have the that port 80 open that ssh open um the only other thing that we need is a file to configure our resource so what we're going to do here is make a new file i'm going to call this userdata.yaml or maybe cloudenit.yaml because that's now we'll do user data yaml but this is basically uh cloud cloud in it when you're using aws this is gonna might vary for providers but you have to start the first line as cloud config even though this is a yaml file this is important for each of us to know what to do i want to install httpd okay and i'm going to do run cmd systemctl start httpd and then we have to do sudo system ctl enable hdb so this is going to install apache which is just a web server start it up and enable it so on reboot it will work um one thing i want to show you if i have not before cloud init examples if you're just wondering like how do you know what to write there there's a bunch of examples on cloud in it and then uh notice like it starts with that so we could literally create users and do all sorts of things here but for our purposes we're just going to keep it really simple um i don't know if it matters if it's a yml or a yml sometimes you have with the a sometimes you don't but i'm just gonna do it that way anyway like that so we just need to set our user data here so we're gonna have to pull in that script so we will type in um we'll need to reference our data so we'll need to create a new data source and this is going to be called template file we'll call it user data and here we'll say template equals file i think i called it cloudinet here oh no we renamed it user data there we go and so now we just need to reference that file so if i go down below and we say user data equals data template file user data and then i think you have to type rendered there so this will deploy a server that's open on port 80 ssh only allow it on our address to ssh into it it's going to copy over that key and it should run the script and install apache so we can see that server and we'll output our public ip address there so i'm going to do a terraform plan to see what happens because we did do a lot there right see if it takes it i don't even know if we did terraform in it yet if we didn't it will complain so it says here a data source 8bitsvpcid has not been declared in the root module it's probably um no we're doing data right so that shouldn't be an issue main oh i didn't write the word main on there so that's on line 29 so i think we just need data here or sorry um main okay and we'll try another terraform plan and sometimes if you want to speed it up you can just type terraform validate before you do your plans that's why you see me do validate a lot without doing a plan first even though they both do it okay and so what we're having here is an error we're saying inappropriate values for egress so description prefix list id security group self are required so when you're specifying things in blocks even if they're optional sometimes like blocks being this sometimes you have to still specify them so we have we don't have prefix id so we should go look this up because i'm not sure what it's expecting here so we'll go down here to prefix id okay so that's just a list so i'm going to go here and just provided an empty list okay i have a feeling that's for ingress egress and it wants security groups right there it's also a list okay and then self that looks like it is what whether the secret group is added by the source or not i think that's a boolean so what i'm going to do here is do security groups self equals false it's not like i know what these mean in granular detail it's just the fact that it's like hey we want these fields and i just go and i go okay i'll give you some defaults because i don't plan to use them for anything right so um and we will paste that in there there's some weird characters there okay so we'll go down here and do tear from plan and we'll see if it likes it now i don't know if we're missing a description here we are so description for growing traffic try this again here all right so we didn't get any errors it looks like it's all good and it will provision so the aws root module does not declare variable name adabus access key id but a value is found in the terraform tfrs if you if you meant to use this value okay that's fine so what we're going to do is now try to provision and see if it works i'm going to do auto approve all right and looks like it's off to the races i will see you here when it's done okay all right welcome back so after a little while there i just wanted to make sure those two checks had passed uh we're ready to see if our server is working and by the way there is a way for us to make sure that terraform only completes uh when those two checks have passed and that's where we can use null resource and so we'll look at that later on but for the time being we'll just manually check that stuff when it's done so what i want to do is go grab that public ip address go and paste it up here and look where apache page is working so everything is working as expected let's see if we can ssh into that instance so what we can do is type in terraform outputs and see what we have here it might just be output my fault here and so notice that um oh we get a lot of stuff okay so i just want i'm not sure why i'm getting so much output here all i want is the public ip address but notice that it's uh giving me a bunch of stuff here that doesn't make sense so i must have made a mistake here if i go down below yes i forgot to do public ip all right so what i'm going to try to do here is see if i can do a terraform refresh and see if that well actually sorry terraform refresh is an old command so i'm going to do refresh only and see if we can get that change that change to reflect refresh only is like we didn't change any infrastructure but our state does not match our um our uh like the actual objects within the cloud so this way we can just pull that information okay refresh doesn't always work as expected but in this particular case i think it should work pretty well yeah see it's going to replace all that information with just that and we're going to type yes here great and so now if we do terraform output it should be a lot more sane and if we just want to get that single one there whoops we can do public ip but what i want is i just want um i want it in raw because i want to be able to use it as a bash command so i can ssh in so i'm going to do ec2 user at sine dollar sign parentheses here and i'm going to hyphen i to specify where my ssh key is my public key or sorry my private key i suppose so we will do ssh terraform and so that should allow us into the server that's much nicer than having to type the ip address every single time i'm going to type in yes and i'm in the server so there we go so we successfully provision with cloud internet the other way to provision is with terraform and packer but we'll leave that for the the packers section um but uh yeah that is that's all we need to know for cloud in it um so there we go all right so i just want to show you some other provisioning things like local exact remote exact and uh file so let's get to it um for local exec i'm just going to go ahead and google that quickly here local exec terraform not working let's just say it is working here and we'll scroll on down and so what this is going to do is run a local command or execute something locally on the machine that is running terraform now right now we are using a remote provider so where this is going to run is actually in the run environment which is not very useful to us so what we're going to do is switch back to the local provider here in a moment but we're just going to go and add this provisioner just use the default one here that is provided to us from the documentation i'm going to go up the top here and i'm going to comment this out so we'll go here i'm not used to migrating from remote to local so i'm not sure what's going to happen probably actually before we do that we should go and tear down our infrastructure so before i do that i'm just going to go terraform destroy we'll just say apply delete auto approve okay terraform did i spell terraform wrong delete it should be that well i'll just do terraform delete then that's fine i'm spelling something super wrong here terraform good destroy you know what it probably is it's probably the destroy flag there we go and so we're just going to tear down what we have and then uh we will set this up for local and then we will deploy that okay so i'll see you back here when that's all destroyed all right so our resources or our server is destroyed so what i'm going to do is go here and comment out the remote back end for the time being and we are going to do a terror form uh apply or sorry terraform init because we've changed out our back end so it's now local a change in the back end has been detected which may require migraine existing state if you wish to migrate it sure we will say migrate state i'm not used to going from remote to local but local to remote but seems to like it worked out okay so we'll say terraform apply okay and we should end up with a local state file we'll say yes here and so what i'm hoping that will happen is that we will once this is done it will output a file called privateips.txt in this folder but we'll see what actually happens here so i'll see you back here when the provisioning done and it actually has rand as private ips okay all right welcome back so uh we had waited for this to execute and notice that it says local exec executing and here is that file with those ip addresses so that is how local exec works okay so we'll move on to remote exec using the same file here all right welcome back so we just did local exec and so let's take a look at remote exact so in our documentation we'll just go down one and here we have an example i want something a little bit more simple than this um so what i'll do is just kind of grab this code here and we'll just kind of tweak it so we'll go down below we don't need both local and remote here so i'll go up here and i'm just going to take this command here okay and paste it on in here but i want to make sure that it actually goes somewhere that i can find it so i'm actually going to just ssh into the server we'll just hit up until we find that ssh command we had earlier there we go just because i can't remember the root directory here so we'll say pwd and i think that we can get it to put it in here i don't know what this is going to execute like in as what type of user i'm hoping that it will execute as the ec2 user if it doesn't i don't know how we're going to find this file or the the command that it's going to run here but what i'm going to do is put in home ec2 user and we will have the echo command in here and we'll just actually copy this wholesale okay and i'm hoping that this will place it where we want it to go if not like it's not a big deal it's just the fact that uh it'd be nice to just be able to easily see that local exactin remote are a little bit different so this one takes just a command and this one can take multiple inline commands or a bunch of other stuff you can read the docs on it it's all covered in lecture content um so this should do the same thing this one says aws instance web private ip address so i don't think self is going to work in the way that we expect it to here uh it might it should actually yeah so let's give this a go and see if that will work to do this because it like from the perspective of terraform nothing has changed in terms of the infrastructure so we're going to have to do a replace so we'll do terraform apply replace and then we'll have to give it the resource addressing names let's address instance dot my server and i've got to type that right if i want that to work terror form oh you know what it's because i'm logged in the server common problem i have here replace equals database instance my server enter and so i'm just hoping that this is going to work actually you know what i'm going to stop that before it happens because we're missing the e there it doesn't matter because i would have had to confirm that action so i guess i didn't have to panic there it's still wrong i kind of put a forward slash on that so we'll just hit up again and we'll try this one more time this time i think i got it we'll say yes and i'll see you back here when it's done provisioning we'll esta station the server and see if we can see that file but maybe like the best we'll get is just the command that it's executed okay all right so we didn't have much luck here um it says missing configure uh connection configuration for provisioner so probably what we need is we might need to specify a connection let me just see here so provisionary invokes a script a remote resource this can be used as etc the example just shows this right and so down below missing connection configuration so i'm thinking what it is is that it just wants the connection information so there's like a connection block for provisioners so we will go and type in terraform connection block i wasn't planning on showing this right away but if this is what it requires then we will provide it that it's not a big deal so i just want one for ssh i really wish they just had oh they do right there there's an example so what i'm going to do is go ahead and grab this actually this probably tells us where it would execute which is kind of the question we had there before um this does not use root first so it's gonna be ec2 user but there's no password okay let's go down below here so the address of the resource to connect to so i would assume that's just the ip address so we just say um self dot private ip actually that'd be public ip sorry public ip uh there is no password so we'll have to pass the private key so that's how we're going to do it so we will take that out here private key the contents of the ssh key this can be loaded from a file on disk using the file function so we've done that once before with file and we actually did this this one i believe oops trying to search in this file here there we go so i'm just going to go down below here so i can see what i'm doing um paste that in there whoops you know this uh this vs code doesn't always work how i want it to so we'll say private i private key oh sorry this is template file private key i mean it's not a template file it's just a file i don't know if we need to really assign it to data i'm going to go google this i'll be back in a sec all right so i took a look here and it seems like it's very simple it's just something like that that's always wondering that maybe we don't have to do a data source there um so what i'm just going to do here is just paste that in there like that and we will go down below to our connection here and this is going to be at the root terraform terraform okay so that looks good to me let me just go double check if there's any other parameters we're missing uh the host the address used to connect to the resource required the other one didn't have it i'm surprised that now i'm kind of like wondering if this is going to work because that other one didn't have the host so maybe it's old the path to use for the script um user type host hps this all looks fine there's really not that much to type in here so i think that we're all good to go and i think that this connection block is in the right area it's with the provisioner so let's pull the trigger and see what happens so we'll try another replace here okay say yes hopefully we're just lucky here so yeah that kind of answers the question what what it would use would be ec2 user there so all right so i'll be back here if we run into any errors okay all right welcome back so uh looks like it finished here and it did establish a remote connection it didn't say that it failed said that it connected and it probably executed that command that we were expecting here it's not saying that it failed in any way so let's go ahead and log in and see if we can see it if we don't that's not a big deal we don't have to really dwell on this to make sure it's perfect more so important that we just kind of go through the motions so that we understand what this is hey the file is there look at that so we can open it up let's see if it's there perfect okay so that is a remote exect and so then we can move on to i suppose transferring files okay all right so this last one should be really easy because i think that we can just modify this one and call it file and then specify file so file takes a source and a destination or a content which might be just easier in our case so we'll just say destination here and we'll say content we'll go look up how this works for file um yeah this one's a bit easier so that's what i'm going to do a little copy this over here and i'm going to just say bar soon which i think is the name for mars in that book there and we'll say dot txt we want the uh directory to be in the home uh home what did we say there before when we logged in it is i think i might need the full path here to know yeah help me see too so we'll say home ec2 user bars soon and the contents will just be mars and so i think that's all we have to do to get that to work content destination okay so let's go give that a go and see if it works so terraform we'll need to do a replace again we're actually logged in the server here so i'll just exit and we will go ahead and replace that again just double checking making sure everything's okay good we'll hit enter let's make sure we don't get any errors here looks like it's good press yes and i will see you here in a bit okay all right so it says that it's been created or at least replaced let's go take a look at our server give it a refresh it's probably in our initializing state we should probably still be able to log in there so we'll sshn and we'll type in yes we'll type in ls there's our file file bar soon i'm just going to cat it to see if it works um and i don't think the uh contents is there oh no it's there okay oh i guess because i wrote cat oh no it's right there it's just there's no line break all right so that all worked out great so uh we're pretty much done for provisioners here so what i'm gonna do is just tear this all down and we'll just we're all done okay so we'll just do a terraform just or i'm going to do a terraform apply auto or sorry destroy auto approve and we're all good so yeah i'll see you later all right so it looks like we do have one more uh follow along here for provisioners and it isn't all resource i thought it was in another section but uh we can do it here so i just noticed that i went back and i broke up the provisioners into separate folders there so that when i share this repository it's gonna be easy for you to find all those examples but let's switch over to this new folder i have here which is for the provisioner null resource and let's create ourselves a new main dot tf file so you know null resource just keeps cropping up in a lot of different use cases but one in particular that's very helpful for is waiting for those status checks uh when spinning up an aws instance so what we're going to do um is we're going to go to maybe one of our examples like the cloud init and we'll go ahead and grab this one okay and so now what i'll do is make my way down to null resource here and i do not believe i got rid of this remote workspace but just to make it easier we're just going to keep it local okay so i'm just going to delete that out of there and to simplify this further i mean we don't need all this stuff while we just leave it in it's not a big deal so i think that's what i'll do i'll just leave it in because i don't feel like ripping all this out to streamline this but what we want is to create a new resource called null resource here and just a moment as i have a reference for this it's not easy to remember so okay and so what we'll do here is create ourselves a null resource and i'm just going to call it status and it's going to have a provisioner inside of it here and it will do a local exec and what it's going to do is execute a command this is going to be the aws ec2 weight instance status ok check and so this is used to check whether it is done or not and so we'll have to do some interpolation and what we need to provide here is the instance id right so down below what i'm going to do is type in depends on and i think just type in ec2 instance here okay i don't use depends on very often so let's just go look it up and check its reference so depends on terraform to see an example and so here it's actually referring to a particular resource that seems like a good idea to me so what i'm going to do is go up here and just bring this down onto a new line i'm just going to say aws instance my server because we want that this to provision before this does and for null reasons we absolutely have to specify that relationship okay so we need to get the instance id here so i'm going to just try to take a single one here and i think the instance id i'm not sure so let's go look up on the terraform documentation so registry.terraform we'll make our way over to providers over to aws into documentation and we're going to type in abus instance and so what i want to know is if we do id do we get back the id i think we would oh well i can't seem to find it very quickly there but i'm almost certain that if we do dot id that's going to give us the instance id back so we'll just type in instance my server dot id and i mean other than the fact that the coloring looks a little bit off i think that is fine and so we'll go ahead and try to provision this and see if it works so we'll do a terraform validate here because i find the terraform plan a little bit slow actually before we do that we have to do a terraform in it this is a new repository i think there's not supposed to be p here so i'll remove that and this will probably fail if we don't bring in the um uh that provisioning file there so we need this user data file here so let's bring it over or it's going to complain i believe it's with a a so let's rename that so it has an a in there there we go okay back to this file here we'll try a terraform init or sorry a terraform validate let's see if it throws any errors we have one error here blocks of type resource are not expected here so maybe my nesting is incorrect and it is because i haven't nested within a resource we cannot do that so let's cut that out and we will place this resource here at the top level and we will run that again and so we have something else failed initiate provider registry hashicorp null to obtain schema unknown provider um we'll do terraform init again since it's asking for it it's installing the hashicorp null i think it's because we added that null resource so if we go over here to the registry go back to the top level we type in null so i believe this is what controls the null resource here okay so if we want to read a bit more about it i think it's all there so it is a separate plugin so now that we have that i'm going to do terraform validate okay looks good and what we'll do here is go ahead and do terraform apply and i'm happy with it because it passed well i guess we should do a plan first and yep it's just going to create stuff so that's all fine so what we'll do is type in terraform apply auto approve and what we're watching for is to see if it's going to wait for the status checks because that's what we care about okay so if we go back over here we're gonna have to pay close attention see what happens you you great so we scroll up here it looks like we hit an error um so it's saying that it does not like our command oh this is supposed to be easy too sorry spelling mistake so we will i don't know if this provision so i'm going to refresh here it did spin up an instance so we will have to tear down here so or what we could do is just do it terraform apply replace that probably easier to do we'll do data as instance my server and we'll go ahead and write yes and we'll see if it works this time okay notice that it's executing our status check here we may be interested also just try out this command while we're waiting up here if i press the plus i can open up a new uh terminal and i can even try it myself here so notice it's just kind of hanging because um it's it's set to wait so until it's actually uh working uh and then it returns that's when it will proceed so that's probably how it's working here so i'm just gonna go ahead and delete this window here and so it's just waiting until it gets a valid check so i'm going to go refresh here notice that it's initializing so we'll just wait all right so notice here it says the creation is completed if i give it a refresh the stats that pass the check so this null resource worked it as intended and once this command had completed and the small resource existed then it was ready so basically that is null resource you can also do triggers with it so let's take a look here quickly so a map of arbitrary strings that when change will force the null resources to be replaced so that is also something else we can do not something we're going to explore uh right now but um yeah there you go okay so we are done the uh provider section but i forgot to tell you to destroy the uh resource here i was just doing another follow along and i noticed that i still had it running so i'm just going back here and doing a terraform uh we'll do destroy okay so yeah just in case always consider that you run destroy at the end of these fall belongs okay and we'll just make sure that is going to work here just before we end here yes great and so we're all good hey this is andrew brown from exam pro and we are taking a look at terraform providers so providers are terraform plugins that allow you to interact with cloud service providers like aws azure gcp software as a service provider so github angolia stripe or other apis such as kubernetes or postgres servers there's a lot there there's like over a thousand providers so providers are required for your terraform configuration file to work so you have to have at least one provider providers can come in three different tiers we have the official one so published by the company that owns the provider technology or service verified so actively maintained up to date and compatible with both terraform provider communities so published by community member but no guarantee of maintenance up to date or compatibility providers are distributed separately from terraform and the plugin must be downloaded before use so if we do terraform init this will download the necessary plugin provider plugins listed in the terraform configuration file so there you go hey this is andrew brown from exam pro and we are taking a look at the terraform registry so this is a website portal to browse download or publish available providers and modules and just remember providers and modules are plugins within terraform both of them okay so to get to this website we go to registry.terraform.io and everything published to the terraform registry is public facing so let's just distinguish between providers and modules and i feel that i should have given providers a little bit more attention in the uh in its own slide but i'll give it a clear distinction between providers and modules here so a provider is a plugin that is a mapping to a cloud service provider's api so if you wanted to call individual api actions that is what the provider is providing to you when we're talking about modules a module actually relies on a provider plugin but a module is a group of configuration files that provide common configuration functionality this is going to help you enforce best practices reduce amount of code reduce time to develop scripts so the way to think about it is imagine that you have to do something in your csp like aws and there's just common things that would go along with it so let's say you're launching a load balancer auto scaling group with ec2 instances that's a bunch of services that you are just very common you'd have to configure it together so there could be a module that allows you to do all that with writing very little amount of code and we'll choose best practices when doing that okay let's take a look here at providers and modules within terraform registry really quickly so um here is the aws one here and so i just want to point out that this official one is by hashicorp it's not by aws but it does mean that it has a proper support so you know it's going to have pretty much onetoone mapping to the itabus api um and so it has really really good documentation now i complain about terraform not having great documentation for learning like their language but for the actual documentation of doing things practically they're really really good and here's just an example where we see app mesh and they just give you full examples for basically everything it's really great and if you need a code sample to get going like to actually install it within your configuration file it's right there over here so you can just go ahead and grab that for terraform modules it looks pretty similar so the idea is you get your module code on the right hand side here you want to check out the examples it's going to be dependent on who is developing these modules this one is made by anton so he has lots and lots of really great examples and then you can see a list of dependent modules here under sub modules so it's not too complicated so there you go so we're taking a look at terraform registry which is a public registry but let's talk about private registry how would we do that well that's where we use terraform cloud it allows you to publish private modules for your organization within the terraform cloud private registry when creating a module you need to connect to a version control system of vcs and choose a repository so here you can see we can be using something like github gitlab bucket or azure devops and of course we're going to cover terraform cloud a lot more further on in the course and it definitely does more than just act as a private registry but i figured this is the best place to put it against the terraform registry okay let's take a look at how we would get a list of the current providers you are using so all you'd have to do is type in terraform providers and you'd get a full list this command is useful if you have a very complex architecture where you're using a lot of files and modules within terraform i wanted to just show this command just because i saw it on the exam and so it's just an easy point if you happen to get that question okay so we know we can set multiple providers in our terraform configuration file but there are some variations here that you should know so one thing is is that if you need to have an alternate provider you can use this thing called alias so if you just notice here there's the alias this is useful if let's say you want to have resources within different regions of aws is a very common use case when you want to reference uh what resource should use what provider you're going to have that little provider attribute and then you're just going to do what the name is of the provider followed by the alias you can also set an alias provider for a parent module so notice here in the required providers we have this attribute here and we're using this configuration alias and then if you need to set an alias provider for a child module but more or less you just need to remember these two up here okay for setting an alias hey this is andrew brown from exam pro and we're giving closer attention to modules so a terraform module is a group of configuration files that provide common configuration functionality to enforce best practices reduce the amount of code and reduce the time to develop scripts i definitely had a lot of confusion understanding the difference between a provider and a module initially but the clear thing is that a provider is just an api mappings to uh the service okay so on the example here on the left we have aws as a provider and the example is to show you if you had to create a vpc you'd have to specify many networking resources and uh just notice that i have the three ellipses there to suggest there is a lot more that you'd have to configure but by using a module and there's one called the aws vpc module it basically has this short domain specific language that allows you to quickly provision a vpc so the easy way to remember modules is imagine clicking a wizard that creates many cloud resources like it must have the vpc wizard that's basically the idea behind modules just to kind of give a better contrast to the value that modules have we'll look at the azure provider so imagine you had to provision an azure virtual machine this is how much code you'd have to write so it's going to vary based on providers so aws does not require this much work it's very short uh gcp requires a little bit more work and for some reason azure requires a lot so this is a case where you'd want to use a module so there's a module called compute and network module and it reduces the code to amount of this still a bit long but that's just what it is okay all right let's talk about the fine line and this is understanding the gray areas of responsibility between terraform infrastructure as code and thirdparty configuration management tools like ansible so there are cases where when you get outside of aws as your gcp you might see providers like for postgres database and you might say okay well what part of terraform should be automating it and so that's a little bit more complicated question because terraform does more than one thing so terraform has providers modules and provisioners and then on outside of that if we're not even using terraform we have third party configuration management tools that we can use like ansible and the thing is is that you could have ansible do everything but that does not mean that you should have it do everything and with terraform more or less most of these levels you can have them do everything but that doesn't mean that they should right so the idea is to try to figure out what should be where and how to define that so let's talk about creating a database so if we created a database that is like setting up a new service so that is going to be under the providers and so you'd use the postgres terraform provider to set up a database now you have users and so users are an entity they're not just like loose data so there's something you can add remove add permissions to and we would treat them as entities and so it wouldn't necessarily be under the providers but that's a great place to put it under modules okay then you have your data so where would the data go well data is not necessarily an entity it's just a bunch of data so i would say that that is for provisioners that can run random scripts and then when we want to do things like backup tables to data warehouses or truncate data daily tables things that are repetitive tasks that is what we're going to use ansible for or a thirdparty configuration management tool outside of terraform you wouldn't have terraform do that stuff at all so when you have a task done one time to set up the database like seating data it's going to go to provisioners when you have repeatable tasks for ongoing maintenance it's going to be out as a third party provider and if you have something that is like identified as an identity like as a resource that you want to manage like asset management which are these things these are going to be over here in providers and modules i do want to point out that a provisioner can be using ansible but you'd still want to use ansible or thirdparty configuration management tool uh isolate or separate to do these kind of things you do not want terraform running these okay hey this is andrew brown from exam pro and we are moving on to our providers section so we already covered aws but let's go take a look at some different ones because i just want you to get a bit of familiarity with something else so you understand that there are different challenges with each one and how the providers are a little bit different so let's take a look at azure first and you're going to need the azure cli installed so if you do not have that already go to azure cli and get that installed it's going to vary based on your requirements the other thing is you have to have an azure account so i'm just going to go to my portal here to my sandbox i guess i haven't logged in in a while so i'm just going to have to open up that for azure hopefully they don't make it too hard on me here there we go and i'm in my azure portal so what i'm going to do here and if i'm still running ml studio i really got to shut that down uh it doesn't look like i am so that's totally fine okay so anyway um coming back to azure what we want to do is make sure you're on the registry go to providers go to azure and we're going to grab the information to configure this and i have a new folder here called providers azure so just make a main.tf and that we're going to paste the contents there and just make sure you're in the correct directory so make sure you're seated into that and i know because i've done this before i know that we need to specify features empty in here cannot tell you why i just know that you have to but there are a lot of different methods for authenticating with azure some very easy some very difficult we can use the cli when we're working in local mode when it comes to using terraform cloud the remote version it's a lot harder we have a lot a lot more options but we're going to take the easy route here and use the cli and this is going to be reliant on us doing the azure login okay so um we have the provider um i'm not sure why the provider name's not there i didn't delete it out i believe it's azure rm so we'll just go back here and make sure that is correct so i'm just gonna click click up here at azure azure rm okay and if we scroll on down i think it even shows you yeah you have to have it like that okay so um we'll do that and i'll just type in terraform init and it doesn't like something i don't know what happened to the names we'll just copy it again no biggie somehow i must have replaced it by accident and we'll do features here and we'll do terraform in it and one of the easiest things that we can create in terraform is probably a resource group if you're not familiar with the resource groups they're just kind of like a folder for your resources so i'm going to go here and make a new one let's just say resource so i believe it's azure rm underscore resource group as you can see i've done this a few times and i'm just going to say you know my resource group or i will just say um providers azure providers terraform azure providers sure why not and we will give that a name okay and we'll have to give the location i'm going to do east us all right and so that says that has been successfully initialized and so um i can do terraform plan this is not going to work until i do a login but i just want to see what it prompts us with if we attempt to uh provision this without any credentials in place actually to be fair i've probably done it before so i'm actually just going to run it because i think it'll just actually work for me because i might be i might already have credentials but what you'd want to do is just do easy login so i'll type in azlogin and that's going to authenticate my machine to azure so see how it opened up my browser i'm going to log in it says you are now logged in you can close this great i'm going to close that and if we go back um you know we have established a connection there so doesn't look like there's any error yep okay we're all good so now if i was to do a plan i don't think it would really throw an air until we do an apply see if this will work while it's going we'll just navigate over to resource groups as you can see i have a bunch of junk resource groups here that i'm not even using some point i should clean that up and it says we're going to create this resource group sounds good to me so i'm going to type terraform apply and just see if that works it's a bit nice not having to handle any it was credentials you know like passing those along with the cli though of course once you get into these other ones it becomes a lot more difficult um every time i have to set this up i have to really uh read through this it's like a lot of work but i imagine if you're working in azure every day it's not a big deal but basically you're just going to be setting a bunch of these in terraform cloud okay so you'd have to get your subscription id tenant id client id um and it's going to vary based on a few different uh scenarios there so anyway what we'll do is make our way back over here and it says do you want to perform these actions we are going to say yes and it says it has created that resource so if we make our way over to azure um and we give this a refresh sometimes their console is not always up to date like s aws is so it could be not showing up here and actually exist and so i don't see it yet and that's terraform for you so i believe that it does exist that it is there because it says here that it has created this here but yeah the um the azure portal is just like that it just takes time to update so i would just say let's assume that we did create it correctly because it did say that it made it and we'll wait for the cash to buy bust or whatever it has to do to make this show up here i mean it's also possible it could have ended up in a different tenant or or that but i don't think so because this is my main one so let's give this another refresh there it is see yeah so you just have to wait again terraform or sorry uh azure's portal is a lot slower than the bus but it also does a lot more so i guess that's kind of a tradeoff there anyway so now that we've have a resource group probably a great idea to set up a server i'm going to tell you right now setting up a virtual machine in azure is extremely painful um i think that if we wanted to go take an example and see like azure virtual machine tutorial for terraform hashicorp has one here and actually no this is actually just on microsoft but look at all the stuff just to set up a single virtual machine like you have your resource group your virtual network your subnet your public ip your network groups your network interface like just tons and tons and tons of stuff so i don't do it this way what i do is i go to the modules because that's the easiest way to set it up for azure so we'll say oops we'll go registry and if we go to modules and we go to azure there's one for compute we just type in compute up here azure compute and this is like way way way easier so we have a linux server a windows server things like that we are going to need we have a resource group but we are going to need our linux server because i do not want to spin up a windows machine just because uh like linux is just very inexpensive that's the reason why it's not because i have an issue with windows i'm working on a windows machine right now uh we'll go ahead and copy the network in because that is just something we have to have and it might be nice to have the output of the the name of the server so we'll do that and we might need to modify this so that it makes sense because i named my resource group that so this one is just called example there so i might just have to swap that out like that and i really should have just named an example i would have saved myself a whole lot of trouble but i did not know i would have saved time if i did that so we'll just scroll on up here and i think that is okay it's not specifying what size a server it is and that is something that is very important to me because i want it to be inexpensive so i i know what we have to say it's called vm size and a very inexpensive one is standard uh b21s okay i remember that for my azure days making the azure courses and that will be very inexpensive and we're not going to keep it around for very long so it's not a big deal and i think that this is correct i'm just going to double check this looks all fine to me so what we'll do is go ahead and see if this will provision so we'll do terraform apply i actually want to do terraform init because we've installed a new module okay and so we can now do terraform apply and we'll just review it make sure that everything is okay and it's happy with it yeah i would say that um azure is the hardest thing to use with terraform and that's not terraform's fault that's just the complexity of azure um but you know again that's a tradeoff you know azure can do a lot of things so you just have to decide what you want okay so we will type yes there's way too much to review there and i'm just going to hope that this succeeds and what we'll do is we'll go back to the top here and i'm just going to go over to my virtual machines and we'll refresh here so we don't see anything yet okay and that is creating this is going to take a little bit of time so i'll see you back here in a moment okay all right so it looks like i might have made a spelling mistake or a minor tweak here so it's saying that uh b b21s is not valid so what i'm going to do just to find out what sizes there are and get the right name i think we can find it this way here and if i go to b1 ls okay so maybe i just missed the uh the l in there i'm just going to double check yeah so i guess i missed that so let's put the little l in there okay and let's see if that fixes that problem hold on here b1 ls b2s okay well sure whatever it wants right i just wanted to be cost effective so i mean you might have to look this up because you know might be the future and they've changed change them here um but i remember this being a valid option okay well it must be my mistake so i want just check it one more time b1 ls i don't trust it so i'm going to copy it just in case it's a capital i and so what we'll do is try this again and maybe we'll have better luck this time and actually just to save myself some time i'm going to just do auto approve okay and i'll see you here in a bit alright okay so after a little bit of waiting there it looks like it deployed successfully so we're gonna go over back to our virtual machines here and give it a refresh and there it is so yeah it wasn't too difficult to get that working um but yeah hopefully you can just see that when you want to figure out these providers here all you have to do again is go to here and go to the documentation go to the first section and that's where the authentication always is and that's the hardest part honestly is just getting beyond that part but you are going to find different challenges locally and also with the terraform cloud because the configuration is different so let's move on to a another provider all right so i actually forgot to destroy the resources here so i just kind of cycled back here i was actually in my gcp one here a moment ago but i just want to make sure that you've destroyed your resources there as well so just type in terraform uh destroy okay all right and just type in yes and you're all good to go all right so we just did azure and we've obviously done it the best so let's go ahead and do gcp and using gcp with azure is actually very nice because google's api is very concise and so it's not a lot of work to set up anything there but authentication is kind of a pain um again aws still has the easiest method of authentication just dropping those keys in not to say that the methods are bad there's just again kind of a pain to set up so what we're going to do is grab our provider information and we will have a new folder here i'm calling this main.tf and we'll paste it in here as such okay um and if i remember correctly to configure this we need a bunch of stuff it's like credentials and other stuff i'll go back here and just see what information we have and so this is this one's a bit odd because it doesn't show that maybe it's under guides um configuration reference we're just looking for the credentials adding credentials okay oh maybe it's under here credentials yep so this would be the options we want here i think this is under the provider because i'm just starting to recognize the name like credentials projects region zones these are the things i remember having to set for it so what we'll do is go over here and again see like the documentation's a little bit harder to get through i mean it's probably all here it's just a lot of work to read honestly um and so i'm gonna do credentials okay i'm going to do project i'm going to do region i'm going to do zone and i'm likely going to want to do this in us central 1 because that is usually what i like to do for tcp i believe this is u.s central one there i'm just making sure i've spelt it right that doesn't look right to me and so we'll have to create ourselves a new project probably so what we'll do is go over to google cloud bye bye azure and we can create ourselves a new project probably be a good idea for this console and we'll give it a moment here and i'm going to go over up here to the top and i'm going to i think that was the test one i did a while back but i'm going to just say make a new project here and this one is going to be terraform gcp example and we'll go ahead and create that it's usually a very very quick creation in progress we'll give this a hard refresh here okay uh and it is now ready so we'll just switch over to that project um i need the project id which is right here so we'll grab that there and we'll paste that in there and now we need credentials so i never remember how to do this we'll say json credentials gcp i just remember that it's a json file there's something like with service accounts and things like that so seems like we'll go here and we want to go into our gcp one here and i'm just going to check my app as a reference i don't remember being that hard my server's account click continue i do not remember this whatsoever okay let me just read through here quickly yeah i do think we have to create a service account i just don't remember what rules click the select the role the role field effects which resources you want i just want everything okay so um i want to be i just i'll be an owner because that'll give me full access to everything there and we'll go ahead and hit continue uh this is optional so i'm just going to hit continue here and so now i am in and so from here what we can do is go ahead and create ourselves uh i guess we don't have to create any things we just have to download our key so just looking at this here um which one is it i cannot tell august 18th that's kind of today um so i think this is where our key would be so if we go to manage keys should be able to download them here maybe i can create it ah here we go okay it's tricky so it just downloaded it right now and like this is so hard for me to remember like i just have a really hard time with tcp around permissions and credentials i don't know why it's my abs brain for you and so what i want to do is place it in this folder just to make our lives really easy okay and we'll just paste that on in there i'm really surprised i can remember all that okay and but i guess the thing is once you're set up you just you don't ever have to think about the stuff again but every time you have to do it's very painful okay so our credentials are in and so this should work um we're gonna need something to provision so i'm going to go back over to gcp we'll just say gcp terraform actually it might be up here and i want to go back to the documentation and i believe that was like it's probably like it always starts with the name so it's google and their services compute so it's probably instance compute engine there it is okay and we'll just see what kind of examples we have here might scroll down have something at the bottom nope the only example we have here is this so i'm just going to quickly read through it and see if it is good for us to use um yeah it looks fine i know that we're going to need a boot disk and we're going to need a network interface we don't need to scratch this we don't need all these things so i'm just going to pair this down okay so we'll go ahead and grab on all this stuff just seems like so much and i'm gonna go down below and we do not have to place in a service account we do not need metadata for this example we'll take out the metadata information the network interface is fine we don't need to put anything in here we will have it on the network as default because it'll save us some time we do not need to specify the scratch disk we definitely need a boot image and i'm going to go debian 10 for fun i feel like 10 is probably out we don't want tags right now it's not a big deal is the zone uh it's almost the zone i want actually i don't think i even need to specify the zone i think it will just like pick up on what i have in my credentials the machine type i want this to be inexpensive i believe it's called micro and we need to give this a name so i'm just going to say terraform instance and i'm just going to say like vm instance up here and let's give that a go terraform plan i'm just hoping that it's going to pick up that credential file here locally and i did that all right okay so what we'll do is scroll up says no changes objects have changed outside of terraform well haven't provisioned anything yet oh you know what i'm in the wrong folder okay i always tell you to be in the right folder and i'm not even the correct folder myself so we need to go back a directory saying like i hadn't provisioned anything what is it talking about so we'll do terraform in it to get gcp installed there i was very surprised like we weren't getting errors okay okay good and so now we'll do a terraform plan and while that's going on i'm just going to bring this up into gcp and make our way over to compute okay and one to add no problems good so we'll do a terraform apply auto approve it has not been used in this project before oh so we've got to enable it of course compute api well didn't take me to the right place that's something i don't like is their uh their api jumps around everywhere i don't want to try it i just want to use it says it's enabled oh i'm in the wrong thing we'll go down here to terraform gcp example and now we'll enable it maybe we just didn't see it because we were in the wrong project i like how the search just vanishes here like that's a great ui choice there google okay you can see like azure really has other than the fact that it's slow it has a really really good uh ui that's someone that likes using aws for you um oh i guess it probably would have brought us here anyway um so i think we're just waiting for this to enable oh maybe the search was here the entire time okay i was just complaining because i didn't see it i don't know why they just wouldn't keep that expanded all the time though honestly i'll hit enable again i'm pretty sure that it is enabling this is initializing it is now enabled sometimes it's better to trust what's over here as opposed to what's here so i believe that it's enabled and the ui is just being a bit slow so i'm going to go here to auto approve and what i'll try to do is maybe just click back here there's nowhere to go back i'm just going to click into another one sometimes that helps then we'll go back to compute is this enabled yet required compute zones get permission forbidden well i'm an owner so i should have everything okay at least this is enabled now i'm going to try this one more time just in case the permissions were still kind of like enabling there okay um so that's our problem service accounts click into that okay maybe i was creating it in my app and i was in the wrong place that's probably what where i was and that's why i was so mixed up yeah so this is in um another test account and so when i created that service account i created in the wrong place if you made it in the right account you're not going to have this problem as i did you can just you probably aren't even countering this error but i am so i will go ahead and manage keys and we will create ourselves a new key sorry about that and and i mean it makes sense because it says my app here so clearly i generated the wrong one okay we'll drag that one over yes i understand it's very secure and i'll go here and i will copy that what we'll do here whoops i don't want that there we will scroll on down and delete that we'll do an auto approve and i believe that this will work now we'll have the correct permissions so yeah i believe it is working now oh that was fast there we go and so we'll go back over here and we will make our way back to compute vm instances here and there it is okay so we can go ahead and do a destroy here terraform destroy yes and we're all done okay hey this is andrew brown from exam pro and we are looking at hashicorp configuration files also known as terraform files that which contain the configuration information about providers and resources this is basically core to terraform and that's what we're doing so terraform files end in the extension of tf or tf json and we'll talk about the json case a little bit later but terraform files are written in the terraform language and so here is kind of an abstract way of looking at the language i know it's confusing here but don't worry we're going to reiterate on it to make more sense but terraform language consists of only a few basic elements you have blocks and so these are containers for other content and they represent an object so i'll have a block type which can have zero or more labels and a body you have a block label it's a name of a block you have arguments which is uh which is what you assign a value to a name so notice like we have assignments so we have identifier to an expression okay they will appear within blocks so here it is within a block as you can see expressions represent a value either literally or by referencing and combining other values they appear as values for arguments or within other expressions you might come across hashicorp configuration language so hcl and this is the lowlevel language for both the terraform language and alternative json syntax i don't know if we'll be getting into it in this course um or if there's even an easy way to distinguish it because it's basically terraform language but just if you see hcl just think terraform language is the easiest way to think about it okay let's take a look here at the alternate json syntax so terraform supports alternate syntax that is json compatible terraform expects json syntax files to be named tf.json so we mentioned that earlier and so this is generally what it would look like okay the syntax is useful when generating portions of a configuration pragmatically since existing json libraries can be used to prepare the generate configuration files and that's pretty much it would you want to work on this it's up to you but yeah so that's the reason for this alternate syntax all right let's take a look at terraform settings so the terraform configuration block type terraform curly braces you'll see this within your configuration file is used to configure some behaviors of terraform itself so here is what it looks like and what's very common is you're going to see those required providers so there are different things that we can put in here so we can put the required version so this expects us to match to a particular version of terraform required providers this is the providers that will be pulled during the terraform init we can also do experiments here so these are experimental language features that the community can try and provide feedback on and then we have provider metadata so this is module specific information for providers okay hey this is andrew brown from exam pro and we are taking a look at the hashicorp configuration language also known as hcl i'm going to tell you i was really confused at the start working with terraform because sometimes they mentioned things like hashicorp configuration files hashicorp configuration language tariff language and i could not discern you know what the difference was but so this is the idea here is to give you that clarity okay so hcl is an open source toolkit for creating structured configuration languages that are both human and machine friendly for use with command line tools and it's an open source project so you can find it at github.com forward slash hashicorp hcl so the idea is that they have this baseline language that you can extend for your own use case so terraform is using it and so it uses a good like it uses the language itself but then it goes ahead and extends it by adding additional functionality for its specific use case and this hcl based language is not just for terraform it's used for packer templates vault policies boundary controllers and workers console configuration waypoint application configuration nomad job specification and this one isn't a hashicorp product but this is an open source project called shipyard and you can use it for shipyard blueprints surprisingly sentinel which is a hatchet corp policy as code service um does not use hcl but it has its own hc acl custom language uh but the idea is that you know we're looking at mostly uh the use case is for hashicorp services but if you wanted to extend this language for your own use case you totally could and so i think that's really cool but hopefully that kind of distinguishes between hcl and terraform language okay hey this is andrew brown from exam pro and we are taking a look at input variables so also known as terraform variables or just variables are parameters for terraform modules that is the way we get data in to our configuration scripts is via input variables so you can declare variables in either the root module or child modules and the way you define them is via this variables block there at the top and just to kind of go over the possible fields for that block we have the default option so the default option which is here is going to be the default uh variable if you do not set it for type this is an argument that specifies the value types that are accepted for the variable so this case up here we can see string and this one is a list for description this specifies the input variable's documentation we don't see an example there i believe that is optional but it's always great to put a description in when you can there is a validation block so a block to define validation rules usually in addition addition to type constraints so we don't see that here on the right hand side but the idea is that you know this just makes sure that there's less of a human error entering the wrong information you can also have sensitive this limits terraform ui output when the variable is used in the configuration and we will cover sensitive a lot more in this course outside of just this one slide okay let's take a look here at variable definition files and these allow you to set the values for multiple variables at once so variable definition files are named with the dot tf vars extension or if you want to use the alternative syntax it's the tfvars.json file by default if you have a file called terraform.tfrs within your project directory this will be automatically loaded so it's pretty common to make that file to create a definition file it just uses the terraform language so you would just assign values here you wouldn't make variable blocks but you just define these um identifiers and give them values okay another way of loading input variables is via environment variables and this is very common way of loading them if you have your own cicd process for terraform so if you're using terraform cloud or you're using some kind of build server that's going to be the primary way you're going to get variables into those build servers probably won't be doing this much locally but the way it works is that terraform will watch for any environment variable starting with tf underscore var underscore followed by the name this is very important to remember because it definitely will show up on the exam so let's say we wanted to set a variable for an image id so we do tf underscore var uh and then image id probably most cases when you follow the name it's going to be a lowercase underscore i don't think you'd probably want to uppercase that stuff and you just set the value okay so there's a lot of ways for us to load input variables we just saw two so we saw terraform tfrs and environment variables but there's a lot more caveats to this so let's just run through them so we already covered uh terraform.tfrs the idea here is that if you create this file and it's in your project it will automatically be loaded we're running terraform apply you can name other tfr files so i just call them these additional tfr files but they won't be loaded by default you'll have to use a command line to load them this is useful if you have like a dev and prod environment and you want to swap those out now if you want to have files that auto load then you can just put the dot auto here and give it any name you want this would be useful if let's say you had a very large terraform tfrs file and you wanted to break it up to make it more human readable you could do that then you have the hyphen var file flag when you're doing tear from apply or or plan and this is actually how you load up these additional variable files if you need to override a single value you can use hyphen var so here i'm overriding the ec2 type to be t2 medium and then lastly here we have environment variables we cover this this is where it starts with tf underscore var underscore followed by the name and this is going to be very common when you are using code build servers or runtimes to run this in a ci cd automated way now there's a presence to which these get loaded meaning that uh that certain configurations of vari or input of variables will override other ones so as we go down this list these ones will override the previous one so at the top you have environment variables if you have a terraform tfrs file that will override the environment variables if you have the json one that will override that one if you have auto files that will override the default tfrs file and then on the last list you have hyphen var and hyphen var file will override the rest so there you go in terms of the exam they're not going to ask you the precedence here but you're going to need to know what var var file are environment variables are in this default one okay all right let's take a look here at output values which are computed values after a terraform apply is performed output values allow you to obtain information after resource provisioning such as a public ip address output a file of values for chromatic integration cross reference stacks via outputs in a state file via terraform remote state and so here's an example of an outputs block so notice that there's a block and you specify some stuff there you can optionally provide a description it's not necessary but generally with outputs i would recommend putting that in there you can also mark it as sensitive so it does not show in your terminal this is important if you're doing like logging stuff you don't want to compromise those values there but understand that output values um even though they might not be outputted to your terminal or sd out they will be visible within the state file so if somebody opens up the state file they're going to be plainly visible there so just understand that sensitive does not protect the values there okay now in terms of how we would use the cli with output values if we type terraform output it's just going to print out all the values that are within the state file i don't show this in the example here but if you wanted to use a um a like bash command to parse json you could extract them out and see they're just plainly in the json okay if you need to get exactly a particular field you type in terraform output and then followed by the name if you want it in a json format all the output then you could give that flag i don't know if it would work with this one i actually didn't test i just thought about that here for this one here if you want the raw output of it meaning like if you output a string and you want it to be escaped or what have you then you could use it pragmatically by passing it to something like curl to do something but the idea with all these output values is that it's one way of inspecting but you could also use this in a configuration script or or something to do kind of like an after action okay all right so we're taking a look at local values also known as locals that assigns a name to an expression so you can use it multiple times within a module without repeating it so here what we're going to do is define our local block up here and then the idea is that we're assigning these names or ids expressions or values so that we can reuse them throughout our code notice that we can define multiple local blocks in the same file and i just say this because like when you use required providers you're only allowed to have a single block but this case like with variables or locals you can have many and you can even nest them within each other so notice down here we're referencing local within a local so that's totally possible and i imagine it's in the order to which it is specified we can do static values or computed values so we can actually here's a function write an expression and then it'll output a value once a local value is declared you can reference it via the dot as local dot the name so here notice within our abuse resource we have local and common tags i have to point this out but when you're referencing you use the singular local because you might get an exam question which shows you local dot or locals dot and the trick here is you got to remember which one it is locals help can help dry up your code it is best practice to use local sparingly since it's in terraform it's intended to be declarative and overuse of locals can make it difficult to determine what the code is doing this all comes back to describing terraform as declarative plus where they give you functionality that's imperative like but the idea is that uh you know if you overuse these you can run into trouble okay hey it's andrew brown from exam pro and we are taking a look at data sources for terraform so the idea here is you want information defined outside of terraform and stuff defined by another separate terraform configuration or modified by functions so the idea here is we are going to define ourselves a data block and we have an external resource we're looking for so we're saying hey i want to see if i have an aws ami we're going to use these filters as a way of kind of selecting it within our aws account so we'd have a provider set up and so it'd be looking within that account to find it and it's even saying look for the most recent ami okay and once we have found that data source we can just reference it so notice we're using data to reference it there so data aws ami dot web id so there you go we're taking a look here at name values and these are builtin expressions that reference uh various values you'll find your configuration scripts we do cover these in their respective sections but i wanted to consolidate them here in one place just so that you get a second chance to reinforce this information because crux of questions on exam could be based on knowing how the name values work so let's go through them the first is resources i'm going to get up my pen tool here and so the way resources work is that you start with the resource type so adabus instance and then you're going to do the name of it so there's nothing that starts before the lefthand side of it so just remember it just starts with that resource type then you have input variables and that starts with var period so that's the singular var then we have local values and again that's singular so local period for child modules it starts with module period again singular for data sources it's going to be data singular just remember singular because they can have a match up on the on the exam questions where it'll be like data or data for file system and workspace info we have path.module this is the path of module where the expression is placed we have path dot root this is the path of the root module of the configuration we have path cwd this is the path of the current working directory and in practice the default cwd is the same as the route so those would be technically the same we have terraform dot workspace this is the name of the currently selected workspace then we have block local values these are things that appear within a body of a blocks so this could be within a resource provisioners things like that so we have if we're using the count meta argument we're going to get count and with that we'll have count dot index so we can say okay this is the uh fourth iteration of you know uh this this count loop um then we have for each and this allows us to have the key and the value so we can access that during our iterations we have self so selfless uh references information within provisioners or connections so it's just like a selfreferencing thing name values resemble the attribute notation of map or object values but are not objects and do not act as objects you cannot use square brackets to access attributes of name values like an object so there you go hey it's andrew brown from exam pro and we are going to be learning all about variables and outputs so let's get to it here uh and the first thing we're going to do is create ourselves a new folder and just so you know that these file names might change because i have yet to actually publish this as i'm creating this course so you know if this one isn't 0 4 0 because i just decided not to do the terraform registry one because i'm doing it later that you know the numbers might be different okay but in the course i will link up the correct repos if you're trying to find them what we'll do is type in main.tf and we just need to provision something so we'll probably go back all the way to our getting started one and try to grab something from there so i will go and grab this aws instance here and we will also grab its outputs because that's probably a good idea and we will go and grab its provider here all right and we will also go ahead and grab a variable because we're all learning about variables so we're gonna have to have some kind of setting here and we also need our terraform configuration block so i think that's in my main and we will go ahead and grab that so we'll go to the top here paste that in okay this looks all good to me actually we're just going to use a local backend for this to make our lives a lot easier and we don't need tags i'll just remove that for the time being and so this should be good enough yeah i'm happy with this so what we'll do is go ahead and deploy this instance but actually this is all about learning again about uh variables right so we said that there's a lot of different ways to inject them so we did we have the terraform.tf vars and other ones like that so let's just go down the road or go down each one and see if we can learn how to do all these okay so the first one is going to be terraform dot t f bars and then here we're just going to specify the instance type that's going to be a t2 micro put that in double quotations and we'll go ahead and type in terraform uh plan and just see if that gets populated oh we have to do terraform in it first we also don't even need to deploy this infrastructure because we're going to just be able to um run terraform plan if it's populated then we know that it's working as expected right and while that's going on i'm just going to go to the documentation here and we're just going to pull up terraform variables because i'm pretty sure it's just straight here in the documentation it talks about all the different ways there's like a list when they talk about the um uh the variable definition files download are down here so they kind of mention all the different use cases there and i mentioned that obviously in the course um but we'll just go and now do a terraform plan and so what i want to see is it's going to use a t2 micro here so if we scroll on up we can see that it says t2 micro so it's loading that from our terraform tfr it's just to prove that it is i'm just going to write a nano and we're going to go down below and run terraform plan and if we scroll up we can see now it's a nano so let's say we didn't have a terraform vars file we had something that is just anything we call it um variables or how about just vars to make our lives a bit easier so let's just say vars.tfrs and if we do terraform plan is it going to autoload that file no see how it's prompting us because if it doesn't have the word auto in it it doesn't know to load it so what we'd have to do here is we'd have to do terraform plan var file and then say vars dot tfrs and so now it should load that file okay we're gonna scroll up see if it's nano it is good i'm just gonna go change this to a medium for fun so let's say we we didn't want to have to always do that hyphen var file because we always want this to be loaded because it's just an additional file what we can do is put the word auto in it all right and so now if we do terraform plan it should just pick that up okay we're going to go ahead and scroll up and we can see we have that t2 medium okay so let's say we just wanted to input it from the uh the api here so i'm just going to rename this here or from the cli so what we can do is type in var uh instance type equals t2 nano and so if we scroll up here this should be t2 now so yeah it's pretty much all the variants that we need to explore but also notice that there is uh an order of presidents right so this is the order that will load in and later sources taking precedence over the earlier ones so the later it is the more likely it's going to override it so what i'm going to do is i'm going to create myself a um new file here and we're going to say terraform dot tf vars so i just want to show how that plays out and we'll have our vars.tfrs file which is fine actually we'll do the auto okay and so what i'm going to do is i'm going to start off small so this is going to be instance type equals nano and then this one here is going to be a micro and so i want to see what happens if i run terraform plan is it going to take this one or that one right and we're going to scroll up and we can see that it's a t2 micro so it's taking the one from the auto file because it's second president's right so this one has priority over this one and then if we want to uh override that there we could do um hyphen var and say instance type equals t2 medium and so that should override those there and we'll scroll up and see we can see there's a t2 medium so that's pretty much all we really need to explore in this one here and so we'll just move on to something like outputs okay you know what i thought about it and i think that maybe what i should do before we move on to outputs is actually just look at how we define these variables here and some of the additional options so here we have variable instance type and we specified it as a string of course there are different types but there's a few other things that we can do we can provide a description okay so we'll say the size of the instance i've never really noticed where the descriptions show up i'm assuming that if you were to run this without any kind of like terraform bars or anything so what i'm going to do here is just go ahead and delete this file here and delete the auto file here and i think that if we were to run it the prompt would show up there so i'll just clear that out i just want to see where it shows up yeah so it shows the description there okay there are some other options so i believe we can do sensitive i think it's just sensitive true here yep so we can do sensitive i'm not the best at spelling so i'm just going to put that off screen so i can see what i'm doing it will say true and what that should do is it should obscure it should obscure the actual value here so if i type in t2.micro and hit enter it should obscure it in the plan if we scroll up here so notice it's sensitive so when you're inputting it doesn't hide it i'm actually kind of surprised that they don't kind of blank that out as you're typing it in um but this is the only place that it's going to hide it and the thing that you need to understand is that just because it's there does not mean it's going to be hidden in the terraform state file so what i'm going to do is i'm actually going to go ahead and deploy this because i just want to show you that it's visible in the terraform state file so we'll say t2 micro here and i believe it's already created the state file you know it's still empty so i'll have to wait a little bit but while that is going on we'll look at something else like validation i don't really play with validation much but i'm sure we can figure it out in two seconds so valid validation just make sure that the input is as you expect it to be so if we go here and we need to give it a condition and so can is a builtin function so i assume it's going to just be true or false we probably should go look that up so we go like builtin uh functions terraform can which is right here so can evaluates the given expression returns a billion indicating whether the expression produced a results without errors okay so that sounds pretty good to me so we'll go back over here to our file here and so we have can and in the input variables we have regex and that's probably what i'll use here just to make things a little bit easier and so what i want to do is i want this to be a t2 or we even say t3 here so regex expects this to be a t3 and i don't need the second parameter here so i can just take that out and make this a period here t3 is just another line of adabus instances instance must be a t3 type ec2 ec2 uh instance okay and so notice this finished and we were seeing if the sensitive would show the um the size of the instance within the file here or would it be sensitive so we'll say instance type and so notice that sensitive does not obscure it in the terraform state file i'm going to go ahead and just uh destroy that so say terraform actually uh we don't have to do that just yet let's go ahead and actually test our validation here and see if we got it right so what i'm going to do is just do terraform plan again and i'm going to take out the sensitive option here terraform plan and so the condition for the variable must refer to var instance type in order for the incoming tests so i guess we do have to specify a second parameter here um the condition for the variable instances must refer to var instance type okay so i think it just probably wants it as the second parameter because we did see that a moment ago right you would think that it would just like infer it because it's already there eh um the validation error message must be at least one full sentence starting with an uppercase letter ending with a period wow grammar police your given message will be included as part of the larger terraform error message written as english prose i guess like if you're publishing your module and they want you to do it properly right so i guess that's a good way of enforcing good practices there and so i'm going to try t2 micro and i'm hoping that my validation works and it's here it says that it must be a t3 type and so that that's where that error is working uh so we're all done here i'm just going to go ahead and do a terraform destroy or actually i'll do it apply because i just like it to happen right away so we'll say destroy auto approve okay and we'll go off screen here and i'm just checking if there's anything else of interest that's pretty much it for the variables so we'll move on to the um actually you know what i want to keep this instance up and running because we're going to use it for outputs okay so um i think that's all good for now i'm going to switch this over to t2 so that it stops complaining okay and we'll look at the output cli all right so let's take a look at other things we can do with the outputs here so i'm going to go and type in terraform outputs cli there's nothing super complicated here but i just want to go through some of these options with you okay so we'll go back here to our terraform here and we should have for output so i want to show you terraform output and that will output all of your um your defined outputs then we can provide its name so we can say public ip and that will give us an individual one you can give it a raw command and this is really useful when you are doing something like ssh or you want to pipe it to another command you saw us do this earlier when we did ssh so we did ssh and then we gave it some kind of address and then we did this dollar sign parentheses and that's actually part of the bash language and so that was great so that we were able to directly interpret it and we had to use the raw so it was escaped as double quotations right uh let's see if there's anything all sets of interest um you could say no color json is something i did not show you before so let's give that a go so we'll just go back and say json okay and that could be really useful if you wanted to parse that there is a um there's a uh a bash library called i think it's like jy or jq it's for parsing json so you could use it with that like uh jq library nope jy nope parsing json um parsing json bash maybe it's like jq yeah it's jq so i think i might have this installed here jq and so this is a very useful tool if you want to parse out stuff here so what we could do here is we could say json and make a pipe and then say jq maybe period i'm not sure what that would give us probably everything but if we wanted to just grab the name see which is like hyphen r we could try that so we could try hyphen r type okay or oh so he has like a little period there so maybe we need to do this i mean i've used jq in the past it's just like i never remember how it works so maybe we do man.jq here might give us some examples that's not very helpful so i could say like jq examples so i know period will get us the start of it here we have fruit period accessing properties okay so i think what we need to do here is do public ip like that and yeah it returns a string and so we can do value okay and so the jq's pretty commonly installed a lot a lot of instances so that's something that you might find uh that you might want to select things here right okay um but yeah that's pretty much uh it for outputs and we'll move on to the next part here okay actually again i probably should talk about some of the output options here and show those to you as well because there are some things we can do so i believe we can set sensitive as well so just want to go and type in terraform outputs here i cannot type well today and we can give it a description and we can set it as sensitive so that's something that we should give give a try here and see what that does sensitive equals true okay and i think that if we do terraform output i wonder if we'll have to do a refresh on this for that to work great so it's still showing it and i want it to be sensitive so i'm going to do terraform refresh or actually again it's terraform apply um refresh only oh it's asking for the type again t2 micro and so refreshing state allows us not to have to reprovision it right so would you like to update the terraform to reflect the detected changes um yeah i'm fine with that yes i think because we had tags before on that resource possibly so now see that it says it as sensitive okay so what we'll do here is type in terraform output and so now it does not show us what it is so yeah there you go all right so now in this follow along what we're going to do is learn about chaining outputs from a sub module because this is something that uh really shows up a lot in the exam and so even though we're not into the module section of our follow alongs we have to kind of learn how to create a module or a sub module i should say so what we're going to do here is create ourselves a new folder and i think that it generally likes it if you call them sub modules you could technically name the folder whatever you want but that's what i'm going to call it and within there i'm going to make a new file and i'm going to call it main.tf and so what we can do is take any of our code that we like and throw it into that module i'm going to grab the instance here and actually while this is going i just want to go ahead and destroy our instance here um that we were running before oops destroy auto approve here and yeah t2 micro and it's because i it wants it every time even on a destroy which is totally fine but anyway so what i'm going to do is i'm going to grab our instance and we're going to really end up with basically nothing in this file here but i'm going to go and um go into the sub module here and basically grab everything okay and we're going to go ahead and paste that in there and so basically this specifies everything that we want but we need to pass we want to get these outputs and reference them in our main tf here so the way we're going to do that is we don't have these resources here anymore so i can just take these out and i can take this out here and what i can do is i can just say module and i'm going to say aws server and i'm going to then specify the source so the source is going to be in sub modules and we'll do forward slash forward slash here and probably it would have made more sense if i named this something like aws so i'll just say like database server i've already changed my mind okay because it didn't make sense like i had to make some modules maybe folders within that and i just didn't really want to move all that around and so if we want to reference this one here it's going to start with module and then the name of the module here and then the resource and so that should uh get us that value i'm just going to go ahead and hit sensitive and so i believe that this should work so we'll do a terraform plan here the module is not yet installed so we'll do terraform net fair enough great and so we'll do a terraform plan and we'll see if that's going to work now we technically have to give that module an input and so see it's expecting that input to have instance type so what we'll have to do here is specify instance type and i guess we'll just try t2 t2 micro here let's see if it likes that so we have another issue here unsupported attribute in the output module aws server aws instance my server is a object known after apply this object does not have an attribute named aws instance um i think i might need to specify oh sorry we just want the outputs so this is actually we don't want to reference it this way we just want to get whatever the outputs is so we just do outputs here okay because it we can't access the aws instance that way it just doesn't make sense so we'll go ahead and hit apply again here and so here it says object does not have that maybe it's just output and that doesn't work so just give me a second i'll be back okay all right so i pulled up the documentation and here it says you know i don't need to put the word output or outputs i don't know why i thought i had to do that and so i should just be able to do this so let's see if that works here see if we're in good shape okay so to reduce risk of accidentally exporting sensitive data that was intended terraform requires that any root module output contain sensitive data be explicitly marked as sensitive if you do intend so it's not our intention to mark it as sensitive so i'm going to say sensitive false this is line nine so let's run that again not sure if it's in our other one here i don't think so because it's line 28 eh oh sorry okay so we had we had it in the other one so we'll just take it out okay and we will run that there cool and so let's go ahead and just deploy that to make sure our sub module works terraform uh apply auto approve but yeah throughout the course you'll you'll see that we're going to be repeating some things because you know it's impossible to show you chaining outputs without covering how to build out sub modules but we'll just have to do some variants down the road there but i just want to make sure that this works as expected and that we get an output so i'll see you back here when it's done deploying okay all right so after a short little wait there you can see that uh we have our public ip address and so that is coming from our sub module so that's all in good shape there so what we can do is go ahead and just start to store this instance i'm just going to double check to see if the next tutorial requires it we technically covered local values earlier but i guess we could cover them again um so yeah i'm going to go ahead and just destroy that instance so we'll just say apply destroy auto approve um gotta type it right two piece there we go okay great i'll see you in the next video all right let's go take a look at local values again i know we covered this in the getting started but it helps to do things more than once and since we've had an opportunity to go through the documentation we understand there's a few extra things that we can do with it um like nesting things in or be able to find them twice things like that but there's really not a lot to do that is new here so we're just going to go through the motions of it again just so that it's part of our memory so remember we've made this into a sub module here and so this is probably the best place to do a local's value and it's not complicated at all so we're just going to do locals and we could use this to abstract a few different things so that's the variable i'm going to go up here one second and uh we'll do this for the instance here oops locals okay we could say ami this is probably not what you'd use it for but you know we just have to have some kind of use case for this so local.ami right and uh i'm not sure if you can do this let's see what happens if we do can we do var instance type kind of would be kind of redundant to do that but let's just do it anyway and what i want to do is a terraform plan you know the key thing to remember is that when we're defining the block it's called locals we probably don't use an equals here um and it's the uh the singular when we are referencing it okay so just scroll up and see if that is correct yep everything is working as expected i was going to pull that out because this really doesn't serve much purpose but again we just had to go through that um just so that you remember how it works okay so i'm just removing that out of our code okay and there we go all right so we're going to be looking at data sources now we did experience creating our own data source in the getting started when we referenced an aws vpc and so data data sources are resources that already exist that you want to reference in your code and so a good example would be using it ami the amazon machine image to change what is being served so if we were to go into our server here it's using this particular ami but we could totally use a data source for that and so anytime you're looking for something you would just type in uh you know edibus ami data source and you'll get some examples here and notice that we have some interesting options like filter and stuff like that these are not available to every single um i might have actually have to update my lecture content because i might have highlighted this as a global feature but i realized that this filter option here is actually reflecting what is in the aws cli so i i originally had thought that this was part of the language but apparently it's just a reflection of this because if you look up something like an rds instance okay and you say data source and you go here this one doesn't have a filter option or at least i don't think it does i'm gonna type in filter right or if we were to go over to google so we'd say like google compute and we would say data source terraform maybe even a project doesn't really matter notice it doesn't have a filter option so i just want to clarify here that this filter option really is particular database because that's what their cli supports and that's being reflected by terraform okay but let's say we want to reference a different kind of instance and so i was looking here and this is kind of an example where they are they are selecting an ubuntu instance and so that's something that we could do to select something there notice that the owner is not ourselves here so if you go over here notice we have self and so this is an account id for aws and this is a particular version of ubuntu so if i go ahead and grab this here uh and what we'll do whoops the one thing i don't know is that this instance like what um what region it's in because a bus you have to launch your amis in the same region but what we can do is paste this on in here and just notice that i'm just under the instance documentation here okay and so it's very important to get something that is again in the same region but we're not specifying the ami image it's going to filter and find it so i think what it's going to do is based on any region it will find it there okay so here i can just go data dot adabus ami and we just choose the id and that should work okay so we'll just type in clear and we'll say terraform plan all right so a data resource aws ami has not been declared in your module aws server so let's just take a look here it is defined right here maybe we aren't giving it the right thing here i'm looking for the thing that we can reference so id is set to the id found in the ami in addition the following attributes are expected the arn so i'm pretty sure yeah it was the id that we wanted okay it says the data source aws my id has not been declared in the module dot aws server okay i have not seen this error before because we're working in a sub module it's not really any explanation so when in doubt what i'm going to do is do a terraform in it and see if that resolves that issue okay and we'll just try this again and it still doesn't like it oh i also have a name so i guess i have to provide that as well so that's probably my mistake right there okay there we go and so what i want to do is just scroll up and see if it selected an ami from aws so notice that it's pulling this one here and that's going to be for the relevant region again i don't want to provision this because i don't but you know i just wanted to show you that that's how you use data source and i really want to emphasize that this filter option that you see here is particularly to aws and the options are going to vary based on how you can select stuff and not everything is available you have to uh google each one and see what uh resources you can pull in for data sources okay hey this is andrew brown from exam pro and we are taking a look at resource meta arguments so the terraform language defines several meta arguments which can be used with any resource type to change the behavior of resources and so we'll quickly go through the list here and then we'll deep dive on each so the first is depends on so this is for specifying explicit dependencies we have count which is for creating multiple resource instances according to account we have four each which is used to create multiple instances according to a map or set of strings provider so this is for selecting a nondefault provider configuration lifecycle this is for lifecycle customizations provisioner this is and also for connections for taking extra actions after resource creation so there's the quick list now let's jump into them all right the first resource meta argument we want to look at here is called depends on and this is the order of which resources are provisioned and is important when resources depend on others before they are provisioned terraform implicitly can determine the order of provision of resources but there may be some cases where it cannot be determined or like the correct order so this is where you can be a bit more explicit so here we have some terraform configuration where we have an ibus instance and it relies on a policy and so what we're doing is we're setting an explicit depends on here so that it knows that it requires that now in a normal use case you would not have to do this but it's hard to find use cases where this happens but when it does become a problem you'll know because your resources will not provision correctly you'll get an error so there you go let's take a look here at the account resource meta argument and this is when you are managing a pool of objects so an example here would be a fleet of virtual machines where you want to use count so here on the right hand side we have an example of us using that in terraform so we can specify the amount of instances we want so here it is for and then we'll have access to this name value called count.index so the tags will start at zero so it'll be server 0 1 2 and 3. then just down below here i just want to show you that with count you can accept a numeric expression so you know if you had a variable that you had set as the subnet ids or even just an arbitrary number like you want to have x amount of servers this would allow you to do that okay but just so you know those numbers must be whole and a number must be known before the configuration which you'd put in your input variables okay all right so let's take a look here at 4h which is for iterating over resource meta arguments but it's slightly different because it allows you to map over dynamic values giving you a little bit more flexibility so here's an example of us defining a4 each and notice that we have defined a map sometimes i call it an object because they're so similar but this is a map and the idea is that once you have your a map defined with your 4h you will now have access to these name values so you could do each dot key or each dot value to extract that out um you can also just use it like with an array so here we have an array and then we use two set to turn it into a set which it will accept as well and then we can just pull out the key because there will be no value so just an example of with a map and then with something that looks like an array okay to understand the resource metaargument life cycle we need to understand how resource behavior works and so when you execute your execution order via terraform apply it will perform one of the following to a resource so the most common one you'll see is a create so these are resources that exist in the configuration but are not associated with a real infrastructure object in the state the way you can tell it's creating it will have this nice little green plus sign the next one is destroy so resources that exist in the state but no longer exist in the configuration and so that's going to tear down your resources out of your cloud providers this is represented by a minus symbol then you have update and place so the resources who arguments have changed so the idea here is that if you have a virtual machine and let's say you change the size of it it's not going to destroy it it's just going to modify its settings this is represented with a tilde and the last one here is destroy and recreate so resources who arguments have changed but uh which cannot be updated in place due to remote api limitations so there are just some cloud resources that always require destroy and recreate and this is something very easy to trigger if you are using the replace command or the older terraform tank command in order to replace a degraded or damaged instance so let's talk about life cycle so life cycle blocks allow you to change what happens to resources on the create update and destroy lifecycle blocks are nested within resources so here is a resource uh which is just an azure resource group and within it we have a life cycle block and we're setting our first option here that's possible called the crate before destroy so this is a boolean and when replacing a resource first create the new resource before deleting it so the default is destroyed old first so this is more about just the order of how it's destroyed prevent destroy so ensures a resource is not destroyed then we have ignore changes uh and this is based off a list of attributes that you feed to it so don't change the resource on create update destroy if a change occurs for the listed attributes so maybe um maybe you uh you're just changing your tag and you say don't don't change uh like don't tear down create or do anything strange if we change a tag okay so there you go that's uh life cycles so we're looking at our last meta argument here which are resource providers and this goes along with the idea of an alias so here we are defining ourselves a provider in google cloud but there's a case where we might need to override the provider at a at a per resource level the way we do that is by creating an additional provider and setting an alias and then here we could change something like the region and then once we have that set we can then reference our provider explicitly under a resource and so that's all there is to it definitely on your exam you will see a question about alias or you'll see that example so definitely want to know how to do that okay hey it's andrew brown from exam pro and in this follow along we're going to be covering all the different types of meta arguments okay so what i'm going to do is just cd into the directory i created for our first one right that arguments depends on and we're going to take a look at this as always we're going to create ourselves a new main.tf file as soon as i can find the correct folder here so we'll say main.tf and i'm just going to go to my variable outputs and just grab some existing code to save myself some time i think everything is selfcontained into this subdirectory here so i'm just going to go ahead and grab that there and i'm just going to take out some of the code that i do not need um so we have an instance type which is fine um we don't have we don't need that we don't need validation we don't need to put the description in there we have this big old one here for the ami and what i'm going to do here is i just want to specify an ami manually just to make our lives a bit easier so i'm here and i'm just going to go and launch a new instance not for real but i just want to go ahead and grab this id here and what we will do is go back here and paste that on in and i'm just going to hard code hard code the instance type t2 micro oops and i'm going to scroll up take out this instance type variable okay so then we get a very small file makes our life a lot easier and so as always we need to do our terraform init that's going to initialize our back end there and we saw it depends on earlier it wasn't super complicated how it worked it was just that if you wanted something to be wait for the creation of something before you do something else that's what it would do so i think in this case what we should do is make an s3 bucket so we'll say and i've got some old tabs here so just close these out and we'll just say like uh aws s3 bucket terraform and these aren't really related in terms of their use cases but just the fact that we can set this on anything so what i'm going to do is go ahead and grab myself this code here and i'm not sure how that happens just close that out there and so i'm just going to go ahead and paste in this s3 bucket here and this is like having a unique name so you have to provide something that is um well i guess we can just call this bucket but here this is like having a domain name so i would strongly recommend to be very unique here so i'm just gonna pound in a bunch of numbers and just say um depends on because i don't want anyone to be using that i don't need to private i don't need to set any tags and that should be enough but what i want to say is that i want the bucket to only be created after the aws instance is created okay so if i go here and put depends on okay and then we say aws instance my server so now it has to wait for the server to be provisioned before the provisions of the terraform are the aws bucket there so we'll go terraform plan and if we just expand this a bit we'll see that it will create our instance and then our server you know i'm actually curious is what would happen if i was to take this and paste it here with the order change in the plan would it actually show in order of creation or is it just saying these are all the resources and what we're actually going to see is after the fact like what order we'll create it in so i go here okay so i guess it doesn't really matter it's just the order that it appears in or not necessarily just all right i'm just curious about that so what we'll do is we'll go ahead and say terraform apply auto approve and we'll let that go ahead and provision and so if we go over to our adabus account here and we go over to s3 okay and you'll notice that it's not creating the bucket as of yet and as we watch our input here notice that it's creating the adabus instance first right so what i'm going to do is i'm going to wait for this to finish and then i'll see you back here okay okay after a short little wait we can see that equator our instance first and then our s3 bucket okay so what i'm going to do is i'm just going to tear this all down and hopefully it tears down to a problem but we'll say tear down or sorry terraform uh apply destroy auto approve again if you uh find that too much to type you can always just type in terraform destroy and then confirm the plan but i like to do this all in one go and so i'll see you back here in a moment once everything is destroyed okay all right so after a short little wait there our server has been destroyed our bucket has been destroyed so now what we want to see is if we were to take the depends on and we are to move it um down below here we're obviously gonna have to change this because we can't selfreference ourself or we're gonna be an infinite loop but we'll paste that in there and call this whoops we'll call this uh a bucket here and so what should happen is uh when it does the terraform apply it should try to create the bucket first and then the instance and we'll know that by the output here so it doesn't like what i typed in this um because i guess it didn't take what i typed so we'll just scroll up here paste that in oops copy and paste when you're in the mode and vs code is terrible okay we'll hit up and so now what we should see is the s3 bucket being created first okay so see that the s3 bucket is being created first and then it's going to create the instance i'll see you when this is done creating uh and then we'll just tear it down okay all right so that's done there and so let's go ahead and just tear that down because we're all done with it and i'm doing destroy auto approve so that's just going to automate that process and uh you know then i'll see you into the next follow along okay so see you there all right so we are on to learning about the meta argument called count so this one is pretty simple the idea is that we are going to provide a thing that says count here and that's going to create additional number of servers okay so what we will do is we will go to our depends on here code that we were just working on i'm going to copy it and i'm going to paste it into a new file here called main.tf in this new folder and there's a few things we don't need we don't need this s3 bucket whoops i don't know what i keep on pressing to do that probably the side here but we'll take this out and we'll take out our depends on and so what we're going to do is specify a count i want two instances and we are going to also make sure that we name this so we know which server we're looking at and we're going to say server we'll do interpolation and we'll do count.index and so that should be good and what we'll have to do is just do one or zero to get that public ip address so what we'll do now is go ahead and switch folders it's very important make sure you're in the right folder i do that all the time where i'm in the wrong folder here whoops so we'll do 0 5 1 for mine again it might be different if i update the numbers when i do publish this course we'll do terraform init as always and then once that is done and that should not take too long we'll do ourselves a terraform apply and we will carefully look to see if it's actually going to provision two instances okay so this shouldn't take too long the unit just depends on how much work it has to do to fetch that information great so now what we can do is do a terraform apply and i'm just going to expand this up here so that we have a better opportunity to look at it apparently i've introduced an error so maybe it's tags or tags so we'll try that i think they show it here on the page so yeah it's with it's plural okay and so what i want to do is just make sure that we're going to have two instances so we'll scroll all the way to the top here it says server one server zero so it is doing that so that's pretty good so we'll type in yes and that's going to go ahead and create those two instances so i'll see you back here when it's done okay all right so after a little wait there um both of our instances have created so what i'm going to do is make my way over to our ec2 console here give it a refresh and i want to see that there are two servers running notice one is zero and one is one and i want to show you our outputs because in our outputs we said that we wanted the uh instance that is index one so that's server one here and its public ip address is 54 242 81 205 and so that is what we get there and so that's pretty much all there really is to this i think it might be interesting to show splat to see if it works here so i want to see if i can get all the ids returned so i'm going to just try or public ips so i'm going to give that a go and see if that works and so we'll do is terraform apply uh we're not apply we'll do yeah apply and we'll just say only refresh because we don't need to reprovision our resources we just want to see if we can update our outputs there and this is an opportunity to show off splat uh maybe it's refresh only and uh notice here that the outputs is going to change to a list so we'll say yes and so now if we do terraform output okay we should get a list back here we say public ips right oops public ip i don't think we can do this but i'm just curious if i was to do this would this work no it does not okay so yeah um you can get the ball back you use splats and we'll talk about splats later but that's uh all there is for now for this okay oh and as always i forgot to destroy our instances there so let's just type in terraform um apply auto approve destroy and then we are all in good shape okay so yeah just make sure you destroy those instances all right so now we're going to learn about the four each so um what i'm going to do is just copy the count because they're kind of similar okay and so what i'll do is create a new file here and we'll call this main.tf we'll paste in the contents here so the difference is that instead of using account what we're going to do is use an object to iterate through and change you know some particular properties so what we can do is maybe change the size of the instance so we say nano micro might be an example here so t2 micro g2 micro i should have made the first one nano there and i could even do a small i suppose and so instead of the instance type being set here what we're going to do is just say each dot value and then for the server name we'll do each dot key now this splats not going to work for a map because that's what this is this is a map data structure and spots only really work with lists so what we can do is use the values function to extract because that this would return if you just had this my server this is going to be a map okay so what we can do is just put the parentheses around here and that will turn into a list at just the values and then we should be able to get our public ip address that way i think so what we'll do is make sure we're in the right folder first that's always important tell you how many times i mess that up we'll do our terraform init to get things going and you know we might not even necessarily need to apply this as long as the plan looks good because if this was not correct this part here would probably error out like i definitely would okay but we just want to see that when we do a plan that this is correct great so what we'll do here is now type in terraform plan and so we have an error here i think it's because it's supposed to be values not value so i'll just correct that there and these are all like builtin functions so we go to while we're waiting for that plan to generate there i'll try to show this to you quickly builtin functions not here so we would just type in terraform builtin functions and probably under collections that's where these things become very useful these all these functions here and so values is the one we just use here for the map so i'm sure there's other ones that would come into play so now if we just scroll up what i want to see is that we have three instances so notice here the public ip is going to give us three back which looks correct to me the first one is server small notice that it's a t too small we have our oh this is too small as well nano and then that says small and if we go up to this one here this is micro so micro that makes sense maybe i just entered the value incorrectly and maybe you're watching me this entire time yeah i did so this is just supposed to be nano up here and so we'll run that again i have to say i really don't like how plans are laid out i find them a little bit hard to read but um i guess it's just the level complexity you have so there's not a lot of ways around that so we have the t2 small the t2 nano and the t2 micro notice it doesn't really respect the ordering of this they're all just kind of there in the plan but yeah so that would definitely work i'm not going to run this i'm going to consider this done and we can move on to the next part here okay sorry i killed the screen there a little bit earlier we have to specify the region again so we'll just say us east one because it needs to know where to take the uh take those operations and so it says you can apply this plan did i not did i not uh oh sorry i guess i hit up i really shouldn't have done that so we'll try this again so we'll say terraform apply uh auto approve i hit up on my arrow and it was going to an old one which is a bad on me here so we'll try that and so we have an error here the image id does not exist the image id does not exist and it's showing the same one here this is my east server and this one is my west server so it's kind of interesting because that should be right again i don't know if it's because we're doing that weird alias so what i'm going to do is i'm just going to copy this here and give us back our default provider i'm going to try that again and see if that resolves our issue we're using a data source so there's no reason it should not be able to find it because it's best it's pulling it based on the uh the alias theorem unless i don't understand how data sources work and i have to set the provider for it as well it looks like it's working so i'll see you here in a bit unless we have an error okay all right so we gave it another go and we're getting this error again but i mean it shouldn't be too hard to try to figure this out because it's looking for amazon 2 ami hvm and you know if we are in aws here we should be able to figure it out like this one's the hvm up here so that's what it's pretty much selecting so we should be able to go to one of those regions and just confirm what it is we're looking at so this one here is for west it didn't complain about east but maybe it didn't ever got to east it just ran west first and it complained but here it says that it completed the creation of it so let's go first check out if that instance actually exists i assume that uh it does not but maybe it does whoops and so we have our eserver and that one worked out fine and then if we go over to our west server here it doesn't exist so that's a bit curious to me i'm just going to check to see if that is uh that ami actually exists in the oregon region i i'm not i wouldn't be surprised if it didn't it's right here ami 0 c 2 d and we look at this and it doesn't say that it has something that says 0 0 dfe so what i want to do is scroll up here and look at my plan and see what it did so for wes it's using 00dfe that's fine and then for east it's using the exact same thing so maybe it's my own mistake here let's just go double check here um no it looks correct so i guess i'll do a little bit more investigate investigation i'll be back here in a second okay all right so i'm not sure why this isn't working as expected because as i read the data source is supposed to be agnostic it shouldn't matter where it's coming from here and it should take into account the provider here the only thing i saw that somebody was doing different was doing interpolation around here so maybe we'll give that a go and see if that makes a difference i don't see why that would matter but uh we're just grasping at stuff here okay and we'll just try this one more time and see if that actually succeeds okay i think we might have to enter where we want that maybe not because we provided the default provider there okay and it still has this problem all right so i mean i don't feel like i should have to do this but i'm going to do this anyway to see if it resolves the issue what i'm going to do is just copy this and make a second one and let's see if that resolves the issue because these are supposed to be looking uh in that particular area where that resource is and just to double check here we have usc's 2 here you know what i'm curious about i wonder if it's just using the data source for the provider so i'm just going to undo that for a second and what i'm going to say here is i'm going to set the default to be usc 1 and we will try this again and let's see if east and west fails because that would be very interesting if that happened eh and we probably just figured out by looking at the plan file so here that is changing and so what i'm going to do is just scroll all the way to the top here and i want to see what it's going to be set as if it's still the same value or it's a different value um and i can't really tell i guess we'll just have to wait for that to provision so i'll see you back in a bit all right so after a little bit of digging i looked at the actual sources here it says for selecting a nondefault provider configuration you use the provider option so you know a lot of people are saying that they're agnostic and that's how i thought they worked but i guess you do have to specify the provider so i suppose we will just have to duplicate this twice alright so that was kind of an interesting investigation something we can try to remember for later so this would be east and this would be west and so i'll just have to specify the provider here and we'll just say adabus west and for this one we'll say adabus east and then we'll scroll down below and so i don't think we need the interpolation here i will leave it in it's not a big deal um where did we put the name well right in front of it okay great so we'll do east here we will do west here try this again west here oops that's the east one and then there's the west one here okay great and so we'll try this again and so i think this time we're going to get what we want so i mean that's really interesting that if you don't provide a provider you have to choose an operation for it to happen and um it's great to know that uh you have to set providers for data sources but you know you learn these things pretty quick because when you get into practical applications you start uh intersecting with those things but i'll see you back here in a moment when this is successful okay all right great so it says those have been provisioned so what i'm going to do is pull up aws here and we are going to make our way over to here and i'm gonna go over to us west one i think we said it too i can't remember and so we should have an instance there great and we'll make our way over to us east 2 and we have our server there great so that's all we wanted to learn here so i'm going to go ahead and just tear this down so we'll say terraform apply destroy auto approve and we are good to go see that it runs here for a little bit and then i'm just going to stop here great and i will see you in the next follow along all right so we're going to learn all about alias and so what i'm going to do is create a new file here in our next folder main.tf i'm going to make sure i'm in that correct directory 0 53 is what i have right now it might be different for you later on in the course and so what i want to do is go to my uh anything like maybe count here and grab this one because i'm just going to update this ec2 instance for our alias and we're actually going to have two instances okay we're going to have an east in the west so i'm going to say east and west and i'm just going to change this here to my server my west server my eserver and what we can do here is just bring this down and the whole point of this tutorial is to show you about aliases so here we can go alias and we'll call this east and we'll have i don't know if we can do this but i'm going to try anyway i actually never tried but i wonder if we can have a um like a provider that has no default like where it does not have an alias because i think that'd be a really great way to be very explicit so here we have our instance i want this to be the east server and then i want to have a west server and then for our server name this will be server east and for this one it will be server west and so then we'll add in our provider and this will be aws west and then for this one it'll be aws east the only thing here is the ami is not going to be any good to us so what we can do is go grab some code so here uh this is like hashicorp supports terraform two amazon links two and so here's the code that we need to pull that so what i'm going to do is just go ahead and grab this aws ami here okay and i'm just going to paste this above our instance here and so that should grab that uh that instance we're going to need the name so i'm going to go down here just paste this line here and we'll just modify it so it's database amazon linux 2 has to start with data because it's a data source oops we don't want to change our instance type that's a mistake we want to do that for the ami here okay and we'll go down and replace it for both because we both want them on amazon links too but this way it'll pull the correct ami so we have server east server west we have the east and west public ip so it generally looks good i don't know if this is going to arrow but i guess we will find out so as always we'll do a terraform init all right and so now that tara for a minute is done we are going to do a terraform plan uh and see if that works and so notice it says the region where aws operations will take place so um i guess what we'll do is set it as usc 1 because we have two resources set um provider database region because we set the provider explicitly in both i'm kind of curious what would happen because it's saying usc 1 usc 2 and that's something i didn't specify what i want to do is i just want to be even more particular and set one provider that is totally and by the way this is supposed to be wes that's a mistake i'm just going to set it to something that i know is very different okay so southeast and west will just change this a little bit so how about we'll do us west one and then usc's two which is a little bit different and we'll do that because i want to see what it prompts so we'll just say us east one here and so the arguments owners is required but no definition was found in our data source which i'm kind of surprised because we copied that straight from hashicorp so maybe it's just a little article or maybe i did not copy that particular line so it should say who the owner is yeah say we're like owner alias but that's fine we can just look it up here because here it says owners and we just specify that as amazon it's not a big deal the real challenge to terraform is just dealing with the changes but i mean like it's pretty pretty powerful system so you just get kind of used to it so i'm just gonna try to fix that indentation i don't know if we need that owner alias there if we have owners up here but we'll try this anyway and see what happens okay i mean the major regions for north america is either uh usc 1 or usps2 so that kind of makes sense uh incorrect attribute value type so we have aws instance us west data dot abus ami is an object with multiple tributes so i think the thing is that we just had to specify its id because that's actually returning the ami it's just not going to infer it so that's just my mistake as per usual so we'll just go there and place in the id um so what we'll do is we'll just take a look here and see if it's going to provision the right place so this looks all good um so let's just go ahead and pull the trigger and see how it goes hey it's andrew brown from exam pro and we are on to our life cycle for the resource meta arguments so what i'm going to do here is just pull up the documentation so we can just take a look at an example for this so it's under providers or sorry it's under resources meta arguments life cycle and so you have this option where you can kind of set the behavior of it we covered this in the lecture content so like create before destroy so by default one terraform must change a resource argument that cannot be updated in place uh terraform will instead destroy the existing object then create a new replacement such as like create or destroy or maybe prevent destroy would be more interesting to do and a lot simpler to do so that's what we'll do we'll just set ourselves a life cycle thing but what i'm going to do is make my way over to one of our pre previous examples an easy one to pull from right now is still count because it's very easy to modify so i'm going to copy the contents of that and what i'm going to do here is open this up and make a new main.tf and we will paste that on in here and apparently i did not copy it i don't know for me like coding and vs codes like coding with like oven mitts on it's really hard i wish i could just use full vim but we're on a windows machine so you don't get to see the full power of my coding um so what we'll do here is get rid of that count because we only need a single instance here and we'll just simplify this to my server and we'll just change this back to my server and so we are going to specify lifecycle and i think it's just destroy but let's just go double check or prevent destroy maybe we go over here actually it's a boolean so it's probably lifecycle as a block yeah it's a block okay and we'll say true so we should be able to create this instance but when we go and try to destroy it that's where we're going to see the effect of this service so i'm going to make sure i cd into that directory that i just created with that new file and we're going to do a terraform init and so we did our terraform init but what we're going to do is do a terraform plan actually we'll just do apply because i have a lot of confidence in what i wrote here if it blows up on our face it blows up and we'll just correct it here but i'm pretty sure that this is going to work out pretty okay and so we will let this provision and i'll see you back here in a moment okay great so that looks like it's successfully provisioned and so let's go ahead and try to do a destroy so we'll do a terraform apply and we'll say destroy and auto approve and then we'll see what happens here because that life cycle should prevent it from being destroyed and so there it says resource abs instance my server lifecycle prevent destroy set but the plan calls for this resource to be destroyed to avoid this error continue with the plan either disable it or reduce the scope of the plan using the target so what i'm going to do here is put false and then we'll try this again and it should destroy the instance and if that's the case then uh what we can do is we'll just end here and we'll move on to our next step but yeah it looks like it's destroying so we are in good shape okay so there we go all right so we're starting our introduction here into terraform expressions because there's a lot we can talk about here so expressions are used to refer to or comp or compute values within a configuration so terraform expressions is a large topic and we'll be covering types and values strings and templates reference to values operators function calls conditional expressions for expressions splat dynamic blocks type constraints actually i don't think we covered typing strains just because there's nothing really to say about it but we definitely cover version constraints so yeah let's start off this section and go to it so we're taking a look here at types and values for expressions and so the result of an expression is a value and all values have types and so we have primitive types no type and complex structural collection types that last one is a bit more complicated than what we are presenting here we're going to simplify it and then cover it later okay so for primitive types we have string so you have your double quotations which represent your string then you have numbers so this can be uh integers or floats then you have booleans so this is either true or false for node types we have null uh and so null is different in all different types of languages so it's very important to understand how it works and so null represents absence or omission when you want to use the underlying default of a provider's resource configuration option so when you're saying null doesn't mean it's nothing it's going to be whatever the default is and the default also could be nothing it's just depending on what that is on the provider so for collection or for collection types complex structural types we have list or tuple and this generally looks like an array then you have map and object and this looks like basically like a json object or a ruby hash or i think they call it in python a dictionary so that gives you an idea of the basic types but for this last one here because this i found really confusing list tuple's map object we definitely explained this more in the course okay okay so we're giving a little bit more attention to the string type because there's a little bit more going on here so when quoting strings you've got to use double quotes uh at one point terraform i believe supported single quotes i think it only supports double quotes now and honestly you generally want to just use double quotes because double quotes always support escape sequences this is pretty much standard across all programming languages but the idea here is you can do things like new line carriage return tab literal quotes literal backslashes unicode characters both basic multilingual plane and supplementary planes there are some special escape sequences this makes sense when we look at the next slide for string templates but there's these things where you can do interpolation and so you might not want to actually do them you might want to do it without and so if you just use double of the symbol that will allow you to do it then there is also the ability to have multiline strings and we use here doc for that and so here doc is a little bit different in all languages but here we're using unix style so that means that we're going to start with these two angled brackets to the left our opening angle brackets followed by some word that is all an upper case it doesn't have to be eot it could be whatever you want i always like to type here doc and then it has to end at the same indentation level with the same word all uppercase and then everything in between will be treated as um as multiline the nice thing about this is that when you have this you can actually just use double quotes wherever you want because you don't have to escape them okay let's take a look at string templates because this is the real power of strings so the first is string interpolation and this allows you to evaluate an expression between the markers so the idea is instead of having to do double quotations and do plus signs to stitch together uh strings what you do is just do a dollar sign curly braces and then put the the expression or variable that you want to be converted okay then you have string directives and these are slightly different this allows you to evaluate an expression uh for a conditional logic between the markers so let's say we want to have an ifelse statement so if the name is blank um then use var name or sorry if it's not blank then use the name provided otherwise put it as unnamed okay you can also use interpolation directives with here docs so you know just to show that you can do it um and then the last one thing here is you can uh strip out white space that would normally be left by directives blocks by providing a trailing tilde um so just notice this little tilde here on the end because these do take up space so if you were to view it there'd just be an empty space there if you want that space to vanish then you just put that tilde on the end so there you go let's take a look here at the possible operators that we can use within terraform expressions and so just a refresher operators are mathematical operations you can perform two numbers within expressions i'm not going to show full examples here and the outputs of them because this is pretty common for programming or scripting languages and also the exam's not really going to focus on the use cases for these so it's just more so to tell you what is available to you so you know what you can use the first is multiplication so you take two numbers and times them to get a larger number division so uses a forward slash modulus if you never use modulus i really like this it allows you to see if something is divisible by a certain amount and then you get the remainder you have addition subtraction uh if you need to flip to a negative number you can just put a minus sign in front of it if you need to do um equals it's doubles if you want to do does not equal its exclamation equals then we have a less than so that's a open angled bracket less than or equal so that will be followed by an equal sign greater than is a closing angle bracket and then followed by an equal sign for greater than or equal you have or which uses the double pipes you have n which uses the double ampersands if you need to flip a boolean you can just put an exclamation in front of it so if it was true now it is false if it was false now it is true i'm not sure what it would do for a null i would think that it would turn it to true but yeah so there you go we're taking a look here at conditional expressions and this is pretty much the only way that you can do if else statements uh within terraform but it works out fine and so it's actually using the ternary style of if else so what that looks like it's a single line so the it starts with a question mark so that's the if and then it's the true value and then the colon represents the else and then you have your false value it's ternary because there's three things one two and three okay so that's the way i remember uh this thing it's not a a preferred way of doing ifl statements in other languages because it is a little bit condensed but it makes sense when you're using scripting language and you're really restricted on per line actions so this is what it would look like in action so we'd have a variable that is a if a does not equal blank then use the variable or set it to default a as a string so that's kind of an example there just wipe that away there the return type of it of the if and else must be the same type so if you have a number okay and the one if statement and then you have a string they have to be the same so uh obviously we want a string to be returned in both cases so what we'll do is use this builtin function to string to turn this into a string so that we're not going to run into any problems so there you go all right we're taking a look here at four expressions and so these allow you to iterate over a complex type and apply transformations a four expression can accept as input list set tuple map or an object i want to distinguish this between for each which is a resource meta argument which allows you to iterate over a a resource or a collection of resources that are similar but four expressions are for these primitive types or not these primitive types but these collection structural types that we talked about in types and values okay so here's an example of something we might want to do imagine we have a list of names and we want to iterate through our list and make them all uppercase so we could do that with this four so we have the four with the in and then we're providing the value of each item in our list uh it's easy to think of list or tuple as an array so i'll just call it an array okay then you have a map and so this is where it has a key and value this is going to be for maps or objects and the idea is that we can then go apply transformations and notice that we are returning only a single string so we're actually going to get back something like a tuple and so how does it decide whether it returns a a array or something that looks like an object we'll explain that here in a moment the last one here is we have a list with an index so it's very similar to the first one but in this case we want to know the index here so imagine this says zero is andrew one is cindy two is peter and it would come back as an array or list so let's talk about the return types the return types are defined by the um the braces or brackets that are around the actual expression so if you have square braces we're going to get back a tuple so let's just think of an array so for in this case where we had our list it was returning back a tuple okay if we have curly braces it's going to return an object so here we have a list so it's like an array that's coming in here and then we're specifying as the return uh this kind of object structure and so that's how we're going to get that so that's that there's one other thing we want to mention which has to do with reducing or ordering so an if statement can be used uh to reduce the amount of elements returned so in this case what we're doing is we're using an if statement and so we're saying unless this is true so if this is true then return if it's not then return less of what is there so if there's any blank names that are in our list they just won't show up it'll just only show names that are actually there then we have implicit element ordering so since terraform can convert an unordered type so map objects and sets to an order type list or tuples it will need to choose an implied ordering so for maps and objects they're stored by key a to z set of strings stored by a strings a to z everything else is going to be arbitrary ordering so there you go all right we're taking a look here at splat expressions and these provide a shorter expression for the four expression which we just looked at so what is a splat operator a splat operator is represented by an asterisk it originates from the ruby language and splats in terraform are used to roll up or soak up a bunch of iterations in a for expression so here is an example where it's for list sets or tuples so here we have a list and the idea is that we're iterating over uh this id or in this case we're iterating over um it's objects or sorry a array and then that array is containing a bunch of objects and so we're accessing the name within it and so instead of writing it like that we don't even have to use a 4 at all what we can do is put this asterisk here and this is going to equate to the same thing so here this is going to return all the ids and in this case it's going to return a all the lists and allow us to access the interfaces along to the name okay so let's take a look at splat expressions uh when we're applying them to lists so if the value is anything other than a null value then the splat expression will transform it into a single element list if the value is null then the expression the then the split expression will return an empty tuple and so this behavior is useful for modules that accept optional input variables whose default value is null to represent the absence of any value to adapt the variable value to work with other terraform language features that are designed to work with collections so i know that's a big mouthful it's just kind of like an edge case to these splat expressions this is not going to show up on the exam but i just wanted to show it to you in case you're interested here and just notice the splats being used over here okay so we're taking a look here at dynamic blocks and this allows you to dynamically construct repeatable nested blocks so i want to emphasize that this is a very powerful feature that can lead to abuse where your code becomes difficult to read but it's also very flexible it will absolutely show up in the exam so pay close attention on how this works so let's say you needed to create a bunch of ingress rules for your ec2 security group and so this would lead to a lot of repeatable elements for rules within your resource and so what you can do with dynamic blocks is you can define objects locally so here i have my ingress rules as an object so here's one and here is two and then using dynamic block what i can do is use a 4h to reference those ingress rules and within this dynamic ingress block we'll have our content and this will specify the things that we're swapping out so the idea is that it will iterate over this and apply all those values there so it's something you can't do with a 4h or a count this is basically the the most advanced iteration but just understand if you remember this use case and it's very easy to understand or remember how to use it when you're doing an exam okay we're looking at version constraints so terraform utilizes semantic versioning for specifying terraform providers and module versions so semantic versioning is an open standard on how to define versioning for software management so you have your major minor and your patch and so here are examples or variants on this here so we have um you know where you see major minor and you can have this rc this rc1 or you could not have it or you can have beta and this can all be read about on the semver.org but just to quickly go through it major version is when you want to make incompatible api changes minor is when you add functionality that is backwards compatible in manner patch is when you make backwards compatible bug fixes there are additional labels for prerelease build metadata that are available as extensions so that's where we see those little additions there at the top a version constraint is a stream containing one or more conditions separated by commas so you have your equals or no operators or sorry your equals or no operators so match exact version of the number so it's either with the equals or not with the operator at all okay that's what i'm trying to write there excludes an exact number uh version so if we just said does not or will not be uh 1.0.0 then you have a comparative one so that the version has to be greater or equal to 1.0.0 um and then we have one with the tilde so allows only the rightmost version of the last number to increment so what this means is that the the last number here um is only allowed to increment okay so let's talk about progressive versioning because this kind of ties into semantic versioning but progressive versioning is the practice of using the latest version to keep a proactive stance of security modernity and development agility and we like to describe this as practicing good hygiene when we're uh working with our code okay so by being up to date you're always pushing left on things that need to uh stay fixed or compatible uh you'll have to deal with smaller problems instead of dealing with a big problem later on run nightly builds is a good example where you might have golden images and the idea is to provide a warning signal just to kind of elaborate on that a nightly build is an automated workflow that occurs at night when developers are asleep so if the build breaks because a change is required for the code the developers will see this upon arrival in the morning and be able to budget accordingly so what i'm trying to get at is that when you are like putting in your providers especially if you copy from the terraform the terraform website to get the providers and modules what they'll do is they'll actually have it set as the i'm just going to roll back here for a second but they'll actually have it set as the equals what i'm saying to you is you want to use something like a tilde or a greater than or equal sign so that you are staying progressive okay so that's just one thing i want you to watch out for and we will talk about that when we go through the fall alongs okay hey it's andrew brown from exam pro and we are moving on to our expressions section starting with string templates let's learn all about that and we are going to have to cd into a new folder here so i have one called expressions and we will make ourselves a new file called main.tf we'll define a local backend and i'm going to just define a new variable i'm going to call this variable hello and i'm going to give it a type of string okay and that's all i'm going to do there and then what we're going to do is create ourselves a tf var file so we'll say terraform dot tf vars and then there we'll just set hello to world and so what i want to do is enter terraform console okay this is going to allow us to just run arbitrary expressions i want to show you how you quit it you just type exit and so we'll do is make a string so we'll just first do a hello world i want to show you that you can put a uh a new line there and we'll get back a multiline document this is uh um this console doesn't allow for multiple lines so we can't write our own here doc but i can show you what it looks like and then we can interpolate a uh a variable there so we'll just say hello and notice we get hello world so that's how interpolation works it's not super complicated uh directives is a little bit different where we have string right so we can do instead this but the control word's a bit different because you're using the uh this um percentage sign the directives when you're doing something like an if else statement so what we could do is say something like barsoon here okay and what i'm going to do is just exit out here clear so i don't know if it um it reloads the uh the variables there if you just change them on the fly but what we'll do is we'll just say hello and we will write ourselves an if statement so we're going to say if var.hello equals bar soon what it's going to do is then print out um it's going to instead print out mars okay otherwise what we're going to get is um world okay and you know what's really interesting is we're using the if and else here but i i could have swore that the only thing you had was ternary operators so like if you look at the um conditional expressions notice here that it's doing this and it's not showing the documentation the efl so you know maybe maybe that's just for a oneliner and if else does exist for expressions and i might have missed that in the course but you cannot blame me if the documentation shows it like that okay so what i'm gonna do here is just go ahead and hit enter and here we get hollow mars so that pretty much uh shows you how string interpolation works um for both interpolation and directives we'll just type it exit and so that's all we want to do there okay all right so let's learn about four expressions so four expressions allow us to kind of iterate over something and do something fun with it and so what we're going to do is create ourselves um some more complex types here so how about instead like this was just hello a second ago we'll change this over to worlds and what i'm going to do is just list out a bunch of worlds here from the uh the book uh you know john carter books so we have barsoon we have jasooom we have things like sesum okay and then we have oops so assume and then we have something like cosum okay and so the idea here is now that we've defined that there we've got to go back to our main tf i'm just going to update this to be worlds this will just be a list all right and so what we'll do is make our way over to terraform cloud or sorry terraform console and we'll try to do a for loop here so i'm going to do square braces for and we'll just say w in var dot worlds and then what we can do here is make a colon whoops okay and then type upper w and so that returns them all in upper case there and if we were to use the splat operator and technically this is something we want to move on to the next part but um yeah we'll leave it for the next video i'll just keep that separate so that is for just if we had a list imagine if we had this as the as an index here or we'll say map because what we can do is actually map these two names so bring this down here and this would be earth now you can use the colon or the equals just whatever you want to use here they're both supported actually this is an earth this is mars and then this one here is earth and this one here would be jupiter and then this one here would be venus okay um and so i think we still need to define it over here so i'm just going to say worlds map and then what we can do here instead of having lists we can say map and we'll try to iterate over this so it's going to be very similar except the difference is now we have a key and we have a value and so if we just want to return the names in capital we can just do k here oh that's the index uh what if we do oh you know why it's because um we have to do worlds map okay so reference to undeclared variable map so we do have to exit and restart and oh sorry the input was complaining there so i'll just copy the one up here so i have to type it again nope it did not work as we thought okay so i do have to type it by hand kind of a pain but i guess that's just how it works so we'll say 4k v in var dot worlds map and then we say upper b here okay or we could just say take the k here and get the other values now i didn't show you this a moment ago but if we do worlds here we can specify an index and an index would come first so it would be the value like the world the second and the index is first so notice that i is all a number the index of it and then the that is the value there um we could probably also return this as a map so notice that square braces are going to give you a list or and then curlers are going to give you map which kind of correspond to their actual data structure so if we wanted to turn this into the opposite here what we could do is just say we probably do stringer interpolation like this here and do i and then do equals or even maybe a colon here and then do the world like that and it didn't like the way i specified it so i'll try it like this instead extra characters after line four so i don't see that wrong there just give me a moment i think um oh you know what it's we need to use in this case i think we have to do it this way okay so you use the hash rocket so in that particular case you have to use the hash rocket that's what that symbol is called the equal zero um and so that's how we can get that value there so that pretty much outlines how to use um the for loops and next we're going to go probably look at the splats okay so i'll see you back here in a moment i'm just going to exit this actually before we move on to splats i just want to add one more thing to four expressions which is filtering so we'll just go back here and get back into our terraform console here and what i'm going to do is write another four and it probably would make sense to use the uh the the world's list we just did there so i'm going to do kv type in var worlds map and so the idea here is that i only want the let's say we'll say the upper i only want the key value here but i would just say at the end here i can say if the v the value equals and i can't remember what we set these as so this is key in value so if it is mars i think it's double equal so if it is mars then only return it that way or we could say the opposite say give me everything but mars okay so i just wanted to show you could use that if to do that filtering so i'm going to exit there and we'll move on to splats okay all right so we're moving on to splats and what we'll have to do is create ourselves a new variable here i'm going to call this one worlds splat and this one is going to be a list and so if we go back up here to tf vars we'll make ourselves a new variable down here and we'll just call this one splat and it's going to be a list but it's going to contain inside of it a bunch of maps okay so we'll do pretty much this up here okay um but what's going to happen here is going to be slightly different where we are going to set um one is the name so we'll just say like um earth name that's actually mars name so it's a mars name here for all these and then over here these are going to be earth name so i think that is valid and what we're going to do here is just type in terraform console and if we wrote that correctly oh no we got an error so it says expecting an equal sign to mark the beginning of a new attribute value so i mean this should be okay uh oh you know what i think this colon is just missing here that up again there we go we're fine so if we just want to look at that variable i think we just type it in here and it might print it out for lucky yes so there it is um so what we're going to do here is use a splat to get maybe the mars name or something so if we used a for loop but we'd have to probably write we could try this but we'd have to do four and then it would be for the actual map so say m for map in worlds splat and then we would have to do m dot mars name and so a reference to the attribute by one access trigger specifying the resource name so i mean that looks oh you know it's because we didn't write var okay i say we but it was really me um so you know that's that but we could write this in a more concise way okay so we use the splat mars name okay so you know that's a lot more convenient if we're just trying to access variables like that um i think that if you're trying to do things like if you want to do upper here i think you still have to use a four expression okay i don't think you can do this we could try it but i really don't think that will work no and if we look at the documentation they don't show an example like that so you know it's not that bad but you can see that it's for a particular use case you can't use that for maps or whatever the equivalent the other map is object but it's useful for this one particular use case okay hey it's andrew brown from exam pro and we are on to the dynamic blocks follow along so this one should be uh pretty fun because it's uh quite a powerful feature so what i've done is i've created a new folder here called dynamic blocks i'm going to make a new file here as always it's going to be main.tf and a really good example for this would probably be a database security group just because there's all those ingress and out outgress or egress rules so what we're going to do is just define our terraform settings block and i'm just going to pull up over here and make our way over to the registry for terraform and what we're going to do is go over to the airbus provider and um go to the documentation and actually i first want to grab the provider itself because that is something very easy that we can do here we'll just move that on over so we can see what we're doing and paste that on in and we're going to have to define our provider of course so we'll name that as aws the profile is going to be default and our region will be us east1 okay and so now what we need is to go create ourselves a security group so we have of course done that previously here but let's pull up the documentation here i believe it was actually under vpc so let's just go down to vpc here and we will expand that and then underneath here there should be aws security group there it is and if we scroll on down there's the thing okay so what i'm going to do is copy uh this code here and go over and we'll just paste that on in and there is our security group so i remember that we had to have the description remember it complained about that so outgoing for everyone and uh we need to also have a few additional things we will just scroll on down here because it wanted the prefix list ids okay remember we needed that um i think there was like self false and there was like security groups i think was actually eight of security groups in particular let's just double check to make sure that is the case it is called uh oh it's just security groups okay so we'll say self equals false we do not need cider block 4 here or 6. we do not need this one here and it doesn't really matter what we set this to so it could be set to the main cider block that's totally fine but we are going to need to add a data source just like last time for the vpc so let's say vpc we'll call that main and i think it just needed the vpc id it was as simple as that and so we will go over to aws over to um dpc and from there we are going to go to rvpcs and i will go grab that vpc id okay so we've grabbed our vpc id and then we just need to name this as data and then we're going to name this as data we don't really care what the cider block is it's just again for this demo purposes we don't need tags we'll take those out and um yeah everything else is fine okay so this now comes to the fact that we want to uh use dynamic blocks before we do that let's just well i think i didn't leave the console there last but what we'll do here is just do our terraform init and as that is pulling that stuff we're going to look up dynamic blocks terraform so we'll go here and so dynamic blocks is like way more powerful than the 4h where what we can do i'm just trying to find that example there but we have uh we have to set the dynamic part the for each you know i'm pretty sure i have these in my slides so let's just use my slides as the reference here dynamic ah here it is okay so the idea is that we'll just set up a locals with all of our information here and then we'll create this dynamic block and then provide the content okay so i'm just gonna move that off screen so i can see what i am doing here as we type it in and we'll see if we run into any problems um failed to query the available pro packages could not retrieve the list of available versions for the provider not have a provider registry terraform name all modules should specify the required providers so i'm not sure why it's complaining here but we'll scroll all the way to the top and the required providers is correctly set here so it shouldn't be a problem not sure what it doesn't like um so we'll just type in terraform providers here the vpc um is vpc a module you know what it's probably because i didn't do aws vpc that's probably my problem here terraforming it and as that's thinking there we'll just pull this on down and we'll start to make our locals block okay so we can go here make some locals and we'll do our ingress and we'll just go like that and the idea is we can say port whoops we can set the port like that 443. uh we have to always have a description so we'll just set that as well so port 443 we can set as much as we want here so i'll just go hit enter okay and i think that looks right yeah so we have one ingress here and then we'll just copy this and make a comma vs code's not really formatting the way i wanted to and so we'll do port 80. and then down below we will need to specify our um for each okay so that's going to be within our dynamic block so what we're going to do is tab in here i'm going to say dynamic and we'll type in ingress because that's a match for what we're doing and then from there we can do our for each equals local ingress and then we need to specify our content i don't really understand why it's called content and things like that but i just know that that's what we have to do and it's not really that big of a deal um so we'll go here and paste that in we can take out our ingress block there we know we're going to need self these all here but what's going to change are these ports so we will go here and we'll say ingress value port and this will also be ingress value port and then this will be ingress value description if we really wanted to we could also set the protocol protocol pro to call and this could be then tcp and so we just say ingress value protocol so it just saves us from repeating these over and over again if they're all the same there's a lot you can do with uh dynamic blocks but honestly you shouldn't do anything too crazy we'll do our terraform plan and see if this works whoops bring that up there um an argument vpc id is not expected here okay so that was me just guessing from memory and i guess i guessed wrong so what we'll do is we'll just look that up database vpc data source terraform oh it's just id okay so what we'll do is just set id here and then we'll just hit plan again that should resolve our issue there uh inappropriate value for attribute egress security groups is required okay that's fine well this one uh it says doesn't say uh serious groups and this one doesn't say security group so that's probably our problem here so we'll just hit terraform plan again and here it says this vpc id does not exist probably what happened is they might be in the wrong region it's a very common problem on aws just because of the way their ui works if i can get this window over here and so this is because we're in usd we're supposed to be in usc 1 here and i'm going to go up to here we will save that i'll hit teraform plan and we could probably like use the filter and also just say choose the default but it's just so easy to put that in like that um so it doesn't seem like we have any problems serious let's go ahead and execute it let's just double check to make sure these values are correct so for the ingress um port 443 port 443 it's probably just because i didn't update the description probably because of a copy paste job yep okay and let's just make sure this works so we'll say terraform apply auto approve and we'll give it a moment and it's already created so it's that fast we can go here and take a look at it if we like it's not that big of a deal um so we should see it in here i just have so many uh junk security groups here this is a bit hard to find oh allow tls is what we called it so here it is go to our inbound rules 80 443 and that's pretty much it so terraform apply destroy auto approve okay and there we go all right so i want to talk about versioning very quickly here and so i have a new folder called versions i'm going to make a new file called main.tf and we're going to create a terraform block but what we're also going to do is set required uh providers or sorry required uh we're not providers required version and so what this is going to do is say explicitly what version of terraform we want to use and i'm setting it this as 1.0.0 and i'm using this tilde arrow if you're wondering you know what is the logic behind all those things i think it's all explained in the semantic or semver.org so if you want to learn more i strongly recommend you read through this to understand all the stuff inside and out highly applicable across the devops sphere not just to terraform um but you know if we go over to terraform github repository and we drop down the branches and go to tags here we can see all the versioning we are using version 1.0.0 and uh gold goes up to 1.1.0 alpha which is not out yet and if you wanted to really know what's going on here you go to releases and you can read what they have done so here 1.0.7 remove check for computer distribute prevent object types with optional attributes for etc empty uh containers so when you're looking at the patch the patch which is the third number the the right most number that's going to keep you up to date in terms of security for the the major minor version that you have for the 1.0 and you absolutely always want to be using the latest and so that's what this tilde does it says take the the far row uh the the farthest number to the right and make sure it's the latest version that has been published and you know this comes back to my progressive versioning slide which is if you want to have really good hygiene in terms of your devops what you should be doing is at least setting the tilde for sure like this the tilde arrow or i would even go as far as saying equals arrow and if you're really concerned about um you know not using the next major version you could say you will less than you know like less than um less than uh you know one point two point zero even if it's not out that's a good indicator to say okay well i don't wanna go too far ahead of time but if you wanna have progressive versioning you should really be setting it like this okay um and this is going to be applicable for your abs providers um anything else so you know if we go over to um if we go over to the registry and we choose whoops aws and we drop this down here we have that required version as well so as you copy it in you're going to notice that it's actually hard coded but i would strongly recommend again if we go here and take this and at least at least do this uh and if you're really really being clever you could do that okay and these are also all in github repositories as that's how everything works so you can go here and click and you can go over to the tags and see the versioning and you can go over to the releases and it's the same thing you can read about all the things that have changed okay and that's something that you should uh you know consider doing all right so that's all there really is to this uh i might want to show you one more thing and this one is with terraform cloud so i'm going to go to terraform io and we're going to open up our terraform cloud and i'm going to sign in i probably haven't signed in a while so i'll probably ask oh no no username and password that's great what we can do is in a workspace we go to settings and is it version control no it is general and under here we can actually set the terraform version so if you happen to be working with a particular version uh you can go and say okay only use this version for terraform cloud and that will um that will not upgrade it'll just keep you there if you need for legacy reasons but again you know what you really should be doing is um using that progressive versioning doing nightly builds and discovering overnight that things are breaking so you can go fix those in the morning okay and that's it hey this is andrew brown from exam pro and we are taking a look at terraform state so what is state well it's a particular condition of cloud resources at a specific time so give an example imagine we expect to have a virtual machine running centos on aws with a compute type of t2 micro that would be the state that we are expecting okay so how does terraform preserve state well when you provision infrastructure via terraform it will create a state file named terraform tf state it's very important to remember that name because it literally is an exam question the exact naming of that okay this state file is a json data structure with a onetoone mapping from resource instances to resource uh or to remote objects and if you're wondering what is a remote object versus a resource instance i cannot tell you i would imagine one is a representation of things that are deployed in the cloud and the other one are objects or or things represented in the state file but they don't clarify it so i just have to take a guess so this is kind of what the json structure looks like you can see you see resources this is describing like a type of instance and stuff like that there's not really any case for you to ever go through the terraform state file and look at it but we might take a peek just so that we get familiar as to what it is doing so just to kind of give a diagram to help you visualize this imagine you have your configuration file so you have your main tf maybe a variables tf a tf vars to load in your variables and then you run a terraform apply command what it's doing is using the terraform api and it's going to create what we'll say these we'll call these remote objects but maybe these are resource instances but uh it will go ahead and create those things and then those will get represented within a state file so the idea is that whatever is in the cloud is going to match what's in that file okay now there is a cli commands for terraform state and it's good just to quickly go through them so we have terraform state list this will list resources in the state terraform state move this will move an item in the state terraform state poll poll current remote state and outputs to st out terraform state push so update remote states from a local state terraform state replace providers so replace a provider in the state terraform state removed so remove instances from the state terraform state show so show a resource in the state some of these are a little bit interesting so we'll definitely look in greater detail to move and some of these we will just explore through our follow alongs okay okay so we're gonna give special attention to terraform state move because it's definitely on the exam uh and it is a little bit interesting to what it can do so terraform state moves allow you to rename existing resources move a resource into a module move a module into a module so if you were just to rename a resource or move it to another module and run terraform apply terraform will destroy and create that resource but state move allows you to just change the reference so you can avoid a create and destroy action so an example for renaming a resource we would have terraform state move and then we would have the we would identify the old one so here we have packet device dot worker and we are renaming it to helper so it's we that's just how we're doing it okay if we wanted to move a resource into a module what we do is say something like packetdevice.worker and then do module.worker.packetdevice.worker okay so the idea here is that we're moving it into this module here uh and i think we could probably even rename it at the same time but we're not doing that okay so move module into a module so here we have module app and then we're moving it into the parent one so we go module dot parent module dot app okay so what's important to remember for the exam is that terraform state move is when you want to rename existing resources they're not going to get into these more complicated use cases but that's how you rename a resource okay okay let's talk about how we backup our state file so all terraform state sub commands that modify state will write a backup file so read only commands will not modify it so imagine listen show will not cause a backup file to be created terraform will take the current state and store it in a file called terraform.tstate.backup so this is what it would look like backups cannot be disabled this is by designed to enforce best practices for recovery to get rid of the backup file you would need to manually delete the files so there you go hey this is andrew brown from exam pro and we are on to the terraform state follow alongs and these are honestly just all about the terraform cli commands as we do cover terraform state throughout this course in a variety of different ways so you can't just really contain it to this one little section here but let's go explore these things and so i have a new folder here on the left hand side and as always we're going to go ahead and create ourselves a new main.tf file and we need to just provision something and so we've done this multiple times over so i'm just going to go back here and i like to always go back to the count one because i find this is the easiest one to update and we will go down here into our terraform state file and while the it's not our actual terraform state file but our main file here and we will go and get rid of the account here so there's just a single one and we will just say my server okay and i think everything else is fine this is all good and so we just have to make sure we are in the correct directory and i'm going to do a terraform in it okay and we'll just give that a moment there and once terraforming it is happy we're just going to go ahead and do an apply because we do need a state fault to be able to do something right great so what we'll do here is just type in terraform uh apply and then we will run um auto approve okay and we'll just give that server a little bit of time to provision there that script and i'll see you back here in a moment okay all right so after a short little wait there our instance is provision and now we can go ahead and do some terraform state cli stuff so just waiting for my console to be a little bit responsive there great and so what i can do is type in terraform state and it's going to show me a bunch of commands i can run so we got list move pull push replace provider remove show i haven't much found a use for push or pull but definitely list move and show or something that we want to look at we could also give remove a try but i don't find much reason to use that so let's do the first one which is terraform state list and what that is going to do is it's just going to tell us what instances we have there or resources we have provisioned of course if we had a lot more this would be a pretty big list if we do show it's not going to show us anything because we have to specify something so we'll do aws instance and we'll say my server here and so we should get a lot more detailed information here okay so just going to pull this up here and as you can see we are getting all that information about that resource there if you wanted to rename something that is a something you're definitely going to want to know for the exam and that's where we use the terraform state move all right the way you should think about it is kind of like how bash has moved that's the way you would rename things there as well so imagine that instead of being called my server we wanted to call this uh our server i don't know and so if we wanted to rename it like that then what we'd have to do is type in terraform state move and then we would type the old name so adabus instance our server and then from there we would say aws instance oh sorry the original one would be my server and then we would do aws instance our server okay and so it says move database instance my server to our server so if we were to open up our state file here okay and we were to take a look at the actual name so we just look at our server you can say that resource has been renamed the only issue though is that just because we've renamed it here and we've moved it within our state file does not mean that these changes are reflected um actually uh in our in our system actually nothing really matters because it's just a name but let's go see what happens if we do a terraform plan okay i don't think it would matter but we'll find out and so down below i mean that's just a syntax error because we have changed the name so this is now our server right and we'll just do terraform plan here so terraform has compared your real infrastructure against your configuration found no difference so no changes are needed because like the logical name that terraform is using the the our server is just something that's within the state file it's not like any of those changes are reflected on the cloud on the cloud provider so there's no need to change anything there so you know that's pretty much it um you know if we go back to just terraform state here we do have replace provider i'm pretty sure i have used that one before let's go take a look at that really quickly terraform replace provider so the command will update all resources using the from provider setting the provider to the specified to provider this allows changing the source of a provider which currently has resources in state so that's kind of cool um so i guess this one here we see we have a hashicorp aws to the registry acme corp act media bus i don't know if we really have much cases for this but i guess here the idea is that if you had forked because all these are public facing right so if you forked it and made your own changes that could be a case where you'd want to do that there right so that's pretty much it uh whoops that's pretty much it there um so there you go oh and as always we have to make sure we tear down our resource there so i'm going to type in terraform apply auto approve destroy and there we go so i'll see you in the next video okay hey it's andrew brown from exam pro and we are taking a look at terraform init so it initializes your terraform project by downloading plugin dependencies so providers and modules creating a dot terraform directory so that's a hidden directory and creating a dependency log file to enforce expected versions for plugins and terraform itself so on the right hand side here we can see we have that hidden directory but also notice here that we have a terraform lock.hcl that is our dependency lock file uh and so our dependencies are all going to end up within this um see where it says providers that's the provider version there okay so terraform init is generally the first command you will run for a new terraform project if you modify or change dependencies run terraforming it again to have it apply the changes you need to know that for the exam because they will absolutely ask you that the first command here is uh and these are ones with flags so you can just do terraform in it but we have some extra options so terraforming it hyphen upgrade upgrade all plugins to the latest version that complies with the configuration version constraint terraform init hyphen get plugins uh uh and i think it's supposed to be uh equals false there but skip plugin installation terraform init plugin hyphen dir equals path so force plugin installation to read plugins from only target directory and then we have terraform init hyphen lock file so you can change the lock file mode it actually doesn't say what the modes are so i don't even know what you do in that case and i could not find examples but it is an option i just want to make it very clear that there is a dependency log file but there's also a state lock file and the way you know that they're different is that one has dot lock in it and the other one has dot tf state this one up here is for dependencies this one of course is for state a terraform init does not create a state log file that is going to happen when you do a terraform apply okay let's take a look at terraform get so terraform get command is used to download and update modules in the root module so when you're a developer you own terraform modules and you may need to frequently pull updated modules but you do not want to initialize your state or pull new provider binaries and so the idea here is terraform get is a lightweight way because it's only updating the modules it's not pulling providers in most cases you want to use terraforming it with the exception of local module development this will not show up on the exam but i saw terraform yet i was just so confused about it so i just wanted to make sure i included it here okay okay so we're going to be looking at three cli commands that are used to improve debugging configuration scripts the first is going to be terraform format this rewrites terraform configuration files to a standard format and style terraform validate this validates the syntax and arguments of terraform configuration files in a directory and then you have terraform console an interactive shell for evaluating terraform expressions and so let's go jump into these three okay all right let's take a look at terraform format so this command applies a subset of terraform language style conventions along with other minor adjustments for readability so terraform format will be uh by default look in the current directory and apply formatting to all your tf files so let's look at some examples of what it would format so the first is adjusting spacing two spaces indent so here we have something and it's over indented and so by running terraform format it fixes the indentation we can also get syntax errors so notice here that we have a problem and so what it's saying is is that this bracket okay is supposed to be up here okay but it's all it's down here and the last one here is we can do terraform format hyphen hyphen diff that's going to show what it would change okay so there you go let's take a look at terraform validate so this runs checks that verify whether configuration is fantastically valid and internally consistent regardless of the provided variables in existing state validate is useful for general verification of reusable modules including correctness of attribute names and value types so here's an example where i just had some code and there was a problem it's just saying you're missing an argument because for a database instance you always have to specify an instance type so when you run terraform plan or terror from apply validate will automatically be performed one thing i need to mention about terraform validate is that it does not go to external resources to check things are valid so if you have a a value and it's expecting a string that's all it's going to check for it's not going to check that the string is actually a proper uh like type of size so if it's supposed to be like a t2.micro and you write you know gobbly goop in there it's not going to know that that's not a valid type so but we do cover that in the fall longs and i think we have like some practice exam questions that cover that use case okay we're taking a look here at terraform console and this is an interactive shell where you can evaluate expressions so the idea is you type in tariff or console and what i can do is i can you know use like builtin functions and expressions so there i'm using min and i've actually entered it in incorrectly so there it's throwing an error and here i'm using the correct way of using it so i get the output so this is a great way just to kind of test very simple things um you can't do things like define variables or or resources or define providers but you if you need to figure out how the expressions work before you apply them in your code this is a great place to do that okay all right let's talk about terraform plans so this command creates an execution plan also known as a terraform plan and it consists of reading the current state of an already existing remote object to make sure that the terraform state is up to date comparing the current configuration to the prior state and noting any differences proposing a set of change actions that should if applied make the remote objects match the configuration and so this is an example of one that is generated you're going to see it uh throughout this course multiple times so it's not going to be unique that's why i don't have to make that too big for you there terraform plan does not carry out the proposed changes that's going to be the responsibility of terror form apply and a terraform plan file if you happen to generate one out is a binary file so if you open it up it's just machine code you cannot make sense of it okay so when you run terraform apply you have speculative plans and save plans and so speculative plans is what's going to happen when you run terror from apply so the tariff so terraform will output the description of the effect of the plan but without any intent to actually apply it when you have a save plan you're going to have this hyphen out flag to save it and you can name that file whatever you like and it will generate out that save plan file and again that's a binary file so you're not going to be able to see what it does and what you can do is then pass it along to terraform apply so you do terraform apply whatever the file name is and when you are using terraform apply what you have to understand is that it will not allow so it will not ask to uh manually approve it as you normally would it would just be auto approved so that's one thing you have to watch out when using those safe plans but you know i just wanted to make it concretely understood the terraform plan can generate a file and it's not actually the one that's doing the apply okay i don't have it written in here but when you do terraform apply it also is running terraform validate as well okay let's talk about terraform apply here so terraform apply command executes the actions proposed in an execution plan and it has two modes the automatic plan mode and the saved plan mode so for automatic plan mode that's just when you run tara from apply what it's going to do is execute the plan validate and then the apply you can or you have to manually approve the plan by writing yes but if you want to skip that process you can use the hyphen auto approve flag to automatically approve the plan we just saw save plan mode like how it worked in the previous slide but let's cover it again so when you provide a file name to terraform to the save plan file it's going to be terraform apply file and it's going to perform exactly the steps specified by that plan file it does not prompt for approval so if you want to inspect a plan file before applying it you can use terraform show okay hey this is andrew brown from exam pro and we're going to be taking a look at speculative plans and save plans just a little bit more in detail there's not a lot to talk about when we're talking about speculative plans because we've been using them throughout that but we'll just contrast them against the save plans and just how you would actually use them with the apply this stuff isn't super complicated but what we're going to do is make a new file here i'm going to call this main.tf and you know what i'm just going to go ahead and grab our code here from the last one to for the state file there and we'll go up and i'm just going to rename this back to my server and we'll save this as my server and there's only a single instance so i'm just going to take out that there i'm going to cd back there and we're going to make our way into the plan and apply i'm going to do a terraform init and we're going to wait for that to finish so you know we've been seeing speculative plans throughout all the follow alongs and that's just where it's going to show you that information but we can also save that uh that plan out to a file i don't think there's a particular naming convention for the file it just has to be named as something but we'll give it a moment here for this to initialize and then we'll do that with the out command okay so what i'm going to do is just type in terraform plan hyphen out and then we can give it whatever name we want probably it'd be good to name it like dot plans that's what i'm going to do here and so i'm just going to call this my save plan okay and what that will do is output that file in a moment here so it ran and then it output it if we open it up notice that it's a binary file so we can't actually um inspect it in any way but if we are happy with the these here what we can do is type in terraform apply and then we can just provide it the name my saved plan dot plan and hit enter and so what it should do is just proceed to deploy and it won't even review it should just deploy at least that's what the documentation says so hopefully it does not contradict what happens here okay notice that it's already carrying out the the action so uh you know save plans would be really great if you are setting up a um like a tool to review so this kind of makes sense when you're looking at terraform cloud and it it applies the plan and then you proceed to the next step where you accept the apply i would imagine that they are using that but i guess when you're using a ci cd pipeline that's something that would be really useful but anyway we're going to let this finish creating and then once it's done we're just going to destroy it but that's pretty much all i wanted to show you was the fact that you can use the hyphen out command to output that stuff so we'll just go here and type in terraform apply auto approve and destroy okay and we'll give it a moment there and we're all good so i'll see you later all right let's talk about managing resource drift so drift or configuration or infrastructure drift is when your expected resources are in different state than your expected state and the way we can resolve drift are in three different ways in terraform we can replace resources so when a resource has become damaged or degraded that cannot be detected by terraform we can use the hyphen replace flag we can import resources so when an approved manual edition of a resource needs to be added to our state file so we use the import command and refresh state so when an approved manual configuration of a resource has been changed or removed we're going to use the refresh only flag to reflect the changes in our state file it's very important to know these three different ways they will all show up in the exam and in practice you're going to need to know them okay let's first here take a look at replacing resources so we can use the terraform tank command it is used to mark a resource for replacement the next time you run apply and why would you want to mark a resource for replacement well the idea is that um you know and here's the command here but a cloud resource becomes damaged or degraded and you just want to return the expected resource to a healthy state so that's the idea behind it and the unfortunate thing is that terraform taint was deprecated in version 0.152 however there is a better way of doing it now and so it is recommended to use the hyphen replace flag and providing it a resource address when you're doing a terraform apply so it's basically the exact same thing the reason why they made this change was so that um you actually have an opportunity to confirm your change beforehand because terraform tank would just run and this one down below will actually prompt you to say are you sure you want to do this okay but it's not complicated you just do a hyphen replace and then you use the resource address of the thing that you want to um uh use that for and this can be used for both plan and apply uh the replace flag appears to only work for a single resource so you can't use multiple resources it's just one at a time and that's something that you should remember okay so we just saw a resource address and resource addressing is very important to know for the upcoming command so let's just give it a bit more attention here so resource address is a string that identifies zero or more resource instances in your configuration an address is composed of two parts so the module path and the resource path and just expand out that module path it would be module.modulename module index and then on the resource spec this is resourcetype.resourcename and then if there's multiple instances you give it an index so modulepath addresses a module within a tree of modules a resource spec address is a specific resource instance in the selected module so a module is the namespace of the module module name is userdefined name of the module module index when the multiple uh so when there's multiple specifying index on the other side that's your resource type your resource name and instance id uh most of the times you're going to be just working with resources but once you start getting to modules it becomes pretty simple it's always going to be module period because that's just i think that's the name of the name value so it's always going to be module dot and then the module name but here we have a very simple example just for resource type so here if we had a resource called abus instance and it was web and there was four of them and we wanted to select the third one we'd do aws instance dot web square braces three and that would get us the third virtual machine so there you go okay let's take a look here at terraform import and this is a command that is used to import existing resources into terraform so this is how you define it so you'd say what resource you want and uh you can just leave it blank so you define a placeholder for your imported resource and configuration file and you can leave the body blank and fill it in after importing but it will not be autofilled so you do have to specify all the values okay so the idea here is you're going to do terraform import aws instance dot example and then the name of the id so that maps over to the resource address and the id okay the command can only import one resource at a time this sounds very similar to that other command we saw for replace not all resources are importable you need to check the bottom of the resource documentation for support okay okay so we're going to look at refreshing and so we're going to break this between the old command refresh and the new command refresh only across two slides so terraform refresh command reads the current settings from all managed remote objects and updates the terraform state to match so here we have the terraform refresh and i just want to point out that the terraform refresh is basically the alias for terraform apply hyphen refresh only hyphen auto auto approve so you technically have this functionality in the latest version it's just that you can't use the old alias terraform refresh terraform refresh will not modify your real remote objects but will modify the terraform state so terraform refresh has been deprecated and the refresh only and with the refresh only flag like it's been replaced with it because it's not safe since it did not give you the opportunity to review proposed changes before updating the state file so that's why the reason they got rid of it let's take a look here at the refresh only mode so hyphen refresh only flag for terraform plan or apply allows you to refresh and update your state file without making changes to your remote infrastructure just to really make this clear i want to give you a scenario and i want you to pay close attention here to understand the difference because this is so important on the exam and also extremely useful for your daytoday operations so here's a scenario imagine you create a terraform script that deploys a virtual machine to aws you ask an engineer to terminate the server and instead of updating the terraform script they mistakenly terminate the server via the aws console because they don't know any better so what happens if you were to run a terraform apply versus with a refresh only flag so that's what we'll do with and without the flag so without the flag first terraform will notice that the vm is missing terraform will propose to create a new vm so the state file is going to be what's considered as correct and the changes and so changes to the infrastructure will be made to match the state file okay if we use terafrom apply hyphen refresh only terraform will notice that the vmu provision is missing uh but with the refresh only flag it's going to know that the the vm is missing and it's intentional okay so i have a couple spelling mistakes there but the idea is that it knows that the vm is supposed to not be there so terraform will propose to delete the vm from the state file so just the json code from the state file so the state file is considered wrong and changes to the state file will be made to match the infrastructure so hopefully that makes it clear okay hey this is andrew brown from exam pro we are on to the manage resource drift follow alongs and there's three things we want to check out replace import and refresh so what i'm going to do is i'm going to go over to our folder here the the manage resource drift we're going to make a new file as always call it main.tf and i think the contents here is going to be pretty much the same as our last one so i'm just going to go ahead and grab that and we'll type clear we'll back our way out i'm going to just do terraform in it okay and uh the idea here is that we're just going to provision this resource here and we're just going to replace it we'll have to try to import something and do a refresh maybe we'll do replace import or we'll do import last just because that one is a little bit more challenging so we'll just let this initialize here and then we will deploy it and then we'll try to replace it great so that's all good so we'll do a terraform apply and we'll just say auto approve and let that go great and so that is done there and so what we can do is go ahead and replace that instance so the reason we would want to do this is let's say our instance became damaged or degraded or let's just say we in general just want to replace it and actually i think through some of the fall longs we had to use replace in some instances so we've already kind of had some experience with it but the idea is we just type in terraform apply and then we can just do replace and then we give it the database instance um like its resource name here so we just say my server now this used to be called terraform taint and depending on when you set the exam uh you know if it's really close to when i uh when i launched this course then you might still come across questions that are terraform tape but now it's just this hyphen replace uh replace command here and so what i can do is just hit enter i actually don't really want to execute this i just wanted to show you it because i want to move on to the refresh one which is going to take a little bit more time here and just if we scroll on up look what it's doing it just says we're going to replace this so destroy and then re recreate it so this is a great way to to re uh force that now notice when you use the hyphen replace flag you're only able to provide a single resource and that's just how it is so i'm going to go ahead and here type no now let's take a look at refresh so a great example of this is if we make our way over to the vpc console and we go over to ec2 what we're going to do is just um go ahead and destroy this instance okay so somebody came in and let's say you know you're working on your with your team and they and you told junior saying hey we need to destroy the server because it's costing us a lot of money and they get they go okay and they're not aware of all the terraform infrastructure or maybe there's an urgency to uh tear it down really quickly and so they use these uh the ui to do that and so here i've terminated the server but the problem is that my state file still thinks that this uh this exists so give this a moment to get into a shutting down stage there we go and so now what's going to happen if i do terraform apply and i don't know if we have to wait a bit longer for it to destroy there but it's going to check the state and see whether that server exists it's going to tell us what action it's going to take okay so there's no changes so we'll just wait a little bit here okay so i'll just talk to you here in a moment i'm just going to wait for this to shut down okay great so after a short little wait you can see my server is now terminated so what i'm going to do here uh once my console is responsive sometimes it just does this i have to like click a few times to get it to react there we go so what i'm going to do is i'm just going to write terraform apply okay and we're just going to see what happens here so notice that it's trying to add the server because the server is gone right but the thing is is that we actually want the server not to be recreated when we run this again and so the problem is that our state file is not telling the truth it should be updated to reflect the fact that that instance is removed i think this is where we could use the terraform state removed to actually remove it as a resource but another thing that we could do is use the terraform refresh and actually now it's called terraform apply uh reflect refresh only okay and what that's going to do is it's going to check the actual state against uh the actual or sorry the actual the state against the actual resource and notice it's just going to remove it because it says hey you removed this from aws and this is your intention right you actually want it gone so let's go ahead and say yes to that okay so yeah there we go and we'll move on to importing okay all right so now let's try to actually import a resource in here so imagine we've already created something like an s3 bucket and that's what we're gonna do i'm gonna make my way over to s3 okay and we're going to go ahead and create ourselves a new bucket here so we'll say create bucket and i'll just say my new bucket and i'll just put a bunch of random numbers here because these are unique names just like domain names so it's easier if you just kind of like dump a bunch of random things in there and so i want to go down here and just uh oops create this bucket here okay so i have the name here for that bucket which is this one here and so we want to import that as a resource so i'm just going to go over here and type in whoops terraform import we're going to take a look at how we can go ahead and do that so um it's not really telling me much terraform import so i'll just go ahead and type the command i thought we'd get a little bit more information there okay and this is not helping much either so i'm gonna go pull up my handydandy uh notes here because maybe i did myself a favor whoops and i detailed it out and i keep on hitting the same button here and it's just not opening the search okay so we'll go look for import great here it is so um yeah we have to provide the placeholder so that's what we're going to do so just go up here and this is going to be resource um aws s3 bucket i think it is just to go double check that there go over to our documentation look for s3 that's what it is good and this is pretty much all it is it's just the name the resource and the name so i'm sure it's not that hard to type but i'm just going to do that anyway we'll just say bucket and then we need our bucket name that we're going to import so go ahead and copy that and we'll paste it there get rid of that space and so now all we need to do is type in terraform import aws s3 bucket bucket and then we need to probably provide the id and i guess the id is the bucket name here so we'll go ahead and paste that bucket name in we'll see if that takes okay so that bucket is uh being added great and so now what we should be able to do is if we want to tear down that bucket we should be able to do terraform destroy i don't think everything can be imported so there's some things that might not be uh possible to import so we'll go ahead and type yes and it says that it's destroyed and so we will go back here give it a refresh and it is gone so there you go um so we covered them all replace refresh and import so let's take a look here how we would actually go about troubleshooting terraform so there are four types of errors you can encounter with terraform uh the first is language error so terraform encounters a syntax error in your configuration for the terraform or hcl language you have state errors so your resources states has changed from the expected state in your configuration file core errors so a bug that has occurred with the core library provider errors so the provider's api has changed or does not work as expected due to emerging edge cases and when we talk about what's easy for us to solve and what's hard well the first two are very easy and the other two are harder to solve so for language errors we can use format validate or version to uh resolve our language errors version would just say hey what version are we using maybe we need to update it right validate would detect if something's wrong with the the the syntax and format would fix formatting syntax but you know that probably wouldn't fix that much there for state errors the idea here is we might want to use refresh apply replace everything that we saw in the drift section for core errors we might want to go check out the log so tf underscore log is um basically just the way of saying like hey these are where the log files are or is logs turned on we have a whole slide on that but really like all you're going to do is use the logs to find information and and then report a github issue since all terraform is on github you just go there and then somebody would try to resolve it and the same thing with providers so providers are all hosted on github and so you would just use tf logs to try to find some information there but uh we'll take a look a greater look at tf log and how to you know get that information for the harder to solve cases okay okay so let's talk about how we would go about debugging terraform via the log file so terraform has detailed logs which can be enabled by setting the tf underscore log followed by the type of environment you want to run so the variables that we have or the environments we can specify is trace debug info warn error or json json will output logs at the trace level or higher and use parsable json encoding as the formatting okay so logging can be enabled separately so you can do this via tf log core or you can get it at the tf log provider so if you just want core stuff or if you just want provider stuff uh you just set those environment variables and as we saw in the previous thing that there were you know there was core errors and provider variables so that could be a good way to uh do that and so tf uh tf core tf log core and tflog provider take the same environment variables we see on the right hand side their trace debug info etc okay if you want to choose where you want to log things you just can set the tf log path i don't think i actually say where the default path is i think it's actually in the the project directory but if you want to override that you can i imagine it either takes an absolute path or a relative path um and here's an example of a terraform log so this is for everything and so there you can see information i'm going to get my pen tool out here for a moment but you can see we have information about the provider this is using um there then there's some back and local stuff so you know there's some information you're not expected to understand this information uh generally but you could go bring it to the provider but you could probably solve something you know if you were to read the core code or the providers okay okay so we looked at tf log um which is the terraform log but there's also a crash log and so if terraform ever crashes and basically this means it goes into panic because it uses the go runtime it saves a log file with the debug logs from the session as well as the panic message and backtrace to the crash dot log and so i imagine this is go lang information so i don't use golang that often but you can see we have dot go dot go so i think that there's not much you can do with it so this is where you would just create a github issue and pass it along to the terraform team because they're going to be able to make sense of it okay hey this is andrew brown from exam pro and we are on to the troubleshooting um follow alongs here so you know there's terraform logs and there's crash logs i've only ever encountered a crash log once i don't know how we're going to replicate that so i don't that's going to be something we're going to be able to cover here but definitely terraform debug log is something we absolutely can do so what i'm going to do is go down below to my troubleshooting folder make a new file as always type in main.tf and we will pull from not this one we'll go grab from our plan and apply since we had a really simple server there and we'll paste that on in apparently i did not copy it so we'll try that one more time and we'll go back over here and we will paste that in um and that all looks good to me so what we'll do is just cd back and we'll go to the troubleshooting folder and i'm going to do a terraforming net and as that's going we're going to go look up how do we set up that log okay so pretty sure i have it in my slides so i'm just going to go ahead here and look up log okay it's really great when i always have uh the code on hand here and so the idea is that through the tf log we're going to set an environment variable and we'll set this trace so we can get a lot more information okay so what i'll do here is i will go and um i'm going to set it when we do the terraform apply so i'll just say tf log equals trace and we will then do the terraform apply and hopefully we should get a lot more information already you can see that we're getting a lot of stuff see all these traces and debugs as we normally wouldn't get them we might want to dump all this data to somewhere so maybe that's something else that we can do i'm just going to say no for the moment here and let's go ahead and try to set a file here so we'll just say tf log path and i don't know if it would take a relative path so yeah let's give it a try let's see if we can give it a relative path and just say um terraform dot log because i want to see if we can get it to log right in this folder here and it did that's nice okay and so again i'm just going to type no and if we open that up there's all our logs okay so you know it's not that complicated you can also separate the logging so they have the tf log core and the tflog provider um i guess it would just be like if you were if you just wanted to log the core stuff so i'm going to go ahead and delete this so let's say you're or let's say you're trying to debug the provider i guess you could just go here and type in provider it might not log anything i don't know we'll just hit enter here and we'll see if we get any output okay i'm going to just type no so open that up yeah we do get stuff and see what says provide in the beginning okay and that's pretty much it so there you go all right i figured i would just include one more thing here because when you are troubleshooting a lot of times you do have to go to the github and open up an issue and so i just want to show you where that is just in case you're not that familiar with github or you're just you use github but you're not used to opening issues so here i'm on terraform and i can open up an issue and i can go here and create a new issue and here you can see that there's different information like feature requests reported reported security vulnerability report bug if there's something else it's going to go here and that's going to go to the discussion but if we report a bug i'm just curious if they actually tell you to include the logs here terraform version configuration file deep debug output so this is where we have the tf log and they're telling you to do it as a trace if you have a crash output so yeah that's pretty much it i just wanted to show you where that would be and also this would be the same for any of the providers so if you go up to a provider here like aws and this one is of course supported by hashicorps so if we go to issues and we open up a new issue we're going to see this something very similar and they're going to probably ask for the debug logs again here but here they might just say can you only give give us for the provider um i'm sure it's somewhere out here panic output right that would be that here we are the debug logs right um and for modules probably the same thing like if we went over to the modules i'm sure it's very similar but i don't know how you get that output for that so like if we just go to one of these sub modules here and go to issues i just want to see if anton is something similar so yeah that's pretty much it so there you go all right so we're on to our module section so let's first talk about how we would go find a module i know we already saw this earlier when we were looking at the terraform registry but let's just cover it again and talk about some of the uh details of a search okay so tariffer modules can be publicly found in the terraform registry and so on the lefthand side when you're under the modules within the terraform registry you can filter your providers okay but another thing you can do is you can type in search terms and you can do partial search terms like azure compute but what i really want you to know is that only verified modules will be displayed in search terms and so i assume that means verified and also official ones and the reason i'm giving this extra emphasis is because it was an exam question so i just want you to know that only verified and official ones are going to show up when you search okay let's talk about using modules and there's our public modules and private modules so public modules are going to be on the terraform registry and private modules are going to be in terraform cloud or i suppose terraform enterprise so terraform registry is integrated directly into terraform so it makes it really easy to start using them so all you're going to do is use the module block so i'm just going to highlight that there then we have the name of our module we're providing the source of our module and then there's the version of our module terraform init command will download and cache any module referenced by a configuration now looking at private modules it looks very similar it's just that the name is different so we're specifying the hostname in front here and a namespace as well so to configure a private module access you need to authenticate against terraform cloud via terror from login so that's something there we definitely cover that a lot in the practice exam so just in case you know you know all the edge cases there alternative alternatively you can create a user api token and manually configure credentials into cli to configure the file so there you go let's talk about how we would go about publishing modules and this in particular is for the terraform registry so these are public modules so uh if we want to publish modules it supports versioning automatically generating documentation allowing users to browse the version histories showing examples and readmes and all of these modules are actually going to be hosted on github so the idea is you're going to put your module there first and once a module is registered to push updates you simply push new versions to properly form get tags uh you have to name the your um your modules in a very particular way on github so the thing is it has to start with terraform hyphen then the provider so aws and then the name so hyphen vpc and the way you publish it on teraform registry is you have to connect and publish uh via your github account so you just hit sign in with github and it's just going to give you a drop down you're just going to choose the repo and that's as simple as it is okay all right let's talk about verified modules so these are reviewed by hashicorp and actively maintained by official contributors to stay up to date and compatible with both terraform and the respective providers so here's an example of a module from our friend anton down below and as you can see it has a little badge that's how you know that it's verified so verified modules are expected to be actively maintained by hashicorp partners verified badges aren't an indication of the flexibility or feature support but just to kind of go through some things here very simple modules can be verified just because they're great examples of modules unfair divide modules could be extremely high quality and actively maintained unverified modules shouldn't be assumed to be poor quality unverified means it hasn't been created by a hashicorp partner so you know that again it's not indicative of quality but it just means that it's gone through a bit of vetting okay all right let's take a look here at the standard module structure and this is a file and directory layout recommended for module development and this is the idea if you were to go and publish your own module this is what people would expect to see so if you had a root module that's what it be and you have nested module i want to point out that when you are writing terraform you technically are creating modules even if you aren't intending them to publish them into the terraform registry but you know when you make a main.tf you've basically made your own root module okay so the primary entry point is the root module these are required files in the root directory so your main.tf is the entry point file for your module variables tf is the variables that can be passed in outputs.tf are outputted values readme describes how the modules work license the license under which the module is available for nesa modules which are optional but must be contained in the modules directory a submodule that contains a readme is considered usable by external users a submodule that does not contain a readme is considered in for only internal use and the idea is to avoid using relative paths when sourcing module blocks so hopefully that gives you an idea okay hey this is andrew brown from exam pro and we are on to our module section so you know we looked at the structure of how modules should be just pulling up the documentation over here and scrolling on down to our shared module structure so this is pretty much what we expect we expect that main variables output readme license and then you you may need a modules directory there if you are learning to write your own what i would strongly recommend is to check out anton so anton um he basically uh he's an abused hero just like myself but he built and maintains like a ton of really good modules for terraform and you can go through any of these and find really good information so like for instance the rds instance has a very good example of how modules like should be used and so we have folders within folders you can see everything is very well organized and if we have a readme that tells you that it's exposed and how he's defined everything are very good examples but for our purposes we just want to make something very simple and so let's go ahead and create ourselves our own module so what i'm going to do is go over here and we've actually done a lot of this work already um when we were using cloud init so i think that would be a great place to kind of grab that stuff and so what i'm going to do is go ahead and grab this entire file here and we're going to scroll on down and make ourselves a new directory here under modules and i'm going to make a new file here and i'm just going to call it main.tf and we're going to go ahead and paste that on in there and so i think that we should have outputs as well what should it be called should be called outputs based on convention so we'll have that and i just made that a folder didn't i okay we'll just delete that there and we will go ahead and create a new file called outputs.tf and we also need a variables tf and we need ourselves a readme and we should also have ourselves a license okay and so what i'm going to do is just copy paste over here from anton because he's done a lot of the work here so we have this license here the apache license if it's good for anton it's good for me okay so we'll go ahead and paste that on in and so now we have that and let's go take a look at the readme and see what kind of work uh has been done here i assume it's just like to show how it works yeah so you know we'll just say in here um terraform module to provision an ec2 instance uh that is running is running apache okay not intended for for production use just showcasing how to create a custom module on terraform registry okay so nothing super fancy there and then we'll just give our um brackets there for the time being i don't know if there's like even uh something for these other you have these three backticks that will you can actually um highlight in particular oh so there is one for hcl so that's great so what i'll do is just type in hcl there and so now what we need to do is just kind of break up our main.tf here and i did not forget the fact that we do not have the um uh the configuration file but we'll get to that in a moment so we'll go ahead and paste that onto here and then in our main tf we might have some variables do we have any variables we do not i assume we don't specify any kind of back end so let's just go take a look at what anton has done here in his main.tf we go to the top here and just looking through here i do not see any kind of thing there so that's fine and you know what i should be doing is i should be making a new folder here and this is going to be new folder we're going to call this aws demo apache okay or maybe what we should do is actually call it hello world it technically is a module so we'll say idris module apache maybe example would be better okay and so i'm just going to uh reveal these in the folder here and i just want to you know place the contents of them in here okay and i've decided that we're going to want to actually use our module so what i will do is create a new file here it's actually making the subfolder actually want it at the top level there so i might have to just touch that file there main.tf so it'll show up there we go and so if i expand that now we have our main tf here and then we'll just call our module so we'll say um just waiting for my page to become responsive here there we go so we'll say terraform and we had module and then we need to call our module aws module is it module or modules let's go up the top here terraform aws rds oh it has to start with the word terraform okay so i'm just going to rename this hopefully this doesn't cause me a bunch of issues we'll say terraform i can always start with terraform aws and then apache example okay so we will go back over here and so we'll say terraform i think we can actually name this whatever we want so i can just say like apache and we have to specify its source i don't really remember this so i know we already did this before with something where did we do this where we had a child one getting started no on oh outputs that's where we did it over here okay so just pulling up our old one here just to save us some trouble since i cannot seem to remember off the top my head how that works so here we are just going to specify the source locally and so that's terraform adabus apache example okay and what i want to do here i'm going to close off some of these older tabs so we're less confused on what's going on um i just want to continue to break up this file here so we'll go to our main and we don't even need a terraform block pretty sure we should be specifying a terraform provider again we'll take a look at what what's going on here in this one here maybe it's under versions i kind of like that let's go call that versions could also call providers but and so yeah that's where we were seeing it there okay so what i'll do is go back over to here and we will cut that out and we will paste it in here and probably we should be very aggressive and with our progressive versioning and do this okay i'm not sure if you specified the provider here so i don't see the provider listed i don't know if you'd actually have to list that i don't think so no okay so what i'll do is i'm just going to grab the provider out of here oops we'll cut that out and we'll put that in our top level main file here okay and so um here we'd want to specify our aws vpc i wonder if there's like a way we could just select it by default so what i'm going to do here is just make a new tab there is vpc data source select defaults in region maybe there's a good example for us data aws vpc i was just hoping there was something we could grab in two seconds there is not i don't i don't feel like fiddling around with filters to figure it out so what we'll do is we'll just assume that we have to provide that as a variable so we'll just say var vpc id okay and then in our variables here we'll just do variable we have to spell it right though vpc id type string and so we can just close our versions here that's fine so that's set um this has a security group which is totally fine that's hard coded to our ip address so we might want to provide our own ip address my ip okay and so with cider okay so provide your ip eg i might just go grab mine really quickly here what's my ip 32. it's probably some builtin functions we could use but oh well my ip right um that's fine we have our deployer key um we only need this if we want to log in but i i suppose we could do that as well so we could just go here and say variable public key type equal string var public key uh we will need this user data file so i will have to go back to our tutorial that we did this in so this would have been for remote exact no cloudinet okay and then we'll just go ahead and grab the contents of this file and we will go ahead and create this in here userdata.yaml we will paste the contents okay so that is good um we probably would want to dynamically select the data source for the ami we have done this multiple times over the last time we did it uh did we do this for alias yeah we did so we'll grab it from here and we will go over back to the data source here um kind of getting a little bit mixed up here so just close some of these other files so we will want this here and so i'm just going to say my server i notice like anton likes to do this which is i guess really good if you just have one of everything i think that's a pretty good idea i don't think i grabbed the right thing here because that is not this is just another server we already have that so i'm going to go back over to that other project there under what do we say it was under alias main tf yeah it's right here i just didn't go up a bit that was my problem so we'll copy that and we'll paste that in there we'll just go up a bit and we'll just say amazon linux 2. we will scroll on down here and we will just make sure that we get this correctly i don't think we need interpolation again but i don't feel like updating this we'll just keep it the same and we'll go over here and we'll just say amazon linux 2. you might want to pass along the instance type so say var instance type put the oops double quotation there on the end um we'll go to variable and we will say instance type we'll just default that to t2 micro okay um this is a real file here deployer key instance type this is all fine this is all fine um we have this file here this is old so we can go ahead and just remove that um we want cloud in it yeah cloud and it's still happening that was just an additional thing there maybe they can name their server so we can just say like var server name okay i think i'm pretty happy with that could have spelling mistakes i don't know but um that seems all fine to me so what i'm gonna do is go back to my main file here and i'm going to do a terraform init i just wonder if i have to apply the provider looks like i don't have to i think it's pulling it from the the sub module there yeah it is okay that's great and it should complain on terraform plan if we don't provide the values in here so if we go to our variables we can go here and i'm pretty sure that anton has a um i'll probably cover this in the course but i think he has like a way of generating out his documentation um which is something we might want to look at at some point but uh we know that we're going to need some of these keys here or these values here so i'm going to go to my main over here i'm just going to go ahead and paste that in so we have server name whoops it's a bit of a mess try that one more time so we have server name we know we want to set that we want our t2 micro here as instance type okay we have our public key here we'll figure that out in a moment we have the ip address and i'm just going to go ahead and grab mine there because we already have it it's going to save me some time let me go grab that to ssh key so i can save myself some time there so we have ssh um terraform oh it's root right for this anyway terraform i guess i actually just want to cat it so we'll do that root dot ssh terraform here dot pub and we will go ahead and grab the contents there copy i'm just going to paste it in like that make sure this the end is the same there that is all good um we just did this so that's fine vpc id just make sure you are in the correct region but first we're going to switch over to vpc because right now we're in global region which is not going to help us that much i want to be in north virginia so i'm going to go over here we'll go to our vpc we'll go ahead and grab that something i don't know is like how would i override the region i just assume i can just specify that it would know so right now this is all hard coded for uh usc 1 so i do specify that up here to the provider which region is so i think that's fine so we will clear that out and i think that's what we need okay so if this all works um then we can put that in our documentation so i'll do a terraform plan here so it says to work with apache module data amazon linux 2 it has to be west okay so i just forgot to remove something in here which is probably like there's a provider or something in here west so we'll just take that out there okay hit up and invalid value for the path parameter no file exists at user data this function works with files that are distributed as part of the configuration source code so this file will be created by a resource uh you must instead obtain the result from an attribute of that resource okay so doesn't like the way i'm specifying this i'm not sure what i'm supposed to do here so i'll come back here in a moment okay all right so just thinking about it for a moment i bet i have to use some builtin functions to do this so we probably could get the absolute path because under the file system functions they definitely have a function like this and see this is calling path dot root um but we have to really figure out what it is that we want to use now we check this in our named uh named value so maybe we can find that in our slides here if we go named values if we just find that here yeah so for a module um there's these here right so file system and workspace info path of the module where the expression is placed path of the root module of the configuration so i think we want path.module okay and so i think if we were to do like a b absolute path and then we were to do path.module again i don't know i'm not publishing these on a regular basis but this is my guess and probably what we could do is do interpolation and i don't know if this is proper but i'm going to do it this way because sometimes like file systems don't use like windows will use backslash so i don't know if we're allowed to do that like this and how that will work but i'm going to do it anyway okay and so we don't need file here just yet actually any interpolation here we're just going to take that out and uh we don't need yeah that makes sense and so we do file like that so let's see if that works okay if that doesn't work i'm gonna have to do some digging okay fingers crossed wow okay that works so i guess we'll know once we provisioned it so what we'll do now and i want the outputs in the main module here so we're going to grab those and we learned how to do that in the outputs section there so we're going to go back and i'm just going to see how i did that i'm a large proponent of like always using your old code as you can tell so we'll go up here paste that in like that this is apache so we'll just say apache here and you know hopefully that works as expected so we'll do terraform apply auto approve i'd be pretty pumped if that just worked first time doing that path there because that was definitely a big guess on my part seems to be creating no problem okay well i'll see you here in a bit and then we'll just verify if the server works okay all right so that is finished provisioning i don't think it's past the initializations but you know sometimes it does work even if we don't do that so what i can do is just checkbox this here whoops and we'll just open that address in a new tab and see if we get that page not sure why it's not filling in the ip address it's kind of annoying but we'll go here and paste that in because it's trying to hit the https and so yeah there you go so it looks like our module works and that means that we can just wrap up some of the documentation here and then we can go ahead and see how we can publish it on the terraform registry so what i want to do is just update my documentation here and so we will go back to our readme not this readme the actual readme for this here and we will paste in our hcl and we'll just clear up some of our values so um own ip address right and then we'll just clear that out and say like zero zero zero zero zero zero and then here you know it's the same thing it's just like okay so nothing super complicated here um and so pretty much this is ready to move on to the publishing thing so we'll make that a separate little follow along here uh but this is pretty much done here okay all right so we're gonna go ahead and start publishing our um module here to the terraform registry and by the way if you forgot to and i might not have told you but you need to go and destroy that previous instance let me just do terraform apply auto approve destroy okay and what we need to do is make our way over to github and we're going to have to create ourselves a new repository here so we'll go here and i'm going to create myself a new repository i'm going to put it under exam pro co and we'll and we're going to name it exactly what it is so terraform aws apache example i think that's what we called it probably have to spell that right though and if i look here on the left hand side terraform aws apache example okay and we're going to set that as public and we're going to go ahead and say create repository and we're going to go ahead and initialize that so just waiting for the server to finish the string there that's all good and so what we'll do is cd into the subdirectory here and we'll go get a net and one thing i want to do is actually go check out what um terraform module vpc github doesn't matter which one i just want to see what he put in his dot get ignore file so i can figure that out as well and i'm just going to copy that because i bet it's good okay so say new file here we'll say dot get ignore get ignore here and paste that contents okay and i'm just going to click back here and see if there's anything else i'm missing doesn't seem like it and what we are going to do here whoops going to go get add all we go back to our github instructions here if i can find it and we're just going to go down the list so we'll copy that in okay and then we'll make our first commit and we'll create our main branch and we'll paste that in there create our origin okay so that's set up for main tracking and so if we refresh this it is now set up there the only thing that's not showing up is our highlighting which i'm a bit surprised i think it's because i didn't name this reamy.md so we'll just rename that here to dot md we'll say get at all get commit m fix readme file type okay get push and we'll flip back here and there it is some crazy indentation there i'm not sure why maybe that's what's happening on mine i'm going to go into the main order to the readme here is it really that crazy like it's that level of indentation it should shouldn't be okay well i mean it's not a big deal it's just aesthetic you might want to update the description here so this is um well we have a little spelling mistake there too i'm going to leave it in there just because i know like how much spelling mistakes bother people and so that's going to give somebody an opportunity to uh you know interact with my uh repo so i'll just leave it in there that's like my personal little touch so uh now that that's all set up um what we want to do is actually just publish it so we're gonna go ahead over to the terraform registry and click on here and i want to just go ahead and sign in and sign in with github and i guess we're granting to everything here because it doesn't seem like we have any other option to say just a few there if there is i'm i'm not being smart about it okay and i need my password for github so i'm just going to go ahead and grab that off screen here i'm just getting it from my um provider i like my password thing and i'm having a really hard time finding it right now there it is found it okay so we'll just paste that on in there we'll hit confirm and so what we want to do here is go and hit publish a module and we're going to go select the repos that already kind of autofilled and we are going to agree to the terms of use we probably should read it right i agree that i won't do anything bad okay that was me reading the whole thing i'm a speed reader we'll go ahead and publish no release tags found that are in the valve format please ensure the repository has at least one tag formatted v version where version is semantic version that's fair so what we're going to do just to see how that is we're going to go terraform modules again it doesn't matter github and we're just going to take a look at uh one of the repositories here i'm just wondering if it's how yeah so he puts the v in front of it i really don't like the v and i think that we don't have to it says yeah v or version so i'm going to i'm going to do the opposite of what anton's doing and i'm going to not have the in mind okay so what we'll do here is go over to the 110 modules and i'm going to go get tag 1.0.0 um oh sorry we've got to go into the subdirectory there and we'll again do that probably still have that other one open there i don't know why i have two now i'm gonna just close this redundant one i don't need to and we'll do git tag push or it's get push tags i should know this i do this all the time there we go so our version has been pushed and so now i'm going to try this again and hit refresh click on that publish the module give it a moment and there we go i'm in so yeah um there it is cool eh and that's all there really is to it uh you can see that i've had less than 100 people provision this so i guess i have some work to do to promote this but you know if you want to provision it and give the project a star and i become uh super famous here i wouldn't mind it um but yeah you'll notice like i i did the aws there and it picked it up and so it shows the aws logo um but yeah so we're all done here uh i don't think there's any infrastructure for us to tear down so yeah that was fun let's talk about core terraform workflows and these have three steps write plan and apply so write plan and apply we saw this kind of in the terraform life cycle and the idea here is that you know it's just to try to describe what it's going to be for your team and requirements as you grow and you're utilizing this workflow so if you're talking about individual practitioners so a single person a team using oss so they're not using they're using open source software so using terraform but they're not using the terraform cloud platform and then what it would be like if they're using the terraform cloud platform in terms of this right plan apply you're going to see these examples don't perfectly fit here i am just presenting a summarized version of the documentation and the reason why is because on the exam this is one of the subdomains that you need to know so i'm not saying that i think these are perfectly presented but i think that i have to cover them because they are on the exam and i you do learn something here so we will go through them okay so let's take a look at a terraform or team workflow for a single person an individual practitioner looking at the right step first so you're going to be writing your terraform configuration in your editor of choice on your computer but the thing is you'll be storing your terraform code in something like github even if you are an individual user you're going to be putting in git or github or some kind of version control system you're going to be repeatedly running terraform plan or even possibly terraform validate to find syntax errors and the great thing about this is that you get this tight feedback loop between editing the code and running your test commands because it's all on your local machine we're not sending things off to build servers or other services so it's very fast and easy talking about the plan stage so when the developer is confident with their workflow in the right step they commit their code to their local repository this is the stage where it's a local commit it's not a remote commit they may be only using a single branch so just probably working in maine or if you're still using the old syntax master branch uh once their commit is written they'll proceed to apply that'll bring us to the apply stage so they will run terraform apply this is on your local machine it's not part of any other process you're just running terraform apply and they'll be prompted to review their plan after the review the final review they will approve the changes and await provisioning after a successful provision they will push their local commits to their remote repository so this is where you will then finally commit your code so there you go so we looked at what it would be like if we had a single person working with terraform let's talk about if it's a team and they're not using terraform cloud they're just doing it uh the oldfashioned way okay so each team member writes code locally on their machine and their editor of choice as per usual a team member will store their code in a branch in their code repository whether it's a per feature per user per whatever is up to you branches help avoid conflicts while a member is working on their code but branches will allow an opportunity to resolve conflicts during emerge into maine it's no different than working with you know code because that's what it is a terraform plan can be used as a quick feedback loop for small teams so we still have that option but as your team grows larger a concern over sensitive credentials becomes a concern and so this is where you may need to introduce a ci cd process so that it's it's going to be in control of the credential so the idea is that you don't run plan you just push to your branch and it could run it or it only happens on pull requests that's up to you know your team and how they decide to set it up when a branch is ready to be incorporated on pull requests an execution plan can be generated i guess when we say execution plan this could be a speculative plan okay so it's not something we're going to run it's just something we're going to review and displayed within the pull request for review to apply the changes the merges need to be approved and merged which will kick off a code build server that will run terraform apply that's the apply stage there so this is all good but what we need to kind of highlight is all the work and labor that goes into setting up your own team if you're going to do it all from scratch without terraform cloud so the devops team has to set up and maintain their own ci cd pipeline they have to figure out how to store the state files whether they're going to be in a standard backend remote state or they're going to encrypt it and put them into the code repository which is not recommended they are limited in their access controls so they can't do granular actions to say okay i only want to allow this person to destroy and this person to apply it's not like that with git repos they have to figure out a way to safely store and inject secrets into their build server's run time and that's not argue arguably it's not very hard depending on the solution that you choose but it is a thing that they have to figure out they might need to manage multiple environments and this can create additional overhead because for each environment you'll have to create another cicd pipeline okay so hopefully that gives you the idea of the effort here and this is going to set us up to say what terraform cloud is going to solve okay let's take a look at what our team workflow or our terraform workflow will be if we are using terraform cloud so 18 will use terraform cloud as a remote backend of course they're using uh their favorite editor as per usual working on their local machines to write that code the input variables will be stored on tara4 cloud instead of their local machine terraform cloud integrates with your version control system such as git to quickly set up a cicd pipeline a team member writes code to a branch it commits per usual so that doesn't change a pull request is created by a team member and terraform cloud will generate the speculative or execution plan however you want to call it for review in your version control system the member can also review and comment on the plan in terraform cloud after the pull request is merged terraform cloud in the terraform cloud runtime sorry the terraform cloud runtime will perform a terraform apply and a team member can confirm and apply the changes within the terraform cloud uh ui okay so terraform cloud streamlines a lot of the ci cd effort storing it starting at securing sensitive credentials and makes it easier to go back and audit the history of multiple runs so in terms of the exam if and i didn't see any questions on this but i know they exist they're just going to be asking you you know which like they might describe something and say which kind of workflow does this fit and so if you generally know the difference between terraform cloud working with the team open source software without terraform cloud and individual workflow it's not too hard you'll be okay all right hey this is andrew brown from exam pro and we are on to the terraform workflows and so i you know i listed out here individual terraform workflow but i think really what i want to do is just show you how to use the vs the vsc workflow because we've been mostly working with the cli and also just like committing our code in a way that we should be doing it okay so what i'm going to do is i guess start a new project here and i'm just thinking about it here uh we did just create that module and i kind of feel like using that module right away just to kind of get this going so what i'm going to do is create myself a new main file here main.tf and i'm going to go back to the previous project here where we have this i'm going to copy this over and we are going to paste that on in here and so this has my credentials here there's some sensitive stuff that i probably wouldn't want to be passing in here so what i'm going to do is make myself a variables dot or sorry not variables terraform dot tfrs and i'm going to just copy the contents here like so and i'm going to paste it on in as such and then what we're going to do is set up a bunch of variables here so we'll have var.vpcid we'll have var and we'll just name them all the same okay we probably could grab that uh that key via um using like the file system but i'm not gonna do that and i'm gonna grab this here oops far.server name okay and we do need to set up our variables so i'm going to make a new file here we'll call this variables uh walt variables.tf would probably be better right and we will go to our modules here and luckily all we've got to do is grab this so we'll grab that and i'm going to go to our new one here am i on the right nope i'm still in modules workflow is good we're going to go ahead and paste that on in i'm just going to remove the defaults okay we want to explicitly set all these okay and so that's all set up and we're going to have to create ourselves a new repository so i'm going to do git whoops get init and i'm going to go ahead and make myself a new repo i'm going to make this a private repo by the way so we will go to github here make a new repo and yeah i'll put it under roman king and this will just be like vsc terraform or version control system i always get that vsc vcs mixed up you can't tell i'm dyslexic and i literally am dyslexic so uh we have that set as private and that's totally fine we're going to create ourselves that repository and we have established that init i think i'm going to go ahead and grab the dot get ignore file that we had there a moment ago with our modules that was in our sub module there because i thought that was pretty good good ignore there so we'll go ahead and grab that and we will create ourselves a new file this will be dot get ignore we'll go paste that on in there and so we just have to go through this whole process so get at all get commit switch over to maine and we will switch over to this i kind of want this menu i'm sure you can move it to the right but i kind of want on the right just so when i click over here i'm not clicking onto a different file and we will go ahead and push this let's refresh this nothing has been pushed yet get remote ads so we add the main did our commit not work here oh you know what i'm i'm in the wrong folder that's fair as always wrong folder andrew okay so we'll do get at all whoop oh well get in it i guess get at all get commits get branch main hit add remote hit push sure we'll set it like that we will make sure that our code is up to date great no read me and that's totally fine um and so what we'll do is make our way over to terraform cloud okay so we'll go over here just gonna close that out we will sign in and i'm gonna just create myself a new workspace we haven't really done anything with this provisioners i can go ahead and delete this we're not even using this anymore let's go ahead and delete that yeah delete terraform cloud put the name in provisioners delete this workspace and we'll go back to our workspaces here we'll create a new one and we're going to choose a version control workflow we're going to go down to github choose github.com authorize it give them everything please disable block up popper okay so we'll go up here done no no no no always always allow here sorry so go to github here authorize terraform cloud this is in my personal account um we only need it for our select repository so what did we call this it was vcs there it is it's a private repo install and there it is i'm going to select it and if i have to do anything there terraform working directory workspaces with no terraform working directory will always trigger runs like i said we'll be doing that the default branch is i'm not sure what it is but i'm going to set it as main uh the branch from which to import new versions this defaults to the value your version control provides by default branch well then it's going to be main anyway so i don't have to change that we don't have any sub modules so we'll go ahead and hit create workspace okay so our workspace is set up um we are going to need to set our variables so we're going to make our way over here and we're going to go ahead and add this here if there's a way to do like an import i would love to know if like terraform is watching this like hashicorp if there's a way i'd love to know how to just like one import my file there but you probably have to bring it one over at a time it's probably like a security reason for that so go over here into our variables whoops rtfrs and we should probably check to make sure that this works um now i think i'm pretty confident with it so we're just going to copy these over so first we have our vpc id i'm just going to make this a little bit smaller okay so we have vpc id we're going to save that and then we have this ip address i'll just copy this one at a time and we'll add that we need our public key this we will consider i guess sensitive and we will paste that on in there we will specify our t2 micro here that would be instance type we are going to need our server name here okay and we do need to set our abs environment variables here so i'm going to go over to aws provider terraform i can never ever ever remember those environment variables even though i work with aws the most and super frequently i can never remember them so we go here to this to documentation we're going to scroll on down and there they are so we're going to grab that one and uh did i close nope i didn't okay good so we have that key and i'm just going to cap my aws credentials again i'm going to get rid of this so there's no chance that this is going to get abused at any time here and we need a secret here fun fun fun fun fun and i should be making these sensitive because they are super sensitive and we'll add a variable here and this one will be our defaults us east one we will save that and so this is all set up okay and so it should trigger whenever there is some kind of change to the repository now i don't know if it's going to change every time so like if i make a change or i add a readme file i don't know if that's going to trigger it and so i think that should be interesting to find out okay so your configuration has been uploaded next you probably want to configure variables we just did that what's cue plans oh okay like if we want to run something and so triggered a few seconds ago i'm not sure what it's talking about i didn't do anything unreadable module directory unable to evaluate the directory sim link at terraform oh that's right because we've published it we actually never tried our module after we published it and we need to refer to it and that's a great opportunity for us to update this file here so we want to reference it from terraform so we'll go registry terraform and we're going to find our sweet sweet module can i go to my profile to show my module under there i've published a module what are they talking about i've definitely published a module um so we'll go to modules here and we're going to go over to what we call it terraform aws apache oh it's not going to show up because they don't show uh show them under there eh oh well it's under modules here aws no i don't like that okay so that's a bit tricky but i think we can find it so this one here is terraform aws module so we could probably just do terraform apache example what come on my module's published they told me it was published right i'm not crazy am i we'll do it one more time yeah i was already published well there it is okay so we found it was a little bit tricky and so we just got to grab grab this here and i'm just going to go and swap out the source and i guess we should set the version and we will do a terraform init oh but something we haven't done is set up our our workspace here so that's another thing we're going to have to do um we don't have any instructions i don't think in our cli or sorry in our overview here no so we're just going to have to go back to our getting started one where we've actually used terraform cloud and use that as an example so we'll go over to our what is under providers now it's under main here it is and so i'm going to go ahead and grab this here and we'll go back here and we'll paste it in at the top and this one is going to be vcs what did we call this terraform terraform and i feel like i'm missing a curly brace here yeah i am and so what we're going to do again is do terraforming nets and then we're going to go terraform plan because that's what you would do you'd say okay does this plan look good before i push it out right running the plan and the remote back end output will stream here we'll stop streaming the log so i guess we can see the run happening not seeing the run here but it was streaming it out it said so if i went to where does that run here copy that and we'll grab it here so here we can see the run this was started as a speculative plan so it cannot be applied and that makes sense right uh if i go back to my runs here does it show up so it doesn't show under here but we can see it in isolate i don't know why they do that i guess it's because it's not a real run it's just kind of like a speculative one so i'm not really sure about that why they would do it like that but that's what it is um so i think this is all good to go like we just we look at over like yeah this is great right and so now what we'll do is we'll go get status we'll say get at all git commit hyphen m and this is going to be um make it work you know because that's what we want to do we want to make it work and we'll do a git push and so what that should do oh i just pushed to the main branch you know what like that's not what i should have done i should have made a pull request and then merged it in but the point is it doesn't matter if you push anything uh there it should deploy it and wow i really spelt work wrong wowrk terrible that's awful uh so we'll give that a moment to deploy it's now in plan so we can close in here and watch it if we want oh it's a pending so it's waiting for us to accept it there eh wow this is actually really nice i have never seen this before in the ui so i guess when it does that you can go here and this is a lot easier way to navigate i think that if i knew this earlier i would never ever ever output here because it just sucks there and so if i'm happy with it i can confirm and apply i can add a comment looks great and since we actually haven't deployed anything yet i actually do want to go ahead and confirm it i just have to write a message so i will accept everything that goes wrong here so that's pretty cool and so we're going to watch that run and i'll see you back here when the server is provisioned okay all right so after a little wait here it looks like our server is provisioned and you know it shows us that we have our resources have been created there and we can see our outputs and so if we go over to aws we'll just see if our server is running and it absolutely is and so now what i want to do is actually do a branch and then push that branch and do a pull request because as far as i understand it's going to output some stuff for us in our pr and that's what i want to see so what i'm going to do is make a new branch here we're going to go get checkout hyphen b and we'll just say um add tags and we're going to go into here and i want to go down to our module so our modules here and i don't think we're going to be able to modify the server directly and add tags to it so i guess what i'll have to do is just add another resource so i probably shouldn't have called it tags it's kind of like too late now i actually no it's not too late i'm going to move back and fix that so we'll go back here go check out main we'll say get checkout hyphen b and i'm going to say s3 bucket we'll do that instead and so we will add our s3 bucket so this will be resource abs s3 bucket and we just need a name here so we'll give it a name and uh we can randomize out the name because there are functions like random with um with what you may call it here so i'm going to go builtin functions i'm just googling this really quickly here terraform random you know even if it wasn't that we could probably just use a uuid as well that'd probably work pretty well yeah let's do that so i'm gonna go here and curly's here and we'll just say um vsc vsc vcs you can't imagine how many times i made that mistake when i made the lecture content way too many times so what we'll do is do a terraform plan just to see if it's happy with that we actually have to give it a name say bucket and so it's going to just run that plan there and we'll just wait here um an argument name named name is not expected here okay so maybe it's called like bucket name or something it's just called bucket terraform this is just called bucket it's just bucket my bad bucket i guess the only problem with using the uid there is every time we run it it will change so we probably shouldn't have called it uuid like that that's probably a bad idea now that i think about it yeah so i think what i'll do instead of doing that is i'm just going to set a new variable in here say like bucket and i'm just going to default it to something like and we'll go back over here and i'm just going to say var bucket and i'm going to do another plan here just make sure everything is okay great and so that plan is all good and so now what we're going to do is go get add git commit m add bucket we're going to do git push it's going to ask us to push up stream so we're going to copy that paste that in there hit enter and what we'll do is make our way over to our browser we're going to go over to github here and i'm not going to bug hashicorp today i'd like to bug them quite a bit and we'll go to github and we'll find our new project what did i call this vcs right vcs terraform there's a thing here so i'm going to go ahead and create this pull request and it's asking to merge into main and i'm going to go over to terraform and see if it does anything interesting oh we got all our resources there that's pretty nice uh we'll go back over to here there are no conflicts we can definitely merge and accept this i thought i thought it would generate out a plan here i really thought that it would do that so i'm just wondering if maybe i don't have it configured how i think i do um don't trigger speculative plans for pull requests to this repository for pull request of the repository that's that's what i wanted i want to turn that on so we'll update that so now my question is if i go back to my pull request is it going to generate one i don't see one maybe it's from then on out so what i'm going to do is get rid of this pull request close this pull request and i'm going to reopen it maybe that will trigger it ah see here here we go so now i think it's going to create a speculative plan here first so we're just waiting for that to finish great and so uh if we we see that it generates a speculative plan i guess i thought it would output it in here we go show all checks so it's not here but it produced i guess a speculative uh plan somewhere i really thought it would be in line here okay if we go to runs i don't know where those speculative plans go so they're somewhere right i mean it's great that it ran it um i just wish i knew where they were and maybe like it would show us a link to it in there so maybe i can get a link details yeah there it is okay so maybe like someone could click in and just review it and that's what they would do so what we're going to do is go ahead and merge that pull request still using my old emails there but that's fine so we're going to add that bucket and we're going to go back over to here and we're going to see that's now running there so that's pretty much it for workflows and that pretty much covers like i mean technically we did it as an individual and so you know if i was an individual i would use the the version control system like as opposed to the cli um but this will also be for terraform clouds we're not like covering the the remote one the uh the middle tier there just because it's a lot uh like the um the terraform workflows for teams without cloud because it's just a lot of work um and you know i honestly think that you should use terraform cloud there so you know once this is done we need to kind of pull it down but you know i don't want to get rid of it because we might come back to this particular project and so maybe we can just destroy the resources here so i'm going to go to our settings and just take a look here what enabled the setting allows destroy plans to be created and stuff like that um queueing a destroy plan will will redirect to a new plan and will destroy all the infrastructure managed by terraform is equivalent of running the terraform plan destroy so i think we'll try that once this is done shouldn't take too long here oh maybe we have to accept it in here so i think that's the thing is like if you were to if you were to have pull requests it'd be kind of annoying to have to like double accept this every time so i think this is where you would go to general and you'd have auto apply turned on right and i'll flip that on because that's gonna get annoying if i'm gonna have to keep on doing that okay and so that's applied this will go pretty fast it's already done and so we'll go back over to settings here because i just want to destroy the infrastructure but i don't necessarily want to get rid of the state file or anything else like all the work we put into this so i'm going to say cue a destroy plan and i'm just going to type in the workspace name so this is vcs terraform and i believe this will just tear everything down but we'll leave our workspace in place so give it a moment because i definitely think we're going to come back to this when we're looking at terraform cloud okay so we have four resources we want to uh possibly destroy there and it has auto applies so it's gonna just automatically start doing that we're not even gonna confirm it i wonder if they should make like a feature that should just be auto like auto approved for just apply or you know etc like that that might be something they should might want to offer because in that case i kind of felt like i should have confirmed that because it's not going through the um the version control system where i'm doing a pull request i just happened to be destroying it but anyway that's good for now and i feel like this satisfies it and we'll come back to this the setup okay all right we're taking a look here at back ends and each terraform configuration can specify a back end which defines where and how operations are performed and where state snapshots are stored so terraform divides their backends into two types we have standard and enhanced first looking at standard this is where you can only store the state and it does not perform terraform operations such as terraform apply so to perform operations you have to use a cli on your local machine and the reason why is that standard backends are basically thirdparty backends so a standard back end could be aws s3 and so you know this is a storage service it doesn't have the capabilities of pragmatically triggering things okay when we have when we talk about enhanced backends we can store both the state and perform terraform operations so enhanced backends are subdivided further so we have local so files and data are stored on a local machine executing teraform commands and remote so files and data are stored in the cloud so terraform cloud the reason why they can perform terraform operations and when you look at local and remote local is your machine so of course it can execute terraform and then remote is terraform cloud which has its own runtime environment it's basically a build server so it of course can do both those operations and that's how you're going to remember the difference between those two okay alright so we were just talking about standard and enhanced backends that i was saying that standard backends are basically thirdparty providers so it's something other than terraform cloud so let's take a look at what options we have available to us starting with the major cloud service providers so aws has simple storage s3 azure has block storage account notice it says azure rm because that's just the name of what they call it i don't know what the rm stands for resource manager i imagine google cloud storage is an option then we have alibaba we have openstack we have 10 cent and then we have um manta which is part of joynet's cloud storage so i don't think a lot of people are going to remember join that joynet was very popular provider like post or pre 2010 so i remember them 10 cent is a asia provider i think they were a texting service they're very popular but they're not the largest provider over in asia alibaba is and of course we have the the three major ones here and then openstack is for uh private cloud okay then on the other side of it when we're looking at more exotic or things that aren't cloud service providers we have artifactory we have hashicorp console etcd postgres database kubernetes secrets and you can also use the acp protocol now notice i have these little locks here that's indicating which have state locking which do not if you don't know what state locking is don't worry we'll talk about it here in a moment would there be a question on the exam saying oh which service you know doesn't have state locking and the answer is no they would never ask that it's to minute but just notice that the only thing that doesn't have state locking is uh artifactory which i'm kind of surprised because it's a universal repository manager and there's the one case like with hp protocol where it's optional so it's not that you can't have it it's just that it's not uh it doesn't necessarily have to be there and in particular some the the state is um or the locking state locking is by another service so for aws it's dynamodb that is doing the state locking and then with alibaba uh alibaba's cloud storage it's table store okay so uh you know there's not much to know here but uh you know it's just kind of interesting if you want to have a different kind of back and maybe you want to use postgresql familiar with it you can actually store it there okay so let's take a look at what it would look like if we were to use a standard back end so here's an example for aws since i think s3 is very popular so if you were to set up your back end so here i have a bucket here and i've i have to name the state file so i call it state file and then i give it the region and there it is so the backup of a state file will reside on your local machine so the backup's not going to be an s3 configuring a standard backend does not require terraform cloud account or workspace um because you know it's just it's totally separate from it so that's something i wasn't sure when i was first using was okay can i use a standard backend but i still have to have a terraform account or workspace and the answer is no all right all right so we're taking a look at enhanced backend so we're going to start with local and then move on to remote so for the local backend we store the state on the local file system and it locks the state using the systems api it also performs operations locally and when we say local we just mean a local machine we don't necessarily mean it has to be our workstation a code build server could also be considered a local machine okay it just means anything but terraform cloud that is running the terraform code so by default you are using the back end state when you have not specified any kind of back end so normally you'd see a background defined in here and we don't so it's going to just default to the local you can specify the back backend with an argument local most people don't we just leave it blank and you can change the path to the local file and working directory so i think that if you were to specify you'd want to put the path in but generally again we keep that blank you can set a backend to reference another state file so you can read its outputted values this is a way of crossreferencing stacks so just notice that we have this thing that says terraform remote state we're going to repeat this later on in the course because this is a very important concept and i feel that it gets overlooked in the documentation but it has to do with local backend so the idea is that you could say hey um i have this other file that has a back end and i'm just going to use data sources its backend and then point to its actual terraform state file okay all right we're taking a look here at remote backends for the enhanced backend type and a remote backend uses the terraform platform which is either terraform cloud or terraform enterprise uh by default i usually just say terraform cloud when i'm referring to the terraform platform but just to understand there is a distinction between terraform cloud and tariff enterprise enterprise being the onpremise um offering okay so with a remote back end when terraform apply is performed via the cli the terraform cloud run environment is responsible for executing the operation so that's what you get when you get terraform cloud you get this run environment so it's basically just a builtin code build server to run terraform commands for you one thing i really want you to know about remote backends because this really tripped me up uh when i was actually trying to make the follow along which is the fact that because the terraform cloud run environment is the one executing the command your provider credentials need to be configured in the environment variables in terraform cloud so you know if you had a project and you configured it with um tfvars locally and then you were to swap out your remote backend uh it's not going to work the way you expect it to because um again the terraform cloud run environment's not going to take your credentials and then move them to the cloud okay you have to do that yourself when using remote backing you need to set a terraform cloud workspace so you would go ahead and go to terraform cloud and just go create one you create one or multiple ones for a single project if you use a single workspace for a project you're just going to use the workspaces name and if you set multiple workspaces via prefa you can use a prefix okay and the way this prefix works is that you're going to say like my app or something and when you go to run terraform apply what it's going to do is prompt you to say which environment do you want to use so and this is what you've created in your terraform cloud workspace you've created one called dev you created one called pr prod and saying which workspace do you want to deploy to i want to know that uh you can only set either name or prefix you can't set both okay so just understand that so since we're talking about backends let's talk about backend initialization in particular the backend hyphen config flag this is more of an exotic option but i figured we should go over it because it could appear on your exam so uh the flag for uh the backend config flag for teraform init can be used for partial backend configuration so in situations where the backend settings are dynamic or sensitive uh so they cannot be statically specified in your configuration file this is what you would do so here would be your main.tf and notice it says back in remote and it has no details in it so then what you do is you create a separate file called backend.hcl and now you're specifying the workspace the hostname the organization and then with terraformingnet you're going to then say okay use this file as the backend information that we're going to inject into our backend remote so there you go okay we're taking a look here at terraform remote state and i give this a lot more attention the course because i feel that it gets overlooked within the terraform documentation it's such a powerful feature and something that i'm used to having in cloud formation which is cross referencing stack so i want to make sure that you know it too so terraform remote state data source retrieves the root module output values from another terraform configuration file using the latest state snapshot from the remote back end so the idea is that you can reference a state file from somewhere else you can do it uh via a remote backend and a local backend so just take a look here we see data and the data sources terraform remote state and we're setting the back end as remote on the righthand side here it is local and if it's a local backend we give the path to the tf state file if it's remote that means it's another workspace in terraform cloud so we set the workspace that we want to access and then when we want to access those resources we're using data sources so we do data dot and then it's terraform remote state and then we specify it notes that it's no difference whether it's remote or local but you're going to be getting data from outputs okay so only the root level output values from the remote state snapshots are exposed resource data and output values from nested modules are not accessible to make module outputs values accessible as a root module output values you must explicitly configure a passthrough in the root module so here's an example of us doing a passthrough so we have a module called app and it has a source and then we're just setting an output notice that we are just grabbing the value and passing it along i want to tell you about the alternative to terraform remote state because if you can you should use these as opposed to using tariff remote state so tariff remote state only exposes output values its users must have access to the entire state snapshot which often includes some sense of information it's recommended explicitly uh it it's recommended explicitly publishing data for external consumption to a separate location instead of accessing it via a remote state so what would be alternatives well you've seen this because when we looked at data sources we were technically reusing alternatives but the idea is that you are going to say aws s3 bucket aws referee 3 zones and these are kind of already set up to work with aws or whichever provider okay so um that's that there but uh you know hopefully that's pretty clear so the idea is that when you can use these data sources because you know they're actually working off of live data right like it's hitting a resource it's not just looking at a state file that contains data okay so we had mentioned state locking just briefly when we were looking at standard backends but let's go take a look in detail what these are because they're very important for your workflows so terraform will lock your state for all operations that could write state this prevents others from acquiring the lock and potentially corrupting your state so state locking happens automatically on all operations that could write state you won't see any message that it's happening if the state locking fails alright so terraform does not output when a lock is complete however if acquiring the lock is taking longer than expected terraform will output a status message so neither on failure and neither when it is complete just if it takes too long so there's a transient issue something with like a networking issue you can disable lock so what you do is use the hyphen lock flag but it's generally not recommended you can force an unlock there's cases where you know just does not unlock or and so what you'll have to do is use the force unlock command um if you unlock the state when someone else is holding the lock it could cause multiple writers force unlock should only be used to unlock your own block in the situation where automatic unlocked failed to protect you the force unlock command requires a unique lock id so terraform will output this lock id if unlocking fails so this is what it would look like so you have terraform force unlock and then whatever the id is hyphen force so yeah there's a lot going on here but yeah that's what it is all right so let's talk about protecting sensitive data so terraform state file can contain sensitive data so longlived database credentials and is possible attack vector for malicious actors and so when you're dealing with the local state when you're using local backend the state is stored in plain text json files you need to be careful you do not share the state file with anyone you need to be careful you do not commit this file to your git repository when you're using a remote state with terraform cloud the idea here is the save file is held in memory and is not persistent to disk the state file is encrypted at rest the state file is encrypted in transit with terraform enterprise you have detailed audit logging for tampering evidence to take it one step further so you can just see that there's a lot of work that has to be done when you are using it locally but with terraform cloud this is kind of the cell for terraform cloud is that it's just going to do everything possible to make that secure would it be secure to use a remote state with a thirdparty storage let's talk about that so you can store state with various thirdparty backends but you need to be careful to review your backend's capabilities determine if you meet your security and compliance requirements some backends are are not by default as secure as they could be so for example abs3 you could have you have to ensure encryption and versioning is turned on and you need to create a custom trail for data events so you can get tamper evidence logging if you turn on uh data events for custom cloudtrail events but one thing that if it's important to you is that you know if you use s3 it's not held in memory you know that be using a cloud hsm or kms so you know you have to understand there are some tradeoffs okay let's take a quick look here at terraform ignore files and if you know it get ignore files it's pretty much the same thing so when executing a remote plan or apply in a cli driven run an archive of your configuration directory is uploaded to terraform cloud and so you could define paths to ignore from upload via the dot terraform ignore file at the root of your configuration directory if this file is not present the archive will exclude the following by default so dot get dot terraform uh and dot terraforming nora works just like a document ignore with the only difference is that you cannot have multiple terraform ignore files in subdirectories only the file in the root directory will be read so there you go and yes i know there's a double though okay so don't worry about that hey this is andrew brown from exam pro and we are moving on to our uh back ends and so the first thing we're going to do is try to use a standard back end so we're going to back something with amazon s3 so what i want you to do uh is we're going to go find our folder here which is called back ends and i think i'm just going to break this up into multiple files or folders i should say because i feel like we're going to be doing more than one thing so i'm just going to rename this folder to standard s3 here okay i'm going to create myself a new file called main.tf and what i'm going to do is type in terraform here and what we'll do is we'll go to the internet and we'll see uh how this looks like for a standard backend so we'll type in standard s3 terraform okay we're gonna scroll on down and there is our example it's pretty darn simple uh to set up terraform there or for um uh you know aws and so we have our backend defined there and we're going to need a new bucket so uh we'll name that here in a moment so i'm going to just call this uh terraform backend and i'm just going to pound into a few numbers here and we're going to have a key and so this is going to be our state file so i'm just going to call this terraform dot tf state and we'll keep the region to us east one so now that we have our bucket defined at least the name we're going gonna go there to aws and go ahead and create that bucket so you know we have something to put that in so we'll make our way over here and i'm gonna go ahead and create myself a new bucket okay scroll all the way down hit create bucket and so now we should have that bucket that's all good to go but we're going to need something to provision because we don't necessarily have anything here so what i'm going to do is go to one of our previous tutorials um actually i think the code in the last one is pretty good with the exception that we don't want to have it backed by um we don't want it backed by all this stuff up here so what we'll do is go grab all of this here okay and i'm just going to go ahead and paste that on in and i will also bring over the variables.tf because we'll need that as well so we'll say variables tf and paste that on in and we'll also grab our terraforms tfrs to save us some time um let's just call terraform tfvrs and we'll paste the contents in there and so now what we should be able to do is go into our folder here and i'm going to do a terraform init i think that should just be in good shape there now notice that we set it to s3 but we didn't specify a provider or details i assume that it would just pick up those environment variables if they are set in our credentials but i guess we'll find out here in a moment what's going to happen okay and while that's going i'm just going to look here and see what they have for permissions um i'm just looking for general permissions configuration like region and things like that so you know uh it looks like we would have to set a particular region and stuff like that but what i'm going to do is i'm just going to go ahead and do a terraform apply and see if this just works and while that is going we're just going to give a read here so region is required if the dynamodb table is used the following configuration is optional so the access key the secret i'm endpoint maxwe tries the profile and i am using the default profile so that's totally fine i would just assume you know if we want to do something besides the re like the default profile we do like profile default here or what have you and so down below i'm just going to type in yes well it's going we're just going to keep taking a look here see how there's a lot of options here um dynamodb endpoints so custom endpoint for dynamodb api this can be sourced from the itabus dynamodb endpoint so i guess if you provisioned a table or created a table you just specify these two options to add that there if you want locking okay but we'll give this a moment here and uh see it all spin up okay see you back in a moment all right so after a short little wait here um our server is done provisioning so what we can do is just confirm that and we'll go into our terraform folder here and give it a refresh and so there we have our terraform tf state file and i want to see if there is a backup and so and here i don't see one so i'm not sure what's going on like when local when you're local you're always going to get a backup here um i didn't turn on versioning here it probably wants us to have that versioning is highly recommended that you enable bucket version on the s3 bucket to allow the state recovery in the case of accidental deletion or human error i guess my one thought is is that um how would you keep track of previous versions right like if i was to update this you know what's going to happen so here i'm just going to maybe just change the instance size so we'll go over to variables or sorry our i think it might be set in our tfrs there and we'll change this to a nano and what i'm going to do is go ahead and deploy this again so we'll say terraform apply auto approve because what i'm really curious about is like the versioning right because if we turn on versioning and then we look at s3 uh will we see those mobile versions because that's just a way of like recovering older versions of the state file and that might be something that is important for us to do because again i don't see any backups over here i could probably open up this folder here and yeah so i don't see any backups all right so i'll see you back here in a moment great so after a short little wait there this deploy is done so we'll go back here and give it a refresh and so yeah we don't uh we don't have a another file here it's just the same file that it's overriding so this is probably where we'd want to turn on our versioning and so i'm not sure if we can we have to empty the bucket versioning as a means i'm not always turning versioning on all the time we'll go here and enable it you might need to update your lifecycle rules to manage previous versions of objects which is totally fine okay and so what i'm going to do is go back over here and i think if we go over here we can actually see um let me see like the version here hmm because where there used to be like an option here to see multiple versions but that's totally fine so i'm going to go ahead and see if i can do a terraform destroy okay because i'm not sure if that file that we've placed uh up there is actually being versioned it might be the one after this not only turn version on there's like no way to actually delete things at least that's what i remember so we'll see how this goes and i'll see you back here in a moment okay all right after a short little wait it turned everything down so i want to go back here and give this a refresh and so our state file is still there um and that's the thing with versioning oh it's right here that's the button so we go here and we can see our multiple versions okay so i guess we might have just peeled back one there and so what i'm gonna do is just switch this back to micro okay oops i don't wanna i don't wanna destroy but we'll say terraform um uh terraform plan again i actually don't want to plan i just want to apply it auto approve okay and my thought process is still again like if i'm doing destroy am i like just falling back to the previous state file of the previous version and the reason why that matters is that um you know if you keep on destroying that means that um you know you're not gonna you're not going to have a state file that actually reflects uh what it is unless the terraform destroy is writing a new version if it's doing that that would actually be pretty useful that's what it might be doing um and so that's something we should really be sure of here so we'll do an apply and what i want to see is another version appear and then i want to do a destroy and i want to see if it removes the state file or just adds another one with the remove things and i think it's going to be the latter okay but we should just definitively know here so we'll see you back in a moment all right so this just finished here so we're going to do is give this a nice little refresh and you can see we have a new state file and so what i'm going to do is now do my terraform destroy so do terraform apply destroy auto approve okay and i will see you back here when this is done destroying and we'll see if we have an additional file or if the last one was removed okay all right so another short wait here and our deploy is done so what i'm going to do is refresh and what we have is another state file so that's what it's doing it's just updating the save file removing all of those things and applying it there some other things that might be important to you is turning on encryption so if we go down to encryption it's it's disabled by default so there is an option to turn it on here but i also noticed in the back end that they have it here as well i'm not sure if that would flip the switch for you or if the fact that you need to have this enabled as well it would be also really great if they told us if this was a boolean or not i'm pretty sure that's what it is um so if i was to go over to here and we'll go up here and say encrypt and say true i'm not sure if it would take that just type terraforming it here if you wish to migrate automatic migration for state terror from init so it sounds like it might have to do a lot of work there so i think you probably want to turn that on before you do this but that's something you want to do is probably have encryption and then make sure that no one can delete the original option option or the object obviously versioning takes care of that for you um but yeah that's pretty much it so we'll move on to uh the next part of our back end stuff okay and uh just as always let's go ahead and destroy our infrastructure there i almost forgot to do this as per usual um you probably might want to tear this down so if you want to do that i think you would have to suspend it but preserve existing object versions um do not change okay that's fine we will save that change there and i'm gonna go ahead and press enter yes here okay and we'll go back to our objects and i want to show the versions i just want to see if i can empty this bucket here whoops i don't want to open that but hey we can see the contents of that file which is nice probably would help to show that as we're doing this we'll go ahead and delete all these say permanently delete and we'll go back over to our back end here and now our bucket is empty and so if you want to delete this bucket just go back a layer here and we'll go ahead and delete this bucket there we go this is andrew brown from exam pro and so we just set up a remote back end or sorry a standard back end with s3 but that was just for a single uh workspace so imagine if we wanted to set up this for multiple workspaces so the first thing i'm going to do is go ahead and create a new bucket and by the way we're not going to go and create a bunch of aws accounts because i realize that's a lot of work for some people but what you i want you to do is go and create that bucket so just make sure it is named the same here and since we're using the same project we might have to do like a terraform init on this or even a migrate um so this looks like oh sorry i'm initializing the wrong directory here we got to go into 120 that's the one mine is called here and we'll do a terraforming it here oh sorry sorry that's the wrong workflow it's 1 30 for me having uh what like one of those days where i'm a bit forgetful here but we'll type in tara from init and because we had just used it we'll have to do like a migrate state on it okay if that's giving us too much trouble another thing that we can just do is just open this up i don't want to find it in a folder i just want to reveal that in my explorer here sorry so we'll go uh reveal and file explorer and i'm going to bring that over and i we've deleted these so we don't have them anymore so it's not a big deal if we delete them so say continue try again and really won't let me delete this here of course that permission the one who created it we'll say continue here okay but that's fine we'll try to do uh terraforming it on it now maybe it will take now that there's just the modules there there we go it's not always easy great and so now we can do is just do terraform workspace list to see what workspaces we have or it's just workspace and we do terraform workspace new um staging and i do not need to update my geforce drivers today and then we can do one for production and so the idea here is what we need to do uh and i have uh it's all in the s3 back end here but i'm just kind of walking you through it but the idea is what you'd first have to do is set up a variable here and we you know we should probably put this in our variables folder if you don't since that would probably be more proper and what this is doing is it's saying okay the default setting is a map and we have one value called staging or key and one key called production and this is going to be pointing to a role and this role is going to be in whatever account is doing the provisioning so you can have one account that is just provisioning both the development or staging and production environments and so you'd have a user and so if i went into uh i am here and i went to my users i guess i just have to create a role so i just create a role again we're not going to go fully do this but it'd be like another items account or third party we'd have to put the id in there uh and that's the way we would go assume that role so once we've created those we still be providing the account ids for each of those and the name of the role there over to whatever it is once we have that then we can go over to our provider which is in our main here and we can just provide this assume roll here okay and notice over here it's getting the variable and then we're passing in terraform dot workspace let's we'll select whatever workspace we're in server in production it's going to pass production in here and that's going to go through and select this and assume that role and we will have permissions to then deploy to that but things are going to still be stored in this single uh bucket as far as i'm aware of um and so that's one part of it but one thing that they don't even cover in the actual documentation here is how are you going to handle your terraform.tf vars because this is a file that generally you don't want to be tracking and so what you probably would do is you create a new file here so i would just go here and say um staging dot tf vars right and then when you want to you just fill in all your environment variables in there but when you want to go execute this uh when you are in production you're going to have to do terraform apply and you just do var hyphen file staging tf vars okay and so there's not really an easier way of doing this it's just pretty much it and this will once this runs it'll it will you know it will um work that way so you probably just make a staging a production one and that's just how it would be you'd have to update your git directory there so whatever it would be you'd have to go to dot get ignore and just you'd ignore everything that had tfrs um i bet that git ignore file that we're using over here probably does a good job of that if we just scroll up and down yeah see already ignores it there so that's pretty much how you use multiple environments again it's just too much work to set up here and it's not really that important to the certification so there you go hey this is andrew brown from exam pro and we're going to be looking at the terraform remote state uh maybe not remote because that might be too much work to set up but um we'll definitely look at local here so what i'm gonna do is go on the left hand side here and then just find uh my folder that i've uh created there and i guess i have back ends there so i'm going to need a new folder um i feel like i should have all the folders here somewhere yes i do and we're just going to make a new one here and we're just going to call it 131 back ends terraform remote state and then within this we're going to have to have two projects so project one and then we're gonna have project two okay and we're not gonna treat these as sub modules they'll both be root modules uh meaning like we're not going to have a main in here so we're just going to go and make a main here main.tf and then we're going to add another one here main dot tf and so what i want to do is provision something in one place and then access it somewhere else so i think this is a good time to go and grab i have some things open here would be a good time to go and grab anton's aws module there so let's say a bus vpc module and we'll just expand this a little bit here so i just want to go ahead and grab that and we'll make that project one okay so this looks fine i want to do us east though and we'll just say my terraform vpc so we uh don't forget what it is i'm going to do a usc 2 just in case i have one in hanging around usc one that i didn't delete because i might have it from something else and i mean the this doesn't necessarily need us to specify the provider because it should get pulled in from this module here and so i'm just going to navigate to that folder uh 131 is what i've called it and we want to go to project one here and we'll do terraform in it just wait a little while there i'm just curious about are the outputs to this so there are a bunch of outputs here and i'm just looking for the vpc id okay so um that initialized there and so i do want to output that value output outputs i cannot remember so i'm just going to go look at another project and see how we do our outputs main tf here yeah just output like that back to our project here and this one is called vpc and um we can specify our provider if we want it's going to use the default anyway but we might as well be explicit here just be explicit about the region so we'll do region usc to 1. and it's going to be double quotations here and we'll do profile equals default okay and then we'll go down below and we'll do a terraform apply and we'll see if that takes we'll type in yes and so that looks like it's going to work while that is running hopefully it doesn't break along the way but we'll go set up our other main.tf and so we just want a basic project i think we've been pulling from the same one which is counts all the way at the top here or maybe we could pull into the standard back end might be a bit easier yeah let's use this one and i all i want is this here the apache module that we created so we'll go down below and we will jump back into our project 2 here and we will paste that in there and notice that we just have an error down below uh can only create the following a b c so there's a minor error there usc's two two two oh it's because i set this as one up here we're gonna do two here okay let's say auto approve we'll go back to this project here and so what i want to do is specify a data source and this is going to be that terraform remote state and we'll call this vpc and we're going to set it to the back end here saying oh we want to be local and then we need to set the config path this is going to be where the actual file is located so i think that we could probably get away with doing this there okay and so then down below here i should be able to data dot vpc vpc id this is going to need a configuration file or tfr is there so i'm going to go here and just go terraform dot tf vars i'm going to go up to our previous project where we might have defined that here but there's one minor difference here and that is that we are not specifying the cider or sorry we're not specifying the vpc id here okay so we'll go down below back to this file and we're just waiting for that vpc to be created it's creating a nat gateway uh oh i don't think i want that um now gateways cost money i mean like it's not a big deal we can just rip it out um but i think what i would have done here is not had either of these i would just said false and false so we're going to have to wait for that to finish to create this is going to take forever um if you've watched up to this point you know save yourself some trouble and just remove that out oh yeah so just finished nope it's still going so i'll see you back here in a bit okay the problem is it's creating that gateways in all the vpcs and there's a lot so i'll be back in a bit all right so we have to wait that long but what i'm going to do is just do false and false on this and i'm going to go and do terraform auto or reply auto approve here or actually i'm going to do terraform apply because i don't know if it's going to just tear down those resources or actually replace the vpc if the vpc doesn't get replaced then we can move on to the other part of this i'm just going to go to the top here because i'm really curious about the vpc so the nat will be destroyed then that will be destroyed the gateway will be changed road tables will be changed but the vpc id is not going to change so we can just say yes okay and what i'll do here is while this is going we can go figure out project two so i'm just gonna open up a new uh terminal here or window whatever you wanna call it shell and once that's loaded i'm just gonna cd into that i believe it's uh 31 we're on right now 131 and the numbers might change depending on if i change them after the fact so uh we sourced our data source there i want to go back to our project 2 and that's the tfvrs file and so this should just work it should take it except this isn't the wrong project so i'm just going to close this out project 2. yes this looks good so what i'm going to do is do terraform plan and see if this is going to take it oh we got to do terror from init first as always great so um we just ran that there and so now what we can do is do our terraform plan and while we're waiting on let's take a peek over at our original one here so that one got rid of all those extra services we didn't know need and so down below it says an input variable with the name server name has not been declared this variable can be declared with a variable server name um i thought we did define these that's right there did i name this far wrong terraform tfrs no that is correct oh it's because we don't have a variables okay so we just do variables tf we'll go back up to this one here and we'll grab all of it and we don't need this workspaces thing um we don't need a vpc id like that because we'll just pass it along via the data source we don't have a bucket so we'll just get rid of that okay and we'll do terraform plan again and they're saying data vpc vpc id has not been declared in the root module i'm going to do terraform init just as a sanity check there and i'm going to go back to my main tf here and just take a look oh it hasn't been defined did we put it in the wrong project here maybe i put it in the 130 here while i was doing it did we put it in project one maybe nope okay well wherever it's gone oh no it's right here okay so then what's it talking about let's try this again terraform plan plus i named it wrong here oh um what we have to do is do outputs or output i think it's outputs on this one here data.bbc so a data resource name that does not exist oh you know what it is we also have to do um terraform remote state like that and now it should take it the region is required but is not set sure it doesn't say for what but we'll i guess maybe it's just talking about the provider region equals us east 2 defaults or profile default and so i'll go down here and hit up okay and so if we just scroll up it's going to take it so let's just go provision that and see if it works terraform apply auto approve okay and i'll see you back here if this successfully works okay all right so we've ran into a little bit of an issue here notice that it's giving us uh saying that it's running in a different network so the thing is what we're doing here is we're passing our vpc id here which is coming from project 1 and so that should be setting this to be usc 2 right because we have the region set up as such um this is all right so we'll go over here and this is all right so some of the security grips all i can think of is we'd have to go back to our modules project and if we went in here and checked out the main this is where we define our security group and we specify the vpc id here and that is what we are passing through so you know i would expect this to be using the correct subnets and things like that but uh it's just not taking for some reason so instead of worrying about that what i'm just gonna do is i'm gonna go back to project one and i'm going to tear this down and the only reason i didn't do this in usc 1 was because i thought i might have already had one there so if we go over to our aws account and this won't be a problem for you this is just a problem for me but if i go over to vpc here and we go to your vpcs notice that i have two and one is called oh it's my terraform vpc that's in north virginia so maybe that never provisioned where we wanted to be so but i'll be back here in a moment all right so we ran into a bit of an issue here after waiting a long time it didn't delete and so uh if this happens there's not a lot you can do except delete the resource out manually this is like something that's not great also notice that somehow i ended up one with in north virginia and also this one has um a virtual private gateway so probably what happened was i deployed in usc one it wasn't correct so then i went to usc's two and uh so i just made a big old mess of this so i'll have to go here and see if i can delete it manually and i'm just going to type in delete and we'll see if that takes okay i'll try that one more time it's possibly that it's not deleting because of all the additional resources so i acknowledge and i really really want to delete this so i'll go here and type in oh hold on that's my default one so it actually did remove it that time what i would say is i would double check to make sure there's no virtual private gateways because those you do not want to leave those running that will cost money but these got deleted out of here um maybe to also check endpoints or not gateways and so those are deleted as well i'm going to go over back to my usc 1 and so this thing uh if we go here oh it's all gone now so i'm not sure why it was showing up in both on that gateways that's fine those are gone so we have my terraform vpc here and if i go down to not gateways there's nothing there and i go over to virtual private gateways i have one set up here i didn't want to create one so what i'm going to do and i'm going to see if i can fake it here but i'm going to just switch this over to one and i'm going to do a terraform apply refresh only let's see if it picks it up and i'm going to see what it gets so here it says terraform detected the following changes made outside of terraform so that resource was deleted so that's not really the behavior i'm looking for i thought maybe we could like kind of like attach it there but i don't think that's going to work so what i want to do is i just want to delete this one here and so we will go and oh sorry i'm going to go delete the vpc because it might just take everything with it if we do it that way and so we say delete vbc and notice it has a virtual private gateway attached so i guess we're going to have to delete that first and we'll go up here and detach say yes detach and we'll make sure we don't have any gnats we don't that's good so we'll go up to our vpc and we'll go ahead and delete this vpc and go delete so yeah terraform is not always perfect sometimes you have to go in and delete resources but generally it's pretty darn good you just got to be careful what you're doing and that's why you should always be doing terraform plan and pushing things through a version control system like git so what i'm going to do is i'm going to try this again and we're going to do this through us east one so i'm going to do a terraform apply and i should be able to do this no problem now because um well there's nothing in my way so and while that's going on there i'm going to switch this over to usc 1 and we'll say yes and while that's going there i'm just going to refresh because once we have the vpc id we are ready to start using it so down below here it says oh right right so this is set up for um two so we'll set one one one we'll hit up here and i'm just going to do a sanity check and make sure there's nothing in my other v my other region here okay good we'll go back to north virginia here and we already have the vpc id so because we have that it looks like it might produce a new one though zero zero nine no it's the same one i think but what i'll do is i'll go back to project two which is referencing this state here we'll go back to the second one here and we'll just do a terraform init because we did change the region here so it might want to do something we'll do a terraform plan i don't think we ran into an issue with the plan last time okay that's all updated there okay great and so i'm really hoping that this just works this time so we'll do terraform apply auto approve so there must be something we don't know about how we developed our module and it's not supporting other regions again this is kind of out of the scope of uh the course here um because we're just getting into very detailed stuff but uh you know if we can just kind of get this working here so error launching source instance and valid security group sg subnet belongs to a different server okay so i'm going to see what is going on here so we have the state file here and except for that i don't think it created a server let me go see go to north virginia here see if we have any servers no and we'll go over to ohio here okay so i absolutely do not trust the state files in here anymore so what i'm going to do is open them in file explorer here for this one here i'm just going to delete them out and i'm going to delete this out and i'm going to just clear out whatever i can clear out it probably won't let us delete everything like the modules that's fine and so i'm going to just try this again terraforming it who knew this would be so hard um terraform apply auto approve and so what i'm hoping is it just takes it i'm going to just also check our terraform vars make sure everything's fine here because we don't say anything in there so i should just take it um double p here so the problem is there's a duplicate key so this is under um i seem to talk about key pairs here so we'll go here and we'll just go ahead and delete that we'll also do that in usc's i think it's more of a problem in usc than anywhere else we'll delete that as well and we will go ahead and hit enter there i'm really surprised i didn't generate like a unique name each time i thought that would do that eh and i guess the security group still exists so we'll go here and delete that out as well so i think it's just this one here delete is the key pair back now do we have to delete that no okay and we'll try this again maybe what it was doing is it was picking up the old security group that was that was pointing to somewhere else i don't know whatever issue we're having it was pretty odd and so let's complain about the security group but now we're doing everything in usc one so i don't know what its problem is so if we go over to our security groups wherever that is it's under vpc security groups so here it's 0 0 9 fe all that kind of stuff there and if we go to the original project here 0 0 9 f e so it is using the correct vpc right and this one here is fine if we go over here to this one this is in us east one so that's totally fine as well so there must be something that's not being set for it so it must be using like the default vpc i think it really has to do with our original module here so what i'm going to do is i'm just going to specify our original source there and so this one's going to be what was it just type in child module terraform here source local just doing this off screen here uh yeah you would just do a period or something the other one like a double slash or something i can't remember so this is in our this is up one directory and it's up another directory and it's in our modules here 110 modules terraform aws apache example okay and so this will just allow us to modify this and and kind of like fix what whatever issue we're having with this terraforming it let's see if we can find it there uh there wouldn't be any version constrained on here so that's right we'll just take that off and so i think what's happening is our um our resource is trying to launch in the default security group so we'll open up our main tf here and so this should be using that right and that should be using that and we don't set like a vpc here we just set the vpc security security group ids i'm just going to scroll up here for a second or this is on wc2 right or wsl2 and so this would be terraform in it to reform autoproof okay so if this is the problem what we'll do is go look up aws instance this is insane because maybe we're not specifying the security group correctly but i'm pretty sure we are so we'll just say vpc this is the optional ec2 classic default vpc only so that's the old way of doing it a list of security groups ids associated with subnet id do we set the subnet id here we don't aha so that's our problem so we can go subnet id here and that's what we want to set so the vpc subnet to id to launch in um i'm not sure how we're going to grab the subnet here so we'll go over to adress vpc so it's just easier to type it up your abus vpc and i'm looking for a subnet aws vpc get for subnet terraform i guess that would be one way of doing it so we could just i suppose select them that way so we're going to say data dot um oh we're in the wrong one we're in the example aren't we oh no that's right okay so then we would just want to go up to the vpc up here so data it's vpc main um vpc id equals data dot vpc.main dot id and these are subnet ids i assume what this is going to return back is like an array so i'm going to i'm just going to take a guess here and do aws subnet ids and just choose zero here and we'll see if that fixes our problem terraform init because we might have changed our module there and there's a command terraform get this i think would be the perfect case because we're just updating the module we're not updating the provider so that'd be the time that we would use that so now i'm going to try this again and see if this works a reference to data source must be followed by at least one attribute um accessible there the problem is i don't know what this is right so that's not really helping me out here uh what this in particular would be um so it was subnet ids a set of attributes found by the ids found this data source will fail if none are found so if that's the case then what we're going to be doing is doing dot ids and then maybe zero like that okay it was subnet ids has not been declared oh okay so maybe we do subnet ids ids is that going to work for us now by the way this looks all messed up oh just maybe the indentation here that doesn't look right um yeah this is this is super messed up hold on here apparently i lost some of the block okay so we said subnet ids.ids a data source vpc main has not been declared it's right there what are they talking about um so what i'll do is i'll just cut this here or like cut it paste this below here data vpc main id i don't know if we can do like it depends on on this probably not apparently we can we can do it i'm seeing an example where they're doing it depends on so what i could do is say depends on and then i would just specify data.aws vpc.main and we'll see if that helps it out there we can do terraform init again and try that if it doesn't like that maybe we can go into the directory itself and see if that will fix it um 110 and we'll just do terraform in it here maybe i remember ever having to do a knit with inside of it so i don't think that's the case oh you know what it's just this mistake and you might have caught that vpc but the depends on is probably a good idea data.vpc.main we'll try this again must be a whole object um okay well we'll take the depends on out then and we will try this again because it should be able to infer the order uh into which it works a data source another vpc vbc has not been declared in this stupid module this is so stupid data.awsvpc oh because it's not called vpc it's just called main okay my fault and so here it says elements of a set are identified but only their value and does not um it does not have separate indexes or keys with it it's only possible to perform operations across all elements in a set so let's just look up set so set terraform i just want to get like the first element in a set first element in a set terraform one one takes a list a set of tuple with either zero or one elements if the collection is empty one it returns null otherwise one returns the first element so what we can do here is if it's doing an id i suppose what we could do is go down to our subnet id here and we can say one and we will try that apparently it doesn't take an index invalid value for list parameter must be a list set or tuple with either values either 0 or 1 elements is a set of string with six elements so i don't know what this thing is like i don't know how you would go and say all right just show me what this value is what i could try to do here i'm just trying to think here how could i see this value without having to provision the resource and that's what i don't know um it's very very frustrating um i'll be back in a second okay all right so this is what i found and what we have to do is actually convert because this is actually a set and we need to convert it to a list at least this is what i think so what i'm going to do is take this out of here and we'll wrap it as such and then we'll give it zero and maybe that's our problem here please be the answer okay so i think it's created now so yeah that's kind of like and we're not in that section under the builtin functions but this is just where sometimes the data set returned is a set or those are really frustrating to use and so i guess you just have to cast it into another type um that one function i think should have worked with it but it just decided not to for whatever reason um but in this provisions that are uh we're all done here and we're all in good shape so yeah that is all good so we can do is now just tear this down because that worked no problem we'll say apply auto approve okay and while that is destroying what i'm going to do i guess i already have the third one open here i'm going to just update the code here git status git add um here git commit oops fix my module so should use the subnet specified for the vpc from the vpc okay and we will do a get push we'll do a git tag 1.1.0 we'll do a git push tags and so now for mo from now on we'll just use the version 1.1.0 um so that's destroyed we'll go back to original one here we'll do a terraform apply auto approve destroy i just want to show you as it's destroying that if we want to do remote it's pretty much the same thing we're just setting the back end as remote and we're applying that configuration values there i'm just going to stick around here just to make sure that this does destroy just because for some reason it just might not so this was project one oh we're in project two in both of these folders okay that doesn't help that that much but we're going to wait until this is destroyed and then once that's destroyed we will um tear down the vpc okay all right so we'll just make sure we go into the other project here project one and we'll do the same thing tear that down so yeah i realize this fall along is a bit of a mess i could go back and reshoot it so it's a lot more streamlined but then i feel like we will miss all of these kind of little things and without getting that kind of experience you're not going to know how to debug that stuff on your own so i i feel that i'm just going to keep this follow along as is you know hopefully you find value at it but it will be a frustrating experience and you'll know this because you'll get to the end of this okay hey this is andrew brown from exam pro and we're going to be looking at how to uh force an unlock okay and so what we're going to do is as always we're going to need a new folder here so i'm just going to expand this and i'm going to uh reveal in my file exp explorer here and we're going to make a new folder here we're going to call it uh 1 3 uh locking right okay like force unlocking i suppose and i'm gonna try to do this with terraform cloud because i feel like that will be the easiest way for us to do this so i'm gonna just go main.tf and what i'm going to do is make my way over to terraform cloud i know we still have that other environment that we're using the uh vcs terraform one but um what i'm going to do is i'm going to create a new workspace i'm just going to call this one cli driven we'll say create workspace and this one oops we're going to say force unlocking and then that's going to give us that nice little code there that we can grab we'll paste that on in there and i'm going to go back to our last tutorial here where we had project two and because i need something that's going to take a little bit of time so that we can force and unlock right so i'll go ahead and grab that code we'll paste that on in there and we are actually are going to use the version if we can here because i would rather do that and this is going to be terraform it was apache example i think i have to exam pro code to get that module there and it's going to be version 1.1.0 and we are not going to import our vpc id here we're just going to set it like we did before so just say var vpc id and we will need a variables here so we'll say and we'll have to go over to our project here we'll copy that over and what i want is to add the vpc id here okay and i really don't feel like entering all the state form files i guess i'm going to have to there's not really any way around that i suppose i'm going to cd back here 132 terraform init um cannot apply constraint to a nonregistered url so i've clearly entered that incorrectly we'll go up to here and see what it was this one's referencing it locally we used it in another project here maybe we used in the remote state one here nope uh standard probably there it is okay so we'll go ahead and grab that we're going to go down to our main here we're going to paste that on in and i'm going to do terraform init just going to initialize that back in there for us and while that's going i'm going to go set up our variables because it always takes a thousand years so we need to add quite a few here so i'm just going to pull this over here and then pull this over there i'm going to go look at a previous one here where we have tfrs so we want a vpc id here okay we want our mo our my cider block here we're going to get our public key here we're going to add another instance type we're going to add a server name and we're going to need our environment variables never can remember these so we're going to go over to the terraform registry have this open already up here so we go to the top terraform registry we'll go over to providers just make this a little bit smaller here whoops a little bit too small and we will go to documentation scroll on down grab these keys here this is going to go first that's going to be sensitive we're going to cat as always and we're going to grab the first one here paste that in go grab the second one here forgot the name here so we'll grab that one here we'll say uh whatever the region is here i should really memorize these so i don't have to ever have to look up that page again um that one's not sensitive we probably want the secret sensitive that's probably more important than the key okay and so we're all configured here to go and so what i want to do is deploy this but before i do i just want to double check to make sure that i know how to use the force unlock so i'm just gonna go here and we're gonna just pull up some documentation so we're gonna say terraform force unlock and so we just write terraform force unlock lock id we need the actual key there um so we can disable it with the hyphen lock command here so that's what i need to find out so all right i'll be back in a second okay all right so what's going to happen is um when we run it it's going to give us that output of a lock id when we do terraform apply twice so i'm going to do is do terraform apply auto approve to get this going i'm hoping this just works you got to spell that right with two p's and we're just waiting for that plan to start and while that's going i'm just going to open up a another one here i'm going to make my way into the same directory cd one three or it's one three two oops we've got to be quick here that's old so i'm gonna close that out that's old i'll go back to this one i want to get it before it finishes so what i'll do is type in um terraform apply and what it's going to say is that it's locked if we can do this quick enough oh interesting so it says waiting for one runs to finish before queued so i guess this is a case where if we're using terraform cloud we're not going to be able to get that lock id and i guess the only way to unlock it would be to go into uh terraform cloud itself as it's executing right and see how it's running and from there you could do a force unlock but that's not what we were trying to do we're trying to use the actual command so i could show you so that means that we do have to um use a terraform back end and so if that's the case what i'm going to do is once this is done here so now it's triggering the other one just gonna stop that so we're gonna go back to our original one here and i'm just gonna tear this down uh destroy and i'm gonna go back over here and what i wanna do is go back to our uh standard back end tutorial because that'll make it a lot easier for us to do in that one and so we will just go and close off these here close out our tabs and what i want to do here is go to our main one here and we need to upgrade that to 1.10 and the other problem is that we're gonna have to actually set this up for a dynamodb table so not only we're gonna have to create this folder right so what i want you to do is go to your s3 and we wanna make sure that we already have this uh bucket and we do good we'll go over to dynovaddb and create ourselves a new thing here so say create table and as always they're updating the ui and i just want to call this like uh force unlock terraform i don't know what we'd have to set as the partition key that's a good question so state locking dynamodb terraform okay so which can be enabled by setting the dynamodb table field existing a single tip it can be used to lock multiple remote state files it's not saying here like what we have to set up as the key for this okay so maybe we can just set it i don't think it's going to auto create it but let's give it a go and see what happens okay so i'm going to go down to dynamodb options here it is custom end point to the adabus dynamodb api this can be sourced from the endpoint and there's the table name used for state locking the table must have a primary key of lock id with the type string okay so that's our instructions there and we're going to go back to dynamodb we're going to set up our partition key and that's going to be a string we don't need to set a sort key here default settings are fine and that's going to go ahead and create there and so what i'm going to do is grab that name and what we need is dynamodb table okay so i'm going to do terraform init and we're going to migrate the state i'm totally fine with that yes great and so now if i do terraform apply oh right we have that old code in there that we're not using all right so yeah we have some old code here we need to remove so we're going to just take out this workspaces thing um to see if there's anything else remaining there no i think that's it so we'll go ahead and we'll try this again and uh we are going to make sure we're going to switch to both of them in order for this to work so i'm just going to go here ahead of time okay we'll go back over to here no problems this time around so we'll say yes and that is provisioning so i'm going to go back to this one here and i'm just going to type in terraform apply and it should complain saying hey this is locked right now you shouldn't unlock it and so this is where you would grab that id okay and so you would just type in terraform force unlock and then we'd paste the value in here and the thing is this is where you just type yes but we definitely don't want to do this because the other one is provisioning but i just wanted to show you how you get that id and pass it along um and you know when i'm talking about state locking in the lecture content i kind of wrote about here it says state locking happens automatically on all operations that could write state you won't see any message that it is happening if state locking fails so it's true as locking is happening it doesn't tell you that it's going on but it will tell you when you do another terraform apply we'll say hey it's in it's in state so i didn't technically lie here but i guess that could be like a little highlight that would have been good in the lecture content there um but i'm just going to cancel it out there we're going to go back to our first one here and we can see that that was deployed and what we can do for fun i don't think there'll be anything within dynamodb because i think that it will create the record and then get rid of it but we just click into our table here and we go view items notice there's zero items right now well no there it is okay so there was a an id at one point so i think that is good and what i'm going to do is just go ahead and destroy the infrastructure type yes and while that is happening um well we gotta wait for this to finish but once that is done then we'll go ahead and we'll just tear down the dynamodb and um s3 bucket okay all right so that is done destroying there so what i want to do here is go ahead and uh just delete this table really don't like this new ui i don't know who came up with this yep we'll delete all that make our way over to s3 here and i'm going to go ahead and just delete this table we'll have to go in and just delete all the records first pretty sure we turned off versioning there so there's no versioning right now and oh i went into the wrong bucket not that it matters that's old anyway oh cool yeah so we didn't look at this earlier but when we had production and staging they placed them into these areas here okay so that's kind of cool um i guess it's something i didn't look at but if we go terraform workspace list are we in the default one i would have thought we were in there eh oh we're in the production one okay so i mean i never showed this to you earlier because we didn't actually deploy it but um we actually did do a deploy this time around and i guess both the environments were set up here and they had their own folders so that's kind of interesting to see we'll go ahead and we'll just go delete all this and i'm just going to leave the bucket around here just in case i want to use it again but it is completely emptied out so we're good from scratch so there you go all right let's talk about resources so resources in configuration files represent infrastructure objects such as virtual machines databases virtual network components and storage and so it pretty much looks like this a resource type is determines the kind of infrastructure object it is so here it says aws instance and this would represent an ac database ec2 instance this is all defined within the provider's documentation so you have to kind of look at what name they use to figure out what it is and even though you don't see provider explicitly set here a resource does belong to a provider and you can explicitly set it and you would do this when you'd want to set a resource outside the default provider that you have in your configuration file um and so one little thing that i hadn't mentioned anywhere else and that's why i made this slide was to mention about special timeout nested blocks within resources so some resource types provide a special timeout nested block argument that allows you to customize how long certain operations are allowed to take before being considered to have failed okay so there you go let's talk about complex types so a complex type is a type that groups multiple values into a single value and complex types are represented by type constructors but several of them are have shorthand keyword versions okay so there are two categories of complex types we have collection types for grouping similar values so list map set and structural types for grouping potentially to similar values so tuple and object and now that we have an overview let's go jump into collection types and structural types a collection type allows multiple values of one other type to be grouped together as a single value and the type of value within a collection is called its element type the three kinds of collection types are list map and set and so looking at our first one here what we're doing is we are setting ourselves something that looks kind of like an array it's this list type here and what we can do is use our index so the indices 0 to reference the first element which is mars so that's going to make our user name mars for a map it's very similar to a ruby hash or a single nested json object and the idea here is that it's very similar to the first except now we're doing a key and value and then we access it by based on the key name so plan b is going to return 50 usd okay we have set it is similar to a list but has no secondary index or preserved ordering all values must be of the same type and will be cast to match the first element okay so it's a great way to kind of have um well i guess no secondary index but yeah so you do two set and then it would turn into this okay all right let's take a look here at structural type so a structural type allows multiple values of several distinct types to be grouped together with a single value structural types require a schema as an argument to specify which types are allowed for which elements so this is what they're talking about when they say this schema so when you actually define the variable notice where it says object and you are actually setting a is going to be a string and b is going to be a string there's this optional option which i think is right now in beta uh but hopefully by the time this course is out or it's the future you have that option there but just assume that they're all required so that's what they're talking about is that you are specifying exactly what you expect the schema to be okay so there are two kinds of structural types we have objects and tuples and they're going to look very familiar to maps and lists because they're pretty much the same but with explicit typing so object is a map with more explicit keying so this example we'd have name for string age for number and so that's what it would expect the data structure to be for tuple multiple return types with a parameter so we can have string number or boolean so this is where we'd have um a as a string 15 or true as a boolean so yep there you go hey this is andrew brown from exam pro and we're going to look at the collection and structural type so i have a new folder down below just in case we need to define some things so i'm going to go here and just call this main.tf and we are just going to configure this for local terraforms we'll just give the brackets there and so the idea is that we might have different kinds of variables and we had done this previously where we created a list and a map but we can do that again so we'll have like planet right so that's list and then we just default that to a value mars earth moon and then we could also have you know plans here and that would be our map type okay and so here we'll just set it with the curlies plan a plan b plan c um so we'll do terraform console and so that should load these variables for us to use and so if i do var.plans i get that and if i do var.planets i didn't like what i did there input variable has not been declared i suppose it's just planet there so i should have named that planets up here and so what we're going to do here is just go ahead and exit type clear i'm just going to expand this a bit bigger so we're taking over more of the screen now let's take a look at structural types so these require you to actually define um parameters so what i'm going to do is go down below and we're going to do the object and object is very similar to the map so let's go down here plans object and so here what we do is we'd say type object and we would just have to define some settings here so we could say a is a string all right we'll see if that works the default value is not compatible with the variable type constraint attribute a is required so that's fine um what we could do is just define this as like plan a plan b plan c and now if we just do var plans object when you are using this you know you might want to specify some different kinds here so you could just say like you say like plan here so we say plan name plan amount maybe it's like number and so then we'd say plan name plan amount basic maybe this would be 10. okay and we'll just uh type exit here and go back into terraform cloud hopefully we don't get an error here so the plan amount is required so you know we can't have a spelling mistake here just do var plan here um well we named it correctly there and when we went up here and specified it i think we got it right plan object so sure what it doesn't like here oh you know what we're not in terraform cloud okay that's fair and we're still spelling this wrong oops okay so there we go we got our basic plan and then we can do a tuple here so i don't know if i've ever defined a tuple before so let's just try it here and so we'll just say uh um groceries or val or random type equals tuple i'm just looking up if there's any kind of definition i can find here i'm not really finding anything but i'm just going to go uh define this here because i thought maybe it needed like a schema or something but maybe it doesn't so we'll just say hello 22 false okay terraform console typical constructor requires one argument specifying the element types as a list okay so if that's the case then what we could do is say string number boolean the uh type constructor requires one argument supposed to find the number of elements so clearly i'm doing this wrong so just give me a second i'll be back in a moment okay all right so i think the problem here was just that i need to make brackets here like this we'll give that a go boolean is not a valid option what if we try bool okay we say var.random good and so i'll just go ahead and exit that out i'm going to see what happens if i change the order here so let's say i do instead of 22 here we go here okay so notice that you know we can have all sorts of kinds but they have to match exactly the order that is there so yeah that's pretty much it so there you go the terraform language includes a number of builtin functions that you can call from within expressions to transform your combined values so we have numeric string collection encoding file system date and time hash and crypto ipnetwork type conversions so we are going to go through all of these we might not go through every single function but we'll go through every single major category uh in terms of the exam the only thing that's going to show up might be string functions why they do this i don't know it's not a very good exam question but those might appear but i think that this is one of the strongest features of terraform over something like cloud formation and i really want to just show you the gambit of them okay let's take a look here at numeric functions starting with absolute so returns the absolute value of a given number so 23 is 23 0 is zero and if you get a negative number it's going to flip to the positive for four what it does is it rounds down to the nearest whole number so see where it says 4.9 becomes a four you have log so it returns the logarithmic i can't say that word logarithm logarithm of a given number in a given base so log 50 comma 10 is going to give you that 16 comma 2 is going to give you 4 okay seal it it's where it will always round up so see where it says 5.1 and it goes all the way to 6. we have min so take one or more numbers and return the smallest number from the set and max take one or more numbers and return the greatest number of the set i don't have examples because that's pretty straightforward you know if there's a two and a four it's going to return the two in min if it's a two and a four it's going to return the four for max we have parse in so parses the given string as a representation of an integer in the specified base and returns the resulting number so if we have a hundred here in strings it's going to and we say comma 10 we're going to get 100 because that's the base system it's base system 10 base system 16 we can see letters in there right so it's able to translate that this is two so that's basically binary so zeros and ones so you get the idea there uh pow so calculates an exponent by raising its first argument to the power of the second argument so that's just the way of doing powers and then we have signum so determine the sign of a number returning a number between negative one and one to represent the sign so there you go all right let's take a look here at string functions the first being chomp so removes new line characters at the end of a string so you know if there's a hyphen n or sorry backslash n you don't want to see that there that's the way you get rid of it then you have formats it produces a string by formatting a number of other values according to the specification so here there are uh percentage delight so this is representing a uh a digit so it's taking that number this says it's going to be formatted as a string okay um format list so produce a list of strings by formatting a number of other values according to a specification string so here we have an array and then we have our specification so you can see it's substituting the name there we'll look at indent so adds a given number of spaces to the beginnings of all but the first line in a given multistring so here we have a string um and what it's going to do is see where we have the interpolation here and then we have indent i know the highlighting is not great because it's a single string but we have interpolation we have parentheses two so give it a a layer of two indentation and then it's going to break that up and give it indentation so we have join so produce a string by concatenating together all elements of a given list of strings with the given delimiter so you use delimiters is double click or sorry is a comma and so it's going to glue that together to make this okay if there's only a single one there just won't be any comma in there we can lower all the text it's pretty straightforward we have regular expressions so that is an extremely powerful feature so here we have the regex i don't know what the regex format is maybe it's pearl i'm not sure there's like a bunch of different types of regex standards so you know do you have to figure that out so you know how to use it and then there's a regex all supplies to a regular expression to a string and returns a list of matches where this just is returning uh one okay we have replaced so search is a given string for another given substring and replaces uh each occurrence within a given replacement string so it's just like the javascript replace we have split this is the opposite of join so if we want to split on the comma we specify comma here we have str rev so string reverse so reverse is a string so hello becomes holley we have sub hole sure i don't know um so string so extracts a substring from a given string by offset and and length so we have a sub string and we're saying we want one to four so we only want uh one two three four here okay because it starts at zero we have title so make a title case we'll capitalize the h and the w we have trim removes the specified character from the start and end of the string so we don't want these and we tell it to remove those there's a lot of string functions so we have trim prefix so removes the specified prefix from the start of the given string if the string does not start with the prefix the string is uh is returned and unchanged so here we say we want to get rid of hello in the front so we do that suffix is the opposite so we want to get a rid of world out of the suffix so we do that we have trim space that removes all types of white space from both the start and end of the line so it gets rid of the new lines and the spaces upper is going to put everything to upper and there you go on the exam they probably will ask you uh like what string function does or which one does not do something so this is the only part of the building functions you have to know for the exam i don't think it's a very good exam question but it does appear there so you need to know it okay we're on to collection functions and these are the most powerful builtin functions and there's a lot of them and i made sure to give you an example for each one because i really do want you to know these because this is the power of terraform the first on our list here is all true so returns true if all elements in a given collection are true or true or it also returns true if the collection is empty so it's either true true right or we have true false so because there's a false it's not going to be true so any true is very similar but there only has to be one that is true so if this is true and there's a false it's going to be true if it's blank it's going to be false okay we have chunkless splits a string list into fixed size chunks returning a list of lists so here we're telling it to chunk it every two so grab every two and make them into their own little array or list i suppose we have coalesce takes any number of arguments returns the first one that isn't null or empty string if you're used to postgres you use this all the time but the idea is it's going to grab the a in this case it'll grab the b because that's blank in this case we'll grab the one because that's the first value we have coalesce list takes any number of list arguments and returns the first one that isn't empty so very similar it's just using lists or if we want to call them array so the first one is available so it takes that one we have compact so takes a list of strings and returns a new list with an empty string elements removed so it's just going to get rid of that space there and we'll get abc we have concat so it takes two or more lists and combines them into a single list so that's very convenient we have contains so determines whether a given list or set contains a given single value as one of its elements so does it have an a yes it does does it have a d no it does not we have distinct so it takes a list and returns a new list with any duplicate elements removed so we just want to make sure we only have one of each so do we have any duplicates here we have two a's and two b so we're going to end up with just a single list so only exactly one of each letter we have element retrieves a single element from a list so get me the element at 3 here so um wait retrieves a single element from a list okay well that's what it does you give it a three and it gives you an a i don't know why it's not clicking for me but i'm i'm not following through here uh index finds the element index for a given value in a list so we say where is b and the index of b is is one because it'd be zero and this would be one still really confused about this one uh flatten takes a list and replaces any elements that are are lists with a flattened sequence of list content so basically it says give me a bunch of arrays or lists turn into one flat list keys take a map and return a list containing the keys from the map so we just want the keys a c and d we want length this is pretty straightforward so what's the length of this zero this is two this is one because it's a one map or one thing key value in there and if it's a string it's going to count the characters so there's five characters we have lookup so retrieves the value of a single element from a map given its key if the given key does not exist the given default value is returned instead so we say uh lookup a and what we get is a y right look up c and it could not find c so by default give us what instead a match keys construct a new list by taking a subset of elements from one list whose indexes match the corresponding indexes of values in another list that sounds complicated let's read that one more time so constructs a new list by taking a subset of elements from one list who indexes match the corresponding index of values in another list that is confusing so we have one list and another one so we have this one here and we have us west u.s east usd so we say okay we have usc's so the elements here is two and three so give us two and three so that's what it does that was it that was the tricky one i can't think of what you use that for but that's a interesting function merge takes an arbitrary number of maps or objects and returns a single map or object that contains a merged set of elements from all arguments so it just merges them together so it's just like concat or i suppose like fladden uh one takes a list set or tuple values from uh with either zero or one elements if the collection is empty one returns null otherwise one returns the first element if there are two or more elements then one will uh one will return an error so it returns null and an empty list it returns the first one and then here it says invalid function so it's just saying is there one right is one or zero uh ranges generates a list of numbers using a start value a limit value and a step value so we say 3 and we get 0 1 and 2. generates a list of numbers using a start value limit value and a step value okay uh reverse so takes a sequence and produces res or not reverse reserve sorry reserve takes a sequence and produces a number uh induced sequence of the same length with all the same elements as the given sequence but in reverse order oh it is reverse r e reverse i guess i spelt it wrong here sorry reverse one two three three two one just notice this is a spelling mistake okay uh set intersection so function takes multiple sets and produces a single set containing only the elements that all of the given sets have in common in other words it computes the intersection of the sets well that's tiring so from what i can tell it's like they all have b so give us b right set product functions find all the possible combinations of elements from all of the given sets by computing the kardasterian product we're really getting into math here so we got app one and app two and so we get uh development develop okay so this continues on so it's gonna say give me app one with development give me uh app two with development then app one with staging and then app two with staging and etc etc because that's why i put the three dots there set subtract function returns a new set containing the elements from the from the first set that are not present in the second set and in other words it computes the relative complement of the first set in the second set uh it lost me there but it says set subtract so here i see a b and c a and c minus it you get b okay set union function takes multiple sets and produces a single set containing the elements from all the given sets in other words it computes the union of the sets so it says set union so we have a b b c and d and in the results we get d b c a so i guess um single set containing the elements from all the given so yeah yeah i guess it's just we get unique ones across the sets uh we have slice and notice like we're going through all these things it's like you probably won't use these more exotic ones so it's not a big deal if we don't nail them here but it's important that we go through these so that you know you just know all the options are here so slice extract some constructive consecutive elements from within a list so here we are saying one and three so we have b and c that's where they start index one and then extract some consecutive elements from within a list one comma three okay sort takes a list of strings and returns a new list with those strings sorted lexographically so we have e d a and x and so now they're alphabetical so a d e and x well i think this is the last one uh sum takes a list of set numbers and returns the sum of those values that's pretty straightforward add them all up transpose take a map of list of strings and swap the key and values to produce a new map a list of strings so kind of like inverts it values takes a map and returns a list containing the values of the map so we saw this earlier we got the keys this is where we just want to get the values zipmap so construct a map from a list of keys and a corresponding list of values so we have a b one two and this turns it into a equal one b equals two i think i saw this on the exam so that one you might wanna remember but yeah that's collection functions as you can imagine they're extremely powerful but they can also be really confusing so maybe just use them a little bit when you need to okay we're taking a look here at encoding and decoding functions so functions that will encode and decode for various formats so imagine we need to encode into base64 so we do hello world or imagine we give that encoded string and we want to decode it back to hello world uh that's what we can do so there's a lot of different encoding decoding functions most of them are the same they're just kind of variants so we're not going to go through every single one but i'll list them out so you know what they are so we have base64 encode json and code text encode base64 yamlin code base64 gzip url and code base64 decode csv code json decode text decode base64 yaml decode and just notice that you know these aren't one to one so there is one for this uh we have one for here uh we have one for yaml and this is unique this is unique this is unique okay just so you can tell for your encode i think this one's a very common one that you'll use but the idea is that let's say you have hello world you want to replace that string with a whatever friendly for a url right so it just encodes it okay it's very useful when you're making uh url links so there you go we're taking a look here at file system functions so this has everything to do with the file system so the first is absolute path so the idea is you give it something that's relative and it's going to give you something absolute directory name so this is a string containing a file system path and removes the last portion from it so we don't need the file name so we just remove that off of there we have path expand so it takes a fascism path that might begin with a tilde and expands it into uh its absolute path so this would be like for home okay base name so it takes a string containing a file system path and it's basically the opposite of directory name we just want the file here okay onto uh the next page here this file will read the contents of the file pretty straightforward we can check if a file exists so we just do file exists here we have file set so it enumerates a set of regular file names given a path and pattern file base64 so reads the contents of a file at a given path and returns the base64 encoding that might be good for images template file so reads the file at a given path and returns its content as a template using a supplied set of template variables so that's really useful if you want to do some kind of templating and just notice it's a twoset process so this is the template file the actual file itself and then we load it here it's called a dot tpl so there you go we're taking a look at date and time functions the first is format date so the idea is that we provide a format that we want and then we give it a time stamp that is in the rfc 3339 format and we get a variety of different um formats out there we can add time so again it's gonna be that rfc 339 format and we say add 10 minutes add one hour then we have timestamp so you it returns a utc timestamp string in the rfc 3239 format so you just say timestamp it's i guess it would get right now and then you get it in that format okay let's take a look at hash and crypto functions so generates hashes and cryptographic strings so the most popular one out there would probably be b crypt so here we just say hello world and we're going to get this thing here uh understand that a hash cannot be reversed so once it is turned uh into uh you know this format the only way you're going to be able to confirm the contents of it is to hash something that is similar and then compare it against it okay so we have base 64 sha256 we have 512 we got bcrypt we have file base64 64 sha256 file based 64 sha512 file md5 file sha 1 file sha 56 file sha 512 md5 rsa decrypts sha 1 sha to v6 sha512 uuid uid v5 so i only showed the one because you know it gets kind of boring to go through all these and really it's just going to be based on your use case what you're going to be using on a daytoday basis is probably bcrypt md5 and uuids so there you go let's take a look at ip network functions these are the coolest functions i think that are built into terraform so we have cider hosts so what we can do is give ourselves a um a address and then we can give it a subnet mass size and we'll get back an ip address and so you can see we have this both in the ipv4 and the ipv6 we have cider net mask so here we are doing saturn net mass so we just say forward slash 12 and it's going to translate it into the full ipv4 then we have cider subnet so this is just where we say okay i want a subnet of a particular size so we say 172 16 0 0 comma 4 2 and look it's going to give us 18 0 back this doesn't make sense that's okay i mean networking is really hard but i just want you to know that these functions are here for you okay cider subnet calculates a sequence of consecutive ip addresses within a particular cider prefix so four four eight four and then you get those sizes there okay all right we're on to type conversion function so the first we're looking at is can so can evaluates the given expression and returns a boolean value indicating whether the expression produced a result without any error so can we use this right so we say local dot foo dot bar and so you know if if this foo wasn't defined then it would say false but apparently we made it all the way to bar okay we have defaults a specialized function intended for use with input variables whose type constraints are object types or collection of object types that include optional attributes and i don't show that one here because it's not that exciting but nonsensitive takes a sensitive value and returns a copy of that value with the sensitive markings removed therefore exposing the sensitive values so if we have an output here and we want to make it nonsensitive that's what we could do then sensitive as you imagine is just the opposite okay um we have to bool so converts its arguments to a boolean value so if we have a string that's true we can turn it into a real boolean value we have to map converts an argument to a map value to set converts it to a set to list converts it to a list two number converts it to a number uh string to string and then we last we have is try so evaluates all of its arguments expressions in turn returns the result of the first one that does not produce any errors the thing that's the hardest to figure out is set i cannot find really good examples of documentation on the use case of set there are some cases where you need to use sets which is an actual type but even talking to da's and technical writers they weren't even sure themselves so this is not something you're going to come across very often but there's like one case where i saw it so i'll probably point that out when we do hit it okay hey this is andrew brown from exam pro and we are going to go take a look at um builtin functions as soon as my terminal decides to be responsive i don't know why as soon as i start recording it decides to lock up so let's just give it a moment there there we go and so i have a new folder there i figured we could just define some variables so that we don't have to uh you know constantly write stuff in so we'll just say main.tf we're going to go terraform here and so might be fun to you know set kind of some kind of variable here and so i have off screen here all the functions so we're just going to kind of pick some at random here to play around with so we get some experience okay so just going through strings i think what we can do is define like our string so we just say str here and we'll just say type equal string and we'll just say default here able to say hello world forward slash n something like that okay and then we'll do terraform console here i gotta remember to do it this way so we do var.str okay so that accesses our string there maybe we might want to take out the new line for now so i'm just going to kind of pull this up over here look at some kind of things we can do okay maybe collapse that get that out of the way all right so um there's a lot of string functions and on the exam they might actually ask you some which is in my opinion i don't i don't really like that but that's what they do and so you might we might want to look at something like split or something so here we could do hello world okay start that up again so we'll do split comma var str okay and that would split that into a list we might want to do something like upper so i think we did that earlier where we did upper okay you might want to do trim remove specify characters from the start and end of a string so maybe we have this here and so we'll say trim var str and whoops that's not what i wanted it to do trim bar str like that okay and uh there's again there's not a lot that's exciting here maybe we'll try a replace so we can do replace and we'll we want to replace we will provide our string and then the substring that we're looking for so world replace that with barsoon which is mars there we go so nothing super exciting over there uh what's more interesting are some things like these hash and cryptos so something we might want to generate out as a uuid i think that we might be able to do this here so let's just see what happens if we try to call it like that clear terraform cloud oops terraform console that's what i meant to type and so functions can't be called in here which is totally fine so go back and just set that like that i just wanted to show you that so if we did uuid we would get that if we used bcrypt so let's say bcrypt hello world okay might be something interesting the ip network here so you might want to generate out a cider subnet right the type of conversions is something that you might come across a bit so we already saw that when we converted a set to a list and things like that so maybe we might want to convert something to a boolean so we might say to bool true okay these are pretty complicated the collections but we might have something that we want to do here so last might be something that's interesting where we have an array so or a list i suppose so we might say like items and make that a list null null empty last okay bar items so we might say coal less okay and that didn't look like it pulled anything out of there to perform coalesce operation with a list of strings use this symbol so we could use that um to do that so that just kind of expands the arguments and so that what happened here is null didn't exist all didn't exist this didn't exist so it pulled out last okay maybe we might want to just use keys maybe we might just want to use keys here okay so i'm gonna say like hello world goodbye moon remember we can do uh hash rocket arrow equals or colons just up to your preference i just wrote that in for whatever reason i'm used to using ruby and that's what we use as hashrockets that's the name of the symbol the a equals arrow um okay it didn't like that so i guess we do have to do it this way that's totally fine i'm not upset by that i thought it supported all three maybe it's like minus equals or something i don't know but we'll do say it's a var stuff and then what we can do here is do keys okay and it didn't look like it grabbed the oh yeah i grabbed the keys that's fine okay and then we might say values all right um you know maybe we might want to try reverse that one's pretty clear one two three okay so nothing super complicated um i wonder if absolute would work in here like the file system so we have absolute path but i don't know if this would produce anything here oh it does okay so get abs path say path dot root there you go okay so that pretty much gives you a general idea of builtin functions so there you go all right let's take a look here at terraform cloud again but in greater detail so terraform cloud is an application that helps teams use terraform together uh and so there is the ui there and terraform cloud is available as a hosted service on terraform terraform dot io it's actually the app.terraform.i once you're logged in and it has a lot of different features so it can manage state files uh have a history of your previous runs a history of your previous states easy and secure variable injection tagging run triggers of chaining workspaces together specify any version of terraform per workspace global state sharing commenting on runs notifications via web hooks email and slack organization and workspace level permissions policy is code via sentinel policy sets mfa single signon uh cost estimation integrations with service now splunk kubernetes and custom run tasks and that is not the limit to what it does but this is what i could fit on the slide okay let's take a quick look here at the terminology or anatomy of terraform clouds so we have an organization and with an organization we have our workspaces and a workspace represents a unique environment or stack then you have your teams these are composed of multiple members and a team can be signed to multiple workspaces then you have runs a run represents a single run of the terraform run environment that is operating on an execution plan runs can be uh triggered by like you your the ui itself or maybe like a git repo it could be api driven or cli driven so there you go so there are three types of cloud run workflows so when you create a workspace you have to choose a workflow and you have either version control workflow we have cli driven workflow or api driven workflow okay so just going over them in greater detail for the first one which is that uh version controlled workflow uh terraform cloud is integrated with a specific branch in your vcs so githubs via web hooks whenever pull requests are submitted for branch speculative plans are generated whenever a merge occurs to that branch then a run is triggered on terraform cloud then you have api driven so workspaces are not directly associated with the version control system repository and runs are not driven by web hooks on your vcs provider a thirdparty tool or system will trigger runs via uploading a configuration file uh via the terraform cloud api so this configuration file is a bash script that is packaged in an archive and you're pushing it as a configuration version so you're basically creating configuration versions every time you do that then there's cli driven and this is the way we're going to be using mostly in the course so runs are triggered by the user running terraform cli commands so you'll run tear from apply and or plan locally on your machine it's going to just work as per usual okay let's take a look at organization level permissions which manage certain resources or settings across an organization so the first things that you can set would be something like manage policy so create edit delete the organization's central policies manage policy override so override soft mandatory policy checks manage workspaces so create administer all workspaces within an organization manage vcs settings so set of vcs providers and ssh keys available within the organization and for an organization we have this concept of organization owners so every organization has at least one organization owner and you can have multiple this is a special role that has every available permission and some actions only available to owners so this could be publishing private modules invite users to organizations manage team memberships view all secret teams manage organization permissions manage all organization settings manage organization billings delete organizations and manage agents so just understand that there are these special ones just for this organizational owner and then these are these other ones here that you can set for other types of organizational level permissions okay well let's take a look here at workspace level permissions that allows you to manage resources and settings for a specific resource and we have granular ones and then we have premade permissions so let's go through the granular permissions first so these granular permissions you can apply to a user via a custom workspace permissions and so we have read runs cue plans apply runs lock and unlock workspaces download signal mocks read variables read and write read state outputs read state versions read and write state versions and so the idea is that what you can do is just go and cherry pick out what you want to assemble your permissions for your user now if you want something a little bit easier to do you can use fix permission sets and these are premade permissions for quick assignment and they're based on the read plan and write so we have read runs read variables read state versions for plans we have q plans read variables read state versions we have write so apply runs lock and unlock workspaces download settings mocks read and write variables read and write state versions and then there are workspace admins and this is kind of like the organizational owner so a workspace admin is a special role that grants all level of permissions and some workspace adminonly permissions those adminonly permissions would be read and write workspace settings set or remove workspace permissions of any team and delete workspaces so there you go let's take a look here at api tokens so terraform cloud supports three types of api tokens users teams and organization tokens so for organization api tokens they have permissions across the entire organization each organization can have one ballot api token at a time only organization owners can generate or revoke an organization token organization api tokens are designed for creating and configuring workspaces and teams they're not recommended as all purpose interfaces to terraform cloud so basically you just use them when you are setting up your organization for the first time and you want to do it pragmatically okay then you have team api tokens so this allows access to workspaces that the team has access to without being tied to any specific user each team can have one valid api token at a time any member of a team can generate or revoke that team's token when a token is regenerated the previous token is immediately becomes invalid designed for performing api operations on the workspaces same access level to the workspace the team has to access to i would imagine this is when you're setting up your own custom ci cd pipelines or something like that i'm not really sure exactly the use case for team api tokens we have user api tokens the most flexible token type because they inherit permissions from the user they are associated uh could be for a real user or a machine user when you do terraform login this is what you're getting a a a user api token okay all right so i just wanted to quickly show you this access levels chart that helps you understand what kind of permissions you're giving at the access level and notice there's implicit and then required or explicit permissions i'm assuming that this means that you need to assign those permissions to the user first before they'd have it so just because you have a user token doesn't mean you get all of these orange diamonds it's just the ones that you've assigned to that user or team where i believe that the organization you're going to run into a chance where you're going to have all these permissions by default whether you want them or not so just understand that you have to double check this before you use your tokens and that this chart exists okay all right so we covered private registry earlier in the course and we were looking at the terraform registry the public one but let's cover it again with a little bit different information so terraform cloud allows you to publish private modules for your organization within terraform cloud private registry and tour from cloud's private module registry helps you share terraform modules across your organization include support for module versioning a searchable filterable list of available modules a configuration designer which i didn't find this thing but it sounds really cool all users in your organization can view your private module registry um authentic for authentication you can either use a user token or a team token so i guess this would be the case where you might want to use a team token for authentication but the type of token you choose may grant different permissions as we saw with the access levels uh just the slide prior using terraform login will obtain a user token just a reminder and to use a team token you'll need to manually set it in your terraform configuration cli file okay so there's a feature within terraform cloud that can do cost estimation uh and it is a feature that will give you a monthly cost of resources displayed alongside your runs uh this feature is only available starting at the teams and governance plant and above but the idea is that it will tell you for specific resources and then give you a summary so notice here that we have some pricing i'm gonna get my pen tool out but we have the overall cost and then it's broken down per resource and so you can see we have an hourly monthly and monthly delta i don't know what the monthly delta is but you know gives you kind of idea of cost you can use sentinel policies to assert the expectation that the resources are under a particular cost so that's just kind of a bonus there where you're like okay i want to assure my spend is this the only downside at least at the time right now for cost estimation uh is the amount of support it has so we have aws azure and gcp so these are the resources that it will support and so you have to look through here and say okay you know is there any resources i'm using outside of this that i really care about um and that so i think that if you're using like core services so like ec2 instances uh load balancers things like that that should help you out so like we see aws instance the load bouncer the volume some cloud watch logs alb for google it's just disk instance and database so yeah it's just really dependent on you know what's here so you know it may meet your needs or you might say okay this is not enough okay here's just a few options that i think are worth noting within the terraform cloud workflows we have a whole section of workflows but i decided to put it over here just because let's talk about it one thing you can do within terraform cloud is set whatever version you want so you can go as far back as you want uh and this is great if you need to mix and match uh different workspaces because you have different stacks and they were built on different terraform versions and you're just not ready to upgrade them yet you can choose to share state globally across your organization for a particular workspace this could be really useful if you need to reference things wherever you can choose to auto approve run so if you don't want to always do that manual approve you can do that this is great if you are looking for that kind of agile kind of workflow where uh if something is merged then it should be rolled out okay let's talk about if we had to migrate our local state and we're using just the default one two terraform cloud how would we do it so to migrate terraform projects that only uses the default workspace tier from cloud it's pretty easy you're gonna create a workspace and terraform cloud you're gonna replace your terraform configuration with a remote backend so if you have nothing it's using local and you just put in your remote state and then once you have that in there you do a terraform init and it's going to say hey do you want to copy the existing state you're going to type yes and once you've done that i believe you have to delete your old state file if you are migrating multiple multiple environments or you're moving from a standard remote backend it's a little bit more complicated they definitely have guides in the docs but this is the pretty much standard one that you're going to come across when you're working very early and we'll definitely see this as we are using terraform in our follow alongs okay i want to talk about what kind of integrations we have for terraform for version control systems so we have github github auth github enterprise git lab get lab ee nce i assume that's enterprise edition and community edition big bucket cloud bitbucket server and data center azure devops service as your devops server so it's very simple you're just going to choose from the one of the four right and then you're going to drop down and choose what variant it is there and connect your repo every single provider has different configuration settings so you might have to meet those depending on what they are you can get from private repos you might have to add your ssh key or something like that okay let's talk about terraform cloud run environment so when terraform cloud executes your terraform plan it runs them in its own run environment so what is a run environment a run environment is a virtual machine or container intended for the execution of code for a specific runtime environment a run environment is essentially a code build server so the terraform cloud run environment is a single use linux machine running on the x86 or x64 architecture and the details of its internals implementation is not known it is possible to install software on it but the only issue is that we don't know what it is is it debian is ubuntu you just can't tell terraform cloud will inject the following environment variables automatically on each runtime so we have tfc run id this is a unique identifier for the current run the workspace name uh the workspace slug so this is the organization followed by the workspace just gonna get my pen tool to just kind of point out over here on the right hand side uh we have the configuration version and git branch so you know if it is gonna be on main it's gonna tell us that if it's going to be a particular version we'll know that as well we can get the shaw of the current commit there's that version and if you want to access these variables you just define variable and the name and then you can access it throughout the code okay let's take a look here at terraform cloud agents this is a paid feature of the business plan to allow terraform cloud to communicate with isolated private or onpremise infrastructure it's kind of like an inbetween uh between a terraform cloud and terraform enterprise where you want to use terraform cloud but you have uh onpremise infrastructure but you're not ready to move to terraform enterprise so this is useful for onpremise infrastructure types such as vsphere nutanix and openstack the agent architecture is pullbased so there are no inbound connectivities required any agent you provision will pull terra from cloud for work and carry out execution of that work locally agents currently only support the x86 architecture or the x64bit linux operating system okay so you can also run the agent within docker using the official terraform agent docker container if you just prefer that over a vm agent supports terraform versions 0.12 and above the system require this request the system requires i'm going to change that in the slide later on but the system requires at least four gigabytes of freedom space for temporary temporary local copies and two gigabytes of memory needs access to make outbound requests uh so you need to have open port 443 for app terraform io registry terraform io releases hashcorp.com and um archivist dot tara for my i o so there you go hey this is andrew brown from exam pro and we are on to our terraform cloud uh follow alongs now we already did terraform cloud version control system earlier than i thought we were going to do so i'm going to remove from the list and what we'll do is focus on permissions and maybe the api tokens and things like that so what i want you to do and i've got some old tabs open here i'm going to make my way over to terraform dot io and i'm going to go log into terraform cloud here and i don't think i've ever done this but i can upgrade to the trial account because the thing is is that when we are in our account here and we're trying to look at permissions and we're not using force and locking anymore i might just keep that around for a little bit but if we were to go to our user settings here we go to organizations um that might not be a very good example i guess i wanted like the organization settings here which would be maybe here yep up here and so you know when we go to our teams and our users our users everyone's being added as an owner we don't have like granular permissions and that's because we'd have to upgrade and so i figured this would be a good opportunity for me to kind of upgrade to show you those more detailed role based access control permissions just so you know where they are so i'm going to go the upgrade now and notice that we're on the free plan and also take note because um later on the course i talk about pricing or we've already already across it but notice that we have a team plan and a team and governance plan this one's at twenty dollars and this one's at seventy dollars so you know this is not something that's reflected at least not right now on the terraform website and so it just looks like there's a team in governance plans for 20 and this middle one's missing the key difference here is this one has sentinel policies code but you can see on the free plan we are able to do team based stuff let's go switch over to the trial plan i'm going to see if i can do this without entering a credit card in so here it says you're currently on trial plan i didn't have to enter anything in that's really great and so that means now i have all these team management options so if i go over to team management um i can actually go ahead and create some teams so i'll just say like developers okay and so now i have all these options so we can say this person if someone's in this team they're allowed to manage policies they're able to do that uh a visible team can be seen by every member or we can keep them secret we can generate team api tokens which i guess we could just like cover this as we do it but notice we can go here and that generates out that token that we can use i'm going to go ahead and delete that token um so nothing super exciting there you know it's not like that complicated if we want to set things on the workplace now if we go back to workplace or workspaces here and now we have team access and notice i can go to add team permissions here and we can say select this team for their permissions and so these are these uh prebuilt ones in um so we have read plan rights so these are those three predefined ones that we talked about previously and then we have down here like assign permissions for the admin of a workspace we are able to set customized permissions so if we toggle this we should be able to do it i mean this looks like it's the same thing no i guess it's more granular so here i guess we have our granular permissions that we can set so for runs we can do read plan or reply lock or unlock a workspace send unlocks things like that it's not super complicated if you want to drain out api tokens for uh well there's the organizational one there's the teams one and then there's the user one so if we go to the organization we can see that we can generate out one here so i can say create an api token so there it is let's go ahead and delete that and if we go back to our teams we did this earlier but we can generate one here and then if you want to generate one for your user it's probably under user settings yeah so we generate tokens there as well okay so i mean again there's not a lot to talk about here but yeah so i guess that really covers permissions and api tokens okay okay so that finished uh deploying there and so we can see our resources have been created but one thing that uh we didn't set was the prefix i'm actually interested to see that that worked properly but what i could do is say prefix and then do an underscore here i don't know how that would affect it and this actually happened over in this repository here i'm actually using a hyphen so i'm going to just change that to that i might have to do a terraform ended there migrate the state so that was a complete mistake on my part but i guess my thought was that i thought i had to have um this is still on main and i guess we never really set up a production branch but yeah so now when we have the prefix end it's actually going to prompt us for the other one so the currently selected workspaces are default does not exist and so dev is showing up and notice that we can't deploy domain so i think the thing is is that if we wanted a production one we would just create that workspace and then it would reflect here so the way you make uh multiple workspaces here would actually have to make them all so we'd have to make a vcs terraform prod and i'm very certain that it would just show up here and then you would select the number that you'd want uh though what's interesting is the fact that we are in the dev branch and we have to say oh i want to deploy the dev1 so that's kind of a little bit of a caveat there but i guess there's not really any way around it but i mean this pretty much you know explores what we need for um multiple workspaces we tear from cloud and we did the remote ones and we're all good so there we go i guess the last thing here we should probably do is just clean up so if we go to terraform dev here we're gonna go down to destruction and we'll run a destroy plan here okay and once this is all done you know you can go ahead and just delete these repositories and notice this one is it has a private lock on it so oh because it's actually running right now so it's being locked so yep there we go so that's it all right now let's take a look at the terraform registry the private registry so just go over here and click on registry at the top and we can bring in public public things here so i can just go here and type this in and we can hit add and so now we just hit add terraform cloud add to my organization and that's public facing but we could also add private facing modules so if we go back to our registry here i'm just going to go ahead and down to publish here and we go to github and i guess custom and so then i suppose we just have to enter all the stuff in here so as an optional display name for your v version control provider client ids client secrets so it seems like there's a lot of work to do we'd have to set up the ssh key pair but i mean that's generally the details that you need to know for that okay it just seems like a lot of work for us to set that up um you know and the course is just gonna be like hey can you add a private module and be like yes okay so go ahead and just remove this so you can add both public and private modules um you know so there you go i have mentioned terraform enterprise so many times in this course but uh we've never really talked about in detail and now is our opportunity to do so so terraform enterprise is the selfhosted distribution of terraform platform and i just want to point out sometimes i call the terraform platform terraform cloud just because that's the more prominent uh version of it but terraform cloud is a separate product from terraform enterprise it's just one is assassin the other one is selfhosted so terraform enterprise offers a private instance of the terraform platform application with the benefits such as no resource limits with additional enterprise grade architectural features such as audit logging so you do you'd have tamper evidence saml single signon and i'm sure there's a lot more other options there so let's just kind of look at the architecture really quickly on how this works so the first thing is you have the terraform platform which is going to be installed on a machine and in particular this is installed on linux and uh it's specifically installed on debian okay so i believe that is the debian logo as far as i remember if it's not we'll find it on the next slide if i'm wrong okay you're gonna have to have some kind of storage and there's a few different options uh probably the most common is going to be on something like s3 but you can store it on the storage or on the disk itself you have to have a postgres database uh so that's part of the infrastructure because that is what the platform uses and you'll also have to have your own tls certificate to access the machine but there are also cases where you know these are going through airgapped environments but the idea is that you have um ssl or tls it's like end to end encryption it goes all the way to the machine that's where it terminates okay um you'll also need your terraform license so you'll have to plug that in once you start up the terraform platform and say hey tell us the code so you can unlock this um this software for you to use on this dedicated machine okay so the requirements for terraform enterprise is going to highly vary based on your operational mode that you choose to run it in and that is really dependent on how data should be stored and when we were looking at the the architectural diagram that was uh the operational mode of external services there's three types of operational modes the first being external services that's when you use postgres and then use cloud storage so in that example we're using s3 but you can use gcp azure blob storage or mino object storage but the idea is that postgres and the cloud storage are external they're not part of that linux server okay then you have a mounted disk so this would just be having a persisted disk attached to the vm so you know in the best case it's called ebs so this stores data in a separate directory on the host intended for external disk so that would be both the postgres database and the storage volume itself you know postgres is still a requirement in no matter what mode you use then you have demo so stores all data on the instance data can be backed up with snapshots not recommended for production use so this is where you have ethereal data so you know the data you know can vanish if you restart the machine unless you make physical snapshots another component is credentials ensure you have credentials to use enterprise and have a secure connection so the first is we need the terraform enterprise license so you obtain that from hashicorp and the other part is having a tls certificate and private key so you need to prove uh your the you own uh your own tls certificate okay then we have the linux instance so terraform enterprise is designed to run on linux and it supports more than one version so you know i said it was only debian but i guess there's a bunch i just forgot so we have debian ubuntu red hat centos amazon linux uh there's a variety for those oracle linux um so yeah i guess i'm just a big fan of debian so that's i guess that was my my thinking there for hardware requirements we have at least 10 gigabytes of disk space on the root volume at least 40 gigabytes of disk space for the docker data directory so that would be the var lib docker at least eight gigabytes of the system memory and at least four cpu cores so there you go let's talk about air gapped environments so what is an air gap an air gap or disconnected network is a network security measure employed on one or more computers to ensure that a secure computer network is physically isolated from unsecure networks so the public internet so it's no internet no outside connectivity industries in the public sector so government military or large enterprises finance and energy often employ air gap networks and so i want you to know that hashicorp terraform enterprise supports an installation type of air gap environments okay so to install or update terraform enterprise you will supply an air gap bundle which is an archive of a terraform enterprise release version so that's how you would um you know provided okay so let's take a look at terraform cloud features and pricing so i just want to quickly go through it here so we have three models we have the open source software so oss we have the cloud offerings and the selfhosted offerings and all these tiers we have free teams and governance technically it's teams and then teams and governance so they're two separate plans but this is the way they display it uh in their marketing content but it really is a separate two separate tiers in there you have business and then enterprise which is considered selfhosted so in terms of feature set across the board you have iec workspaces variables runs resource graphs providers modules the public model registry which is terraform registry workspace is a bit odd because there are terraform cloud workspaces right and then you have local workspaces so technically those should be broken up into two separate things or named differently but that's just how it is with terraform so you know just asterisk on that workspace is there for the free tier you get remote state or sorry for everything outside of the open source you get remote state vs uh vsc connection so that's version control state connection so connecting to github or or git lab whatever workspace management secure variable storage remote runs private module registry uh once we get into cloud we get team management sentinel policy is code management cost estimation the reason why i have that in red is because on the exam it could ask you when is sentinel policy available is it available at what level and the thing is it goes from teams and governments all the way to the enterprise level now technically there is again one called teams and there's teams and governance so it's part of teams in government it's not part of teams okay once we get into business this is where we start to get single signon and audit logging so you know if you need it in the cloud or if you need it selfhosted both options are available in the business we have the you can have the selfhosted agents for configuration designer servicenow integration you have it for those uh as well in terms of how many runs you can have this is very important because this is how many this is going to put a bottleneck in terms of your infrastructure right so on the free terror you can have one current run uh of a workspace in teams you can have two and then at the business level and beyond it's unlimited current runs for uh how you would actually interact with um terraform you know this is going to be through the local cli for the open source software uh for these it's cloud meaning that um it's cloud that is triggering the execution commands and then selfhosted it's not in the cloud it's on that private machine okay uh then we have support so for support it's all community um so that's just going reaching out to da's maybe there's a slack channel i believe that they have a forum so they have like a forum where you can ask questions and then they have these layers like bronze silver and gold i could not determine what these are like what is offered in them and the odd thing is is that you know there's a silver and gold but it's offered both at business and enterprise so i don't know if like you can upgrade to from silver to gold so it's optional or you always get silver and gold could not get clarification i tried asking the sales team no one would tell me so i think you have to really be deep in that sales funnel to find out uh in terms of pricing it's zero to up to five users so the thing is and this is really confusing about terraform cloud and they really shouldn't have called it teams up here but you can start using terraform cloud for free up to five users as a team okay so just negate the fact that it's not called teams what they're saying is that teams is really about getting um uh basic workspace remote management which is actually our rba like um our abc controls uh rolebased access controls so that's the whole point of using teams so if you need that and that's when you're at five that's how you use it but you can use it in the free tier as a team and you absolutely should once you get to the team's plan it's going to be twenty dollars a month and then if you need teams and governance it's actually like seven dollars a month so again it's kind of like a bit misleading how they've labeled this out but if you go and open up teams cloud you can see what the actual packages are for uh business selfhosted your contact and sales so i have no idea what the cost is there so there you go all right we're taking a look here at workspaces so workspaces allow you to manage multiple environments or alternate state files such as development or production and there are two variants of the workspace we have cli workspaces a way of managing alternate state files locally or via remote backends and then we have terraform cloud workspaces that act like completely separate working directories i'm going to tell you these two are confusing because they don't exactly work the same way but they have the same name and originally workspaces were called environments and so you know when you're using terraform cloud it makes a lot of sense to call them environments and the cli workspace it's just a little bit different so you know i'm not sure if i'm going to do a great job explaining the difference of these things you really have to go through the motion of it to really get the hang of it but i'll do the best i can here okay so think of workspaces as being similar to having different branches in a git repo workspaces are technically the equivalent to renaming your state file okay so in terraform 0.9 they used to be workspaces used to be called environments but people got confused which i have no idea why but uh you know that's what it is now so by default you already have a single workspace in your local backend called default and the default workspace can never be deleted so even if you don't think you're using workspaces you absolutely are even the first time you use terraform at least in the cli workspace okay let's get a little bit into the internals this isn't really that much detail but depending if you are on a local or remote back end changes how the state file is stored so if you're on a local state or remote state it's going to be different so terraform stores the the workspace states in a folder called terraform.tf state.d on the road state the workspace file are stored directly in the configured back end in practice individuals or very small teams will have been have known to commit these files to the repos but using a remote backend instead is recommended when there are multiple collaborators so i guess there's not really much to say here but just understand that when you have a local state file it's going to be in that terraform tf state d and then when it's remote state you don't have to worry about it okay let's talk about interpolation with current workspaces so you can reference the current workspace name via the terraform.workspace uh named value so we saw that in the lineup way earlier in the course so the idea here is that if you wanted to see if the default like let's say you want to say am i in the default workspace then return five as opposed to one because maybe you're very comfortable spinning up more in the default than whether it was something else and just another example maybe you want to use it to apply the name of the workspace as a tag so here that would actually give this virtual machine an aws the name web hyphen whatever it is production or development so there you go let's talk about multiple workspaces so a terraform configuration has a back end that defines how operations are executed and where persistent data is stored so like the terraform state so multiple workspaces are currently supported by the following backends azure rm console cos gcs so that's google cloud storage kubernetes local manta postgres remote s3 they're not going to ask you this on the exam which ones are supported but you know for your own purposes if you want to use multiple workspaces with a a standard backend you probably want to know which ones certain backends support multiple name workspaces allowing multiple states to be associated with a single configuration that the configuration still has only one back end but multiple distinct instances of the configuration to be deployed without configuring a new backend or changing authentication credentials why would you want to use multiple workspaces for something like a standard um a standard backend well the idea here is that you know if let's say you're using terraform cloud and you've reached your limit of five users and it just gets too expensive to go to the six user where you have to pay for all of them uh you know then the thing is is that you know this is an option for you it's just kind of like another option out there until you are ready to pay for terraform cloud at the next tier up so that's the reason why i'm mentioning it here for you okay all right let's quickly walk through the terraform cloud workspace and the easiest way is to just show you screenshots so uh you create a workspace on terraform cloud so first you'll create an organization mine's called exam pro and within that you'll create multiple workspaces from there you'll click into your workspace and you'll see like previous run states variable settings we'll click into runs from runs what we'll get is a list of what happened previously we can click into one of those and we can see our plan and our apply we can leave a comment on each run that has happened if we if we just want to expand the plan and apply here for plan we will see all the details of what it would change and then apply is it actually setting up that infrastructure and whether it was successful or not um notice you can also download sentinel mock files we'll come and talk about that later when we get to our central section we can also see a history of previously held states so these are snapshots of that infrastructure and so you can click in there and exactly see what it looks like this is useful if you want to go and download it if you were to need it so here's a diff of what changed since the last state okay and of course you can download that stuff so you know hopefully that gives you an idea of what you can do with terraform cloud workspaces let's talk about terraform cloud run triggers so terraform cloud provides a way to connect your workspaces to one or more workspaces via run triggers within your organization known as source workspaces so runtriggers allows runs to queue automatically in your workspace on successful apply of runs in any of your source workspaces and you can connect each workspace to up to 20 source workspaces so run triggers are designed for workspaces that rely on information or infrastructure produced by other workspaces if a terraform configuration uses data sources to read values that might be changed by another workspace run triggers lets you explicitly specify the external dependencies so the idea is just allow you to say okay i have one workspace i i've triggered that i want it now to do that so this is really great if you have a bunch of uh of um environments or or stacks that are reliant on each other and you want it to kind of have a chain reaction the reason i'm mentioning run triggers is that i think it's a cool feature and b because um triggers is something that is also uh something else when we're looking at provisioners and i just wanted to just clarify that there's run triggers from terraform cloud and then there's triggers that are for um well i said provisioners i really mean null resources they have triggers in that okay so it's not going to show up in the exam but it's just a good to know feature i just want to make sure there's no confusion with the other triggers let's take a look at some of the terraform workspace cli commands that we have available to us the first starting with terraform workspace list so list all the existing workspaces and the current workspaces indicated by an asterisk so that is our current workspace there terraform workspace show show the current workspace so right now we're working in development terraform workspace select switch to a target workspace so here we could say select default and now we're in the default terraform workspace new so create and switch to a new workspace and then we have terraform workspace delete so delete a target workspace now understand that this is affecting um your local ones uh for the cli commands okay but um yeah so this would actually show up in the exam they might ask you like you know which is select and what does list do and things like that so make sure you know these commands okay all right so i just wanted to contrast against the local or cli driven workflows via the terraform cloud workflows because there's this great uh table chart that's from the um documentation that i want to show you so terraform cloud workspaces and local working directory serve the same purposes but they store their data differently so just looking here we'll go down the components here so for terraform configuration it's going to be on disk for local for terraform cloud in linked version control repositories or periodically uploaded via the api or cli uh we have variable values so this is where we use tfrs and when we're in terraform cloud it's in the actual workspace the terraform cloud workspace and so that means that we are setting environment variables to propagate that into our code or inject those variables into our codon execution for state it's on disk or in a remote backend uh and in the workspace for terraform cloud it's actually in the workspace credentials and secrets are in shell environments or are entered at prompts workspace they're stored as sensitive variables these are environment variables again so there you go hey this is andrew brown from exam pro and we are on to our terraform cloud uh follow alongs now we already did terraform cloud version control system earlier than i thought we were going to do so i'm going to remove from the list and what we'll do is focus on permissions and maybe the api tokens and things like that so what i want you to do and i've got some old tabs open here i'm going to make my way over to terraform dot io and i'm going to go log into terraform cloud here and i don't think i've ever done this but i can upgrade to the trial account because the thing is is that when we are in our account here and we're trying to look at uh permissions and we're not using force unlocking anymore i might just keep that around for a little bit but if we were to go to our user settings here we go to organizations um that might not be a very good example i guess i wanted like the organization settings here which would be maybe here yep up here and so you know when we go to our teams and our users our users everyone's being added as an owner we don't have like granular permissions and that's because we'd have to upgrade and so i figured this would be a good opportunity for me to just kind of upgrade to show you those more detailed role based access control permissions just so you know where they are so i'm going to go the upgrade now and notice that we're on the free plan and also take note because later on the course i talk about pricing or we've already already across it but notice that we have a team plan and a team and governance plan this one's at twenty dollars and this one's at seventy dollars so you know this is not something that's reflected at least not right now on the terraform website and so it just looks like there's a team and governance plan for 20 and this middle one's missing the key difference here is this one has sentinel policies code but you can see on the free plan we are able to do teambased stuff let's go switch over to the trial plan i'm going to see if i can do this without entering a credit card in so here it says you're currently on trial plan i didn't have to enter anything in that's really great and so that means now i have all these team management options so if i go over to team management i can actually go ahead and create some teams so i'll just say like developers okay and so now i have all these options so we can say this person if someone's in this team they're allowed to manage policies they're able to do that uh a visible team can be seen by every member or we can keep them secret we can generate out team api tokens which i guess we could just like cover this as we do it but notice we can go here and that generates out that token that we can use i'm going to go ahead and delete that token um so nothing super exciting there you know it's not like that complicated if we want to set things on the workplace now if we go back to workplace or workspaces here and now we have team access and notice i can go to add team permissions here and we can say select this team for their permissions and so these are these uh prebuilt ones in um so we have read plan rights so these are those three predefined ones that we talked about previously and then we have down here like assigned permissions for the admin of a workspace we are able to set customized permissions so if we toggle this um we should be able to do it i mean this looks like it's the same thing no i guess it's more granular so here i guess we have our granular permissions that we can set so for runs we can do read plan or reply locker unlock a workspace send on locks things like that it's not super complicated if you want to drain out api tokens for well there's the organizational one there's the teams one and then there's the user one so if we go to the organization we can see that we can generate out one here so i can say create an api token so there it is let's go ahead and delete that and if we go back to our teams we did this earlier but we can generate one here and then if you want to generate one for your user it's probably under user settings yeah so we generate tokens there as well okay um so i mean again there's not a lot to talk about here but yeah so i guess that really covers permissions and api tokens okay okay so that finished uh deploying there and so we can see our resources have been created but one thing that we didn't set was the prefix i'm actually interested to see that that worked properly but what i could do is say prefix and then do an underscore here i don't know how that would affect it and this actually happened over in this repository here i'm actually using a hyphen so i'm going to just change that to that might have to do a terraform ended there migrate the state so that was a complete mistake on my part but i guess my thought was that i thought i had to have this is still on main and i guess we never really set up a production branch but yeah so now when we have the prefix end it's actually going to prompt us for the other one so the currently selected workspace is our default does not exist and so dev is showing up and notice that we can't deploy domain so i think the thing is is that if we wanted a production one we would just create that workspace and then it would reflect here so the way you make uh multiple workspaces here would actually have to make them all so we'd have to make a vcs terraform prod and i'm very certain that it would just show up here and then you would select the number that you'd want uh though what's interesting is the fact that we are in the dev branch and we have to say oh i want to deploy the dev one so that's kind of a little bit of a caveat there but i guess there's not really any way around it but i mean this pretty much you know explores what we need for um multiple workspaces we tear from cloud and we did the remote ones and we're all good so there we go i guess the last thing here we should probably do is just clean up so if we go to terraform dev here we're going to go down to destruction and we'll run a destroy plan here okay and once this is all done you know you can go ahead and just delete these repositories and notice this one is it has a private lock on it so oh because it's actually running right now so it's being locked so yep there we go so that's it hey this is andrew brown from exam pro and we are taking a look at sentinel which is an embedded policies code framework integrated within the terraform platform so what is policy is code when you write code to automate regulatory or governance policies and features of signals include it that it's embedded so enable policy enforcement in the data path to actively reject violating behavior instead of passively detecting so it's it's very active or proactive finegrained condition based policies so make policy decisions based on the condition of other values multiple enforcement levels so advisory soft and hard mandatory levels allow policy writers to warn on or inject reject behavior we have external information so source and external information to make holistic policy decisions we have multicloud compatibili uh compatible so ensure infrastructure changes are within business and regulatory policy across multiple providers and central is a paid service part of the team and governance upgrade package so starting at team and governance it's available for that business and enterprise okay let us expand a bit on the concept of policy as code and relating to sentinel so sentinel is built around the idea and provides all the benefits of policy of code let's talk about the benefits we get with this so sandboxing the ability to create guardrails to avoid dangerous actions or remove the need of manual verification codification the policies are well documented exactly represent what is enforced version control easy to modify or iterate on policies with a chain of history of changes over time testing so syntax and behavior can easily be validated with sentinel ensuring policies are configured as expected automation so policies existing as code allows you to uh allows you to direct integrate policies in various systems to auto re remediate and notify we're talking about sentimental and policy as code we have language so all sentinel uh policies are written using the central language this is designed to be nonprogrammer and programmer friendly embeddable and safe for development sender provides a cli for development and testing and for testing sentinel provides a test framework designed specifically for automation so hopefully that gives you an idea of the benefits of policy code and in particular with sentinel all right let's take a look at the sender language and also just a broad range of use cases that we could use these for so you can start thinking about how to start applying sentinel the great thing is that there are a bunch of example policies provided by hashicorp so you can easily um you know start using them right away but let's go through the big list to kind of give you an idea where you would use policies codes so for aws maybe you want to restrict the owners of the aws ami to a date of the data source maybe you want to enforce mandatory tags on taggable aws resources restrict availability zones used by ec2 instances disallow 0.0.0.04.0 basically anywhere address out to the internet um restrict instance types of ec2 so maybe you only want people using t2 micros require s3 buckets to be private and encrypted by kms since that is a big um a big problem for people on a bus where their buckets get leaked uh require vpcs to have dns host names enabled we're looking at gcp enforce mandatory labels on vms disallow anywhere cider enforce limits on gke clusters because those can get really expensive restrict machine types of vms just like aws for vmware require storage drs on data store clusters restrict size and type of virtual disks restrict cpu count memory of vms restrict size of vm disks recaro nfs 4.1 and kirbrose i never can say that properly on nas data stores for azure enforce mandatory tags of vms restrict publishers of vms restrict vm images restrict the size of azure vms enforce limits on aks clusters restrict cider blocks of security groups for cloud agnostic allow only say we can only use these allowed providers say or explicitly say what providers are not allowed limit proposed monthly costs prevent providers in nonroot modules require all modules have version constraints require all resources be created in modules and private module registry use most recent versions of modules in a private module registry that's more so like about the tooling around modules now let's take a look at an example and this is one for restricting uh available zones on ec2 instances so like what data centers you're allowed to use and so we first import our language functions that's going to allow us to use particular feature functions in this we're going to specify our azs we're going to get all the virtual machines we're going to filter that and restrict that easy for those vms we're going to define that rule to make it enforceable so there you go all right let's take a look here with sentinel with terraform so central can be integrated with terraform via terror from cloud as part of your iec provisioning pipeline and where it's going to sit is between plan and apply okay so the way you do it is you're going to have to create a policy set and apply these to the terraform workspace so it's not that complicated to get it hooked up um so yeah that's all there is to it okay hey this is andrew brown from exam pro and we're going to learn a bit about sentinel with terraform i'm not going to say i'm amazing at it but we are going to stumble our way through and see what we can accomplish we know we can download sentinel box and there's also the ability to set policy sets and i do know that uh there are a bunch of premade um sendal policies so we go send all policies here uh terraform uh and we go examples uh there we are probably here there are a bunch of ones that we can go in here so i'm thinking that there's something that we can do here um but we'll have to figure our way through here because i actually haven't ran any policies myself so we have these two environments i'm not using dev anymore i'm done with this i'm going to go ahead and destroy that and we're going to go down to terraform destroy i'm pretty sure i don't have any running infrastructure actually i'm going to double check by going to the overview everything has been destroyed and so i'll go back over here and we're going to destroy this i'm going to type in vcs terraform dev great if we go into this workplace or workspace nothing is provisioned right now so i want to get everything running again because last time we ran a destroy so i think that if we want to get this working it should be pretty easy i'm going to go back to our workflows file here and we're just going to revert some changes so i'm going to go back and change this to name and i'm just going to go whoops we're going to go into our 120 directory here and we're going to get checkout main and that actually might just revert those changes there i don't think anything really changed much other than this part here and so what i'm going to do is just go make a minor change it doesn't matter what it is maybe a space get at all whoops git commit hyphen m changes get push we'll have to do a get pull here get push sorry get push and so what i want to see here is a trigger for the run there we go and i'll see you here in a bit when it's provisioned okay all right so after a short little wait there it looks like our uh branches ran so i think our resources are provisioned um it's cool we actually have cost estimation i didn't have to do anything to turn that on we already have it notice that it's giving us an hourly of um zero twelve cents the monthly is going to be eight dollars in you know 35 cents there if there was more resources there we would obviously get that i assume that it would show up here in the top right corner so we're not really interested in the provision infrastructure but more so looking at these uh sentinel locks so i'm going to go ahead and download them there and that's going to download as a a zip or an archive of some sorts and so what i can do here is just unzip it so i'm just going to make a new folder here and we'll just call these sentinel mocks okay i'm just going to open up the zip and so here's all the stuff in here so we have a variety of different files i think some of them might be redundant i'm not sure what we have to do with them but i'm just going to go ahead and grab these and drag them into the folder here okay and actually what i'm going to do is i'm going to just make a new section in my folder here whoops just give me a second here let's open up the explorer to anything yeah we have a folder right here because what i want to do is just drop those files and so we can just see them in vs code with the contents of them there we go so now i'm just going to go down to here and we'll take a look so we have sentinel hcl all right and so that's just defining a bunch of mocks uh we have this sendal file here so i was hoping when we opened this that we'd be able to figure out what to do with this and i have no idea so you know what what i'm going to do is i'm just going to do a little bit of reading and i'm going to come back to you after i finished reading this okay all right so spending a little bit of time uh watching some stuff so i was just going through the deep dive of sentinel here and just going through the documentation and as far as i understand it looks like that you write policies and then you can also write tests for your policies to assert that your policies are doing what you expect them to do and i guess those uh sentinel mocks are written in a form of hcl but it is a little bit confusing because you get this folder with a bunch of stuff in it and it can be either written as json or like this hcl like format but as far as i can tell it's just saying what it's done is it's generated out the the current state of exactly what your infrastructure is and i think that it's going to check to see is it exactly what you expect it to be so i don't know if mox is that very uh useful and might be a little bit too much for this particular course so i'm just going to say let's just kind of ignore blocks because they're just a little bit too too difficult and out of scope here let's focus on trying to get a policy implemented so i'm going to go back over here and what i'm gonna do is i know that if i go to settings i mean i've seen it before i just can't remember if it's under a workspace no it's i think it's at the organization level so we're gonna go to the settings here and there we have our policies so we here we can create new policies so managing individual policies terraform is deprecated policy sets now supports vcs integration with direct api uploads uh this provides a streamlined policy management experience policies which includes okay so this is the old way of doing it and so we'll go here and create a new policy set so connect a new policy set um okay so i guess what we have to do oh boy this is a lot different than i thought it was gonna be so i thought it was just like we're going to go here and create it and then dump our code in which apparently that's what it is but it seems like we need to associate with the policy set so just give me a moment because i do want to show you the the most uptodate way to do this i'll be back in a second all right all right so doing a little reading here it looks like what we have to do is create ourselves a sendal.hcl file and this is going to say what policies we want to enforce so i assume this is basically the policy set as a file and here we specify the policies that we care about um i actually just want to go back to the files we were looking at earlier because we saw this htl file so i guess this would technically be a policy set is that what we call that here but notice it says mock so these aren't policies per se these are just grouping mocks but in any case i think we'll have to create this file so what i'm going to try to do and i don't know this is going to work but we'll just stumble our way through here because the best way to learn is we're going to create ourselves our own sentinel file here so we're going to say sentinel dot hcl and we're going to define ourselves a policy this isn't going to be the one that we're going to use but i'm just going to grab it here notice there are different enforcement levels so i don't really care we put it i just want to see that we can successfully get anything working here and i'm going to go back to the examples um if we can go find that there so sentinel policy examples and let's just go take one of those and see what we can do with it okay so if we scroll on down disallow zero zero zero cider block in the security group that seems like something that would be pretty relevant restrict instance type of ec2 instance that could be something as well that we could do so you know i just have to decide what it is we want to do here restrict owners so there's a few that are good here let's take this take a look at this one because i feel like this might be very simple so yeah this is perfect okay so what we'll do is we'll take uh this policy here so i wonder if i could just go download this file here there's probably a download button well i can't find it so we'll just maybe it's up here no okay we'll just create this by hand here so i'm going to go copy and it looks like we can just drop it in here so just go new file here and put that there and we'll just go to raw and we will go ahead and drop that on in there so i wish i had like send all highlighting i don't know if there is such a one for vs code if there is it'd be really nice so we would type in sentinel um yes we do this one has more downloads so we'll go with that one no rating as of yet looks like it works so let's go give them a five star i think that's only fair because uh no one's done that yet might be a bit too hard to uh i've never written a review before but we'll go here and say works as expected thank you for this uh extension okay so what i'm going to do is go back over to here and so here we have some kinds now we're running a t2 micro i believe so this policy should uh cause it to fail that's exactly what we want but i'm just going to go look up and down to see if it's all correct it looks good to me so i think we'll have to change over here is the name so i'm just going to clear this out and we'll say restrict ec2 instance type we'll save that hard mandatory sounds really good to me um probably have to spell it right for it to work res yeah strict okay great and so what i'll do is just copy this up here okay and so we have our sandal hcl file and it's referencing a local file now the question is you know can we use the same repository i assume we would be able to for our policy set but it almost seems like it might encourage you to have your policies separate from your repository that you're testing and that might be really good because let's say you have multiple workspaces or environments and they all require the same policy set you wouldn't want to have them in your code base like that but for the purposes of this we're just going to keep it simple i'm going to go ahead and open up terminal here and we're going to commit these these changes to our repository and this will end up triggering a deploy even though we don't necessarily want that to happen but there's no way around that so get well i suppose we could just cancel it out but or not have the auto apply but i don't feel like changing that so we'll do git status here we'll go get add all git commit hyphen m uh simple policy here get push okay and so that's being pushed to our repository that's going to trigger a deployment we don't care i i assume that it won't pick up the policy because we have to connect the policy set so um apparently you use the api to upload your policy set which is kind of cool i suppose we could have done that but um well too late we probably should use vcs anyway you know what i mean so we'll go to github here and we will find our terraform repository which is here um you know policy well we should probably name this right so we policy to enforce uh instance type i don't know if we need a description i guess we'll find it in a second here i guess we could have also put the policy in a um a subdirectory there that might have been okay to do it's going to default to the main branch which is fine policies enforce on all workspaces or policies and force on selected workspaces and we only have one but that's what we'll do down here so we'll say update the name is invalid oh uh it has to be like a proper name so restrict ec2 now again this is a policy set so you could just say like um you know basic server policy set that probably better and then you probably want a list to say what it does restricts um ec2 instances instance type okay and we'll go down here and create that policy set and that looks like we're in good shape so we applied it um now will it actually happen on this run because it's already running i believe we go to this workplace workspace i like to say workplace it's workspace and we go over here this is already planned and finished so what i want to do is just trigger another uh um deploy here so there's nothing changed so i'm not sure what we do here um i guess what we could do and actually this is something that i'm i don't know but like how would you trigger a replace on here because if we're doing let's go to plan and see what happens i wonder if we could do that in the plan here reasons for trigger do refresh only plan because one thing i was thinking about is like imagine i wanted to replace an element you can do that hyphen replace but i don't know how you do that through vcs but anyway what i'm going to do is just go change anything in our code um so it could just be a space it doesn't really matter get at plus okay commit trigger uh change and we just want to observe the uh the policy working okay so i'm just going to open this up here i'm not sure if it's going to show up in the plan section or the apply section so we'll just wait here to see the plan generate out and so the plan finished um we don't see any sentinel uh central being applied there apply will not run let's expand that there this looks fine i guess technically we didn't change anything so that probably is not very helpful so what i'm going to do is go and change a variable because maybe that's that's what's going to help here so we have a micro here which is fine we're just going to change this over to nano that makes sense why it didn't do it so we'll go back over to runs and i'm going to trigger i'm going to start a plan so change ec2 instance type we'll say start plan okay so we have one change which is fine we just okay so that part pass is going to go to cost estimation that passed it's going to apply it because remember we have um auto approve on the server so it's not even going to ask us to confirm it and so i want to see if that policy is in place well it's running i'm just going to go review our policy here just to make sure it's not like the opposite saying like you cannot have these so include now a loud ec2 instance type so it's small medium or large so it really should quit out on this one here but it seems like it's working like it's not uh it's not picking up the policy but i'll see you hear it back in a bit okay all right so i didn't see the policy trigger there so i'm gonna go back to policy sets and notice here it says zero workspaces which is unusual because i definitely selected one but maybe i didn't click through or hit add so i'm going to go down here and click this one again and maybe i didn't hit this button here okay and now i'll probably have to hit update um paul this is set before we do i just want to read about this these parameters are passed to center runtime when performing policy checks so i guess i'd be like a way where you'd have a generic policy and then you could kind of put parameters in so that's kind of cool so i'm going to go back here and double check to make sure that we have a workspace set and so what we'll do is just change the variable again um so we will go to our variables here and i'm going to go change this back to a micro and so i think this time we are going to have better success okay so we'll hit save we'll go back up to runs we'll go and start a new plan change instance type again here and we will save that plan and so that plan is now running i will see you back here in a bit uh when we see that sentinel policy i don't know when it triggers i'll see you back here in a bit all right welcome back so after our cross estimation it did a policy check and you can see that it failed um and here the air says import tf plans function is not available so i'm not sure why that's happening so i think that um i mean our set failed but not for the reason we wanted to so i'm gonna go investigate this i'll be back in a moment okay all right so uh what i've done here is i've gone and looked up uh like how to create a policy set and hashicorp learn has this um example project here and if we go into its github project and i go here you're gonna notice that it it's like this apparently does basically the same thing restrict instance type and apparently tag as well but it doesn't have the tf functions the tf plan functions here so um maybe we don't need that function in there and maybe the the example is just out of date at this time so import common functions for sentinel okay but this one doesn't have it it does it does have it for mocks right um so maybe we just need to kind of like walk through this really quickly and see how we can fix this so the policy uses the central tf2 plan import to require that all ec2 instances have instance types planned on the loud list but i don't see that import there okay and it is in here so i guess what we'll do is just grab this one okay and i'm gonna go ahead and just delete this one out here um again this isn't working i don't know if this would work with that one so i'm gonna take it out this is pretty clear what this does so we'll just have that allowed types it's interesting like here it's underscoring that here it's like uh title case there's some inconsistencies there so they have a lot of types as well um and i'm just seeing if there's like find resources in here so allow types rule to enforce the name tag so i don't care about that rule to restrict the instance type so i'm going to go ahead and grab this one here and let's just take a look at the differences here okay so instance type allowed rule all these two instances as that instance change after instance type allow type so this is way way different um so i mean i fully don't understand this but i do know that this one it will probably work so i'm going to go down here we have count violations i'm not really worried about that and the rules different like if i was really serious about this i'm sure i could you know figure out the logic here but again this is just for the purposes of this learning so we don't have to go too crazy here now this says instance type allowed and mandatory instance tags we're not dealing with tags here so i'm just going to say this okay and so i think this will produce what we want so allows those types i don't know if it had this in here get all instance types from the module i think we didn't put this in here so this might be kind of the equivalent ec2 instances filter tf plan resource changes okay contains a create or an update okay um i mean this isn't bad we technically have a name set so you know what i'm just going to grab this whole thing because then we're just going to have a much easier time we don't have to worry about it but it was nice to walk through that file very quickly because the name tag is set um in our project a because we can see we can see that it's the server name so what we'll do is we'll just go ahead and add this to our repository here and the great thing is that since it's the vs code or it's in the same version control system i would think that it would update in time so what we'll do is just to get at all git commit hyphen m fix the policy get push okay and we'll go back over here and we will see if the policy check happens and when it does happen it's actually erroring out because we're not using the right instance size right that's what we want to see a little bit of trial and error it's not a big deal i also read like over here that the sendal file for hcl only contains module and policies but then we saw a single file or hdl file that clearly had mocks in it so i mean maybe maybe just only used locally maybe it's not intended for um production um so we'll go down here tf plan so it didn't pick it up okay so what i'm gonna do is go back to my policy set and maybe it's just like the order of how this happened so see this says it was updated last five minutes ago updated it a minute ago so this could just be like a race case where um you know this ran before the other one so i'm going to try to execute this again start a new plan uh trigger plan and we'll see if that works now because again this said literally updated a minute ago so maybe it didn't pick it up so you can see why it would also be good to have your policy set in a separate repo because if you're deploying this you don't want to keep triggering your deploys so i think probably that's what you know we should have done i mean it's a lot extra work but you know this way you kind of understand why so waiting on that plan run i really don't care about cost estimation i mean you could make a policy to check based on that i i'm assuming we just turn that off if we wanted to and we'll go over to cost estimation here yeah we could just disable it but the thing here is that it said our policy passed so we'll go here so the result means that all central policies passed so restrict the instance type so description main rule that requires other rules to be true uh ruleton force name tag is on all instances that's true rule to restrict the instance type so maybe we don't understand uh maybe this works in the opposite way oh the t2 micro is here okay so i just want to see it fail so what we'll do is go back up to our variables here and we'll go to our instance type and we'll just change this to nano and we'll save that we'll go back over here to our runs oh this is still running the old one here that's fine we can just cue up another one here so we can just say start a new plan uh new instance type okay and if we go back over to here the last one wouldn't have done anything because the infrastructure would have been the same so the previous one we just did here right it would just been like oh no it's still trying to apply it so i guess there is a change maybe we changed the instance type last time i don't know so anyway i'll see you back here when this is completely done okay all right great so we got an error if we go into our instance type here right and we look at it we can see that it failed because uh it wasn't the uh right uh type so um i mean that's pretty interesting so the other thing i would say uh that we could do is also kind of check out mocks now because i kind of feel like i have a better grasp on it now that we have a test running so just thinking straight about it a mock really is a representation of the state of infrastructure at the time of so if we go back to our runs and we go to a successful run like the trigger plan here and this one was successful we could go to the plans here and then download these mock files so we do have the ones from prior and i think those are totally fine and valid to use so what if what we do is go back to our project over here and we have um the mock files over here but really where they need to be is within the workflow directory because looking at the documentation here what it's saying is that you get all these things and this basically represents the state of those mock files and then you need to make a test folder and then a test data folder and then there's gonna be something based on the name of this uh the mock file so what we'll do is we'll go um up to this folder here and we'll say new folder test and then we'll make another new folder here test data those folders are files i think those are files so we'll delete that it's just out of habit to click the um the file there so we'll say new folder so we'll say test and then we'll say another new folder there test data okay and so we have our sender file here so we need to um have i think a similarly named one here so if we go back over here um this is foo whatever so i think we need to have a folder in here because it's all based on convention and i just it's pretty not that hard to figure out i don't have to read the docs to know that uh we'll just put that in here take out the word sentinel and then i would assume that we need a file in here what's it called like just pass and fail so i'm gonna just do a pass file new pass.hcl okay and then we have our test data so that was what we had down below here so i need to go grab that information i'm just looking for a folder where i might already have open here if i don't that's fine we'll just go ahead down below and just right click and reveal and explore we'll go over here and i need to move all these over so i just copy them over and we're going to go over to our terraform work flow here and i'm going to go here and paste that data in i don't know if these contain any kind of sensitive data because if they're based on the tf state file these might be something you don't want to share that might be a security vulnerability i don't know but i definitely won't have these available when i put this repository up for free um so we have those files in the right place and we have all this stuff here so i i think that um like you notice it's not there so i'm assuming that we need to open up this file and copy into our main hcl file so we'll go down below here and then i think it's just a matter of copying all this stuff right we'll say cut and then we'll go to um back up to here i suppose into our file it's getting a little bit confusing with all the stuff eh okay so that's in the right place our test date is there good here we are okay so what i'm going to do is just go down here and paste that in okay and so we didn't write any kind of pass test data test so that's something we will need here i'm not sure what we'll get so we'll just scroll down here so you can find the contents of a pass dot hcl it's not showing me anything here so just give me a moment i'm going to see what we have to do for this this test okay all right so a little bit of googling it looks like this one's on the same track here so since we probably copied the mock data from this one or somewhere through here we could probably just go grab this so um this is pretty much what our pass file will look like so we'll go ahead and grab this here i don't know if we really need a fail to write a failing test i don't really care about that i just want to see anything pass here we'll paste that in here we do have to be sure that we are accessing our data correctly so if we're in test it's going to go up one directory to the terraform directory but wouldn't it have to then cd into test so i don't think that source path is correct i'm just going to double check that here did you have an example repositories let's take a look here what we have um yeah that's kind of odd so i think that if this is relevant it needs to go to test data because how else would it get there okay so we'll do that so test rules main equals true um okay so that's a pretty simple test and so i think the way we run tests is there's like a sentinel test thing here i don't know if we have cinder installed i don't think so so there's no sentinel command so i guess that's something we have to install sentinel um cli terraform okay over here uh we're on technically linux even though we're on windows we're on linux so here it's just saying uh download it and then put it in the correct path so install so we'll get the appropriate package here and we're technically on linux and i guess we are 64bit just gonna download here scroll up oh it is already downloading okay great and so i'm just gonna go to my downloads and i'm gonna open it up here so there it is and so i need to get it into the user local bin here so i'm just going to first get it in anywhere so because i'm just working here i'm just going to go open this up so reveal in the explorer okay and this is not where i want it to be i'm just dropping here for the time being technically we could run it from there i don't think it'd be that big of a deal so i'm just going to go back to my vs code here and i'm going to just type sentinel sentinel it's there right yep it's there i'm not sure if it's executable but i'm just going to type in sentinel here signal test okay so it doesn't think it's command so maybe i have to do like chamod u plus x that makes it executable on linux said no command not found well heck i'm right there maybe i have to put a period forward slash like that okay there we go so um i mean of course you don't want to leave it in here you and this would also end up in a repository so this will go to like your user local bin probably so i'm going to say like move sendl to user local bin and so now i should just be able to type sentinel it should get picked up it does great so here i can do test and down below it says open test no such file or directory so it can't find the mock data notice that it's going into the test test data so that is no good for us we did say to go up a directory so maybe if i go up back one more like this would that work no let's go put back in what they actually had there which i have a hard time believing that would be correct so open mock okay so that's definitely not right okay and so personally i just want this to work so i'm just going to cheat this is absolutely what you should not do but you know like i don't wanna be fiddled around with paths all day here and so i'm just gonna give it an absolute path and see if that fixes our problem okay and this will just say test data here um so that should absolutely work i'm just going to expand this here this is mock tf plan oh but it says pass in the name okay so the problem isn't that it's the fact that uh the mock data isn't named it's because the thing is you could download two different mocks right so you could have a state that is successful and failed and you probably want to rename them to say passed or failed so we don't necessarily have that so i think my original thing was correct where we had this test data and so here we just have to make sure we match the name so mock tf v2 is fine here okay again i don't understand the difference between all these files i definitely saw the documentation they explained them all so you know that might be something we want to read through here um so this is looking a little bit better so mock tf plan hyphen version 2 sentinel so that is correct um but the director it doesn't like the direction it's going into that test again so again i'm going to just go back up one more layer here okay there we go and it's passing so um yeah so that's all it takes to um do that again i think if we were to commit this to our code i don't think that these run so we go like so we can just go add it and see what happens so we'll say git add git commit hyphen m validation and again i don't know if this mock data should be allowed to be committed into the repository because we have a tf state file here right okay i don't know but i'm going to just do a push here to see what happens but again i i really think that we're probably not supposed to have it in there um so what we'll do is go back to our terraform io sign in and we'll just see what happens here i mean we don't expect the this to pass because it's still using the wrong instance type but i was just curious to see if the mock would appear in any way here i don't think it does i think that's just something that you'd have to do uh beforehand and i think what you'd have is you'd have a pull request and the pull request could be used to run those unit tests because that's basically what it is okay so yeah that's exactly what i thought would happen but down below here it says the mock block is not supported so i wonder what you would do so if you can't have mocks in the file what would you do locally because you need to i guess the thing is is that the mock file the sendal.hcl file would not be in this fold so you might have the central hdl file in your main repository for mocking right and if you committed it wouldn't run it because the policy set would actually be in another repository so i think that's how it's supposed to work so yeah i think really we want to have policy sets in their own repository like completely away from there because we're seeing we're running into a lot of problems but we pretty much accomplished what we wanted to do with sentinel more than i thought we were going to do uh so that's pretty great so there you go um in terms of this we probably want to tear this down uh we do need to do something with vault and stuff like that but i think that uh what we'll do is just tear this down and you know if we need to bring it back up we'll do that so i'm gonna go to destruction here and we're gonna go ahead and just destroy the plan here okay and we're all now in good shape and so um yeah i'll see you in the next part okay but we're all done here for for sentinel all right actually i guess we're not gone here just yet because it looks like our destroy run failed uh because we didn't pass here so um that is a bit of a problem so we'll have to go to the variables i guess it's a good edge case to know about but um we'll go back and change this to a micro even though it's going to just tear it down anyway you know so we'll go and type in micro save variable and we'll go back to our runs we'll start a new plan or sorry we'll go to settings here destruction cue the plan i'm just curious giving a plan we'll redirect a new up output here okay cool um so i'm just going to type in vcs terraform again here okay and so this should work and i will come back and just confirm this with you okay so i'll be back here in a second all right so the real reason we can't uh get rid of this is because we have those darn blocks in there so um what i'm going to do is go over to our sender file here um up to i mean we don't use this one so i'm going to go ahead and delete that that's not even something that's going to happen and we need to update our hcl file here okay and i'm assuming that this supports this okay because this is not how we should be doing this um and here we go git add git commit hyphen m minor change okay and this is going to trigger a run here i really wanted to destroy so let's give it a moment there to start so we can kill it um did i not push oh maybe i didn't push and we'll go back here there's that run i'm going to go in here i want to stop it uh cancel run okay and so now what i'll do is go over to the here destroy this we'll run that okay we'll destroy that and i will again see if this is working and i'll see you back here in a moment okay all right so i just wanted to confirm there that everything is uh destroyed so we're all in good shape okay so uh yeah so we're actually done sendal now for real okay bye all right let's take a look here at hashicorp packer so it's a developer tool to provision a build image that will be stored in a repository using a build image before you deploy provides you with the following immutable infrastructure your vms and your fleet are all one to one in configuration faster deploys for multiple servers after each build earlier detection and intervention of package changes or of deprecationable technology so let's take a look at what that workflow would look like so you'd have your code you commit it to your ci cd pipeline and within that pipeline it would start up a build server running packer and that would trigger a build image so you'd use a something to provision it with so you could use ansible or a variety of different provisioners within packer and then packer would then store it somewhere so maybe this would be amazon machine image because you're deploying to aws and then what you do is reference that image in your terraform code and when you provision it would get deployed to your csp so this would be aws in this case so packer configurations is a machine uh packer configuration configures the machine via oops hey it's andrew brown from exam pro and we are taking a look at hashicorp packers so packer is a developer tool to provision a build image that will be stored in a repository so using a build image before you deploy it's going to give you the following benefits immutable infrastructure your vms in your fleet are all onetoone in configuration faster deploys for multiple servers after each build earlier detection intervention of package changes or deprecation volt technology let's take a look at what that workflow would look like so first we'd have github or or your git so wherever you commit your changes and from there that would trigger a ci cd pipeline with within that csd pipeline it would trigger a virtual machine so or a build server that's a running packer and so that would trigger the build image process from there packer would use some kind of provisioner like ansible to provision the image and then when it was done and and it was all good it would store it somewhere like an amazon machine image once it is stored wherever you want it to go then in terraform you would just reference it using like a data source and then from there you could provision your resource okay so packer configures a machine via a packer template and yes i know the e is missing so sorry about that but packer templates use the hashicorp configuration language hcl which we saw if you remember way earlier in the course and that's what we're going to review next is what that packer template file looks like okay all right so packer configures a machine or container via a packer template file and packer template uses the hashicorp configuration language hcl so that's why it looks very familiar to terraform and a variety of other languages we've been looking at in this course and so what this file is doing is provisioning a virtual machine on aws so here you can see that it's a t2 micro and the us west 2 region that it's probably going to be installing apache since it's named httpd and the way it's going to be created is via an ebs volumes let's talk about kind of the components that we're looking at here so when you have a packer template file you have to specify a source and this says where and what kind of image we are trying to build so the source is amazon ebs so it's looking for an ami image or it's being backed by that ebs volume there okay in this case it's an ebs backed ami the image will be stored directly in a bus under the ec2 images and so we have the build step so the build allows us to provide configuration scripts packer supports a wide range of provisioners so we have chef puppet ansible power power shell bash salt whatever you want basically has it and the post provisioners runs after the image is built so they can be used to upload artifacts or repackage them all right and the place where this is going to be stored is going to be on amis okay so there you go let's look at how we actually integrate terraform and packer together in terms of a ci cd workflow we kind of saw this in uh that overall graphic in the first uh packers slide let's just kind of look at the code okay so to integrate packer there are two steps you're going to build damage so packer is not a service but a development tool so you need to manually run packer or automate the building of images with a build server running packer then the second part of that is referencing the image so once an image is built you can reference reference the image as a data source so if it's stored in abus ami we're going to just source it from there and the way we select it is what we can do is say okay get us the most recent one and use this regular expression and the owner has to be us and and those kind of parameters to decide how to choose that image so that's all there is to it you're just using data sources to reference them after they've already been built okay hey this is andrew brown from exam pro and we are taking a look at uh using packer with terraform and mostly it's just about just using packer uh and so what i want to accomplish here is to generate an image and store that onto amazon machine images and then load that into a terraform file or like reference it as a data source so i've never done this before but it should be fun and we'll figure this out so what we're first going to need to do is download packer so notice in the top right corner we make your way to packer however you want to and we'll go ahead and download and this one is for windows it's a binary but we are going to be using linux uh we've done this so many times these three two commands so i'm not going to do that again here but if you have yet to do so you can go and run that and so i'm going to go ahead and install packer and once packer is installed i will come back here and we will get to it okay all right so after a short little white there packer is installed and so what i want to do is go into my packer folder here and i'm just going to run packer and see what we get and so we have packer build console fix format init so install missing plugins looks kind of similar to terraform build images from a template that that sounds kind of interesting so i think the first thing we're going to need to do is define ourselves a template file so uh i remember i researched one and and put one in my uh slides here so let's make our work way over there and see if we can kind of just like use our notes here as a reference so going down to this packer file let's go ahead and just write one here uh i don't say what the name of the packer file is that would probably help but i believe that they're just named as dot hcl files so what i'm going to do is go into this here and make a new file and we're going to say i guess apache.hcl since we're already very familiar with how to install apache that seems like the easiest way to do it and again this is going to be very similar looking to terraform because it's you know all based on hcl so we'll do a type string and we are going to need some kind of default ami so uh we can go grab the one we've been using all along here um i think we specified it and we can just go back to count counts always a good one to go to so i just want to go and grab where is it um count count count where are you anybody see it i'm blanking today so i'm just going to grab it from aws it's not a big deal i'm just pulling up aws here we're going to make our way over to ec2 and we're going to go ahead and launch ourselves a new server actually i could probably grab it from the old one now i'll launch a new one just in case you don't see anything there that might not be fair i'm going to go ahead and grab that ami id and i'll just move that off screen here for a moment and we're going to place in that am id because i assume we want one to override then we're going to say locals uh app name and i think the example i wrote here is is apache because that is what apache is httpd not sure how they came up with that name but that's how they call it so we need to provide ourselves a source so we're going to do amazon ebs httpd notice that like the source is not called data it's just called source uh if we go over to the documentation here just when i want to show you here docs if it ever loads come on docs you can do it so down below here or on the left hand side we have sources so if i believe if we were to go over to here and go over to amazon ami someone says amazon ami overview builders ec2 ebs i'm just trying to find the same kind of information that it has there eh it's not really doing what i want but anyway i know that this code is correct even though we can't seem to find uh this out probably just go type in packer ebs amazon ebs i really like to always refer to the documentation when i can here so it does say it's a builder amazon eps source down below here we go all right so yeah um i don't understand this uh this builder flag as of yet but uh we'll work our way through here and figure it out okay so i'm gonna go back and pull up my vs code here and we're gonna put curly's here and so we need our ami name here so my server dollar sign local app name instance type t2 micro region this is going to be us east 1 source ami this is going to be the variable we set up above ami id then we are going to do ssh username that's going to be ec2 user that's the default that abuse always has ec2 user we can do some tags here not really necessary but it's good to probably give it a name right so we'll just say name apache server and actually we could probably just do local.app name maybe instead and then we have our build step here so we're going to specify our sources and we're going to do source.amazon.ebs.htpd and we're going to do provisioner pro visioner shell and then we want to provide a script i think we can we can actually do it in line if we didn't want to do a script there but we know our script works so maybe we should just stick to that so i'm just going to call this userdata.sh because we already have that somewhere before so we'll do post process we don't need a post processor so we just want to run that script i believe we have that in our terraform workflow we go over there to our workflow wherever it is might also be under modules if we go into our module here didn't we create one there called user data oh that's a yaml file oh okay i mean that's not a big deal um we could probably just okay so we're not going to do it that way all right um if we're not going to do it this way we probably can provide inline things we don't probably have to do script equals so what i'm going to do is go back to the terraform documentation here or packer documentation i should say and what i want to do is look at provisioners we're going to look at shell so it has this inline step and i assume that this is going to run in into sequential order so inline array of strings okay so what we will do here is we will type in inline and i've done this like a thousand times but i'm just gonna go google it apache install aws tutorial there's probably one on the adabus website for it for like user data and this is pretty much has some of it here i was just kind of looking for these commands like the yum install and the pseudo system start so we're going to go ahead and grab that and then we're going to go and grab the next few lines here just want to start and enable that's the three things that we need to do not complicated at all and so what i'm going to do is type in packer build and see what happens now i didn't specify any adwords credentials or anything like that i assume it would pick up the default and we're going to go to the top here so it looks like we have to provide the template name so maybe we'll do apache hcl here and it says error parsing json invalid character v for the beginning of the value oh so it has to be pkr.hcl okay i'm really liking the user experience of the developer experience for the cli they're really good at telling us what's wrong with them um pkr hcl if there's like a default file i don't know what it should be called so we got a bunch of errors which is fine unsupported argument locals an argument locals is not expected here did you mean to define a local's block it's because i put an equals in front of it supposed to just be this not that we were really using locals for much here and it looks like it is provisioning found in ami it's going to use that as the the source one creating a temporary key pair authorizing to port 22 uh name packer builder so i don't know if this uses i don't think it does but i don't know if it uses amazon because there's like ec2 builder image and there might be a way to use it with um packer directly but i'm not sure how to do that it's going to go over here i'm just going to see to make sure it's not running a pipeline here is it image pipelines no okay that's good but what i will do is go over to my ec2 here and what i want to go do okay so packer builders is running as a virtual machine so it's actually um going to spin up a vm and then bake the ami that way which seems a lot better we'll go over to our amis and see when that happens there um it's just unlock another those that red stuff doesn't look good seems it seems like it didn't really matter so thing like aws has an entire pipeline for ec2 image builder but it does cost money to run where i kind of feel like if all packer is doing is spinning up a virtual machine temporarily to make that image that's going to be a lot more cost effective i mean we could go look up what the cost is to use ec2 image builder while we were watching this builder can't seem to type today uh just pricing i just wanted the pricing it can't be free oh is it there's no cost i could have swore there was a cost for this no cost image builders offered at no cost other than the cost of the underlying aws resource i think the thing is that it's that when you use um ec2 image builder you have to use of a particular size you know if you don't really use aws you're more wearing azure gcp i understand why this is not much of an interest but i'm pretty sure if i go here that the size that you get for the image what size of each image does ec2 image builder use because i remember was like really really large un like unreasonably large and that was the cost involved in it can't find it today it's not a big deal but waiting for the ami to become ready so if we go over to our amis here and give us a refresh we can see that it is spinning so it is provisioning that ami while that is going on what we can do is just start setting up the next part of this so within our packer here we can say new file and i'm going to say main.tf i'm going to go as per usual and grab some default code from our account example which is right here okay copy that we're going to go all the way down to the ground here and i'm going to go into the main tf here paste that on in and we probably want to keep the public ip around we actually don't really care but i'm putting it in anyway i'm going to take out the tags oh i want to leave the name in so i'll just say like server packer okay server apache packer and uh this is the thing that we want to replace out this all looks fine so this is what we need to figure out is our ami here it's probably going to come in as a data source it has to come in as a data source and i'm pretty sure that's what i wrote in our documentation here so yeah it's a my example things like that so what we're going to do is type in a bus mi packer image and we'll just define that data source so adabus ami packer image and we have executable users executable users equals self i'm not saying i know what all these options do but like you just go to the documentation you grab them you got something works true name regex okay and so we would do something like uh start with the little carrot character and what did we name this this starts with uh my server hyphen probably would have helped if we named it with like something like packer in the name but i think that's fine um we might as well might as well go the full name here and say httpd because that's technically what it's going to be um we might want to match for more values here so i'm not sure i guess like we do that because sometimes it's like three digits or whatever but i don't know what packer is going to do if we keep pushing additional ones i'm not really familiar with with that so we'll just say owners equal self and so now that should be all set up to go as that is running it finished so that's all good we're going to say terraform init and here it says a block definition must have a block content deliminator so we have a small problem here it looks correct to me this is not right okay we'll see if we can knit this now whether our build image works properly i don't know so it'd be really good to write like some tests for it i imagine that there is some kind of way to do that um i guess it'd be like the post processor scripts maybe you'd want to do that where you'd want to use that as a means for testing i'm not really sure obviously different provisioners might have that kind of stuff built in so you know it might be just part of the provisioning tool you can use so it initialized here we're going to do a terraform plan because i'm hoping that it might complain about the data aws ami here if it does not exist properly and it did so your curry return no results please change your search criteria and try again so however i wrote this is probably not correct so i will just take this out here try this no results so what i'll do is go over to uc2 here and actually that's the only name that's here for the ami so i guess i could just go here and grab the name but maybe that's not the problem oh no that might be fine so we'll just do this name regex okay so let's go look up data aws ami excavable users most recent name regex owners maybe we could just do like a filter here let's look at name x a regex to apply to an analyst returned by aws this allows for more advanced filtering not supported by the database api filtering is done locally on the aws returns so i suppose that is good but like i just need it to work so i'm going to try the filter instead and i'm actually going to put literally the name in my server httpd i'm going to take out the regex assuming that is the problem owners itself executable users itself um please change the criteria i don't know what x google users users actually does let's maybe look up what that is limit search to users with explicit launch permissions on the image is that required no so let's just take that out if more than one there isn't so let's just take that out for the time being who's the owner of this we're the owner right we have to be owner is this ip address that must be us or sorry not ip but like our account number so i mean that should be fine and incorrect attribute value type oh okay so that was fine so we'll do dot id but you know if you're doing this like if you wanted a continuous pipeline you'd probably want to get the most recent and have a better regex and so i'll do a terraform apply auto approve and see if this works one thing i kind of wonder is like with packer how would you do like a versioning because that's what i'm not certain about so like i'm just kind of like looking through here and seeing what they would do for that i would imagine that uh you're probably supposed to like increment it and have it part of the name nothing's really speaking to me there but you know like the idea is that you want to have things like zero zero zero zero one zero two zero three but i imagine like there's some pragmatic way maybe there's like a builtin function or something that we can do to do that um or what you do is you just have a variable probably that's actually what you probably do is you'd have like variable like version right string and then you'd probably set it and it would come through that way like you'd set it over here it says our server has finished provisioning let's go c and take see if that actually worked we'll go up to ec2 instances here that is running copy that paste that in um the security group doesn't have any open ports right so it probably did work it's just we didn't create a security group with us so there are no open ports for us to check i'm not worried about this i don't care if it actually did work or not because we more or less follow all the steps there but i believe the reason it's not working like there is just because we don't have a security group and i just don't want to uh fiddle with that and put it into a state so that it does not match so anyway we're all done here so i'm going to do a terror forum um apply auto approve destroy but there we go we accomplished that with packer that pretty much wraps up all the main follow alongs for the course so hopefully that was a lot of fun um yeah we'll just continue on here all right so let's talk about terraforming console because you're going to hear consul mention throughout the documentation and you might think it's critical to the exam but it's not so i just want to make sure we understand its relation to terraform so console is a service networking platform which provides service discovery so central registry for services in the network it allows for direct communication so no single point of failure via load balancers it has a service mesh so managing network traffic between services a communication layer on top of your container application so think middleware it has application configuration capabilities so console is useful when you have a microservice or service oriented architecture with hundreds of thousands of services so these are containerized apps or workloads and so the way console integrates with terraform is in the following ways it is a remote backend because console has a key value store and this is where you could store the state of your terraform files then also there's a console provider because you can use terraform to set up some things in console for you but there's not much else outside of that okay all right we're taking a look here at hashicorp vault so vault is a tool for securing accessing secrets from multiple secret data stores vault is deployed to a server where a vault admin can directly manage secrets and we have operators also known as developers can access secrets via an api vault provides a unified interface to any secret such as aws secrets console key values google cloud kms azure service principles it provides tight access control so just in time which is reducing surface attacks based on a range of time and just enough privilege so reducing surface attack by providing at least permissive permissions we can also record a detailed audit log so we have tamper evidence so this is kind of the idea of our little hashtag fault stack so you have your secrets engines these are thirdparty services or sorry cloud services that actually store the secrets you have your vault cluster which act as the adapter to your resources and the resources which are going to access them so again vault is is deployed to virtual machines in a cluster and vaults can be backed up via snapshots so if you do provision them and you're worried about the state of those vaults you can definitely save those for later okay let's take a look here at terraform and vault how they would work together so when a developer is working with terraform and they need to deploy a provider like aws they will need aws credentials so abs credentials are long lived meaning a user generates a key in secret and they are usable until they are deleted so the ada's credentials reside on the developer's local machine and so the machine is at risk of being compromised by malicious actors looking to steal those credentials so if we could provide credentials just in time expire their credentials after a short amount of time so shortlived we could reduce the attack surface area of the local machine and so this is where vault comes in because vault can be used to inject shortlived secrets at the time of terraform apply so imagine you are you are the developer and you run your terraform apply at that point in time it's going to inject the secrets the way we do that is via data sources data source is always the way we get data into our terraform configuration file but let's look at that in greater detail on the next slide here okay all right let's take a look at how this vault injection via data source works so a vault server is provisioned a vault engine is configured like aws secrets engine the vault will create a machine user for aws vault will generate a shortlived aws credential for that machine user thought we'll manage and apply the database policy and then within our terraform we can provide a data source to the vault so that's what we're doing we're saying vault about access credentials and we are getting the output from our terraform remote state admin outputs backend uh and then from there we can reference them into aws okay so when terraform applies run it will pull shortlived credentials to be used uh used for the scope of the duration of the current run every time you run apply you will get a new short live credentials which is the whole point of uh the shortlived idea okay hey this is andrew brown from exam pro and we are taking a look at vault and so the idea here is that we want to be able to inject uh secrets from vault in a secure manner for our local developer environments i really kind of wish i included this screenshot or this graphic within my slides i just found it as as of now because it does really represent all the types of secret engines and capabilities of vault one thing in particular i wasn't aware of is that it has its own key value store uh so that's what we're going to be using we're going to keep it really simple here um but the first thing we're going to have to do is go ahead and install vault so just down below i have a link here that i found and we'll go down below and it's not shouldn't be too hard to install so we are on linux today i mean i'm on a windows machine but i'm using linux as the windows subsystem there and so this is where we're going to start and grab our stuff so making my way over to vs code whoops um and i'm just trying to think should we use this for a new project probably so i'm going to just cd out here and i'm going to make my way into um vault which i apparently don't have a folder for so i'm going to just go here and we're going to find reveal and explore and we'll make a new one 200 volts okay and so we'll start first install something then we'll set up a project all right so um let's go through the installation process here okay so we'll go do a curl which is our first step and that's just gonna grab the gpg i think we already have it because we did it for probably the the cli4 um terraform there but we'll just do it again there it doesn't hurt i'll add the repository again i think we already did this when we installed the cli in the beginning of this course but we'll let it go again there i remember this takes a little bit of time so we'll just wait here for a bit all right so now we need to run the last command which is actually going to go ahead and install vault here for us let's go ahead and grab that line and i'm going to go ahead and paste that on in i'm not sure if i grabbed that properly we'll try that one more time it uh oh yeah my console is unresponsive there we go okay just happens when i um i stop and start recording it just for some reason times out like that so i'll go ahead and hit enter there and that will go ahead and install our vault and then after that we're gonna have to start getting it running um there is again a tutorial to inject secrets i'm not going to stick one to one with it because it does come with a repository but i find that it is a little bit more work than we want to do here we just want to kind of get a basic example working and i just want to make our lives a little bit easier so i'm just going to modify it as we go here but uh yeah we'll just wait for that to install i'll see you back here in a moment okay all right so after a short little wait here i believe that um vault is installed let's find out if it works so we'll type in vault once i get the responsiveness back from my console here just give you in a moment great oh nope there we go vault and so vault is there and so what we can do is start it up in a developer mode and i remember from here they actually had some pretty good instructions on the starting of that so um like the way they do this project and i have the repo here is that they um they provision vault with a bunch of different things so i think they're using like s3 here and that would probably be a really common use case for this but i really want to simplify and i don't want to have to provision that terraform and crossreference the stuff so we're just going to uh simplify that so i'm just looking for the command to start fault because i saw a good one here that was like vaults um ah here it is right there so vault server hyphen dab that starts in the developer mode dev root token id there's something about like ceiling or unsealing stuff i don't know what that means but i assume that's a way of securing the vault but we're going to go ahead and just type that in so we're going to go vault server hyphen dev hyphen dev root token id and obviously you wouldn't want to do this for your production they call there's education i'm just going to stick with that to make our lives a bit easier and so what that's going to do is start up a vault server it is running on this port here so i suppose we should export that or or keep this because we'll probably have to reference it somehow notice we have this like unseal key so the unseal key and root token are displayed below in case you want to seal or reauthenticate um development should not be used in production so what i'm going to do is i'm just going to create a a readme file in our vault here so let's just say new file read me because i just want to dump this stuff of course you know you should not share these with anybody but i just don't want to forget these while we're working through this so i'm going to go ahead and copy that and we'll go ahead and save that uh and so what i want to do now oops did we lose our terminal did i close it okay i must have closed it so which one we're working in second third one which is it fourth okay it's the third one so don't be like me close out your old ones so i'm just gonna close out these old ones so i'm less confused there we go and so it says that it started on uh this address here so i'm gonna go copy that address and we're gonna open this up you can do everything via the cli i just want to copy that there but they have a nice ui which is nice and so this is where we're going to put that token education and drop that down so there are some other options or there's a lot of options for authenticating but token is obviously the easiest and probably not the most secure uh it's just the way we wrote it and notice that we have a couple things preinstalled so we have cubby hull which is a per token private secret storage and then we have key value secret storage again i don't know much about these because this isn't a um this isn't a course on vault it's just kind of us showing a basic integration and more focus on the terraform side but here is where we can create our secrets we can of course use the cli to do that and i think they showed in the getting started here and we don't have to do it this way i would i'd rather do to ui but you do like vault key key v put and you put the name of your secret so here's secret forward slash hello and then the key and the value that's where the store i assume that this would go to the well this would specify we're using here so what we'll do is we'll go over here and we'll create ourselves a new secret because we're going to want to store something here so we want the path for the secret this is pretty common with um if you've ever used a parameter store you have a path i don't know if it starts with a forward slash it may not end in a forward slash probably can begin with it so i'm going to say adabs key because we'll do the key and the secret right so here oh okay cool cool so we can do four slash aws and then down below i would just add another one maybe i gotta add each one at a time so we'll say key and i'll go actually go grab our proper ones um oh i should have stopped that i'm gonna have to s start that up again okay and we'll add a plus there because everything lives in memory when you're in the dev one so you really don't want to shut that down or you'll have to redo all this from scratch so what i'm gonna do is just go back here and drag this down a little bit more okay and i'm just gonna go see if i have to relog in because i might have messed this all up yes i do so type in education so we really don't want to stop running that server during the duration of this follow along okay and so we'll go back into secret here create a secret sports slash jws um we wanted to jason no i don't think it matters if we can add two keys that's all that matters to me and so what i'm gonna do is cat out credentials of course this is not the secure way of doing it so you know again don't show people these things and so i want this and i probably should match the name i'm going to like type in the whole darn thing and we'll grab this oops i want to see that value is correct good we're going to add another one here this is going to be our axis secret or axis secret access key i really don't like how those have been named and we'll go ahead and grab on this and um i mean we don't really need to really store the region here but why not because we're doing all the rest of here we might as well just throw them all in here for fun and uh here it says maximum number of versions i don't need anything beyond one because we're not going to be updating these um require check and set so rights will only be allowed if the keys current version matches the version specified in the cas parameter not sure what that means maybe just like you're passing something along when you are doing something but uh i think this is all good you know what i'm just going to leave that back to 10 just in case i've made a mistake and we have to go debug that i'm going to hit save and so there are secrets and so what we want to do is be able to access them and so maybe this is our opportunity to learn the cli here a bit so i have it pulled up on the lefthand side and so what i'm going to do is type in vault tv get and we'll do aws i don't know if we can start with the forward slash there i'm going to hit enter and um the server gave an http response to an https client so i'm not sure why that's a problem because like i mean i understand that it started up in hd http but i mean i'm in development so you know what else am i going to really do here let's see if i can just scroll up here and if there's anything else um and i kind of swore that it installed a private key as we were doing this because i remember seeing that there it was like a private key i could have swore there was one something but private key so i'm not sure what the problem is here i'll be back in a moment and i will resolve it okay so the suggestion i'm getting is that we need to export a couple of environment variables so see here where it writes this so we say you need to set the following so maybe we will go through and set those so i'll go grab that there but here's the thing is like how do i run that because these are i think these are like not the same so i mean i can't run it over here can i i don't think so uh well i guess if we're doing a key vault value there maybe we can um still no good what if we export the vault token i think we said it was education here let's do vault status so yeah i'm not sure how we're going to do it that way i mean it's not a really big deal because i don't think that we have to access it that way but notice here like as i was reading here you know they're just saying down below oh we had to set this and that so i'm not really sure what i would do here so the output is like this run these commands and it should do it again the error message can be similar or different problems so that or maybe i'm just specifying the key incorrectly and that's why it doesn't like it so um let's just type in vault and see what we have here so vault tv maybe if we do like a list can we get a list list the secrets um aws aws clear i'm not sure what parameter it wants there uh let's go look it up so let's say like tariff or was it uh vault tv list option seems to want another parameter here i'm going to scroll on down so secret forward slash my app um folders are suffix with the forward slash the input must be a folder list of a file will not return um do i have to put secret in front of it secret aws no so i don't know what the issue is there it just would would have been nice to use it via the cli but the thing is is that again we don't need to use it that way we just need to um you know set it and and get it but i thought it'd be fun to kind of use the cli there so now that we have those set the way we're going to extract out these values is by using a data source and so what i want to do is just create a new local project and i think we'd like to always pull from our account repo here so i'm going to go all the way up to here and i'm going to go grab the main and i'm just going to copy the contents there we're going to go all the way down to the ground and we're going to make a new main tf file here we're gonna go paste that on in and we just want my server we don't need an output it's fine this is all fine this is all fine but uh the one thing is we don't want to use our particular provider there so what i'm going to do um is i'm going to just open up our credentials file there and i'm just going to change this to something else like other so that it doesn't load that profile there okay i'm going to just take these out of here um i think we can leave that alone and i think that's everything so what i want to do now we don't need that count we'll get rid of that count we'll go check out the documentation or the code base here because it gives us a bit of an idea how we need to implement this we'll go over the operator uh we'll go over to the main and so they're setting some variables here like name region path things like that but again we want to grab it from the source they're actually cross referencing it like this other they provision the admin and grabbing it that way i don't want to do it that way i wanted to use just the data source like this so i'm not sure how that's going to work so let's go look that up okay so here it says read it's credentials from an abra secret back end and i'm not trying to do that i'm just trying to read them from the key vault okay so we probably want vaults generic secret would this be from key vault this resource is primarily intended to be used with the generic secret backend but it is also compatible with any vault endpoint that is provided but is that the key value one that's not clear to me um so i think it is so let's see if we can figure that out here so i'm just going to move that off screen here and we're going to add ourselves the data source so i guess we're really not following that other tutorial at all because it we literally have to use a different um key value there eh so we'll say secret and this is going to be like aws credentials maybe there's creds i don't have to worry about spelling mistakes and we need to specify a path notice it always starts with like secret i don't know if we always have to start it with secret um so i will just say aws here and there might be some additional options i'm just scrolling through to hear that so you have path so this is the fully lo the full logical path from which to request the data to read data from generic secret back in mountain vault by default this should be prefixed with secret forward slash so we do have to do that reading from other backends as data sources possible consult each backend documentation to see which endpoint supports the get version version of the secret to read we only have a single version so we don't have to specify that so technically that should be correct so what we will want to do now in our provider is specify all those options so again i'm just going back to the source code this is off screen but we need to set the region the access key and the secret key here and so this is going to be data and it's going to be vault generic secret and i guess it would be aws and then we're accessing those things like region and so i'm going to go ahead and just copy that really quickly and we will go over back to our vault here because the names are over here so go grab that paste that in there we'll go grab that paste that in there and i'm just going to double check to make sure if i've made any mistakes this one it's showing it from the admin so it goes admin outputs but we're not outputting from anything we're just grabbing it from the vault there so maybe what we need to do is just kind of review how this generic fault works so this does data vault generic and then it does data and then square braces so i wonder if we always have to do data so for example the vault there is a a key named auth token the value is a token that we need to keep secret but yeah i don't understand is this a json object or just a way of referencing it because it doesn't specify that so we'll just give it a try nothing hurts with trying right so we'll say data and this might again might not be the right way i don't know if it's single or doubles there it's doubles so i just wonder if that was like the one case where it's doubles okay and we will do this and so i think that that should maybe work don't know what i'm wondering is if i if i'd led with a forward slash would it have considered that and or is it now double but i don't think so because look here looks like it's stripped it out because it just says aws here so we got a secret since just aws almost looks like there's a space in the front of it eh but it's not there so maybe there's not it's just kind of like a little glitch so um we need to go and cd into this directory here and we just need to do a terraform init that's kind of interesting because like we haven't set up the provider i guess it's not going to happen until we actually use the provider so maybe it's not an issue just yet i'm curious to see if it pulls any kind of modules in for the vault generic secret so i'll just give it a moment there to initialize okay so after there we can see that it did actually add vaulting so it must be ready to take it from there um i'm going to do a terraform plan here and you know i'm going to just change this to like my server with faults now remember it's not going to be able to pull from the um from our local credentials because we're not setting a profile and we overrode the default just in case so here it's saying a resource a data resource vault generic secret aws has not been declared in the root module um it hasn't i mean it looks like i did no maybe i typed it wrong so we'll go here i don't think it matters but i'll just put it above okay and i'm just gonna double check to make sure nope it matches oh because it's eight of us creds that's fair um you didn't use the option oh that's fine so my question will be will this correctly provision because we will not know until we uh use this right here i suppose if we try to use a data source for aws that would probably also indicate whether it's working or not so maybe we should try doing that so we do like data address vpc and then we just do like id equals here because that would have to use the credentials right um and so we'll just go well that's actually it's not specifying any of the the vpc here so maybe maybe we won't do that because it's just too much work um so what i'll do here is i'm going to do a terraform apply auto approve and let's cross our fingers and hope this works and while that is running what i'm going to do is just pull up my aws environment here and apparently i'm not logged in so that'll give me a bit of time here to kind of catch up here while this is provisioning there and uh so it looks like it actually provisioned the server if that's the case that means that our secrets are being pulled correctly right so if we go over to ec2 here and we go and check out this instance it is running so it worked if we just want to do a sanity check to make sure it absolutely is working we can just introduce a bug into this so maybe we go here and we just say um i guess we'd have to make a new version create a new version and what i'm going to do is purposely introduce some mistakes so we're just going to put like an at sign here on the end we're going to save that and i'm going to make a minor change like nano and so what i'm expecting is for this to fail let's see if it fails on the plan i don't think it will you're going to fail on the apply and it does okay so the plan would tell us whether it didn't work or not so that clearly uh clearly means it absolutely is pulling from it especially when we're doing the plan so um i want to go back to our file there i just kind of lost the folder i'm just looking for it the i got too many um too many chrome windows open here there it is okay so we'll go back here and we'll what if we can just revert back to the previous version um see i don't know if i would delete there i don't want to i don't want to jinx it so i'm just going to go here and take out that sign we're going to go ahead and save that and so that should be updated we're going to do tear from plan great and so what i want to do is just tear this down so it'll say terraform apply auto approve and destroy okay and while that is destroying i'm pretty pretty confident that's going to work i'm going to stop my vault server oh wait was that going to still work did i get the credentials in time oh no i i made a big booboo okay so um i uh i killed my vault server before i was supposed to that's really embarrassing um anyway that's not a big deal because i kind of wanted to stop the server anyway but i want to go back into our airbus credentials there and turn that back to defaults and i wanted to go back up here and just flip that back so that we can get rid of the server right so i don't want to kind of lose these for the tutorial so i'm just going to go here and just comment those out for a second profile default oops region usc 1 and we'll do that again that's embarrassing okay and i'm just going to preemptively i'm not going to save this file but i'm just going to do this for now um it's still trying to connect oh boy so just put these back in here because it's set to the vault can i do a tear from refresh probably not no probably not uh what if i do a terraform init because i did change like i was using vault so maybe i just have to do that to fix that problem and let's try destroy again that was a big booboo on my part eh nope okay so let's go back over here and start it up again and i'm pretty sure there's like a way to back up your vaults like there's probably some kind of snapshot or something um again i'm not that deep into it so i cannot tell you if that's the case um so i guess we'll just go back here and remake our secrets because it shouldn't have persisted right if it did i'd be so happy nope okay aws we'll leave 10 in there and then we'll just have to copy all the stuff over again because of my bonehead mistake there so we have region which is u.s east one u.s east one here and go over here well at least you know what to do if that happens to you okay um i don't need the equal sign there go ahead and add this one okay and what we're going to do is go ahead and save that and we'll just quit out of that we'll do a terraform plan since we know that that will pick it up right great and we'll do terraform apply auto approve destroy okay so again this only applies to development but uh yeah don't kill your fault server before you're done destroying okay so i'll see you back here in a moment all right so that infrastructure is destroyed we can go back to here and then we can stop our server and for your benefit i'm just going to bring back these in here so you don't have to worry about that and uh yeah we uh we accomplished vault for injections now you might say well how would you do this with terraform cloud well the thing is the terraform cloud already uses a vault under the hood when you store your environment variables there and the idea is that i suppose you don't need to pull them in from all those sources but i think that was one of my my questions i had when i was talking to one of the das which was like okay it's great that terraform cloud has um you know uses vault behind the scenes but what if i want that to live somewhere else but maybe that's not really necessary um because i don't know but yeah that's it so we're all done with vault hey this is andrew brown from exam pro and we are taking a look at atlantis which is an open source developer tool to automate terraform pull requests which you can find at run atlantis.io so the idea is once this is installed on your github and you merge a pull request then it's going to go ahead and do a terraform apply so this would be a way for you to do um uh get ops or to automate your uh your infrastructure as code and uh the interesting thing is that hashicorp actually maintains this project they didn't originally build it was built by two people from another company and it wasn't that they did not want to use terraform cloud which can uh do this but at the time i think they had a hard time at the company getting procurement because it was a very large company and so they had to build something so they built out this thing um and anyway these two people end up getting hired by hashicorp and hashgraph maintains this project which is really nice because it is an alternative for terraform cloud um but uh yeah that's all let's take a look at cdk for terraform and so to understand this we need to first understand what is cdk so aws cloud development kit is an imperative infrastructure is code tool with sdks for your favorite language so the idea is that you can use something like typescript python java csharp go and ruby ruby's definitely there that's the language i like to use and aws cdk is intended only for aws cloud resources because cdk generates a cloud formation so cfn templates this is known as synthesizing and uses that for iac but cdk for terraform is a standalone project by hashicorp that allows you to use cdk but instead of cfn templates it generates out it's going to generate terraform templates and so basically anything terraform can do you can do it through cdk and that allows you to do interesting things like um use cdk to provision azure resources so that is very uh interesting uh and a great development that i think that they're doing hey this is andrew brown from exam pro and we are taking a look at grunt work which is a software company that builds devops tools that extends or leverages terraform the reason we're talking about them is that they produce a couple of very popular open source tools that work with terraform and you're going to see their name because um you know the cofounders there are very active in the community uh jim has wrote in a really good book on terraform so you know it's no surprise that uh they are present but it's worth giving them a mention so you know who they are uh the first thing i want to mention is the infrastructure is a code library so these are a bunch of reusable battle tested productionready infrastructure code for aws gcp azure um and so they have some free ones there and some paid ones there then there's tara grunt so a thin wrapper that provides extra tools for keeping your configurations dry we have teratest a testing framework for infrastructure provisioned with terraform we have grunt work landing zones for aws this is a multiaccount security on aws we have grunt work pipelines and then there's the grunt work reference architecture and so where we're going to focus our attention here is just on terra grunt and tara tess because those are things i think are essential to know uh if you are using terraform because you know you'll run into those use cases where you might want to use them okay all right let's take a look here at teragrun so this is a thin wrapper for terraform that provides extra tools for keeping your configuration dry working with multiple terraform modules managing remote state and this is accessible at the tariff tara grunt.gruntwork.io so the idea here is the concept of don't repeat yourself so it's a programming methodology to abstract repeated code into functions and modules or libraries and often in isolate files to reduce code complexity efforts and errors so the way that works is that you'll see these hcl files which are the uh teragraph code and they're actually named terragrant.hcl and that's what's going to be used to abstract away or dry up your terraform files so here is an example of terror grunt now terra grunt does a lot of different things and you're going to uh find its use when you actually use terraform in practice and you run into these limitations in terraform and you go and i wish there was a way around it interrogant like almost always solves that and so one example is being able to generate um dynamic providers and i don't mean like dynamic values here in the sense that there's that dynamic value feature of uh terraform but i just mean the fact that at the time of this it's very hard to inject or to write out providers so they have this generate function that allows you to get around that another really interesting thing is that terra grunt supports better granularity for modules by reducing lots of boilerplate uh the way they do this is is that you are referencing your terraform files uh via the source here okay so you're not including your modules within your code you're just referencing them and then you pass along their inputs and this is going to be very important when we look at wanting to write unit tests for your infrastructure because when you learn about how you test iac you have to really break things down into smaller parts and if you have a lot of friction there it's going to make your team not want to adopt that or it's going to make that process really slow but again this is more like at scale or when you hit these kind of requirements okay all right let's take a look here at testing in terraform and so what we have here on the lefthand side is our usual um pyramid that tells us the layers of testing and so i kind of want to walk through the layers there and talk about a bit of the tools that are available to the terraform community and you know the reason why we want to move up the pyramid here to get uh better tests and then we'll take a look at teratest at the bottom we have static analysis and this is where you test your code without deploying and you've been doing it all along when you do terraform validate terraform plan or you're using sentinel uh you're doing static analysis and that just means that we're testing you know like the composition or the the shape of our code or like its outputs to what it says it should be doing okay but you can't catch all your problems there and that's where you move on to unit testing and unit testing uh you know traditionally means like in programming to test like a particular functions its inputs and its outputs uh it's a little bit harder for infrastructure because um you know you have to have it connected to other things so it the definition is a little bit warped but the idea here and specifically with terraform is you're just testing a single module and that really says like okay well you need to really pare down that module to be of the small scope and that's where you end up dividing your modules into very small units of work and so for tooling here we got teratest kitchen uh terraform and inspec um and so uh yeah that's where that motivation came with um you know teragram the last thing saying okay let's split them up into smaller stuff uh you have integration testing this is pretty much just using multiple um uh modules together you know so you say okay well i know that this lambda function is working but do i know it works in conjunction with this sqsq or something like that then you have endtoend testing and this is where you're testing basically like business use cases so it's not just saying okay from a technical perspective but from a business use case do or the customer use case do we meet the requirements here uh and this uh is very hard because what you have to actually do is set up a persistent test network environment but once you have one you're going to be really good shape one example of a test environment and it is paid but grumborg has their own called the grunt work reference architecture uh but you know if you had to do it without that you'd have to just roll your own kind of environment so you know if you do want a good breakdown of all these different kinds uh you know jim from grunt work has a complete talk on automated testing for infrastructure as code i strongly recommend it because it really gives you a better scope than what i can cover here but let's just go take a quick look at teratest so teratest allows you to perform unit tests and integration tests on your infrastructure it tests your infrastructure by temporarily deploying it validating the results then tearing down the test environment and so here's an example of what a a test function would look like in teratest it is written in golang i know golang can be very hard to use but you don't need to know much about it if you you pretty much copy and paste it and just kind of tweak the values to get the result you want so you know hopefully that helps to tell you how you would test in terraform and you know a bit about tear test okay hey this is andrew brown from exam pro i'm going to show you how to book your hashicorp certification so type in hashicorp certification into google we'll go to the first link and we'll just scroll around and try to find where it is that we can schedule so it's not that clear as to where we can go but let's say we click into the terraform associate certification and we have schedule and take the exam this will bring us to this page and it will just give us some instructions saying you have to have your id things like that so we'll say click here to go to the exam platform so we click that and it's going to bring us to the single signon so notice or it's not single signon but it's at ipd through offhashcorp.com so we'll click on our github and we will authorize that you could probably sign up via ps psi exams online if you don't have a github account but generally you probably should have one if you're taking a hashtag corp certification so what i'll do is scroll on down we'll click on schedule and i'm just going to enter some of my personal details here so we'll say andrew brown at andrew exam pro dot co okay and now i need to choose my location so we're gonna choose canada i'm going to choose my time zone so i am in toronto and so now i have some options down below so you can see we have available dates i'm going to put mine between wednesday and friday so i'm gonna take it wednesday and i'm gonna try to find a time that suits me so i'm thinking probably 8 p.m that's the time i like to take my exams we'll go ahead and hit continue and we'll just review our details here and hit continue and notice this is a remote online proctored exam it's probably possible to take it in person but at this time this is not possible to take an inperson exam so this is for the online process here and so what you're going to want to do is go ahead and go to pay now or actually sorry you have to acknowledge the terms and then go to pay now and so that would redirect you to the payment portal i actually have a code so i'm going to go ahead and enter my code in and that's how i'm going to proceed here but if you were paying you just go to the pay now okay and so mine has been set i'll go ahead and click pay now great and so now my exam is uh ready to go so that's all there really is to it they're going to give you a bunch of information that you need to follow through you need to make sure you have your government id and make sure that matches the name that you put in so i put in andrew brown so my government id needs to say that and that's all there really is to it