in this video we're going to talk about a challenging task of data management in kubernetes and a tool that makes data management very easy for the kubernetes administrators which is castings k10 so what does data management in kubernetes actually mean and why is it a challenging task imagine we have the following real world application setup in our kubernetes production cluster let's say we have an eks cluster where our microservices application is running our microservices use elasticsearch database which is also running in the cluster and in addition to that our application is using amazon's rds data service which is a managed database outside the cluster this means our application has data services both inside and outside the cluster and this data will be physically stored on some storage backend rds data will be stored on aws of course and data for elasticsearch will be used in the cluster through kubernetes persistent volume components but they also need to be physically stored somewhere and this could be a cloud storage on aws google cloud etc or on an onpremise server now let's look at the use cases we would have to think about in terms of data management of this specific application setup imagine the following scenarios in your kubernetes cluster the underlying infrastructure where the cluster is running fails and will lose all the pods services and the whole cluster configuration we would need to recreate the cluster with the same cluster state and the same application data so we need to restore our cluster to the previous state or let's say our elasticsearch database gets corrupted or hacked into and will lose all the data there again we need to restore our database to the latest working state or another very common use case say our cluster is running on aws but we want to make our production cluster more reliable and flexible by not depending on just one cloud provider and by replicating it on a google cloud environment with the same application setup and application data in all these cases the challenge is how do we capture an application backup that includes all the data that the application needs whether it's the databases in the kubernetes cluster or a managed data service outside the cluster so that if our cluster failed or something happened to our application and we lost all the data we would be able to restore or replicate the application state with all its components like pods services config maps secrets etc and all its data and that is a challenging task so essentially you need a way to capture and backup all these parts of the cluster to then easily take that backup and replicate or restore the cluster state with it now let's look at what alternatives we have available for that if we do vm backups of our cluster nodes or ecd backups we will save the state of the cluster but what about the application data they are not stored on the worker nodes right they are stored outside the cluster on a cloud platform or on onpremise servers on the other side for the cloud storage backends the cloud providers themselves have their own backup and replication mechanisms but it's only partially managed by the platform so you still have to configure the data backups and take care of your data yourself plus it's just the data in the volume this doesn't include the cluster state many teams write custom scripts to piece together backup solutions on different levels like components and state inside the cluster and data outside the cluster but these scripts can get very complex very soon because the data and state is spread on many levels and many platforms and the script code usually ends up being too tied to the underlying platform or infrastructure where data is stored the same goes for the restore logic many teams use custom scripts to write restore logic or cluster recreation logic from all the different backup sources so overall your team may end up with lots of complex selfmanaged scripts which are usually hard to maintain and these are exactly the challenges that castings k10 tool addresses so how does k10 solve these problems k10 abstracts away the underlying infrastructure to give you a consistent data management support no matter where the data is actually stored so teams can choose whichever infrastructure or platform they want for their application without sacrificing operational simplicity because k10 has a pretty extensive ecosystem and integrates with various relational or nosql databases many different kubernetes distributions and all clouds so instead of backup scripts for each platform or level you just have one easy ui interface of k10 to create complete application backups in the cluster so everything that is part of the application like kubernetes components themselves and the application data in volumes as well as data in managed data services outside the cluster will be captured in the application snapshot by k10 so you can easily take that snapshot and reproduce or restore your cluster on any infrastructure you want and k10 works with policies so instead of manually backing up and restoring your applications which means more effort and higher risk of making mistakes you can configure backup and restore tasks to run automatically with the settings you define in the policy now what if you have multiple clusters across multiple zones or regions or even across cloud platforms how do you consistently manage tens or hundreds of cluster backups for that k10 actually has a multicluster mode in cayton's multicluster dashboard you have a single overview of all your clusters as well as a way to create and configure global backup and restore policies that you can then apply to multiple clusters now if you have hundreds or thousands of applications across many clusters of course you don't want to create policies on the ui and for that k10 actually provides us with kubernetes native way of scripting policies with yemo so you can also automate your policy creation and configuration as part of your policy as code workflow now let's see how k10 actually works first we install k10 in a kubernetes cluster we can install it easily using a helm chart in its own namespace once deployed k10 will automatically discover all the applications running inside the cluster and in our case let's say we have a mysql application running in its own mysql namespace with persistent data storage configured and you can see those automatically discovered applications on k10's dashboard which also gets deployed in kubernetes along with other components the applications card also shows warning that the discovered applications are unmanaged which means we don't have any backup policies configured for our applications yet so basically the application data isn't protected that's what the warning is about and for each application we have a details view which shows all application related components grouped together including all the labels data components workload as well as configuration and networking components so as a next step we can create automated backup policy for our mysql application to protect mysql application and its data and if i click on new policy i can create a policy for my application with all needed configuration options creating a policy on ui is as easy as simply choosing a snapshot action and selecting which application you want to backup and how often now you have an option to decide exactly what you want to back up we can choose to protect everything that's associated with that application or be more granular and protect only some components of the application using filter resources or we can go even broader and snapshot multiple applications at once using the labels now this will configure local snapshots but ideally we want to store our snapshots on an external storage location so we have our backups protected and living outside the cluster for that we can enable backups via snapshot exports and select the export location which is going to be the backup target this backup target can be configured in location profile section in the settings and this backup target can be any s3 compatible storage like amazon s3 google cloud storage azure storage min io etc so you can store your application backups in your preferred location so in our case we can configure a min io storage profile by adding the credentials and endpoint bucket name and save profile now we can use this location profile as a remote storage location for our snapshots by selecting it here and before creating the policy if we click on this yaml button here you will see the policy component in a familiar yaml format and this is actually the kubernetes native api behind this policy so everything you see in the ui is enabled by this api so you can script your policies and this will be very useful if you have hundreds or thousands of applications in your cluster that you want to backup and you need a way to scale your policies and configuration options so we create the policy and this policy will run every hour since we configured an hourly backup but we can also run the policy manually at any time so if we click on run policy this will trigger a backup job that you can see on the dashboard and when completed we will see that all application components have been captured in that snapshot now that we have a backup of the application with a local snapshot as well as its remote copy we have the whole application protected so if something happens and we lose the data or application gets misconfigured etc we can restore the application from the latest snapshot simply by clicking restore and selecting the snapshot we can restore the application or even clone it in a different namespace in the same cluster in our case let's clone the mysql application in a new namespace called mysql clone and when i click on restore this will trigger restore job and if we go back to the cluster we can see what's happening in the background new namespace was created and we brought back all the application components and application data so they are now all available in that new namespace and finally when you're restoring the application maybe you don't want to clone and run the application exactly the same way with the same configuration for example if you're cloning your application to another platform maybe you want to change the storage type to use the storage of that platform or change the number of replicas of your applications or change the availability zone the application will run in and so on you can actually do such adjustments to the application when restoring it using what's called transformations in k10 just by selecting transformations as an option and then basically configuring what you need to be adjusted so as you see k10 can make the data management for applications running in kubernetes way easier and you can actually get started with k10 for free as it has a free forever option for managing up to 10 notes and even more in the description of this video you will find a link to k10's page where you can go through a handson lab to quickly try out the tool yourself without any cluster setup as well as the link to the free k10 version so make sure to check out those links and with that thank you for watching and see you in the next video