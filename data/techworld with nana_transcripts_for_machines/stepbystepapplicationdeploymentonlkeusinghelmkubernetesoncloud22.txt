in this video we will go through a practical use case of deploying a managed kubernetes cluster on lynode we will deploy a replicated database and configure its persistence and make it accessible through a ui client from browser using ingress and we will use helm to make this process more efficient so you will see helm in practice and some of its advantages to give you a more detailed overview first we will deploy mongodb in lynode cluster using helm we will create replicated mongodb using statefulset and we will also configure data persistence for mongodb database using lynode's cloud storage we will then deploy a ui client express for a mongodb database in order to access it from the browser and for this client we will configure nginx ingress so we will deploy ingress controller in the cluster and configure ingress rule in order to demonstrate handling browser request in the cluster and almost hundred percent of this whole setup is what you probably will always need to do when you set up your kubernetes cluster no matter which database or cloud platform you use so you can use the concepts you learn here for many other use cases as well so the first thing we'll do is create kubernetes cluster on lean node kubernetes engine so i have clean state i don't have any nodes yet i don't have any volumes it's all clean so here from create tab i can choose kubernetes and this is a ui where basically you can give all the information for your kubernetes cluster let's call it test i'm going to choose a region which is closest to me this version i'll choose the latest from the list and this is a place where you can choose your notes so as i explained to you in the theoretic part of the video manage kubernetes service basically manages the masternodes for you so you don't have to create or end masternodes they're hidden away from you you don't have access to them and they're managed including their security and backups etc you only need to care about the worker nodes and this is a place where you choose your worker nodes these are the capacities of different ones so i'm going to choose the second one actually the 4gb and i'm going to choose number or how many of those worker nodes i want i'm going to choose 2 and i'm going to add that to my cluster and here i see the capacity again and i also see the monthly cost of that cluster and create cluster so basically this is all you need to do in order to create a cluster this is all the information you need everything else will be done in the backend for you and then you see this dashboard with all the information and you see the progress basically of your worker notes provisioning or being created so we're gonna wait until that creates it takes actually just a couple of minutes to create the cluster and here in the notifications you actually see what's happening in the background so you see for example your worker nodes got created some configuration has been added etc so you see the nodes are running they're ready so now we have a kubernetes cluster on leanode platform and obviously we want to access it from our local machine from a laptop so that i can execute cubectl commands and deploy stuff on that in order to do that i need access file or access credentials and this is all stored right here so you can download it and this is what i have right here so this file basically if you open it you can see there are credentials for the cluster and also the certificate so this will make it possible for you to connect to the remote kubernetes cluster so the first thing you want to do when you download this file is i'm going to go to the folder where i downloaded it so this is the cubeconfig file and you have to set it as an environmental variable so i'm going to do export cube config and set the value to this file and now if i do cube ctl get node i see my two linode worker nodes so i'm connected to this remote cluster and i can now deploy stuff in there using cube ctl command and all you need to do that for that is set this variable and you see the status of nodes is also ready so we've created kubernetes cluster and we are now connected to it now the second step that we're gonna do is deploy mongodb stateful set in the cluster so there are two ways to do that the first one is we can create all the files or the config files necessary to deploy or mongodb stateful set this will be the stateful set config file itself this will be the two services that we need and maybe some configuration as well and in order to do that we need to find the image the version for the stateful set or maybe google and find correct configuration for mongodb like a script that synchronizes the parts of the stateful set and so on or the second option the easier one is we find a bundle of those configuration files that somebody already created tested and is managing or maintaining and use that file so that we don't have to figure out all the details and that bundle could be a helm chart so whenever you have this situation where you need to deploy a stateful set for example which has a lot of configuration details the first thing you can do is search if there's a helm chart for it so i'm gonna look for mongodb helm chart and currently the maintained mongodb chart helm chart is uh managed by bitnami by the way if you don't know exactly what helm is and helm charts are i have a separate video about that where you can learn exactly what helm is what are the advantages of it and then you can come back to the video and see how to actually use it in practice okay so the first thing i need to do is add the repository that contains my helm chart so i'm gonna go back and i'm gonna execute this helm command here you have to install helm if you don't have it yet and one thing to note here as well when i execute helm command it is gonna execute it against the cluster that i'm connected to right so we connect it to the cluster so now we can execute cubectl and also help comments against that cluster so helm will use cubectl in the background so i'm going to add bit number repository it has been added and what i can do now is i can do helm search repo bitnami and i can see all the charts that this repository contains and let's actually search for mongodb and these are the two so i have mongodb chart right here i see the version of the chart and the version as well so this is our chart this is what we're gonna install in our cluster now when you're installing a chart there might be some values that you want to override so chart provides you some default values and you want to see or you want to check what parameters or what values you can override so let's go back to the browser and let's see what parameters we have available so let's check mongodb and this is all the description for the chart and here are the parameters so the first thing that we are going to do is we're going to define that we want to run a stateful set right so because we want to replicate our mongodb database we want to we don't want just one pod we want multiple replica parts so we're going to set this to replica set another thing that we're going to do is pass root password or set the root password ourselves if not it will just create a random one which we can also access later so that's our choice and another thing that we want to override here is the volume configuration so we want the chart to use the storage class of leanode cloud storage because we want it to connect to linode and create volumes or physical storage on lynode and attach it to our pods this may sound a little bit complicated as a concept but you as a user you don't have to do much for it it's just one line and everything else is done in the background now if you want to learn more about stateful sets or what persistent volumes or storage classes are i have separate videos on all of those topics so you can check them out right so how do we actually pass those parameters to a chart so how can we override some values that are defined in the chart already and we do that in helm using a values file so i'm going to go back and create a file that will overwrite some of these parameters so i have the file created already this is a yaml file and these are the parameters so this is just the yaml file with key value pairs defined to override those parameters so i have architecture which is replica set replica count is going to be three so when you set it to replicate then you can use all these parameters for stateful set so i set replica count to three and in persistence i use storage class linode block storage right so let's go back and see persistence persistence parameters so persistence dot storage class and this is how i define it here and the value of it is linode block storage so this is everything you need to do in order to configure persistent volume for your mongodb this is easy as that so what this will do is in the background it will connect to lenode and it will create physical storages using linux cloud storage and attach it to your pots again if you don't understand this concept you can watch my video about storage and you will have a better understanding there and we also overriding the root password so we have everything ready we have the chart and we have the values that we use to override some of the parameters of the chart so now all we need to do is execute the command in order to install the chart using those override values and that command is helm install and then i define an arbitrary name that i want to give mongodb in my cluster so let's call it mongodb and this is where we pass this parameters file that we created so this is going to be values flag and i have that file in downloads folder so let's see let's test mongodb that's the file and finally we are going to provide the name of the chart so this is the name repository slash chart name and this is the complete command so install this is the name that we give our mongodb stateful set the values file as a parameter and the chart name so when i execute this it will install that mongodb chart in my cluster and you see i get some additional output of the status so it basically started to deploy them i have three replicas as i provided here and each one of them gets their own service so now let's actually check what is happening in our cluster and you see that our pod replicas are being created so this can take a little bit of time so we clear this up okay so it must be started already and as you see i have three parts of mongodb running plus there is another part that manages um the replication uh between those but again you don't have to worry about the details you don't have to know how the whole thing is done because this gets updated as well all the time that's why it's much more practical to use the charts instead of trying to patch together your own configuration files okay let's also see what other things got created so i'm just gonna print out everything in the default namespace um so in addition to our pods you see the services we have three mongodb services that have been created and one of them is mongodb headless service again i'm not going to go into much detail to how stateful set and services work because i made a separate video on them so go check that out if you haven't seen that already and the stage will set of course and this is the name that we gave when installing the helm chart it's called mongodb and what we also have is a secret of mongodb that actually contains the the root password that we provided here so now what about the persistent storage let's actually head back to leenote ui and let's go to first of all in lean nodes you have those two worker nodes and their status if you click in one of them you can see all the configuration there like ip addresses etc and in volumes you see it was empty when we set up the cluster and now we have three persistent volume components that were dynamically provisioned or created so basically this configuration right here the node block storage defined as storage class what happened is that when the stateful set was created for each pod one a physical storage was created for each of the three parts so this is the physical storage somewhere on the node servers and for each physical storage a persistent volume was created and that is now attached to the node where the pod is running we have only two nodes so these two are the same and this is the second node so again we didn't have to do much here everything is configured pretty easily and now we have a replicated mongodb with its persistent volume configured in the cluster now the next thing we're going to do is deploy express which is going to be the ui for mongodb now since express is actually just gonna be one part um so we don't have to replicate it and it's gonna have one service it's pretty straightforward i actually went ahead and created own configuration file i don't need to search for a chart or anything there because it doesn't have so many parts um so this is the file and by the way all these files that you see here i'm going to put them in a git repository and link them in the description so you can use them as well if you want to practice along with this video so this is very simple straightforward deployment configuration we have express name everywhere and this is our container so we take the latest express image is going to run on port 8081 and this is the configuration for connecting to mongodb and these are the environmental variables configured so that express can connect to mongodb database and if you're asking where i got these environmental variables from or how do i know what they're called you can check out the express docker file it comes with the documentation of how it works and here are all those environmental variables so it's pretty easy to find that out and also if you want to fixate the version you can choose one of the texts i'm just using the latest okay so we have configured username the admin username which is root by default and we have admin user password this is what we configured here and because those yaml files are usually checked into the repository it's not a good practice to write passwords directly so we are getting it from the secret right and this is a syntax for it again i have a separate video about that if you want to check that out so i'm not gonna go into syntax details but just very quickly i'm taking that root password value from the secret this is secret that we saw before so this secret actually contains we can check that like this you can check the values inside so we have two key pair values we have the replica set key we don't need that and this is the root password key so i'm going to be root password that's how i'm accessing it and the third one this is also important one is the value of mongodb server so this is the end point where express will connect to mongodb pod and this is the pod endpoint this is the pod name and this is the headless service name so this is how the endpoint looks like this this concept is also covered in a stateful set video so you can learn it there so i have the endpoint user and password in order to connect to mongodb let's look at the service also very straightforward it's an internal service so it's not accessible through browser it's only accessible within the cluster it listens on port 8081 and sends the request to the pod on port 8081 so this is the target port right here so this is all we need to configure express and i'm gonna create that in the cluster so let's clear that actually keep ctl apply like this so now we have the express running as well and container will create so when it successfully connects to mongodb it will have a running state so let's check again and as you see it's running we can also check the logs to be sure logs admin database connected cool so we have mongodb running in the cluster the data is being persisted and we have express so we can access the mongodb ui however as you saw the express is internal service so we have to open it to the browser for external requests and we're going to do that using ingress so the next step will be to install ingress controller in our lee notes kubernetes cluster and let's see how that works so now we're going to deploy ingress controller in our cluster uh english control also has some different components so instead of creating the configuration file ourselves for it we're gonna use helm chart for ingress controller as well and i believe there are a couple of different helm charts for ingress controller we're gonna deploy the kubernetes managed nginx ingress controller and i already found a helm chart for it so i'm gonna add the repository first of that helm chart it's been edit and now i'm gonna execute the installing of the helm chart so again the name that i giving to this component this is the chart name from the repository so it's stable nginx ingress and i'm passing in some attribute or some parameter and here again we see the output this is a example ingress rule file and we can now check that the ingress controller was deployed we see two nginx ingress pods are running here the one is just a default backend if no rule is configured and the controller itself so this means that now we can actually create ingress rules in our cluster so now we can define a domain name or host name that will then route to some kubernetes service now as i also explained in the theoretical part of this video series ingress controller uses some cloud native load balancer in the background so if i go back to lee notes ui and if i go to node balancers this is leenode's own node balancer or worker node balancer that was dynamically created and provisioned as we created the ingress controller and as i explained this node balancer becomes the entry point into our cluster so this node balancer basically gives us the external ip address this is the one accessible from browser we have the ports open on it the 80 and so http and https ports and the node balancer will then forward the request coming into into the cluster then to the ingress controller and to our internal services based on the ingress roles that we create so let's go ahead and create the ingress role for our express service so that we can access it from the browser we can also see that nginx ingress service was created so let's see service and here we have the enginex ingress controller service and as you see the type is load balancer this basically means that this service is accessible externally and the cluster ip services are internal services so they're not accessible from outside the cluster and the external services also have external ip address in addition to the internal cluster ip address and this ip address is actually the same as the ip address of the node balancer so as you see here here we have the ip address of the node balancer and this is the same one as this here so as i said this will act as an entry point into our cluster and will forward the requests based on the nginx rule that we create to respective service so now we're going to go create ingress rule for express service so that we can access it from the browser so this is the ingress rule that we're going to create we're going to call it express and the first thing we need to configure is the host so host has to be a valid domain address it cannot be an ip address so this is the first value that we're going to get so the host is basically a domain address that is connected to your cluster so i'm going to go back to linux and load balancer i have the hostname of the load balancer as well so i'm going to use that one but in production for example in normal case you would have your application domain so myapp.com or whatever it is so basically you have to configure the domain wherever it's hosted to point to the ip address of the note balancer so that whenever someone types the domain address in the browser the domain name server will resolve that domain name to the ip address of your cluster entry point server right so i'm just gonna go with the host name that i have for the node balancer because it's already pointing to the ip address and i'm gonna go back and paste that in so i have my host and here we basically define a http forwarding of request that's coming from this domain to our internal service so request came into the cluster from this domain on that path on the root path basically and we are forwarding it to service name called express service this is the service name which we created here the internal service on the service port 8081. this is where the service express is listening to and this will be it for the ingress file so let's actually apply that in the cluster let's clear that cube ctrl and our ingress is created as well let's actually check that that's our ingress roll so now if i copy that this is the domain that we defined in our ingress rule so when i access this domain i get express ui so now again for clarification i typed in the host name that i configured in my ingress rules in the browser this host name was resolved to the ip address of node balancer which is the external ip address of my cluster or entry point of my cluster so now the ingress controller looked at the request and looked at the ingress rules that it has inside the cluster and actually resolved that request must be forwarded to our internal service called express service at the port 8081 and that's how the whole request flow happened in the cluster and that's why we see express ui under that host name so now i can create a new database you can see it here and update some stuff as well so everything works i have my database here and this changes will also be persisted because we have data persistence configured as well using the volumes so this means that if i now delete the pods and restart them the data will still be there so let's actually do that now i'm going to scale down the stateful set called mongodb to zero replicas let's check that pod it's terminating so all the parts are gone so now i'm gonna scale it back to three so this means the containers um inside so the pods and the containers inside will be created again so if i go back to lean node you see that the volumes were unattached and now as the pods are creating a gain they're reattaching the volumes that belong to them which is a good thing because on the new start on the restart they basically get the same data that they had before they were stopped or they were removed so all the data is reattached to those pods and now if i'm done with the chart for example or for example if i want to reinstall my charts or update or whatever i can also uninstall it pretty easily using helm so with helm ls i see all my charts here i have mongodb and nginx ingress so i can do helm uninstall mongodb and the great thing about it is that if you manually created all those components like secret services pods stateful set etc you would have to go and clean up all those stuff manually or you would have to know what was created and remember so that you can remove them as well with helm basically uninstalled as the revert of install so this is another advantage of using helm charts actually so now after uninstall you see all the volumes got unattached again so i don't have mongodb stateful set running at all in my cluster all the components were deleted but i still have the volumes or i still have the data in case i restart them or reinstall that stateful set and this is a security feature because you may not want to lose the data when you delete the application and if you don't need those you can actually just go and delete them and also if you're done with cluster you don't have to go and delete all those components like volumes and workers etc you go to your kubernetes delete the whole cluster pretty easily or maybe if you've corrupted cluster i don't know you tested around some stuff and kind of got messed up you can basically delete it and start from scratch so that's it for the demo i hope you also practiced along and you were able to create the same setup if you got stuck somewhere or if you have any questions please write them in the comment section below and i will try to answer as many questions as i can thank you for watching this video and see you in the next one