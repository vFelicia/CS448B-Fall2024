in this video we're going to talk about fluent bit which is a locks and metrics processor tool as you know all applications need logging and the main use case for logging is data analysis something breaks in the application you check the logs to see what caused the error or you're trying to reproduce a bug and by looking at the application logs you can understand what happened or simply to have an overview of what your application is doing logs can come from different places logs are produced by applications but also server processes and so on so you have different sources of logs and fluent bid is actually a general purpose log processor meaning it can read and process logs from all these different sources but note that in addition to collecting logs fluent bit also has metrics collection capabilities for embedded linux systems for example it can gather metrics on cpu memory storage etc and because its general purpose fluent bit can be deployed on any environment like bare metal servers virtual machines embedded devices and containers however fluent bit is used the most for processing logs in kubernetes clusters now the challenge of logging in complex environments like kubernetes is that you have many different applications which produce logs in different formats each application is running in containers which run in pods which then run on kubernetes nodes so in addition to the log message and the application name itself we have all this additional information about where the log is coming from so if you have five replicas of the same application you want to know which pod replica on which node produced this log this means the challenge is to collect these data from different sources and then process it like parse all the values and identify where they are coming from as well as what the actual log contents are and parse them in key value pairs so that they can eventually be stored in elastic or kafka so that finally we can see the logs and do data analysis on them so as you see the log processor has a very important but also challenging job now processing the data of course needs resources the log processor needs enough memory storage and cpu resources to collect the logs then parse the logs and filter them and this should all be done as a background task right it shouldn't interfere with your main application's performance because then we have compromised the speed and performance of our application for a proper logging mechanism and of course the requirement for resources increases when you have applications with high throughput meaning producing high amounts of locks so as you see the log processor not only needs to collect and process logs but it needs to do it in a performant and resource efficient way so we need a lightweight and high performance log processor and one of the most popular ones today happens to be fluent bit so how does fluent beat work fluent bit uses input plugins to read the logs from the data sources for example if you need to read log files you need a plugin to read from log files if you're going to receive messages over tcp you need an input plugin that listens for messages over tcp and as mentioned at the beginning fluent bit supports many different input sources fluent bit also has input plugins for metrics data collection for example it supports statsd and collect the input plugins but also supports collecting metrics on the host systems cpu memory and disk once logs are collected and read fluent beat will process them and of course depending on the log format we would need to parse them differently for that fluent beat has different filters and parsers filters can be used to change the log record or even add some additional metadata to it like pod id or namespace where the log is coming from and so on you can also use filters to drop or ignore some records to make the filtering even more flexible in fluent bits you can use custom lua scripts as filters to modify and process the records in addition to all of these one unique advanced feature that fluent bit has is sql stream processing this allows users to write sql queries on the logs or metrics to do aggregations calculations even time series predictions this is super useful if you need to calculate an average max or min before sending the data to the storage or count the number of times a message appears or aggregate data to reduce data costs the best part about the sql stream processing is that no database is required and no indices are required everything runs on the same lightweight high performance process so you still keep that high performance and resource efficiency of fluent bit after the logs are processed fluent beat will send them to a storage like elasticsearch or splunk where you can then see the logs in a nice visualized format again fluent bits supports many different storage backends and to send the logs to the storage backhands fluidbit uses output plugins so basically the input plugin knows how to transform the data of a specific format to what fluent bit can read and process so for example tcp input plugin knows how to parse tcp data into fluent bit data an output plugin knows how to transform the fluent bit data into what the output target understands so elasticsearch output plugin knows how to translate the fluent bit data into the format which elasticsearch can read and save and in fluent bit you can send logs from multiple input sources to multiple output destinations you can do this log routing pretty easily using tags you can add text to logs and then group them so that you can say parse all the logs with a tag that starts with apache with this parser or send all the logs that match nginx to elasticsearch now how does fluent beat actually run in a kubernetes cluster fluent bit gets deployed as a daemon set which means it will run on every kubernetes node so when a new node gets added to the cluster a fluent bit pod will start there immediately so on each node fluent bit will gather logs from all the containers on that node in addition it will gather metadata for those logs like pod ip container ip name space and so on from the kubernetes api a cool feature of fluent bit is that we can suggest which parsers to be used on pods using annotations in kubernetes configuration files some other advantages of fluent bit are that it has a pluggable architecture as a log collector it doesn't try to replace the data sources like systemd or journal d instead the goal is to integrate with different data sources and to do that fluent bit needs to be able to talk to tcp read logs from a file system talk to systemd api etc it also has builtin security because when you are sending logs from the cluster out to the storage backends you are talking to thirdparty services outside your cluster so of course you don't want your logs to be sent in plain text you want to use https or tls for that connection and it has a simple architecture which makes it easy to scale fluent bit on hundreds of servers because as i mentioned fluent beat will run on each node in the cluster now fluent bit works in a very similar way as fluentd which is another log processor from the same company i have a separate video on fluentd as well so if you know fluentd you may be asking what is the difference between these two if they work the same way which one should i use in which case first of all fluent beat is much more lightweight than fluency which means it's highly optimized for performance and low resource consumption compared to fluentd and as i mentioned at the beginning if you have a complex application setup which generates a lot of logs you want your log collector to work efficiently so fluent bit is designed to run at high scale with low resource usage and it's actually the preferred solution for containerized environments however fluent beats follows the similar philosophy as fluentd as a log processor but also as a matrix processor fluent bit is actually a cncf subproject under the umbrella of fluency and also they're both vendor neutral so they can run on any environment regardless the platform and also interesting to know that there are even use cases where you can use both fluent beat and fluenty together to create a very efficient and high performance log processing architecture for your environment now let me know in the comments what other technologies you want me to cover on my channel with that thank you for watching and see you in the next video