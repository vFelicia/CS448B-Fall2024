With timestamps:

00:00 - this video I talk about analyzing data
00:01 - specifically I'm gonna talk about mean
00:03 - median and mode so when I have this is
00:07 - considered to be by the way one variable
00:09 - statistics or I only have there's not
00:11 - it's not a sort of graphing relationship
00:15 - for you have an X Y you just have single
00:17 - numbers that you're working with so the
00:19 - most common way these are called
00:21 - measures of central tendency I'll throw
00:23 - that in the corner over here central
00:27 - tendency because you're saying something
00:29 - about where the middle of the number is
00:32 - or what happens a lot or that sort of
00:34 - thing so all that's in play here I'm
00:41 - getting lazy on my handwriting late at
00:43 - least I'm trying to fix it
00:44 - so anyway mean median mode those are the
00:47 - big ones that you use deal with there's
00:50 - also range by the way range in the case
00:52 - of one variable statistics II how far
00:55 - how spread out the data is the biggest
00:58 - minus the smallest that's or so and when
01:00 - that what that said it's probably a good
01:02 - idea that we organize the numbers
01:04 - numerically first if we put them in
01:06 - numerical order it makes a lot more
01:08 - sense my suggestion is if you do it by
01:11 - hand once you write a number down mark
01:13 - it out so I look and I see that three is
01:16 - the smallest number and then there's
01:19 - another three so I'm going to put three
01:20 - again and then there's four so that's
01:25 - out another four and another four then I
01:31 - need to put six
01:34 - seven and this is one of those areas
01:38 - where not getting sloppy is in your best
01:41 - interest because if you scribble it on
01:43 - paper and you lose stuff that's when you
01:45 - start to get these wrong so there's my
01:49 - number in like a nice numeric fashion so
01:52 - when I'm dealing with mean it's the only
01:56 - one that doesn't have like a little code
01:57 - word that tends to go with it
01:59 - median you tend to code word middle
02:07 - mode you might say most mean average
02:15 - really some people have gone really far
02:19 - and said like you know you're mean
02:21 - teacher averages your low test grades
02:23 - together that sort of thing I don't
02:24 - really get in on that party but it is
02:27 - what it is anyway so really what you're
02:29 - dealing with is the sum
02:38 - of the values so add them all up and
02:42 - then you want to just divide by how many
02:45 - there are so the number of values
02:52 - so you might say something like som over
02:56 - how many that tends to be the the short
02:58 - version of that so if I did 3 plus 3
03:05 - plus 4 plus 4 plus 4 plus 6 plus 7 plus
03:14 - 8
03:19 - plus 10 plus 11 and my suggestion is if
03:24 - you're typing it in this way in a
03:26 - calculator you just make sure that you
03:28 - have everything the way that you want it
03:30 - so go back through and look at them and
03:32 - it supposed to be a 10 go back through
03:35 - and look at them and make sure
03:36 - everyone's there
03:37 - you should probably count the numbers I
03:38 - know there are 1 2 3 4 5 6 7 8 9 10 of
03:43 - them which is helpful for the
03:45 - denominator anyway because the number of
03:46 - I use is 10 that works so I can just go
03:49 - like into my calculator to make sure I
03:50 - have 10 numbers there and they're the
03:52 - right ones so I end up with a total
03:55 - value on in the numerator of so I'm
03:59 - gonna have to make a little space for
04:01 - myself messed that one up
04:05 - dinging myself enough room so anyway I
04:09 - end up with a numerator value of 60
04:20 - over 10 so my mean value is 6 right
04:25 - there that's how that set up sort of
04:26 - sort of works now the median number
04:28 - would be the middle I hope something to
04:33 - do that in blue there we go
04:36 - so the median number would just be the
04:38 - middle so what I need to do is put them
04:40 - out all the numbers so write them here
04:45 - you don't have to rewrite them you can
04:47 - just use the original version if you
04:48 - don't have to be able to see them very
04:51 - well and then I tend to start at the
04:53 - left side and Mark it out with like a
04:55 - slash down into the left and then I'll
04:58 - go the other direction for the second
05:00 - one just so I know that I'm where I am
05:02 - if I kind of lose my place then I'll go
05:04 - back to the original direction then in
05:07 - in this case I have two middle numbers
05:10 - so what I need to do if you just have
05:13 - one that's your median if you break it
05:14 - down into an odd number so say there's
05:16 - nine will it'll be one in the middle and
05:18 - that's your median value in this case I
05:19 - have two of them so I just need to find
05:24 - the middle number I mean it's five but
05:25 - you know you can add them up and divide
05:27 - by two and you get a median value of
05:29 - five that's how that works and the mode
05:32 - is just the one that happens the most so
05:35 - you sort of if I were to do a little
05:37 - mini frequency chart
05:44 - and you definitely don't have to do a
05:46 - frequency chart with this I'm just doing
05:48 - it for my own benefit so for three
05:51 - there's two of them for four there's
05:53 - three of them for six there's one all
05:55 - the rest just have one so the one that
05:57 - happens the most is four so my mode is
06:04 - four if I had another three in there or
06:08 - one less four you can have multiple
06:11 - modes or it could be what's called
06:12 - bimodal or you can have no mode at all
06:21 - if all the numbers are different you
06:24 - just say no mode if it has two modes you
06:27 - just say you know you just name which
06:29 - modes they are so four and three that
06:31 - sort of thing that's the gist of how it
06:34 - all goes in terms of the difference
06:37 - between the mean and the median you'll
06:39 - see that the mean value is actually
06:41 - greater than the median value in this
06:43 - case well if we look at the numbers that
06:45 - sort of makes sense because you you lose
06:48 - a lot of capital in the median setup
06:51 - because the first five numbers are just
06:53 - the same two numbers and they're very
06:54 - close together and they won't be but the
06:57 - 11 and the 10 which are much bigger in
06:59 - the second set will stretch that mean
07:01 - value out a little bit so sometimes you
07:03 - have to tell which one is the better and
07:06 - now which one better analyzes the data
07:09 - median will always tell you the middle
07:11 - but it doesn't necessarily like if I was
07:13 - going to get an idea of what kind of
07:15 - test scores my students made on a test
07:18 - or whatever I would probably use the
07:20 - mean as my setup more than likely
07:22 - because if I just use the median I could
07:24 - have a ton at one end and it may give me
07:27 - a little bit of a skewed I sort of would
07:30 - like to look at the information from the
07:33 - mean maybe or you know maybe I wanted to
07:35 - I had one kid made a really good grade
07:37 - basically I would want to it to be the
07:39 - median or sorry be the mean because if I
07:42 - have a couple kids who make really good
07:43 - grades versus the other ones doesn't
07:45 - make the other ones look so bad so I
07:46 - want to feel good about how things have
07:47 - gone for that test on the other hand if
07:50 - I was going to do a reasonable analysis
07:51 - my original explanation was a little bit
07:54 - weird I realize now if I want to do an
07:56 - actual analysis medians probably the
07:58 - need to go just because it'll it'll
08:01 - analyze the spread a little bit better
08:03 - if I have a bunch of really low scores
08:05 - and just a couple Highlands that would
08:07 - bring it up the median would tell me
08:09 - that yeah things didn't go too well on
08:10 - this test the mode would have no benefit
08:13 - to me
08:14 - for the most part let's add a whole
08:16 - bunch of hundreds or something but the
08:18 - mode probably wouldn't tell me much in
08:19 - terms of the data there's other
08:21 - situations where the mode is a
08:23 - reasonably useful setup but in that case
08:27 - the mode would not be that helpful to me
08:28 - but anyway look at the data in terms of
08:32 - how it's sort of skewed around and you
08:33 - get a good idea of which one mean
08:35 - meaning our mode is the best for you to
08:37 - analyze central tendency welcome in this
08:40 - video I'm going to be analyzing data
08:42 - central tendency stuff specifically mean
08:44 - median mode using a ti-84 plus so I have
08:48 - my data set there at seven four six
08:50 - eight thing and I'm gonna go in and just
08:53 - make it happen
08:54 - now when you have one set of data like
08:56 - this you want to just punch it in as a
08:57 - list in order to edit a list you go to
09:00 - the stat button so go in and then under
09:04 - the Edit menu just click enter for
09:06 - number one I've already typed it in so
09:09 - it should be you don't have to put it in
09:11 - order before you type it in in fact in
09:13 - the edit menu that I was just on it has
09:15 - sort a which is sort ascending so the
09:18 - numbers go from smallest to greatest or
09:20 - sort D which is sort of descending so it
09:22 - goes down so you could deal with that
09:23 - later but for right now the biggest
09:25 - thing is once you type them in and
09:26 - you'll just type the number in hit enter
09:28 - it'll take you to the next one go down
09:30 - to the bottom one the last time you hit
09:32 - enter it'll fall below the numbers click
09:34 - back up just to see this number right
09:37 - here it says l1 which means list 1 and
09:39 - in parentheses it has 10 which means
09:41 - there's 10 values in list 1 so you count
09:44 - up your values and there are 10 of them
09:46 - so you know that you have the right
09:47 - number in there why wouldn't you know
09:48 - just be thorough to go back and check
09:50 - whatever anyway now that I've typed it
09:53 - in I need to quit out of the Edit menu
09:55 - so I'm just gonna hit 2nd and quit to
09:57 - get back to the main screen from here
10:00 - I'm gonna go and just do some math with
10:03 - the
10:04 - the data that I've put in the list so
10:06 - hit stat again sorry I'm gonna do
10:12 - specific thing so I need to hit second
10:14 - in list if you're working with numbers
10:16 - in the list you're not just doing some
10:18 - sort of generic regression or whatever
10:19 - you'll need to hit second list that's
10:21 - where you pick the list it's also where
10:23 - you do some of the you know operations
10:25 - and math using the list so the math menu
10:28 - has mean median and it'll give you
10:34 - standard deviation Oh give you a minimum
10:36 - value of maximum value all that's there
10:39 - you know not huge big deal so anyway I
10:41 - want to know the mean so I'm gonna hit
10:44 - mean and then I need to go pick the list
10:46 - that it comes from so here's that list
10:52 - you get six if I want to know what the
10:56 - median value is oops second list I need
11:02 - to go over to
11:07 - the median here so I'll do a second list
11:11 - again they'll choose list one and there
11:14 - it is now to find the mode and I think I
11:18 - already found the median and make sure
11:20 - yeah I did okay to find the mode in
11:22 - older versions are like the T is 73 Plus
11:26 - which is the middle school version
11:27 - there's actually a mode button that you
11:29 - can it'll do it for you in the ti-84
11:31 - plus they assume that you can count so
11:33 - the best you can hope for is organizing
11:36 - your list and then just finding the one
11:37 - that happens the most so what you're
11:39 - going to do is go in and go to second
11:45 - list so you can fiddle with your list
11:46 - again you could do this from the Edit
11:48 - menu too so hit o-p-s says sort a which
11:51 - means sort ascending and then you want
11:54 - to go second list again and pick l1 and
11:57 - hit enter it just is done it doesn't
12:00 - give you the information now you can
12:01 - look at your list so I just stood here
12:04 - and go to your edit and you just count
12:09 - the one that happens the most so in this
12:11 - case four but in old some version the
12:14 - calculators are actually a setup that
12:15 - will give you the mode but in this case
12:17 - just kind of find the one that happens
12:19 - the most and you know that's it done all
12:25 - right in this video I'm going to talk
12:26 - about analyzing data specifically
12:27 - looking at quartiles interquartile range
12:30 - and box and whisker plots so I'm going
12:33 - to take my data that I have here the
12:35 - seven four six eight line and I'm going
12:37 - to just analyze it using those setups
12:41 - the first thing that I need to do is
12:42 - rewrite it in such a way that I have it
12:47 - in numerical order so ascending
12:51 - preferably three it's kind of McDonalds
12:56 - colors now three
12:58 - four four four six seven eight ten
13:14 - and 11 now when I talk about
13:17 - interquartile range or when anybody
13:19 - talks about interquartile range that
13:20 - knows any idea what they're talking
13:22 - about we're talking about breaking it up
13:25 - into groups of four like a court a Keene
13:28 - tile would be five so I tend to think of
13:30 - it in terms of a dollar bill and then
13:32 - the quarters that could go into it so in
13:35 - a dream universe I could draw good
13:37 - circles but I'm not living there so you
13:42 - just have to accept the fact that these
13:43 - quarters are awful looking so anyway 25
13:48 - cents that whole thing so there's four
13:54 - quarters in dollar essential is where
13:55 - I'm headed with it now there's a couple
13:58 - points of reference that we need to make
14:00 - when we work with these the first which
14:02 - is the minimum number not realize how
14:06 - awful that color is is they against this
14:10 - background so the minimum number so
14:12 - we'll say men in our dollar OB wherever
14:16 - it is down here kind of men by the way
14:21 - the dollar thing will pay off because
14:22 - it'll make it really easy for us to do
14:23 - the box and whisker plot here in just a
14:26 - minute the next thing that we probably
14:28 - look for is the maximum number of course
14:31 - because why have a min if you don't have
14:33 - a max
14:38 - Max would come right here in the old
14:40 - dollar analogy then we'd want the median
14:47 - median would come right here at the 50
14:50 - cent point so 50 percent of your data
14:54 - goes to one side and 50 percent of the
14:56 - data is above that number and then we'll
14:59 - have q1 and q3 so basically we'll have
15:08 - q1 will be here after the first quarter
15:10 - so it's essentially the median of the
15:12 - lower level or the lower two quarters on
15:16 - the other end you'll have q3 which is
15:18 - the median of this set of data so in my
15:22 - little setup here I need to figure out
15:23 - what the median is so the specific
15:27 - amount from the minimum by the way would
15:29 - be 3 because it's the smallest the
15:31 - maximum would be 11 now my median is
15:34 - what I'd look for next these cancel
15:43 - so I'm looking somewhere between six and
15:45 - four so to get my median value I'll do 4
15:49 - plus 6 divided by 2 so my median value
15:52 - will just be 5 so here's my median right
15:55 - here to get q1 I need to look just it's
16:06 - this set of data right here I need to
16:08 - find the median value there which is
16:11 - right here so the q1 value by the way if
16:16 - I had 2 in the middle there I would do
16:20 - the average of those two so say I'd been
16:23 - 3 and 4 together or 3 and a half would
16:25 - be the median or the q1 but the q1 here
16:27 - is 4 because it's the median value of
16:31 - that first set the first two quarters on
16:33 - the other side of it if I'm dealing with
16:36 - this set the top half so to speak I want
16:42 - to find the median there it's the 8 so I
16:47 - would say that my q3 value is 8 now what
16:52 - this what I can do with this information
16:54 - oh I should also talk about
16:55 - interquartile range I'll get to that in
16:56 - a second what I can do with this is make
16:59 - a box and whisker plot which will give
17:01 - me some idea about how the data is
17:02 - skewed whether it's one direction for
17:05 - where there most of the data falls at
17:07 - one end or you know that sort of thing
17:08 - as you can see there's a considerable
17:10 - distance between q3 and the maximum
17:13 - compared to the minimum and the q1 so
17:16 - that will shift with the the the graph
17:19 - looks like which will tell us that the
17:21 - data sort of shifted in one direction
17:22 - and might push us to pick the median as
17:25 - opposed to the mean as our central
17:27 - tendency of choice that kind of thing so
17:29 - the interquartile range
17:36 - I'm gonna call it the IQ range which is
17:39 - really unfair
17:41 - so the inte Q range I don't know
17:43 - interquartile ranges right there
17:46 - anyway interquartile range is q3 minus
17:50 - q1 so basically this distance right here
17:54 - I need to know how far they are apart so
17:58 - the middle two quarters so the middle 50
18:01 - cents so in this case would be 8 minus 4
18:04 - so the interquartile range is 4 and all
18:08 - of this stuff is really sort of an
18:09 - assessment of range the maximum minus
18:12 - the minimum will give you the range of
18:13 - the entire data set the interquartile
18:15 - range will give you an idea of what's
18:17 - going on in the middle so you can sort
18:18 - of see maybe one of those numbers is
18:21 - what's considered to be an outlier and
18:23 - outlier is a number that's way out of
18:25 - the scheme of things and if we look at
18:27 - the box and whisker plot we may be able
18:29 - to see if there's really sort of an
18:30 - outlier here so let's make a box and
18:33 - whisker plot box of whisker plots you
18:37 - want to start out with sort of a number
18:39 - line underneath and it has two dots one
18:43 - at the minimum one at the maximum so I'm
18:45 - gonna make my little set up I'm gonna
18:48 - have three at the one end
18:58 - and 11 at the the right side so I'm
19:02 - gonna make little dots here those are
19:07 - eventually going to be my whiskers now I
19:09 - need to make my box I'm gonna make a box
19:11 - that sort of looks like this in some
19:15 - form so the first line I'm gonna make is
19:18 - a q1 so right at 4 there I'm gonna go
19:22 - ahead and make a line right here
19:28 - that's q1 the next line I'm gonna make
19:32 - is at the median so right here and then
19:36 - I'm gonna make another line at q3 and
19:40 - then I'm just gonna make a box out of it
19:42 - and now to finish it off I need to
19:46 - connect my whisker so I'm gonna draw a
19:48 - line here and draw a line here so if you
19:50 - see the box and whisker plot you can
19:52 - tell they'll say what's the minimum
19:54 - value well you go to the dot on the left
19:55 - and it's 3 if they want to know what the
19:57 - median is you look for that little line
19:59 - in the middle of the box and is 5 but
20:00 - what it really tells us is how the data
20:03 - is skewed you can see that the median
20:05 - value is way down here as opposed to the
20:07 - whisker that's way up here we can't
20:10 - really tell necessarily if 11 is an
20:12 - outlier based on a box and whisker plot
20:15 - so I guess I should write that word up
20:17 - in case people never seen it
20:20 - an outlier is basically a data point
20:24 - that's uncharacteristic of the set but
20:27 - since 10 is here and you know Elevens
20:30 - probably okay as an outlier but if I had
20:32 - like 25 in there that would be
20:35 - significantly further away from the rest
20:38 - of the data set so I could say yeah 25
20:40 - is an outlier so the term outlier makes
20:43 - the most sense here it's just the one
20:45 - that's a way outside
20:52 - the overall feel the tendencies of the
20:59 - number says so way outside the number
21:00 - said essentially one that's kind of the
21:02 - weirdo outlier set number so anyway
21:05 - quartiles just find a minimum maximum
21:09 - find your median q1 would be the median
21:12 - of the first group or the first half of
21:14 - data points the q3 would be the median
21:17 - of the second half of data points and
21:19 - find the interquartile range you want to
21:21 - subtract q3 minus q1 find out how far
21:24 - apart that middle is which is you know
21:27 - not insignificant here and then finally
21:30 - you want to have your maximum number of
21:32 - course make your little box and whisker
21:34 - plot out of it and based on the one that
21:36 - I have right here I can see that most of
21:37 - the data is sort of shifted down to the
21:39 - 4/5 range and you know all my data is
21:43 - sort of skewed to the lower end whereas
21:45 - Elevens keeping it propped up but
21:47 - there's enough numbers at the the top to
21:50 - spread it out so at least the
21:52 - interquartile range shifts up to eight
21:54 - so it tells me something about the data
21:57 - in this video I'm going to analyze we
21:59 - talked about anyone analyzing data
22:01 - quartiles interquartile range and box
22:03 - and whisker plots with the ti-84 plus so
22:05 - in case you ever need to do that the I'm
22:09 - going to go ahead and just get into it
22:11 - really we're working with the list here
22:13 - so I'm going to turn it on and eat to
22:15 - clear out my list
22:20 - I can get it to do it okay generally you
22:23 - want to do it individually because if
22:25 - you go up to the top and delete it it
22:27 - will delete l1 which makes it all kind
22:29 - of get wonky after a while so it's just
22:31 - in your best interest to delete them
22:33 - individually if possible anyway once you
22:35 - do that type min
22:47 - and I'll go back up and check there
22:49 - should be ten there is so I'm you know
22:51 - ready to work with it now this is what
22:54 - I'm going to end up doing is a one
22:56 - variable statistics so I can get a whole
22:58 - bunch of information from it so if I go
23:00 - into the stat menu and click over to the
23:03 - calc which is calculations I'll go to
23:05 - one variable stats and hit enter to pick
23:08 - l1 is my list I'm not going to pick a
23:09 - frequency list and hit calculate if I
23:12 - click down a little bit this is a whole
23:13 - bunch of information you can get
23:15 - standard deviation there you can figure
23:17 - out you know kind of what the values of
23:20 - the sets are and that that whole thing
23:22 - so what I'm interested in is what's
23:25 - minimum maximum q1 median and q3 are so
23:29 - just click down a little bit there's the
23:31 - minimum value of 3q one value for median
23:35 - of five q3 of eight and Max of eleven
23:38 - now I want to make a box and whisker
23:41 - plot which could tell me all that
23:42 - information as well so what we're gonna
23:44 - do I'm gonna clear that quit out first
23:46 - you have to still type your list in
23:47 - otherwise it won't work I'm gonna use a
23:49 - plot here so hit second and y equals and
23:54 - you're gonna actually turn one of the
23:56 - plots on by the way once you turn a plot
23:58 - on you have to turn it back off or when
23:59 - you try to graph normally your
24:01 - calculator will go out of its mind it
24:03 - doesn't understand what you're trying to
24:04 - do so I'm gonna hit enter I need to turn
24:07 - that plot on and I need to go down to
24:10 - type I'm gonna pick the one in the
24:12 - middle here the box and whisker plot
24:14 - choose that one it's gonna ask me which
24:17 - list do I want to use and I want to use
24:19 - l1 of course and the frequency is fine
24:21 - the thing is my calculator right now is
24:24 - set up to graph normally so I probably
24:26 - have X values of negative 10 and 10 or
24:30 - something like that but I'm gonna my
24:32 - numbers go from the number 3 all the way
24:35 - up to the number 11 which is above 10
24:37 - obviously so I need to adjust my window
24:40 - a little bit so I'm going to go into the
24:41 - window here I'm not gonna do it that way
24:43 - I'm gonna hit enter to choose the
24:45 - frequency
24:47 - might help if I just kind of quit out of
24:49 - it really quickly yeah sorry
24:51 - so I'm gonna quit out now that it's all
24:53 - set up and ready to roll ski I'm gonna
24:55 - go to the window and I'm gonna change it
24:57 - I usually go like one below the smallest
24:59 - number so two and my X maximum I'm going
25:01 - to put one above so twelve and now that
25:04 - that's all kind of where it needs to be
25:05 - I'm gonna hit graph and it should make a
25:07 - nice box and whisker plot for me the
25:10 - cool thing about it is if I hit the
25:12 - trace button it'll start telling me
25:14 - where all the information is so mine
25:16 - tells me that the median is five if I
25:18 - click to the left it'll tell me q1 is
25:20 - for the minimum X is three and then you
25:23 - can go over and get q3 of eight and
25:25 - maximum of 11 so all that information is
25:27 - there for you you can make it pretty
25:29 - easily so it might be a nice way to
25:31 - organize your information this video I'm
25:34 - going to talk about analyzing data
25:35 - specifically I'm going to talk about the
25:37 - term percentile where you'll see
25:39 - percentile most often is in things like
25:42 - standardized tests the a CT the SAT that
25:45 - kind of stuff the those tend to pop out
25:48 - things like your percentile is this so
25:50 - maybe you're in the 75th percentile for
25:52 - your composite score on the a CT what
25:54 - that means is the value of your score is
25:57 - at or above 75% of the values that other
26:01 - students have scored or including
26:03 - yourself so 75% of the scores earned by
26:07 - students on that test were as good or
26:10 - worse than yours that's what you need to
26:12 - know now on the Left I have this little
26:14 - set of numbers it's okay that some of
26:16 - them repeating that happens
26:18 - so this is our 80 a CT scores just once
26:23 - I've made up in order to find the
26:26 - percentile I need to take the number of
26:28 - terms and then multiply it by the
26:30 - percentage it's pretty simple so let's
26:32 - just do the 75th percentile I want to
26:38 - know what I have to score to get in that
26:39 - 75th percentile because maybe that means
26:42 - something for college I don't know but
26:44 - apparently they're only picking people
26:47 - from my school to go because and I have
26:50 - a very small school by the way because
26:52 - only 20 people took it but you know I
26:54 - just I guess so I went over the 75th
26:57 - percentile starts here so there are 20
27:01 - terms and I just want to multiply that
27:07 - by 75% specifically I wanted multiply 20
27:13 - by 0.75 and once I do that I can find
27:19 - the value of that I would need to make
27:22 - to fall in the 75th percentile so I do
27:24 - 20 times 0.75 ended up with 15
27:30 - that does not mean a score of 15 it just
27:33 - means 15 terms into the data set 15
27:36 - terms in
27:42 - to the set so right there that's the
27:50 - fifteenth term in the set so in order to
27:52 - fall into that 75th percentile I need to
27:56 - have a value of 27 if I wanted to get
27:59 - way up there like I wanted to just you
28:01 - know over achieve a lot maybe I want to
28:07 - get in the 95th percentile well in that
28:13 - case I would take the same number and
28:15 - multiply by 95% which of course would be
28:20 - 20 times zero point nine five and I
28:24 - would find out that that would be the
28:25 - 19th term in
28:33 - the set so right here in order to be in
28:37 - the 95th percentile of this group I need
28:39 - to score a 34 so there it is that's all
28:42 - percentile means it's not overly
28:44 - complicated but occasionally you'll get
28:46 - questioned about this and this is the
28:47 - way to find it in this video I'm going
28:49 - to talk about using standard deviation
28:51 - information to describe data like where
28:54 - a data point actually false so in my
28:56 - theoretical universe that I'm dealing
28:58 - with here I'm going to say that I have a
29:01 - mean value of 18 and I know that my
29:07 - standard deviation is say for something
29:13 - like that so in this what I'm going to
29:15 - do is just make a little number line
29:17 - here so 18 would be my mean to do my
29:22 - standard deviation I'll do plus 4 up
29:24 - here so so if I have my set up numbers
29:36 - 19 20 21 22 here's my standard deviation
29:47 - away from where it happens to be that'd
29:50 - be one standard deviation above and then
29:53 - here 23 24 25 26
30:00 - it's another standard deviation outs I'm
30:03 - a called
30:03 - 2 standard deviation on the other side
30:06 - of it
30:15 - one standard deviation away
30:23 - two standard deviations away so if I
30:26 - want to know specific information about
30:28 - a number so say I want to know where 22
30:33 - Falls or I want to know where 10 happens
30:37 - to fall
30:37 - well 22 is one standard deviation above
30:48 - the mean 10 however is two standard
30:58 - deviations below the mean so basically
31:06 - it just gives me a sort of a reference
31:08 - point to explain where information tends
31:12 - to fall usually depending it does depend
31:15 - on the distribution a little bit
31:18 - most of the data will fall somewhere
31:20 - between the two between two standard
31:23 - deviations away if it's a value that
31:25 - you're actually going to use so you can
31:27 - get sort of an out like the ten is way
31:29 - away from the mean so it may be
31:30 - something that I sort of question
31:33 - whether I really want to use it in my
31:35 - analysis of the situation whereas 22
31:38 - being one standard deviation above the
31:40 - mean may be something that I would
31:41 - consider a pretty solid you know data
31:45 - point that's okay and say to use if I'm
31:47 - doing a very specific type of research
31:50 - it just sort of depends on where you
31:52 - want to go with the information but a
31:53 - lot of times you will have standard
31:54 - deviation pop up as being a tool that
31:57 - you can use to analyze where a point
31:59 - falls in the data set so there it is
32:04 - in this video I'm going to analyze data
32:06 - talk about the standard deviation
32:07 - variance using the ti-84 plus so we're
32:11 - dealing with I've dealt with standard
32:14 - deviation and variance I should say in a
32:15 - different video basically you find the
32:17 - mean of a set of numbers you find out
32:19 - how far away each individual data point
32:22 - in the set is away from that mean then
32:24 - you want to square that difference so
32:26 - the negatives aren't canceled out by the
32:29 - positive so everything's positive
32:30 - basically then you add those squares
32:33 - together then you once you have the
32:36 - added squared differences away you just
32:39 - divide by how many terms there are and
32:40 - that'll give you your variance and then
32:42 - to find the standard deviation you want
32:44 - to sort of eliminate the effect of
32:45 - squaring it by taking the square root so
32:47 - you square root the variance and it'll
32:48 - give you the standard deviation now a
32:50 - calculator will do this relatively
32:52 - quickly for you specifically in this
32:53 - video ti-84 plus so let's bring it up
32:56 - and see how it works now to do this I
32:59 - need to make a list of my numbers I'm
33:01 - gonna go to the stat menu to do that and
33:03 - edit there's a list already in here be
33:07 - careful if you go up and click l1 and
33:09 - delete it it'll often delete l1
33:11 - completely so when you go back and try
33:13 - to use l1 to do other statistical things
33:16 - or box and whisker plots or any time you
33:19 - have to use l1 you'll think that the
33:21 - first one you typed in is l1 and it kind
33:24 - of messes with you so it's easier
33:25 - sometimes just to sort of click up and
33:27 - down the list a little bit and then just
33:29 - start deleting individual points unless
33:32 - you have a gigantic number I would
33:34 - probably go that route
33:35 - anyway type them all in there's not that
33:38 - many in this set because I just kept the
33:40 - one I did when I did it by hand and
33:43 - or I did a long explanation I don't want
33:45 - that many of them so click backup to
33:48 - make sure the 1/5 is that number should
33:51 - be it means list 1 there's five terms in
33:53 - it if you're in the last number so that
33:56 - way it matches in case you have a big
33:58 - set they have to deal with anyway now
33:59 - that I have my list I can hit second and
34:01 - quit and get out of it I'm gonna go in
34:03 - into the setup menu again so I hit stat
34:07 - I'm gonna do one variable statistics so
34:12 - when I do that I want to tell it what
34:13 - list I'm picking from I'm not gonna pick
34:15 - a frequency list here and I'm just gonna
34:17 - hit calculate
34:18 - now it'll tell me pretty much everything
34:21 - that I need to know it tells me what my
34:24 - mean value is so it tells me it's 8 so
34:28 - if I were to pop that out I would say
34:31 - well here's my mean value right here if
34:35 - I can get it to do it I'm gonna bring it
34:36 - back up now so in this case right here
34:43 - is my mean value so I could say my mean
34:46 - value here is 8 and then what I really
34:49 - want to look for is the Sigma because
34:51 - that's where standard deviation kind of
34:53 - lives and it is 3.1 or 3.0 9 8 this
34:58 - whole thing so I might say just like I
35:04 - found before but the nice thing is it
35:06 - gives you all the information one little
35:08 - setup very convenient it tells you the
35:10 - number of terms in the series and if you
35:12 - need to do some sort of quartile
35:13 - analysis it tells you all that
35:15 - information so that's good yeah go ahead
35:18 - and use how it goes it also in this case
35:21 - sort of gives you the sum of the numbers
35:25 - it'll tell you the sum of the numbers
35:26 - squared in case you need to know that
35:28 - the whole thing kind of the world is
35:30 - your oyster in a way I guess so
35:32 - but standard deviation is what you're
35:34 - looking for here just pull the Sigma
35:37 - term and you're fine
35:38 - in this video going to talk about the
35:40 - idea of frequency tables and histograms
35:42 - basically a frequency table is when you
35:46 - first off you want to take a set of
35:48 - numbers and so you want to have data and
35:50 - you want to break and enter intervals
35:51 - which are basically even sized groups
35:57 - evenly sized groups
36:05 - if I were to do say one through twelve
36:10 - or something I may say how many numbers
36:12 - in that group fall between 1 and 3 and
36:14 - then 4 and 6 and then 7 and 9 and then
36:18 - maybe 10 and 12 so those would be my
36:22 - intervals I'm breaking it into groups of
36:24 - equal size in in most cases they're even
36:28 - occasionally they're not but that's what
36:29 - how it works
36:30 - frequency is how often or how many times
36:34 - a number falls into that group so the
36:41 - number of data points
36:49 - in each interval
36:55 - so maybe I have six of them that fall
36:59 - between one and three I have five here
37:01 - four here and two here and then a
37:05 - frequency table it's just a way to
37:07 - visualize that information so it groups
37:11 - them in intervals and then shows the
37:13 - value for each interval so it's like a
37:16 - it's a table that displays the intervals
37:30 - and the corresponding
37:40 - frequencies
37:45 - basically
37:48 - this if I put what each thing is so
37:52 - frequency and then I'm just going to do
37:58 - a generic title here so generic I don't
38:01 - know what 1 and 3 equal is just making
38:04 - it up in my head so whatever it happens
38:06 - to be able to leave it blank actually so
38:09 - the other section should tell you the
38:11 - frequency so basically this setup right
38:13 - here is a nice frequency table a
38:15 - histogram is just a graphical
38:17 - representation
38:28 - of
38:30 - a frequency table
38:39 - now a histogram comes in three basic
38:43 - looks the first would be uniform and I'm
38:54 - just gonna draw it but out in when I get
38:56 - to the question part I'll actually
38:57 - explain how to make it look so the first
39:01 - one is when you have a uniform is when
39:05 - they basically are all the same height
39:07 - they can be a little bit off but for the
39:10 - most part pretty much the same height
39:15 - all the way through the sections
39:22 - that's my histogram in this uniform so
39:24 - uniform same and we're talking about the
39:28 - height specifically the frequencies but
39:30 - whatever the next type would be skewed
39:43 - skewed histograms would be off to one
39:45 - side
39:53 - have a whole bunch of stuff up here
39:59 - but as it goes it tends to sort of move
40:04 - out I'll even have a little buffer there
40:05 - but still for the most part a lot of its
40:09 - over here and the last type would be
40:11 - symmetric
40:20 - symmetric sort of looks like a building
40:22 - or a normal distribution if you know
40:26 - what that means you tend to have one big
40:28 - part in the middle and then the sides
40:34 - are pretty close and then it just sort
40:36 - of goes down so essentially you have a
40:44 - axis of symmetry you can break it in
40:46 - half I could fold one part over the
40:48 - other it doesn't have to be exact it
40:49 - just has to have the general idea that
40:51 - it is symmetric so you're looking for
40:54 - sort of a line of symmetry or you can
41:02 - fold it over so that's enough of that
41:07 - let's do some
41:10 - so the first one says the number of
41:12 - eagles observed along a certain River
41:14 - per day over two-week period is listed
41:15 - below make a frequency table that
41:18 - represents the data so I'm gonna look
41:20 - and I see that the numbers go from about
41:22 - one to eighteen a reasonable number of
41:25 - groups probably there would be let's say
41:28 - I don't know five groups maybe or we
41:32 - could do six so if I wanted to do six
41:35 - I'd do
41:36 - groups of one two three four to six
41:42 - seven to nine ten to twelve thirteen to
41:51 - fifteen and sixteen to eighteen if you
41:57 - spread them out too much you're not
41:59 - really gonna get a good feel for it so
42:01 - it's sort of sometimes it's a little
42:02 - trial and error about how many things
42:04 - fall into it so I need to find oh it
42:06 - goes from zero I'm sorry so zero to
42:08 - three so which spreads that one out
42:11 - makes it a little bit uneven but you
42:12 - know that's okay so what I'm going to do
42:15 - is look to see how many fall in that
42:16 - group so there's one two three four that
42:22 - fall in that group four to six
42:27 - one two seven two nine eight nine seven
42:34 - so there's three there 10 to 12 I've got
42:37 - one two of those 13 to 15 I've got one
42:42 - two of those and 16 to 18 I've got one
42:46 - so that's my frequency table it
42:48 - represents the data relatively well if I
42:51 - wanted to combine groups together like
42:52 - maybe I did zero to six and then I did
42:58 - seven to twelve and then 13 to 18 if
43:06 - that's the case I would do six for this
43:11 - one five for this one and three for this
43:17 - one now depending on what I'm trying to
43:18 - figure out either one of those is a good
43:20 - frequency table it just depends on what
43:22 - the overall outcome is supposed to be
43:24 - the first one gives me much more
43:26 - detailed information in terms of I can
43:29 - get very specific I mean you could go
43:31 - down to I guess one in each interval but
43:32 - that would seem kind of silly
43:34 - but I could get I could see that the
43:36 - number of times an eagle has been
43:37 - observed zero to three is definitely the
43:39 - biggest one whereas it doesn't seem as
43:42 - between zero and six like seeing an
43:44 - eagle six times is kind of a major
43:48 - difference between seeing it you know
43:50 - six times and zero times or whatever it
43:52 - happens to be so I would probably use
43:54 - this one just because it gives you more
43:55 - information
43:56 - that's detailed you know whatever the
43:59 - last one also the second one also makes
44:01 - it seem like the 16 to 18 group would
44:03 - pop up more often than it probably would
44:05 - so that's that one number two the data
44:08 - show below shows the number of games won
44:10 - by a football team in each of the last
44:11 - 15 season I need to make a histogram so
44:14 - to make a histogram you have to start
44:16 - out making a frequency table because
44:18 - they're you know very closely related
44:22 - ones just another version of the second
44:25 - actually I might do the data below shows
44:28 - the average number of text messages a
44:29 - day that would make more sense just
44:31 - because it gives me a room to work it so
44:33 - I have
44:35 - this is text per day and then my
44:43 - frequency
44:48 - and here I have it going up to 22 and my
44:53 - lowest group is one so somebody's only
44:56 - doing one so I might do groups of 5 so 0
45:02 - 2 4 5 to 9
45:12 - 10 to 14
45:21 - 15 to 19 and then 20 to 24 I should get
45:27 - everything covered
45:32 - now I just count them make sure you mark
45:35 - them out so you can see what you're
45:36 - doing one there is between zero and four
45:39 - and that's it not a lot of low-level
45:41 - textures here between 5 & 9 I have 1 2 3
45:47 - 4 5 between 10 and 14 1 2 3 and that's
45:59 - it
46:00 - you'll notice I'm trying to use
46:01 - different symbols each time that way I
46:03 - can go back and assess how I got my
46:06 - answer just in case I need to check 15
46:08 - to 19 1 2 3 and the last one twenty two
46:18 - twenty four one two and that's it it's
46:22 - also a good idea by the way to check to
46:23 - make sure you have this bright number of
46:25 - frequencies in your table to determine
46:28 - that you've gotten them all 1 2 3 4 5 6
46:31 - 7 8 9 10 11 12 13 14 so 6 7 8 9 10 11 12
46:38 - 13 14 so that works that's my frequency
46:40 - table now for a histogram I'm just going
46:42 - to on the bottom put text messages
46:50 - and over here I'm going to put frequency
46:53 - so on my y-axis so maybe 1 2 3 4 5
47:07 - sorry for writing frequency so small I
47:08 - come to running out of room now it might
47:10 - 0 to 4 group I only have 1 so that's
47:17 - that in my 5 to 9 group I have five so
47:22 - there's mostly 5 to 9 would be the most
47:25 - common number of text messages sent in
47:28 - our sub in our little group that we've
47:30 - created and then I'll do 10 to 14 and
47:32 - they're at 3 and then 15 to 19
47:42 - they're at three as well and then
47:46 - finally 22 24 it only has two so that's
47:56 - my histogram basically just set the
47:58 - boxes and each one of them represents
48:00 - one section of the frequency table it
48:02 - also gives me a nice visual I can see
48:04 - that this one here really doesn't like
48:08 - the zero for group is very small it's
48:10 - easier to just have it there and it sort
48:13 - of gives me the idea that it tends to
48:15 - sort of you know skew out this way a
48:17 - little bit more so than it it hits a big
48:21 - high point at five to nine but it skews
48:24 - higher than it does lower which means it
48:26 - spreads out that way a little bit better
48:28 - so that's frequency tables and
48:30 - histograms I'm gonna see if there's any
48:32 - more things I need to cover I don't
48:33 - think so oh no we're gonna look at types
48:36 - really quickly so we talked about the
48:39 - three types uniform skewed versus
48:40 - symmetric this one has a little bit
48:46 - sorry I don't know I rolled down so much
48:48 - this one has a little bit of skew to it
48:50 - as you can see it sort of fades off to
48:52 - the right so it goes this way
48:55 - it's positively skewed a little bit so
48:58 - that's that one and for number five
49:02 - which is another type this is a perfect
49:07 - example or not a perfect example at a
49:08 - very good example of a uniform histogram
49:12 - just because this was the uniform
49:15 - histogram I'm sorry this is a perfect
49:18 - example of uniform Instagram I'm looking
49:19 - at another thing while I'm doing this my
49:21 - apologies I've been doing this a long
49:22 - time today anyway the uniform amount
49:25 - because it's the same you wear a uniform
49:26 - looks exactly the same as everybody
49:28 - else's so that's no it's uniform this
49:29 - one is symmetric my bad
49:31 - so yeah it sort of fades down a little
49:34 - bit any sort of like dual sided
49:36 - Christian descent is sort of the way
49:39 - that you want to go to make sure that
49:40 - you have a skewed or sorry symmetric
49:43 - representation of your histogram so
49:46 - that's it frequency tables histograms
49:48 - not that big of a deal I'm sure you'll
49:50 - do fine
49:51 - this vide I'm going to talk about the
49:53 - idea of sampling and surveys as a way to
49:55 - collect information to make decisions
49:57 - the first thing that when you talk about
49:59 - is the idea of population versus sample
50:02 - a population represents all members of a
50:11 - set
50:14 - so if you're gonna do a population of
50:18 - people who live in the United States you
50:20 - have to deal with every single American
50:22 - has to be involved in whatever you're
50:24 - doing to get the total population of the
50:26 - United people in the United States now
50:28 - that's usually impossible to get
50:31 - everybody to do in your set unless your
50:33 - set is extremely small you can't get the
50:35 - population so instead you want to go
50:38 - with a sample instead a sample is part
50:41 - of that population
50:53 - so if I was dealing with the idea of
50:56 - here's my population a sample would just
51:07 - be part of it that's how they get
51:10 - polling data and stuff when they ask
51:12 - about political opinions like
51:14 - seventy-five percent of Democrats say
51:15 - this well obviously they don't go and
51:17 - ask everybody who's a Democrat to say
51:19 - what they believe or Republicans either
51:21 - what they do is take a random number or
51:24 - are they picking a number of people and
51:25 - try to assess them maybe random I say
51:29 - random because I assume they're doing
51:31 - things in the best interest of the study
51:33 - but many cases they're probably not so
51:35 - they pick a group of them maybe at 50 or
51:37 - 25 or 100 or whatever and then they
51:40 - garner information about the overall
51:43 - belief system based on that sample
51:44 - that's how that's what they're doing so
51:47 - the real goal is to try to pick a sample
51:49 - that's representative of your population
51:51 - if you don't it becomes a problem that's
51:54 - called this process is called sampling
51:56 - there's a few different ways that you
51:58 - can do it some of them are listed here
52:00 - the first is a convenient sample a
52:03 - convenient sample is one is easily
52:08 - accessible
52:11 - so if I wanted to pull somebody who were
52:15 - like I wanted to pull Democrats about
52:18 - something I might pull only local
52:20 - Democrats because I know where the local
52:22 - Democratic office is so it's easy for me
52:24 - or the headquarters or whatever it's
52:25 - easy for me to go down there and just
52:26 - ask people now that might not give a
52:30 - realistic view of how Democrats think
52:32 - because I live in one area and Democrats
52:34 - here may be different than Democrats in
52:35 - other parts of the country but it's an
52:37 - easily accessible sample so I guess
52:40 - that's good enough but not really the
52:42 - next step would be looking at self
52:45 - selected samples self selected is a nice
52:48 - way of saying volunteer I ask people who
52:52 - are interested to give information that
52:54 - is not exactly the best way to get
52:58 - unbiased information in your set just
53:00 - because you're getting people who are
53:02 - passionate about it if you only ask
53:05 - people who vote to volunteer to do it
53:07 - you're basically getting people who care
53:08 - a lot about it in one way or the other
53:10 - so they're you know they have a true
53:12 - opinion they're not people who won't be
53:14 - affected by it or whatever a systematic
53:17 - sample is a little bit more realistic it
53:23 - has less bias in it in this case you
53:25 - want to order the population
53:34 - and then you want to pick people at
53:37 - random intervals
53:51 - like if there's an elementary school and
53:54 - they need to assess something about
53:56 - field-day or whatever it would be
53:58 - ridiculous for them to go and the
54:00 - teacher who's assigned the activity to
54:03 - to do the survey just picks people from
54:06 - their class because it's convenient
54:07 - you're only getting maybe he or she's a
54:09 - fifth grade teacher
54:10 - you only get 5th grade kid information
54:12 - that doesn't help you a self-selected
54:14 - sample is hey who wants to fill out this
54:16 - survey about field-day well some people
54:18 - who may be really interested in field
54:19 - they just don't feel like it or don't
54:21 - like the survey or whatever so they just
54:23 - don't do it you have to go online and
54:24 - they're trying to do other stuff
54:25 - whatever it happens to be a systematic
54:27 - sample would probably split the school
54:30 - which it already is in two classes so
54:32 - you make sure that some people from
54:34 - every grades and then you have an
54:35 - interval system to choose like maybe you
54:37 - go down the roster and you choose every
54:40 - third person until you get to six
54:43 - respondents which means you could
54:44 - potentially get some but you get the
54:45 - third person you get the sixth person
54:47 - the ninth person but then if the class
54:50 - only has 15 in it or whatever then it'll
54:53 - cycle back around says a chance you'll
54:55 - get the people who you missed before so
54:57 - that's a systematic sample you've
55:00 - organized it you've organized the
55:01 - population and then you use an interval
55:03 - to pick people or maybe randomly like
55:05 - you have them pick six people or
55:08 - whatever it happens to be the other type
55:10 - is random sample and this is where all
55:14 - members
55:19 - of a population
55:24 - are equally as likely
55:34 - to be chosen
55:43 - now countrywide sort of random sample is
55:46 - very unlikely you're gonna pick from
55:48 - certain things I mean you can't get
55:50 - everybody but if we're our school
55:51 - scenario for instance if you just put
55:53 - all the kids names in no matter what
55:56 - grade they're in all in and you pick 50
55:58 - of them out and you shake it up each
56:00 - time and whatever it's a random sample
56:02 - so it's possible to do it if the
56:04 - population is small enough and make it
56:06 - legitimate so those are the sampling
56:08 - type so convenience it's just easy for
56:10 - the person who's doing it so the person
56:13 - who's sampling it's simple for them self
56:16 - select good sample means that they
56:17 - volunteered systematic sample means you
56:20 - order the population in some way and
56:22 - then you use random intervals to pick
56:23 - them and then a random sample with
56:25 - everybody has the same amount of
56:27 - likelihood to be picked for the survey
56:30 - as anybody or for your sample group as
56:32 - anybody else from there we're going to
56:35 - look at sampling bias for just a second
56:37 - to determine whether these situations
56:39 - introduce bias in the sampling process
56:41 - bias would be that certain groups of
56:44 - people will be chosen over others in the
56:46 - first one it says a newspaper article
56:48 - about property taxes asked readers to
56:50 - call the newspaper to express their
56:52 - their opinions so in this case what
56:55 - you're really dealing with of course is
56:56 - a self selected sample
57:09 - not symbol sample and this is a bias
57:14 - method because you basically get the
57:22 - passionate people
57:29 - do the passionate nature
57:34 - of the respondents only people who care
57:37 - about it deeply are gonna call in it's
57:41 - like radio shows with Collins they pay
57:43 - usually have to have reasonably large
57:45 - groups of people listening to them
57:47 - because like for every 15 or 20 people
57:50 - or something you may get one caller so
57:52 - it's one of those things about it this
57:54 - is a self-selected sample self-selected
57:56 - samples are generally biased the next
57:58 - one says our reporter interviews sorry
58:01 - people attending a local sporting event
58:04 - well this is a convenience sample and
58:11 - this is bias because there's a little
58:16 - bit more homogeneous feel to how it goes
58:21 - you're basically gonna get sports fans
58:27 - one of the things in the local system
58:30 - that I'm working in is they want to put
58:31 - turf out on the field well if you go to
58:33 - a football game and ask the people who
58:35 - go to the game a lot of them will say
58:37 - that they really support the idea of
58:39 - having turf but if you go you know to
58:41 - the library or something they may say
58:44 - well couldn't that money be spent on
58:45 - books or whatever it happens to be so in
58:48 - that case you're adding bias into the
58:51 - situation by picking like-minded
58:52 - individuals people who'd spend Friday
58:54 - night at a sporting event or whatever
58:55 - and the last one says a political
58:57 - polling company calls every 30th person
59:00 - in the phonebook so basically they take
59:02 - the entire phone book and they call the
59:05 - 30th person each time this is a
59:08 - systematic sample
59:13 - because there's a system in place
59:14 - anytime it says every 30th person or
59:17 - whatever it generally means that it's a
59:22 - the the its systematic I'm sorry
59:25 - now is there bias in it possibly
59:35 - depends on what they're asking if
59:37 - they're asking about phone service then
59:39 - it may be different because some people
59:40 - aren't listed in the phone book anyway
59:42 - that's back years ago it might have been
59:45 - different and even then you're basically
59:47 - getting a certain subset of people who
59:49 - are in the phonebook so if you pool the
59:51 - xxx is it as biased as going to sports
59:53 - fans and asking them about turf no
59:55 - obviously not but there is a possible
59:58 - bias there the newspaper article asking
60:00 - for a self-selected trying to create a
60:02 - self select a sample it's much more
60:04 - biased but there is possible bias in the
60:06 - idea that you'd pick people out of a
60:07 - phone book because some people are
60:09 - unlisted and you know some people only
60:11 - have cell phones and they don't list
60:12 - themselves in a phone book that kind of
60:14 - thing so depending on the phone book
60:16 - depending on the question there is a
60:17 - possible bias in place so that's the
60:19 - kind of stuff that you have to consider
60:21 - when you sample a group and the last
60:24 - section is that I want to talk about is
60:26 - the idea of completing a study what
60:28 - types of studies are there and the three
60:30 - I'm going to talk about our
60:30 - observational studies controlled
60:34 - experiments and surveys now
60:36 - observational studies are studies where
60:40 - the study is done
60:49 - in a way
60:53 - that does not
60:59 - effect
61:09 - the sample group
61:16 - so an observational study is just kind
61:18 - of where you watch what was gonna happen
61:19 - anyway you're not affecting it or not
61:21 - changing anything you're just sort of
61:23 - observing what's going on in the regular
61:26 - scenario that's there the next type
61:28 - would be a controlled experiment in this
61:31 - group you have two groups you have the
61:33 - control group and the control group is
61:40 - the group that you just keep normal it
61:45 - doesn't change or anything on the other
61:47 - side of it you have the experimental
61:48 - group
61:58 - the experimental group is the one that
61:59 - you actually imposed treatment so you
62:05 - actually do something to them whatever
62:08 - it happens to be and the control group
62:12 - just stays the same so they're the
62:14 - status-quo group the nice thing about
62:18 - the control experiment is that you have
62:23 - some idea that what you're doing has an
62:25 - effect outside of anything else like you
62:27 - can see that that specific change
62:30 - affected the people in the control in
62:33 - the experimental group versus the
62:34 - control group but you know it's not
62:37 - always the best way to do it and there
62:38 - are certain things you can't do there
62:40 - are certain rules about whether you're
62:41 - legally allowed to effect one group and
62:44 - not affect another and it just sort of
62:46 - depends on the scenario and the last one
62:48 - would be a survey the survey is when you
62:50 - ask all members of a sample set
63:04 - some questions
63:09 - so in the first case you're just
63:11 - observing what they're doing and the
63:12 - second you're splitting them into two
63:13 - groups applying a treatment to
63:15 - experimental group and seeing if they're
63:17 - affected if their lives change in some
63:20 - way compared to the control group which
63:21 - is the status quo and doesn't change
63:23 - it's like you were never even involved
63:25 - and the last one is a survey where you
63:27 - basically just ask all the members of
63:28 - your sample set some questions now you
63:31 - can add bias in the survey questions but
63:34 - I'll have a different video on that in
63:35 - the future so that's it completing a
63:38 - study sampling a set and looking for
63:41 - bias in that sample set in this video
63:46 - we're gonna talk about bias and survey
63:48 - questions a survey of course is when you
63:50 - ask every single member of a sample set
63:53 - so like your entire school for instance
63:54 - a set of questions the problem is the
63:56 - questions that you ask them specifically
63:58 - the way you ask them in the wording
64:00 - could affect how they answer so what
64:03 - you're trying to do is not introduce
64:04 - bias into the equation biases when you
64:07 - make the decision go one way or the
64:09 - other even if it's unintentional so I
64:11 - don't like your you're pushing the
64:12 - agenda whether you mean to not the first
64:15 - thing that you don't want to do is
64:16 - combine two or more issues so for
64:19 - instance if I was doing a little
64:21 - informal informal survey or I was doing
64:24 - a formal survey and I said should school
64:27 - days be shorter and start earlier well
64:35 - in some ways people I could get some
64:37 - support for this because a lot of people
64:38 - want school days to be shorter students
64:42 - mostly in teachers people who actually
64:45 - have to do it one of the days to be
64:46 - shorter but to start earlier earlier
64:49 - part doesn't really sell where I go to
64:51 - school or where I work right now school
64:53 - starts at 7:30 in the morning so let's
64:56 - just say for instance I saw this
64:58 - question and I wasn't really sure what
65:00 - it meant all of a sudden that kind of
65:02 - ambiguity makes the bias start to be eat
65:05 - into the equation let's just say maybe
65:08 - that means that school days will start
65:09 - at 6:30 in the morning and there'll be
65:11 - fifteen minutes shorter so instead of
65:13 - getting out at 2:30 like the school does
65:15 - now it gets out at 1:15 because we but
65:18 - we go an hour earlier which would
65:20 - normally the norm
65:21 - the length of the school day would make
65:22 - us leave at 1:30 when we get out of 1:15
65:24 - so 15 minutes less of school I only have
65:26 - to get here an hour earlier
65:28 - that would be perfect for somebody who
65:29 - really likes afternoon but not anybody
65:33 - else so once I entered two components
65:35 - into the equation it added bias to it so
65:38 - it's not a good survey question from
65:40 - there we may deal with using double
65:44 - negatives I you know don't you or do you
65:50 - not disagree that kind of thing anytime
65:51 - you use double negatives you're starting
65:53 - to add sort of murkiness into the
65:56 - question process and people may choose
65:58 - the wrong thing and something that they
65:59 - don't mean overlapping answer choices
66:02 - overlapping answer choices are much like
66:04 - combining two or more issues in your
66:05 - question if you give them choices and
66:07 - all of a sudden two things are involved
66:11 - in your answer and it's sort of like
66:12 - well I'm answering this but not this and
66:14 - that whole thing that's when the
66:16 - overlapping answer choices become a
66:18 - problem you want to keep answer choices
66:20 - as separate as you constantly can I mean
66:23 - they can have certain components that
66:24 - are the same but you don't want to have
66:26 - them seem like well like the earlier
66:29 - start time question before I didn't want
66:31 - one of the choices to be like start
66:33 - earlier and be 15 minutes shorter and
66:36 - then you have start earlier and be
66:38 - shorter it's sort of confusing about
66:41 - what does that mean you know they're
66:43 - almost the same thing so you want to
66:45 - make sure that they're as separate as
66:46 - possible using loaded words as a big
66:48 - deal it's really how a lot of people who
66:52 - do surveys gain the information that
66:54 - they want to get even before they start
66:55 - things like for instance in the abortion
66:59 - debate if you use pro-choice or you use
67:02 - pro-life those are both positive words
67:06 - depending on what side of the argument
67:08 - that you're on if you use the word
67:10 - poison as opposed to pesticide that
67:12 - should be a problem any time you start
67:14 - using adjectives generally it becomes a
67:17 - problem if you call a book would you
67:20 - rather watch an exciting movie or read a
67:22 - boring book once you add those loaded
67:24 - words into the equation you're pushing
67:26 - the mindset already so you don't want to
67:29 - do that and then asking a leading
67:31 - question you don't want to ask questions
67:33 - where you say sort of like don't you
67:34 - agree
67:35 - with this or wouldn't you say that this
67:38 - is true or blah blah blah once you start
67:40 - already assuming that they agree with
67:43 - you then the questions become you know
67:45 - kind of a big problem the thing you
67:47 - don't want to do is have don't you agree
67:50 - that teachers are underpaid or don't you
67:52 - agree that teachers can pay too much
67:53 - whatever it happens to be once you start
67:55 - pushing that agenda into the equation it
67:58 - becomes a problem so long story short in
68:01 - your question you should only focus on
68:02 - one thing at a time your answer should
68:04 - be very specifically answering one thing
68:07 - at a time you don't want to use double
68:09 - negatives and you never use loaded words
68:12 - so don't use anything that's sort of
68:15 - show of bias in the question don't like
68:18 - presuppose things and which would be the
68:21 - last one sorry ask leading questions you
68:24 - don't want to ask questions that already
68:26 - sort of assume they agree with whatever
68:28 - you're saying and then they had to
68:30 - disagree because it sort of changes the
68:32 - mode they're not giving a choice anymore
68:33 - they're doing a yes/no based on your
68:35 - assumption that they believe something
68:37 - to be true so that's it in order to
68:39 - avoid bias and survey questions avoid
68:42 - those five things and then you should be
68:43 - making a reasonable survey question in
68:47 - this video I'm going to talk about
68:48 - looking at data in terms of it being
68:50 - considered quote/unquote normally
68:53 - distributed
68:53 - let's look before I even get to that
68:56 - let's look at the idea of what types of
68:58 - maybe various types of distributions
69:02 - that you would see just the most generic
69:04 - ones of course so a normal distribution
69:07 - most of the day like here's the mean
69:09 - value so most of it sort of flows around
69:11 - the mean in you know a pretty even
69:14 - fashion even though that doesn't look
69:16 - like the greatest job ever so if I
69:20 - delete if I get sort of racist around so
69:23 - most of the data tends to fall within
69:24 - the mean pretty close the further you
69:27 - get away from the mean in terms of
69:28 - standard deviations away it the number
69:31 - of data points significantly fall the
69:34 - other options that you could have I mean
69:36 - there's a bunch of them but most likely
69:39 - you could deal with
69:41 - a distribution that's sort of skewed
69:47 - positively so sorry skewed negatively
69:59 - and it's because the mean would seem to
70:02 - go here but you've got these negatives
70:04 - that flow out so that makes it a
70:05 - negatively skewed data set or you of
70:09 - course you could have the opposite of
70:12 - that where you end up with sort of a
70:17 - skew to the positive so this is
70:23 - positively skewed data which means that
70:26 - there's a few points that are really
70:28 - positive that are sort of pulling up the
70:30 - overall set now but what we're talking
70:32 - about is normal distribution now think
70:36 - about normal distribution is it's used
70:37 - in a variety of cases one of them being
70:40 - IQ we also tend to look at it really any
70:45 - metrics tends to a lot of metrics tend
70:47 - to fall their height and you know weight
70:50 - and that whole thing but what we want to
70:52 - look at here is just what percentage is
70:55 - fallen that's the nice thing about
70:56 - normal distribution I can get an
70:57 - analysis of what percentages of the data
71:00 - fall into each one of these groups now
71:02 - at the bottom you'll see they use this
71:05 - term for this little symbol for the mean
71:08 - value but I'm gonna change it to this
71:12 - that's the mean value in the middle so
71:15 - most of the data tends to fall generally
71:17 - there this would be one standard
71:19 - deviation two standard deviations and
71:24 - even three standard deviations below on
71:30 - the other end you'll have one two and
71:33 - three standard deviations above now for
71:38 - each section one standard deviation
71:40 - below and one standard deviation above
71:42 - the normal distribution or m'l
71:47 - distribution curve it'll be something
71:49 - like 34 percent of the data will fall in
71:54 - each one of these segments
71:59 - so the percentage of data between one
72:03 - standard deviation of below to one
72:07 - standard deviation above is 68 percent
72:11 - or so of the data which is a lot so a
72:15 - lot of it falls with one standard
72:17 - deviation away by the way this for IQ
72:20 - for instance my mean value would be a
72:24 - hundred of course that's how this set up
72:27 - with the standard deviation of about 15
72:30 - so if we're going to do an IQ analysis
72:33 - here we'd say a hundred is the IQ at
72:35 - this point this is about eighty-five
72:38 - this is an IQ of 115 to up would be 130
72:49 - and then three standard deviations above
72:51 - the mean you're looking at something
72:52 - like 145 each one of these to school
73:00 - officials and you know other people who
73:01 - are in intellectual analysis and that
73:04 - sort of thing each one of these numbers
73:06 - tends to stand for something of
73:08 - importance in fact we identify
73:11 - intellectual or cognitive disabilities
73:14 - at that seventy IQ and below tends to be
73:17 - two that's why they picked that number
73:18 - because it's two standard deviations
73:20 - below a lot of gifted programming starts
73:23 - somewhere around 120 so it's somewhere
73:26 - between 115 and 130 depending on the
73:29 - state I mean that's just where people
73:31 - tend to qualify for so those sorts of
73:33 - things anyway moving forward let's look
73:36 - at how much is between what percentage
73:38 - of the data falls between 85 and 70 ways
73:41 - you can see like these sets that's a lot
73:44 - of data that's going on whereas here not
73:47 - as much because the 70 is a lot less
73:49 - data than would fall in in terms of a
73:52 - percentage then when fall between the at
73:55 - 85 so what we're looking at here is a
73:58 - number somewhere around 13
74:03 - and a half percent on each one of those
74:07 - sections so if I was going to go back to
74:14 - my analysis of how much data falls where
74:19 - if I wanted to know from two standard
74:23 - deviations below the mean to two
74:27 - standard deviations above the mean in
74:29 - that case I want to add 13.5 plus 34
74:36 - plus 34 plus 13.5 because all those
74:41 - sections are covered it's easy to fall
74:43 - for the idea that you just add the 13.5
74:45 - together but that's you also have to
74:47 - consider that 34 are there and this
74:52 - number ends up being something around
74:55 - 95% so it's really common to see these
75:03 - figures sort of pull made known to
75:08 - people so we could say that two standard
75:09 - deviations above or below the mean
75:11 - you're looking 95% of all the data so in
75:14 - an IQ sense that means that all IQ are
75:16 - 95 percent of IQs fall somewhere 70 and
75:20 - above all the way up to 130 and below
75:22 - that's kind of where that number is now
75:24 - the different the percentage of data
75:26 - that falls between two and three
75:28 - standard deviations is even
75:30 - significantly smaller than it is between
75:32 - one and two at that point you're looking
75:34 - at something around two point I'm gonna
75:38 - try to get a different color so it's
75:40 - relatively obvious that where I'm going
75:42 - with it so the difference here would be
75:44 - two
75:48 - Oh point three five percent that's just
75:54 - between here and here so two point three
75:59 - five percent here as well so to get the
76:02 - different the distance between three
76:05 - standard deviations below and three
76:09 - standard deviations above you're looking
76:13 - at adding the sixty-eight that we had
76:16 - before the thirteen point five twice
76:21 - would be twenty seven and then you want
76:25 - to add two point three five plus two
76:30 - point three five so
76:38 - ninety nine point seven percent of all
76:44 - data falls within 3 / 3 standard
76:47 - deviations above or below the mean value
76:49 - in a normal distribution so you can
76:51 - really start to get the idea of you know
76:55 - how closely packed the data is in terms
76:58 - of what huge percentages it would be for
77:01 - one standard deviation out if I were to
77:03 - sort of chart it I guess I would say
77:18 - this
77:20 - to
77:27 - and three
77:39 - so that's a lot so what does it all mean
77:42 - really the big issue is that you need to
77:44 - consider how much data it is recognized
77:49 - up to a certain point like if I wanted
77:51 - to know what percentage falls below
77:54 - three standard deviations below the mean
77:56 - so less than so X values less than three
78:09 - standard deviations below so what I need
78:11 - to do is take all of the data that's
78:13 - above that number and just subtract it
78:15 - well I know that all the data that falls
78:19 - between here and here would be
78:22 - ninety-nine point seven so I'm gonna
78:24 - take a hundred percent and I'm gonna
78:27 - subtract ninety-nine point seven percent
78:31 - and I'm gonna end up with our sorry 99.7
78:35 - I need to hit the percent I'm going to
78:36 - end up with zero point three now that's
78:39 - the distance of all numbers that are
78:41 - outside three standard deviations so I
78:42 - need to break it into two parts because
78:44 - I just want less than so I divide by two
78:47 - and end up with 0.15 so something like
78:51 - 0.15 percent of all data falls below
78:57 - three standard deviations and sometimes
78:59 - you have to do you know I want to know
79:01 - how much is above two standard
79:05 - deviations below so there's a you know
79:06 - there's a couple ways I could do it I
79:07 - could add at this point by the way
79:10 - you're looking at 50 percent over here
79:13 - and 50 percent over here so what might
79:15 - be advantageous to do if I was looking
79:18 - for two below would just be to take 50
79:20 - percent which would be all of this on
79:22 - the positive side and then add 34
79:25 - percent and then 13.5 percent so if I
79:28 - wanted to know how much data was above
79:30 - two standard deviations below the mean
79:32 - all I would do is add 34 plus 50 plus
79:35 - 13.5 and find out that 97 and a half
79:38 - percent of all data is there so be
79:40 - careful about what the question asks you
79:42 - if it's asking you about a subset that's
79:45 - less than something you need to probably
79:47 - do you might have to do a division
79:49 - because they're broken up into groups
79:51 - represented in that
79:52 - if they want to know just a little bit
79:54 - more than half remember that it's easier
79:55 - just to break it at the mean and do 50%
79:58 - above just to make the calculations a
80:01 - little bit easier so that's normal
80:03 - distribution set up in a way that I hope
80:06 - is useful to you it's probably a good
80:08 - idea to have some charts somewhere with
80:10 - the percentages because sometimes it's a
80:13 - little difficult to remember them all
80:14 - and there's a little bit of a the
80:17 - sixty-eight percent thing there's
80:19 - sometimes you'll see it is like the 67
80:22 - arrangement just adjust for your needs
80:25 - specifically

Cleaned transcript:

this video I talk about analyzing data specifically I'm gonna talk about mean median and mode so when I have this is considered to be by the way one variable statistics or I only have there's not it's not a sort of graphing relationship for you have an X Y you just have single numbers that you're working with so the most common way these are called measures of central tendency I'll throw that in the corner over here central tendency because you're saying something about where the middle of the number is or what happens a lot or that sort of thing so all that's in play here I'm getting lazy on my handwriting late at least I'm trying to fix it so anyway mean median mode those are the big ones that you use deal with there's also range by the way range in the case of one variable statistics II how far how spread out the data is the biggest minus the smallest that's or so and when that what that said it's probably a good idea that we organize the numbers numerically first if we put them in numerical order it makes a lot more sense my suggestion is if you do it by hand once you write a number down mark it out so I look and I see that three is the smallest number and then there's another three so I'm going to put three again and then there's four so that's out another four and another four then I need to put six seven and this is one of those areas where not getting sloppy is in your best interest because if you scribble it on paper and you lose stuff that's when you start to get these wrong so there's my number in like a nice numeric fashion so when I'm dealing with mean it's the only one that doesn't have like a little code word that tends to go with it median you tend to code word middle mode you might say most mean average really some people have gone really far and said like you know you're mean teacher averages your low test grades together that sort of thing I don't really get in on that party but it is what it is anyway so really what you're dealing with is the sum of the values so add them all up and then you want to just divide by how many there are so the number of values so you might say something like som over how many that tends to be the the short version of that so if I did 3 plus 3 plus 4 plus 4 plus 4 plus 6 plus 7 plus 8 plus 10 plus 11 and my suggestion is if you're typing it in this way in a calculator you just make sure that you have everything the way that you want it so go back through and look at them and it supposed to be a 10 go back through and look at them and make sure everyone's there you should probably count the numbers I know there are 1 2 3 4 5 6 7 8 9 10 of them which is helpful for the denominator anyway because the number of I use is 10 that works so I can just go like into my calculator to make sure I have 10 numbers there and they're the right ones so I end up with a total value on in the numerator of so I'm gonna have to make a little space for myself messed that one up dinging myself enough room so anyway I end up with a numerator value of 60 over 10 so my mean value is 6 right there that's how that set up sort of sort of works now the median number would be the middle I hope something to do that in blue there we go so the median number would just be the middle so what I need to do is put them out all the numbers so write them here you don't have to rewrite them you can just use the original version if you don't have to be able to see them very well and then I tend to start at the left side and Mark it out with like a slash down into the left and then I'll go the other direction for the second one just so I know that I'm where I am if I kind of lose my place then I'll go back to the original direction then in in this case I have two middle numbers so what I need to do if you just have one that's your median if you break it down into an odd number so say there's nine will it'll be one in the middle and that's your median value in this case I have two of them so I just need to find the middle number I mean it's five but you know you can add them up and divide by two and you get a median value of five that's how that works and the mode is just the one that happens the most so you sort of if I were to do a little mini frequency chart and you definitely don't have to do a frequency chart with this I'm just doing it for my own benefit so for three there's two of them for four there's three of them for six there's one all the rest just have one so the one that happens the most is four so my mode is four if I had another three in there or one less four you can have multiple modes or it could be what's called bimodal or you can have no mode at all if all the numbers are different you just say no mode if it has two modes you just say you know you just name which modes they are so four and three that sort of thing that's the gist of how it all goes in terms of the difference between the mean and the median you'll see that the mean value is actually greater than the median value in this case well if we look at the numbers that sort of makes sense because you you lose a lot of capital in the median setup because the first five numbers are just the same two numbers and they're very close together and they won't be but the 11 and the 10 which are much bigger in the second set will stretch that mean value out a little bit so sometimes you have to tell which one is the better and now which one better analyzes the data median will always tell you the middle but it doesn't necessarily like if I was going to get an idea of what kind of test scores my students made on a test or whatever I would probably use the mean as my setup more than likely because if I just use the median I could have a ton at one end and it may give me a little bit of a skewed I sort of would like to look at the information from the mean maybe or you know maybe I wanted to I had one kid made a really good grade basically I would want to it to be the median or sorry be the mean because if I have a couple kids who make really good grades versus the other ones doesn't make the other ones look so bad so I want to feel good about how things have gone for that test on the other hand if I was going to do a reasonable analysis my original explanation was a little bit weird I realize now if I want to do an actual analysis medians probably the need to go just because it'll it'll analyze the spread a little bit better if I have a bunch of really low scores and just a couple Highlands that would bring it up the median would tell me that yeah things didn't go too well on this test the mode would have no benefit to me for the most part let's add a whole bunch of hundreds or something but the mode probably wouldn't tell me much in terms of the data there's other situations where the mode is a reasonably useful setup but in that case the mode would not be that helpful to me but anyway look at the data in terms of how it's sort of skewed around and you get a good idea of which one mean meaning our mode is the best for you to analyze central tendency welcome in this video I'm going to be analyzing data central tendency stuff specifically mean median mode using a ti84 plus so I have my data set there at seven four six eight thing and I'm gonna go in and just make it happen now when you have one set of data like this you want to just punch it in as a list in order to edit a list you go to the stat button so go in and then under the Edit menu just click enter for number one I've already typed it in so it should be you don't have to put it in order before you type it in in fact in the edit menu that I was just on it has sort a which is sort ascending so the numbers go from smallest to greatest or sort D which is sort of descending so it goes down so you could deal with that later but for right now the biggest thing is once you type them in and you'll just type the number in hit enter it'll take you to the next one go down to the bottom one the last time you hit enter it'll fall below the numbers click back up just to see this number right here it says l1 which means list 1 and in parentheses it has 10 which means there's 10 values in list 1 so you count up your values and there are 10 of them so you know that you have the right number in there why wouldn't you know just be thorough to go back and check whatever anyway now that I've typed it in I need to quit out of the Edit menu so I'm just gonna hit 2nd and quit to get back to the main screen from here I'm gonna go and just do some math with the the data that I've put in the list so hit stat again sorry I'm gonna do specific thing so I need to hit second in list if you're working with numbers in the list you're not just doing some sort of generic regression or whatever you'll need to hit second list that's where you pick the list it's also where you do some of the you know operations and math using the list so the math menu has mean median and it'll give you standard deviation Oh give you a minimum value of maximum value all that's there you know not huge big deal so anyway I want to know the mean so I'm gonna hit mean and then I need to go pick the list that it comes from so here's that list you get six if I want to know what the median value is oops second list I need to go over to the median here so I'll do a second list again they'll choose list one and there it is now to find the mode and I think I already found the median and make sure yeah I did okay to find the mode in older versions are like the T is 73 Plus which is the middle school version there's actually a mode button that you can it'll do it for you in the ti84 plus they assume that you can count so the best you can hope for is organizing your list and then just finding the one that happens the most so what you're going to do is go in and go to second list so you can fiddle with your list again you could do this from the Edit menu too so hit ops says sort a which means sort ascending and then you want to go second list again and pick l1 and hit enter it just is done it doesn't give you the information now you can look at your list so I just stood here and go to your edit and you just count the one that happens the most so in this case four but in old some version the calculators are actually a setup that will give you the mode but in this case just kind of find the one that happens the most and you know that's it done all right in this video I'm going to talk about analyzing data specifically looking at quartiles interquartile range and box and whisker plots so I'm going to take my data that I have here the seven four six eight line and I'm going to just analyze it using those setups the first thing that I need to do is rewrite it in such a way that I have it in numerical order so ascending preferably three it's kind of McDonalds colors now three four four four six seven eight ten and 11 now when I talk about interquartile range or when anybody talks about interquartile range that knows any idea what they're talking about we're talking about breaking it up into groups of four like a court a Keene tile would be five so I tend to think of it in terms of a dollar bill and then the quarters that could go into it so in a dream universe I could draw good circles but I'm not living there so you just have to accept the fact that these quarters are awful looking so anyway 25 cents that whole thing so there's four quarters in dollar essential is where I'm headed with it now there's a couple points of reference that we need to make when we work with these the first which is the minimum number not realize how awful that color is is they against this background so the minimum number so we'll say men in our dollar OB wherever it is down here kind of men by the way the dollar thing will pay off because it'll make it really easy for us to do the box and whisker plot here in just a minute the next thing that we probably look for is the maximum number of course because why have a min if you don't have a max Max would come right here in the old dollar analogy then we'd want the median median would come right here at the 50 cent point so 50 percent of your data goes to one side and 50 percent of the data is above that number and then we'll have q1 and q3 so basically we'll have q1 will be here after the first quarter so it's essentially the median of the lower level or the lower two quarters on the other end you'll have q3 which is the median of this set of data so in my little setup here I need to figure out what the median is so the specific amount from the minimum by the way would be 3 because it's the smallest the maximum would be 11 now my median is what I'd look for next these cancel so I'm looking somewhere between six and four so to get my median value I'll do 4 plus 6 divided by 2 so my median value will just be 5 so here's my median right here to get q1 I need to look just it's this set of data right here I need to find the median value there which is right here so the q1 value by the way if I had 2 in the middle there I would do the average of those two so say I'd been 3 and 4 together or 3 and a half would be the median or the q1 but the q1 here is 4 because it's the median value of that first set the first two quarters on the other side of it if I'm dealing with this set the top half so to speak I want to find the median there it's the 8 so I would say that my q3 value is 8 now what this what I can do with this information oh I should also talk about interquartile range I'll get to that in a second what I can do with this is make a box and whisker plot which will give me some idea about how the data is skewed whether it's one direction for where there most of the data falls at one end or you know that sort of thing as you can see there's a considerable distance between q3 and the maximum compared to the minimum and the q1 so that will shift with the the the graph looks like which will tell us that the data sort of shifted in one direction and might push us to pick the median as opposed to the mean as our central tendency of choice that kind of thing so the interquartile range I'm gonna call it the IQ range which is really unfair so the inte Q range I don't know interquartile ranges right there anyway interquartile range is q3 minus q1 so basically this distance right here I need to know how far they are apart so the middle two quarters so the middle 50 cents so in this case would be 8 minus 4 so the interquartile range is 4 and all of this stuff is really sort of an assessment of range the maximum minus the minimum will give you the range of the entire data set the interquartile range will give you an idea of what's going on in the middle so you can sort of see maybe one of those numbers is what's considered to be an outlier and outlier is a number that's way out of the scheme of things and if we look at the box and whisker plot we may be able to see if there's really sort of an outlier here so let's make a box and whisker plot box of whisker plots you want to start out with sort of a number line underneath and it has two dots one at the minimum one at the maximum so I'm gonna make my little set up I'm gonna have three at the one end and 11 at the the right side so I'm gonna make little dots here those are eventually going to be my whiskers now I need to make my box I'm gonna make a box that sort of looks like this in some form so the first line I'm gonna make is a q1 so right at 4 there I'm gonna go ahead and make a line right here that's q1 the next line I'm gonna make is at the median so right here and then I'm gonna make another line at q3 and then I'm just gonna make a box out of it and now to finish it off I need to connect my whisker so I'm gonna draw a line here and draw a line here so if you see the box and whisker plot you can tell they'll say what's the minimum value well you go to the dot on the left and it's 3 if they want to know what the median is you look for that little line in the middle of the box and is 5 but what it really tells us is how the data is skewed you can see that the median value is way down here as opposed to the whisker that's way up here we can't really tell necessarily if 11 is an outlier based on a box and whisker plot so I guess I should write that word up in case people never seen it an outlier is basically a data point that's uncharacteristic of the set but since 10 is here and you know Elevens probably okay as an outlier but if I had like 25 in there that would be significantly further away from the rest of the data set so I could say yeah 25 is an outlier so the term outlier makes the most sense here it's just the one that's a way outside the overall feel the tendencies of the number says so way outside the number said essentially one that's kind of the weirdo outlier set number so anyway quartiles just find a minimum maximum find your median q1 would be the median of the first group or the first half of data points the q3 would be the median of the second half of data points and find the interquartile range you want to subtract q3 minus q1 find out how far apart that middle is which is you know not insignificant here and then finally you want to have your maximum number of course make your little box and whisker plot out of it and based on the one that I have right here I can see that most of the data is sort of shifted down to the 4/5 range and you know all my data is sort of skewed to the lower end whereas Elevens keeping it propped up but there's enough numbers at the the top to spread it out so at least the interquartile range shifts up to eight so it tells me something about the data in this video I'm going to analyze we talked about anyone analyzing data quartiles interquartile range and box and whisker plots with the ti84 plus so in case you ever need to do that the I'm going to go ahead and just get into it really we're working with the list here so I'm going to turn it on and eat to clear out my list I can get it to do it okay generally you want to do it individually because if you go up to the top and delete it it will delete l1 which makes it all kind of get wonky after a while so it's just in your best interest to delete them individually if possible anyway once you do that type min and I'll go back up and check there should be ten there is so I'm you know ready to work with it now this is what I'm going to end up doing is a one variable statistics so I can get a whole bunch of information from it so if I go into the stat menu and click over to the calc which is calculations I'll go to one variable stats and hit enter to pick l1 is my list I'm not going to pick a frequency list and hit calculate if I click down a little bit this is a whole bunch of information you can get standard deviation there you can figure out you know kind of what the values of the sets are and that that whole thing so what I'm interested in is what's minimum maximum q1 median and q3 are so just click down a little bit there's the minimum value of 3q one value for median of five q3 of eight and Max of eleven now I want to make a box and whisker plot which could tell me all that information as well so what we're gonna do I'm gonna clear that quit out first you have to still type your list in otherwise it won't work I'm gonna use a plot here so hit second and y equals and you're gonna actually turn one of the plots on by the way once you turn a plot on you have to turn it back off or when you try to graph normally your calculator will go out of its mind it doesn't understand what you're trying to do so I'm gonna hit enter I need to turn that plot on and I need to go down to type I'm gonna pick the one in the middle here the box and whisker plot choose that one it's gonna ask me which list do I want to use and I want to use l1 of course and the frequency is fine the thing is my calculator right now is set up to graph normally so I probably have X values of negative 10 and 10 or something like that but I'm gonna my numbers go from the number 3 all the way up to the number 11 which is above 10 obviously so I need to adjust my window a little bit so I'm going to go into the window here I'm not gonna do it that way I'm gonna hit enter to choose the frequency might help if I just kind of quit out of it really quickly yeah sorry so I'm gonna quit out now that it's all set up and ready to roll ski I'm gonna go to the window and I'm gonna change it I usually go like one below the smallest number so two and my X maximum I'm going to put one above so twelve and now that that's all kind of where it needs to be I'm gonna hit graph and it should make a nice box and whisker plot for me the cool thing about it is if I hit the trace button it'll start telling me where all the information is so mine tells me that the median is five if I click to the left it'll tell me q1 is for the minimum X is three and then you can go over and get q3 of eight and maximum of 11 so all that information is there for you you can make it pretty easily so it might be a nice way to organize your information this video I'm going to talk about analyzing data specifically I'm going to talk about the term percentile where you'll see percentile most often is in things like standardized tests the a CT the SAT that kind of stuff the those tend to pop out things like your percentile is this so maybe you're in the 75th percentile for your composite score on the a CT what that means is the value of your score is at or above 75% of the values that other students have scored or including yourself so 75% of the scores earned by students on that test were as good or worse than yours that's what you need to know now on the Left I have this little set of numbers it's okay that some of them repeating that happens so this is our 80 a CT scores just once I've made up in order to find the percentile I need to take the number of terms and then multiply it by the percentage it's pretty simple so let's just do the 75th percentile I want to know what I have to score to get in that 75th percentile because maybe that means something for college I don't know but apparently they're only picking people from my school to go because and I have a very small school by the way because only 20 people took it but you know I just I guess so I went over the 75th percentile starts here so there are 20 terms and I just want to multiply that by 75% specifically I wanted multiply 20 by 0.75 and once I do that I can find the value of that I would need to make to fall in the 75th percentile so I do 20 times 0.75 ended up with 15 that does not mean a score of 15 it just means 15 terms into the data set 15 terms in to the set so right there that's the fifteenth term in the set so in order to fall into that 75th percentile I need to have a value of 27 if I wanted to get way up there like I wanted to just you know over achieve a lot maybe I want to get in the 95th percentile well in that case I would take the same number and multiply by 95% which of course would be 20 times zero point nine five and I would find out that that would be the 19th term in the set so right here in order to be in the 95th percentile of this group I need to score a 34 so there it is that's all percentile means it's not overly complicated but occasionally you'll get questioned about this and this is the way to find it in this video I'm going to talk about using standard deviation information to describe data like where a data point actually false so in my theoretical universe that I'm dealing with here I'm going to say that I have a mean value of 18 and I know that my standard deviation is say for something like that so in this what I'm going to do is just make a little number line here so 18 would be my mean to do my standard deviation I'll do plus 4 up here so so if I have my set up numbers 19 20 21 22 here's my standard deviation away from where it happens to be that'd be one standard deviation above and then here 23 24 25 26 it's another standard deviation outs I'm a called 2 standard deviation on the other side of it one standard deviation away two standard deviations away so if I want to know specific information about a number so say I want to know where 22 Falls or I want to know where 10 happens to fall well 22 is one standard deviation above the mean 10 however is two standard deviations below the mean so basically it just gives me a sort of a reference point to explain where information tends to fall usually depending it does depend on the distribution a little bit most of the data will fall somewhere between the two between two standard deviations away if it's a value that you're actually going to use so you can get sort of an out like the ten is way away from the mean so it may be something that I sort of question whether I really want to use it in my analysis of the situation whereas 22 being one standard deviation above the mean may be something that I would consider a pretty solid you know data point that's okay and say to use if I'm doing a very specific type of research it just sort of depends on where you want to go with the information but a lot of times you will have standard deviation pop up as being a tool that you can use to analyze where a point falls in the data set so there it is in this video I'm going to analyze data talk about the standard deviation variance using the ti84 plus so we're dealing with I've dealt with standard deviation and variance I should say in a different video basically you find the mean of a set of numbers you find out how far away each individual data point in the set is away from that mean then you want to square that difference so the negatives aren't canceled out by the positive so everything's positive basically then you add those squares together then you once you have the added squared differences away you just divide by how many terms there are and that'll give you your variance and then to find the standard deviation you want to sort of eliminate the effect of squaring it by taking the square root so you square root the variance and it'll give you the standard deviation now a calculator will do this relatively quickly for you specifically in this video ti84 plus so let's bring it up and see how it works now to do this I need to make a list of my numbers I'm gonna go to the stat menu to do that and edit there's a list already in here be careful if you go up and click l1 and delete it it'll often delete l1 completely so when you go back and try to use l1 to do other statistical things or box and whisker plots or any time you have to use l1 you'll think that the first one you typed in is l1 and it kind of messes with you so it's easier sometimes just to sort of click up and down the list a little bit and then just start deleting individual points unless you have a gigantic number I would probably go that route anyway type them all in there's not that many in this set because I just kept the one I did when I did it by hand and or I did a long explanation I don't want that many of them so click backup to make sure the 1/5 is that number should be it means list 1 there's five terms in it if you're in the last number so that way it matches in case you have a big set they have to deal with anyway now that I have my list I can hit second and quit and get out of it I'm gonna go in into the setup menu again so I hit stat I'm gonna do one variable statistics so when I do that I want to tell it what list I'm picking from I'm not gonna pick a frequency list here and I'm just gonna hit calculate now it'll tell me pretty much everything that I need to know it tells me what my mean value is so it tells me it's 8 so if I were to pop that out I would say well here's my mean value right here if I can get it to do it I'm gonna bring it back up now so in this case right here is my mean value so I could say my mean value here is 8 and then what I really want to look for is the Sigma because that's where standard deviation kind of lives and it is 3.1 or 3.0 9 8 this whole thing so I might say just like I found before but the nice thing is it gives you all the information one little setup very convenient it tells you the number of terms in the series and if you need to do some sort of quartile analysis it tells you all that information so that's good yeah go ahead and use how it goes it also in this case sort of gives you the sum of the numbers it'll tell you the sum of the numbers squared in case you need to know that the whole thing kind of the world is your oyster in a way I guess so but standard deviation is what you're looking for here just pull the Sigma term and you're fine in this video going to talk about the idea of frequency tables and histograms basically a frequency table is when you first off you want to take a set of numbers and so you want to have data and you want to break and enter intervals which are basically even sized groups evenly sized groups if I were to do say one through twelve or something I may say how many numbers in that group fall between 1 and 3 and then 4 and 6 and then 7 and 9 and then maybe 10 and 12 so those would be my intervals I'm breaking it into groups of equal size in in most cases they're even occasionally they're not but that's what how it works frequency is how often or how many times a number falls into that group so the number of data points in each interval so maybe I have six of them that fall between one and three I have five here four here and two here and then a frequency table it's just a way to visualize that information so it groups them in intervals and then shows the value for each interval so it's like a it's a table that displays the intervals and the corresponding frequencies basically this if I put what each thing is so frequency and then I'm just going to do a generic title here so generic I don't know what 1 and 3 equal is just making it up in my head so whatever it happens to be able to leave it blank actually so the other section should tell you the frequency so basically this setup right here is a nice frequency table a histogram is just a graphical representation of a frequency table now a histogram comes in three basic looks the first would be uniform and I'm just gonna draw it but out in when I get to the question part I'll actually explain how to make it look so the first one is when you have a uniform is when they basically are all the same height they can be a little bit off but for the most part pretty much the same height all the way through the sections that's my histogram in this uniform so uniform same and we're talking about the height specifically the frequencies but whatever the next type would be skewed skewed histograms would be off to one side have a whole bunch of stuff up here but as it goes it tends to sort of move out I'll even have a little buffer there but still for the most part a lot of its over here and the last type would be symmetric symmetric sort of looks like a building or a normal distribution if you know what that means you tend to have one big part in the middle and then the sides are pretty close and then it just sort of goes down so essentially you have a axis of symmetry you can break it in half I could fold one part over the other it doesn't have to be exact it just has to have the general idea that it is symmetric so you're looking for sort of a line of symmetry or you can fold it over so that's enough of that let's do some so the first one says the number of eagles observed along a certain River per day over twoweek period is listed below make a frequency table that represents the data so I'm gonna look and I see that the numbers go from about one to eighteen a reasonable number of groups probably there would be let's say I don't know five groups maybe or we could do six so if I wanted to do six I'd do groups of one two three four to six seven to nine ten to twelve thirteen to fifteen and sixteen to eighteen if you spread them out too much you're not really gonna get a good feel for it so it's sort of sometimes it's a little trial and error about how many things fall into it so I need to find oh it goes from zero I'm sorry so zero to three so which spreads that one out makes it a little bit uneven but you know that's okay so what I'm going to do is look to see how many fall in that group so there's one two three four that fall in that group four to six one two seven two nine eight nine seven so there's three there 10 to 12 I've got one two of those 13 to 15 I've got one two of those and 16 to 18 I've got one so that's my frequency table it represents the data relatively well if I wanted to combine groups together like maybe I did zero to six and then I did seven to twelve and then 13 to 18 if that's the case I would do six for this one five for this one and three for this one now depending on what I'm trying to figure out either one of those is a good frequency table it just depends on what the overall outcome is supposed to be the first one gives me much more detailed information in terms of I can get very specific I mean you could go down to I guess one in each interval but that would seem kind of silly but I could get I could see that the number of times an eagle has been observed zero to three is definitely the biggest one whereas it doesn't seem as between zero and six like seeing an eagle six times is kind of a major difference between seeing it you know six times and zero times or whatever it happens to be so I would probably use this one just because it gives you more information that's detailed you know whatever the last one also the second one also makes it seem like the 16 to 18 group would pop up more often than it probably would so that's that one number two the data show below shows the number of games won by a football team in each of the last 15 season I need to make a histogram so to make a histogram you have to start out making a frequency table because they're you know very closely related ones just another version of the second actually I might do the data below shows the average number of text messages a day that would make more sense just because it gives me a room to work it so I have this is text per day and then my frequency and here I have it going up to 22 and my lowest group is one so somebody's only doing one so I might do groups of 5 so 0 2 4 5 to 9 10 to 14 15 to 19 and then 20 to 24 I should get everything covered now I just count them make sure you mark them out so you can see what you're doing one there is between zero and four and that's it not a lot of lowlevel textures here between 5 & 9 I have 1 2 3 4 5 between 10 and 14 1 2 3 and that's it you'll notice I'm trying to use different symbols each time that way I can go back and assess how I got my answer just in case I need to check 15 to 19 1 2 3 and the last one twenty two twenty four one two and that's it it's also a good idea by the way to check to make sure you have this bright number of frequencies in your table to determine that you've gotten them all 1 2 3 4 5 6 7 8 9 10 11 12 13 14 so 6 7 8 9 10 11 12 13 14 so that works that's my frequency table now for a histogram I'm just going to on the bottom put text messages and over here I'm going to put frequency so on my yaxis so maybe 1 2 3 4 5 sorry for writing frequency so small I come to running out of room now it might 0 to 4 group I only have 1 so that's that in my 5 to 9 group I have five so there's mostly 5 to 9 would be the most common number of text messages sent in our sub in our little group that we've created and then I'll do 10 to 14 and they're at 3 and then 15 to 19 they're at three as well and then finally 22 24 it only has two so that's my histogram basically just set the boxes and each one of them represents one section of the frequency table it also gives me a nice visual I can see that this one here really doesn't like the zero for group is very small it's easier to just have it there and it sort of gives me the idea that it tends to sort of you know skew out this way a little bit more so than it it hits a big high point at five to nine but it skews higher than it does lower which means it spreads out that way a little bit better so that's frequency tables and histograms I'm gonna see if there's any more things I need to cover I don't think so oh no we're gonna look at types really quickly so we talked about the three types uniform skewed versus symmetric this one has a little bit sorry I don't know I rolled down so much this one has a little bit of skew to it as you can see it sort of fades off to the right so it goes this way it's positively skewed a little bit so that's that one and for number five which is another type this is a perfect example or not a perfect example at a very good example of a uniform histogram just because this was the uniform histogram I'm sorry this is a perfect example of uniform Instagram I'm looking at another thing while I'm doing this my apologies I've been doing this a long time today anyway the uniform amount because it's the same you wear a uniform looks exactly the same as everybody else's so that's no it's uniform this one is symmetric my bad so yeah it sort of fades down a little bit any sort of like dual sided Christian descent is sort of the way that you want to go to make sure that you have a skewed or sorry symmetric representation of your histogram so that's it frequency tables histograms not that big of a deal I'm sure you'll do fine this vide I'm going to talk about the idea of sampling and surveys as a way to collect information to make decisions the first thing that when you talk about is the idea of population versus sample a population represents all members of a set so if you're gonna do a population of people who live in the United States you have to deal with every single American has to be involved in whatever you're doing to get the total population of the United people in the United States now that's usually impossible to get everybody to do in your set unless your set is extremely small you can't get the population so instead you want to go with a sample instead a sample is part of that population so if I was dealing with the idea of here's my population a sample would just be part of it that's how they get polling data and stuff when they ask about political opinions like seventyfive percent of Democrats say this well obviously they don't go and ask everybody who's a Democrat to say what they believe or Republicans either what they do is take a random number or are they picking a number of people and try to assess them maybe random I say random because I assume they're doing things in the best interest of the study but many cases they're probably not so they pick a group of them maybe at 50 or 25 or 100 or whatever and then they garner information about the overall belief system based on that sample that's how that's what they're doing so the real goal is to try to pick a sample that's representative of your population if you don't it becomes a problem that's called this process is called sampling there's a few different ways that you can do it some of them are listed here the first is a convenient sample a convenient sample is one is easily accessible so if I wanted to pull somebody who were like I wanted to pull Democrats about something I might pull only local Democrats because I know where the local Democratic office is so it's easy for me or the headquarters or whatever it's easy for me to go down there and just ask people now that might not give a realistic view of how Democrats think because I live in one area and Democrats here may be different than Democrats in other parts of the country but it's an easily accessible sample so I guess that's good enough but not really the next step would be looking at self selected samples self selected is a nice way of saying volunteer I ask people who are interested to give information that is not exactly the best way to get unbiased information in your set just because you're getting people who are passionate about it if you only ask people who vote to volunteer to do it you're basically getting people who care a lot about it in one way or the other so they're you know they have a true opinion they're not people who won't be affected by it or whatever a systematic sample is a little bit more realistic it has less bias in it in this case you want to order the population and then you want to pick people at random intervals like if there's an elementary school and they need to assess something about fieldday or whatever it would be ridiculous for them to go and the teacher who's assigned the activity to to do the survey just picks people from their class because it's convenient you're only getting maybe he or she's a fifth grade teacher you only get 5th grade kid information that doesn't help you a selfselected sample is hey who wants to fill out this survey about fieldday well some people who may be really interested in field they just don't feel like it or don't like the survey or whatever so they just don't do it you have to go online and they're trying to do other stuff whatever it happens to be a systematic sample would probably split the school which it already is in two classes so you make sure that some people from every grades and then you have an interval system to choose like maybe you go down the roster and you choose every third person until you get to six respondents which means you could potentially get some but you get the third person you get the sixth person the ninth person but then if the class only has 15 in it or whatever then it'll cycle back around says a chance you'll get the people who you missed before so that's a systematic sample you've organized it you've organized the population and then you use an interval to pick people or maybe randomly like you have them pick six people or whatever it happens to be the other type is random sample and this is where all members of a population are equally as likely to be chosen now countrywide sort of random sample is very unlikely you're gonna pick from certain things I mean you can't get everybody but if we're our school scenario for instance if you just put all the kids names in no matter what grade they're in all in and you pick 50 of them out and you shake it up each time and whatever it's a random sample so it's possible to do it if the population is small enough and make it legitimate so those are the sampling type so convenience it's just easy for the person who's doing it so the person who's sampling it's simple for them self select good sample means that they volunteered systematic sample means you order the population in some way and then you use random intervals to pick them and then a random sample with everybody has the same amount of likelihood to be picked for the survey as anybody or for your sample group as anybody else from there we're going to look at sampling bias for just a second to determine whether these situations introduce bias in the sampling process bias would be that certain groups of people will be chosen over others in the first one it says a newspaper article about property taxes asked readers to call the newspaper to express their their opinions so in this case what you're really dealing with of course is a self selected sample not symbol sample and this is a bias method because you basically get the passionate people do the passionate nature of the respondents only people who care about it deeply are gonna call in it's like radio shows with Collins they pay usually have to have reasonably large groups of people listening to them because like for every 15 or 20 people or something you may get one caller so it's one of those things about it this is a selfselected sample selfselected samples are generally biased the next one says our reporter interviews sorry people attending a local sporting event well this is a convenience sample and this is bias because there's a little bit more homogeneous feel to how it goes you're basically gonna get sports fans one of the things in the local system that I'm working in is they want to put turf out on the field well if you go to a football game and ask the people who go to the game a lot of them will say that they really support the idea of having turf but if you go you know to the library or something they may say well couldn't that money be spent on books or whatever it happens to be so in that case you're adding bias into the situation by picking likeminded individuals people who'd spend Friday night at a sporting event or whatever and the last one says a political polling company calls every 30th person in the phonebook so basically they take the entire phone book and they call the 30th person each time this is a systematic sample because there's a system in place anytime it says every 30th person or whatever it generally means that it's a the the its systematic I'm sorry now is there bias in it possibly depends on what they're asking if they're asking about phone service then it may be different because some people aren't listed in the phone book anyway that's back years ago it might have been different and even then you're basically getting a certain subset of people who are in the phonebook so if you pool the xxx is it as biased as going to sports fans and asking them about turf no obviously not but there is a possible bias there the newspaper article asking for a selfselected trying to create a self select a sample it's much more biased but there is possible bias in the idea that you'd pick people out of a phone book because some people are unlisted and you know some people only have cell phones and they don't list themselves in a phone book that kind of thing so depending on the phone book depending on the question there is a possible bias in place so that's the kind of stuff that you have to consider when you sample a group and the last section is that I want to talk about is the idea of completing a study what types of studies are there and the three I'm going to talk about our observational studies controlled experiments and surveys now observational studies are studies where the study is done in a way that does not effect the sample group so an observational study is just kind of where you watch what was gonna happen anyway you're not affecting it or not changing anything you're just sort of observing what's going on in the regular scenario that's there the next type would be a controlled experiment in this group you have two groups you have the control group and the control group is the group that you just keep normal it doesn't change or anything on the other side of it you have the experimental group the experimental group is the one that you actually imposed treatment so you actually do something to them whatever it happens to be and the control group just stays the same so they're the statusquo group the nice thing about the control experiment is that you have some idea that what you're doing has an effect outside of anything else like you can see that that specific change affected the people in the control in the experimental group versus the control group but you know it's not always the best way to do it and there are certain things you can't do there are certain rules about whether you're legally allowed to effect one group and not affect another and it just sort of depends on the scenario and the last one would be a survey the survey is when you ask all members of a sample set some questions so in the first case you're just observing what they're doing and the second you're splitting them into two groups applying a treatment to experimental group and seeing if they're affected if their lives change in some way compared to the control group which is the status quo and doesn't change it's like you were never even involved and the last one is a survey where you basically just ask all the members of your sample set some questions now you can add bias in the survey questions but I'll have a different video on that in the future so that's it completing a study sampling a set and looking for bias in that sample set in this video we're gonna talk about bias and survey questions a survey of course is when you ask every single member of a sample set so like your entire school for instance a set of questions the problem is the questions that you ask them specifically the way you ask them in the wording could affect how they answer so what you're trying to do is not introduce bias into the equation biases when you make the decision go one way or the other even if it's unintentional so I don't like your you're pushing the agenda whether you mean to not the first thing that you don't want to do is combine two or more issues so for instance if I was doing a little informal informal survey or I was doing a formal survey and I said should school days be shorter and start earlier well in some ways people I could get some support for this because a lot of people want school days to be shorter students mostly in teachers people who actually have to do it one of the days to be shorter but to start earlier earlier part doesn't really sell where I go to school or where I work right now school starts at 730 in the morning so let's just say for instance I saw this question and I wasn't really sure what it meant all of a sudden that kind of ambiguity makes the bias start to be eat into the equation let's just say maybe that means that school days will start at 630 in the morning and there'll be fifteen minutes shorter so instead of getting out at 230 like the school does now it gets out at 115 because we but we go an hour earlier which would normally the norm the length of the school day would make us leave at 130 when we get out of 115 so 15 minutes less of school I only have to get here an hour earlier that would be perfect for somebody who really likes afternoon but not anybody else so once I entered two components into the equation it added bias to it so it's not a good survey question from there we may deal with using double negatives I you know don't you or do you not disagree that kind of thing anytime you use double negatives you're starting to add sort of murkiness into the question process and people may choose the wrong thing and something that they don't mean overlapping answer choices overlapping answer choices are much like combining two or more issues in your question if you give them choices and all of a sudden two things are involved in your answer and it's sort of like well I'm answering this but not this and that whole thing that's when the overlapping answer choices become a problem you want to keep answer choices as separate as you constantly can I mean they can have certain components that are the same but you don't want to have them seem like well like the earlier start time question before I didn't want one of the choices to be like start earlier and be 15 minutes shorter and then you have start earlier and be shorter it's sort of confusing about what does that mean you know they're almost the same thing so you want to make sure that they're as separate as possible using loaded words as a big deal it's really how a lot of people who do surveys gain the information that they want to get even before they start things like for instance in the abortion debate if you use prochoice or you use prolife those are both positive words depending on what side of the argument that you're on if you use the word poison as opposed to pesticide that should be a problem any time you start using adjectives generally it becomes a problem if you call a book would you rather watch an exciting movie or read a boring book once you add those loaded words into the equation you're pushing the mindset already so you don't want to do that and then asking a leading question you don't want to ask questions where you say sort of like don't you agree with this or wouldn't you say that this is true or blah blah blah once you start already assuming that they agree with you then the questions become you know kind of a big problem the thing you don't want to do is have don't you agree that teachers are underpaid or don't you agree that teachers can pay too much whatever it happens to be once you start pushing that agenda into the equation it becomes a problem so long story short in your question you should only focus on one thing at a time your answer should be very specifically answering one thing at a time you don't want to use double negatives and you never use loaded words so don't use anything that's sort of show of bias in the question don't like presuppose things and which would be the last one sorry ask leading questions you don't want to ask questions that already sort of assume they agree with whatever you're saying and then they had to disagree because it sort of changes the mode they're not giving a choice anymore they're doing a yes/no based on your assumption that they believe something to be true so that's it in order to avoid bias and survey questions avoid those five things and then you should be making a reasonable survey question in this video I'm going to talk about looking at data in terms of it being considered quote/unquote normally distributed let's look before I even get to that let's look at the idea of what types of maybe various types of distributions that you would see just the most generic ones of course so a normal distribution most of the day like here's the mean value so most of it sort of flows around the mean in you know a pretty even fashion even though that doesn't look like the greatest job ever so if I delete if I get sort of racist around so most of the data tends to fall within the mean pretty close the further you get away from the mean in terms of standard deviations away it the number of data points significantly fall the other options that you could have I mean there's a bunch of them but most likely you could deal with a distribution that's sort of skewed positively so sorry skewed negatively and it's because the mean would seem to go here but you've got these negatives that flow out so that makes it a negatively skewed data set or you of course you could have the opposite of that where you end up with sort of a skew to the positive so this is positively skewed data which means that there's a few points that are really positive that are sort of pulling up the overall set now but what we're talking about is normal distribution now think about normal distribution is it's used in a variety of cases one of them being IQ we also tend to look at it really any metrics tends to a lot of metrics tend to fall their height and you know weight and that whole thing but what we want to look at here is just what percentage is fallen that's the nice thing about normal distribution I can get an analysis of what percentages of the data fall into each one of these groups now at the bottom you'll see they use this term for this little symbol for the mean value but I'm gonna change it to this that's the mean value in the middle so most of the data tends to fall generally there this would be one standard deviation two standard deviations and even three standard deviations below on the other end you'll have one two and three standard deviations above now for each section one standard deviation below and one standard deviation above the normal distribution or m'l distribution curve it'll be something like 34 percent of the data will fall in each one of these segments so the percentage of data between one standard deviation of below to one standard deviation above is 68 percent or so of the data which is a lot so a lot of it falls with one standard deviation away by the way this for IQ for instance my mean value would be a hundred of course that's how this set up with the standard deviation of about 15 so if we're going to do an IQ analysis here we'd say a hundred is the IQ at this point this is about eightyfive this is an IQ of 115 to up would be 130 and then three standard deviations above the mean you're looking at something like 145 each one of these to school officials and you know other people who are in intellectual analysis and that sort of thing each one of these numbers tends to stand for something of importance in fact we identify intellectual or cognitive disabilities at that seventy IQ and below tends to be two that's why they picked that number because it's two standard deviations below a lot of gifted programming starts somewhere around 120 so it's somewhere between 115 and 130 depending on the state I mean that's just where people tend to qualify for so those sorts of things anyway moving forward let's look at how much is between what percentage of the data falls between 85 and 70 ways you can see like these sets that's a lot of data that's going on whereas here not as much because the 70 is a lot less data than would fall in in terms of a percentage then when fall between the at 85 so what we're looking at here is a number somewhere around 13 and a half percent on each one of those sections so if I was going to go back to my analysis of how much data falls where if I wanted to know from two standard deviations below the mean to two standard deviations above the mean in that case I want to add 13.5 plus 34 plus 34 plus 13.5 because all those sections are covered it's easy to fall for the idea that you just add the 13.5 together but that's you also have to consider that 34 are there and this number ends up being something around 95% so it's really common to see these figures sort of pull made known to people so we could say that two standard deviations above or below the mean you're looking 95% of all the data so in an IQ sense that means that all IQ are 95 percent of IQs fall somewhere 70 and above all the way up to 130 and below that's kind of where that number is now the different the percentage of data that falls between two and three standard deviations is even significantly smaller than it is between one and two at that point you're looking at something around two point I'm gonna try to get a different color so it's relatively obvious that where I'm going with it so the difference here would be two Oh point three five percent that's just between here and here so two point three five percent here as well so to get the different the distance between three standard deviations below and three standard deviations above you're looking at adding the sixtyeight that we had before the thirteen point five twice would be twenty seven and then you want to add two point three five plus two point three five so ninety nine point seven percent of all data falls within 3 / 3 standard deviations above or below the mean value in a normal distribution so you can really start to get the idea of you know how closely packed the data is in terms of what huge percentages it would be for one standard deviation out if I were to sort of chart it I guess I would say this to and three so that's a lot so what does it all mean really the big issue is that you need to consider how much data it is recognized up to a certain point like if I wanted to know what percentage falls below three standard deviations below the mean so less than so X values less than three standard deviations below so what I need to do is take all of the data that's above that number and just subtract it well I know that all the data that falls between here and here would be ninetynine point seven so I'm gonna take a hundred percent and I'm gonna subtract ninetynine point seven percent and I'm gonna end up with our sorry 99.7 I need to hit the percent I'm going to end up with zero point three now that's the distance of all numbers that are outside three standard deviations so I need to break it into two parts because I just want less than so I divide by two and end up with 0.15 so something like 0.15 percent of all data falls below three standard deviations and sometimes you have to do you know I want to know how much is above two standard deviations below so there's a you know there's a couple ways I could do it I could add at this point by the way you're looking at 50 percent over here and 50 percent over here so what might be advantageous to do if I was looking for two below would just be to take 50 percent which would be all of this on the positive side and then add 34 percent and then 13.5 percent so if I wanted to know how much data was above two standard deviations below the mean all I would do is add 34 plus 50 plus 13.5 and find out that 97 and a half percent of all data is there so be careful about what the question asks you if it's asking you about a subset that's less than something you need to probably do you might have to do a division because they're broken up into groups represented in that if they want to know just a little bit more than half remember that it's easier just to break it at the mean and do 50% above just to make the calculations a little bit easier so that's normal distribution set up in a way that I hope is useful to you it's probably a good idea to have some charts somewhere with the percentages because sometimes it's a little difficult to remember them all and there's a little bit of a the sixtyeight percent thing there's sometimes you'll see it is like the 67 arrangement just adjust for your needs specifically
