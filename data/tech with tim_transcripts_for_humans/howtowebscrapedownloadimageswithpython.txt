With timestamps:

00:02 - [Music]
00:08 - hello everybody and welcome to another
00:10 - youtube video so in today's video i'm
00:12 - going to show you how to web scrape and
00:14 - download images from the internet now
00:16 - what we'll actually be doing is going on
00:18 - google images we'll be looking for a
00:20 - certain number of images grabbing the
00:22 - source of all those images and then
00:24 - using the source of that image to
00:25 - download the image to our computer
00:27 - there's a variety of reasons you may
00:29 - want to do this the first that i could
00:31 - think of is you probably need testing or
00:32 - training data for some type of machine
00:34 - learning model and maybe you want
00:36 - hundreds of thousands of images or you
00:37 - want a ton of different pieces of data
00:39 - obviously it would not be efficient to
00:41 - go manually download those so you could
00:43 - use a script like this now of course
00:44 - there's a ton of other reasons and what
00:46 - i'm going to show you here will work for
00:48 - other websites it's not only going to
00:50 - work for google images but you will need
00:52 - to tweak the script slightly if you're
00:53 - going to apply it on a different site
00:55 - anyways i just want to mention before we
00:57 - dive into the code here that there is
00:59 - some legal concerns with doing this so
01:01 - if you're just doing you know 10 or 20
01:03 - images or something you probably don't
01:04 - need to be concerned but if you're
01:05 - running really large bots that are
01:07 - scraping like tens of thousands of
01:09 - images you may get ipband you may have
01:11 - all kinds of things negatively occur to
01:14 - you and in fact if you want to
01:15 - potentially be able to avoid some of
01:17 - those issues with web scraping you
01:19 - should check out the sponsor of this
01:21 - video before we get started i need to
01:23 - thank smart proxy for sponsoring this
01:25 - video smart proxy is a smart but down to
01:27 - earth tech head platform that helps
01:29 - clients solve data access and
01:31 - entrepreneurship problems oftentimes you
01:33 - want to access or scrape data that is
01:35 - only accessible from a certain
01:36 - geographic location maybe you want to
01:38 - scrape and compare real estate prices
01:40 - data mine ecommerce products or acquire
01:43 - testing and training data for machine
01:44 - learning models well if that's the case
01:47 - smart proxy can help you do this smart
01:49 - proxy lets you bypass country
01:51 - restrictions and website blocks by
01:53 - providing the highest quality
01:54 - residential proxies in over 195
01:57 - locations with over 40 million
01:59 - residential proxies you can connect to
02:00 - your target source as many times as you
02:03 - need from any type of device smart proxy
02:06 - also has advanced rotating proxies so
02:08 - you never need to worry about ip bands
02:10 - in addition smart proxy provides a no
02:12 - code smart scraper tool to perform data
02:15 - collection that you can use for no
02:16 - additional cost with a smart proxy
02:18 - subscription using the smart scraper is
02:20 - extremely simple just install the chrome
02:22 - extension open up a website start the
02:25 - scraper and select the items that you'd
02:27 - like to export check out smart proxy
02:29 - today from the link in the description
02:30 - to get access to the best proxies for
02:32 - web scraping and use the code tech with
02:34 - tim20 for 20 off residential and data
02:37 - center proxies thanks again to smart
02:39 - proxy for sponsoring this video alright
02:42 - so let's go ahead and get started the
02:44 - first thing we need to do here is
02:45 - download and set up a few dependencies
02:47 - for this project these are just python
02:49 - libraries so we're going to need pillow
02:51 - we're going to need requests and we're
02:52 - going to need selenium now we'll discuss
02:54 - what all of those do in a second but
02:56 - first let's just install them so go to
02:58 - your command prompt or terminal if
02:59 - you're on mac or linux and then you're
03:01 - going to type the following pip install
03:04 - and we'll start with pillow now you
03:05 - actually want a capital p here so pip
03:08 - install capital p pillow now for some
03:11 - reason that command doesn't work for you
03:12 - you can try doing pip 3 install pillow
03:15 - so just tack a 3 on right here and if
03:17 - that doesn't work for you i will leave
03:19 - two links in the description on how to
03:20 - fix the pip command for your system one
03:23 - for mac and one for windows okay so now
03:26 - that we have pillow we're going to
03:27 - install selenium so we want selenium
03:29 - like that
03:30 - notice that i already have all of these
03:32 - installed this is going to going to
03:33 - install a bunch of stuff but selenium is
03:35 - actually going to allow us to automate
03:37 - our web browser so that we can go and
03:39 - click on all of the images that we want
03:40 - to download get their source and then
03:43 - well download the source of the image
03:45 - okay so now that we have selenium the
03:46 - last thing that we want
03:48 - is requests like this this is going to
03:50 - be used to actually grab the data of the
03:53 - image that we want to download uh notice
03:55 - i'm getting some error here saying
03:56 - selenium 4.0 has requirement url lib you
03:59 - can just ignore that this will be fine
04:01 - in fact it actually fixed that error for
04:02 - me right here but everything should be
04:04 - good now okay so now that we have that
04:06 - we just need to install one thing that
04:08 - we need to use with selenium this is
04:10 - known as a web driver so just go to the
04:13 - link in the description i have it right
04:14 - here
04:15 - it is called chrome driver now i'm going
04:18 - to be doing this tutorial using google
04:19 - chrome i'm not going to show you how to
04:21 - do with a different web browser so just
04:22 - make sure you're using chrome otherwise
04:24 - this won't work anyways go to this link
04:26 - and then you want to click on one of
04:28 - these two versions chrome driver 95 or
04:30 - 94. now this is dependent on sorry the
04:34 - version of your google chrome so i
04:35 - believe i have google chrome version 94.
04:38 - if you had version 95 then you would
04:40 - download 95. anyways you can just try
04:42 - both of them if one of them doesn't work
04:43 - you can download the other one it's
04:44 - really easy to do this so i'm going to
04:46 - go with 94. again i'll leave this link
04:48 - in the description okay and then what
04:50 - you want to do is click on your
04:51 - operating system so i'm going to be
04:52 - win32 obviously you have mac and you
04:55 - have linux so win32 is going to download
04:57 - a zip folder for me so let me download
04:59 - that i'm going to open the zip folder
05:02 - and inside of here you will see that
05:03 - there is an executable so what i'm going
05:05 - to do is i'm going to cut this
05:06 - executable and i'm going to paste this
05:08 - in a location that i know so paste it
05:11 - pretty much anywhere on your computer so
05:13 - that i can use it and reference it from
05:15 - my python script so what i'm actually
05:17 - going to do is go to my desktop i have a
05:18 - folder here called web scripting images
05:20 - this is where the tutorial is going to
05:22 - be i'm just going to paste the
05:23 - executable right inside of here i know
05:26 - the path of this executable it would be
05:28 - this right here so i could just copy
05:30 - that path and now i'm able to actually
05:32 - reference this executable so just put it
05:33 - in a place where you are able to
05:35 - reference it you know the path to it
05:36 - because we're going to need that path in
05:38 - one second
05:39 - okay so now that the executable is
05:41 - installed the steps will be a little bit
05:42 - different for mac and linux but i trust
05:44 - you guys can figure that out just
05:45 - extract the zip folder move the
05:47 - executable to a path where you know the
05:48 - location of i can close this and this
05:52 - and i can go back to my python script
05:54 - and i'm just going to start by putting
05:55 - in the path of this web driver so i'm
05:57 - going to say path
05:59 - is equal to and then this now if you see
06:02 - something like this like this yellow
06:03 - highlight and kind of some errors here
06:05 - you just need to escape these slashes so
06:08 - you just put two slashes and then
06:09 - everything should be fine all right so
06:11 - let me just take a quick pause here and
06:12 - explain why we just did all of that so
06:14 - when we use selenium this allows us to
06:16 - automate our browser but we need a
06:18 - browser to automate so we need to
06:20 - download the web driver for whatever
06:22 - browser we want to use you could do this
06:24 - with firefox you could do this with
06:26 - safari but i want to use google chrome
06:28 - so i downloaded the chrome web driver
06:31 - which now allows us to use that
06:32 - executable file to automate chrome okay
06:35 - that's pretty much all we're doing here
06:37 - so you just need this you need to supply
06:39 - this to your actual what do you call it
06:42 - script for it to know where the
06:43 - executable is and then use that to
06:45 - automate the appropriate web browser so
06:48 - i have this here it's in web scraping
06:49 - images but i need to put the name of the
06:51 - driver which is
06:53 - chromedriver.exe so i'm going to put
06:54 - that like that
06:55 - now i'm going to go up here and i'm
06:56 - going to import
06:58 - selenium okay
06:59 - now i'm just going to show you how this
07:01 - driver works so actually i'm going to
07:02 - say from selenium i'm going to say
07:06 - import web driver like that and then i'm
07:08 - going to say wd standing for web driver
07:11 - is equal to selenium dot or actually i
07:13 - could just say
07:14 - web driver and let me check here i
07:17 - believe this is with no actually it's
07:18 - not with a capital that's fine and i'm
07:20 - going to say chrome because we're using
07:22 - google chrome and then i'm going to put
07:24 - the path right here to this executable
07:27 - file
07:28 - great so now that we have that what i
07:29 - can do is just run my code and let's see
07:31 - what happens here notice that we're
07:33 - getting this deprecation error you don't
07:34 - need to worry about that right now and
07:36 - you can see that actually opens up a
07:37 - google chrome window because i just
07:39 - started my web drive so hopefully that
07:42 - makes a bit of sense let me run this one
07:43 - more time and you can see here in google
07:45 - chrome it's saying chrome is being
07:46 - controlled by automated test software
07:49 - that would be selenium okay so we've got
07:51 - the first bit of setup done now that
07:53 - we've done that i want to show you
07:54 - simply how we can download an image so
07:56 - if we know the source of an image
07:58 - downloading it is quite simple so let me
08:00 - just go here to google chrome alright so
08:03 - you can see i'm in google chrome here
08:04 - notice that i was on images some google
08:06 - images and i searched dogs now let's
08:08 - just do cats and let's click on some cat
08:12 - okay let's right click and click inspect
08:15 - and then let's find the source of this
08:17 - image this is the source right here okay
08:18 - src is equal to this so this is actually
08:21 - the url it's using to display this image
08:23 - so src so what i'm going to do is paste
08:25 - this into a new tab and now notice it
08:27 - gives me the actual image itself that's
08:29 - great that's exactly what we want so if
08:31 - i just copy this here
08:33 - i can put this inside of my script i'll
08:35 - say image underscore url
08:38 - is equal to this and now i will show you
08:40 - how we can download this image all right
08:42 - so let's go ahead and write a function
08:43 - here that can download image so i'm
08:45 - going to say define download underscore
08:47 - image and then inside of here we are
08:50 - going to take the download path we are
08:52 - going to take the url and we're going to
08:54 - take the file name of the image that we
08:56 - want to download now before i go any
08:58 - further i do want to give credit to
09:00 - someone that i've kind of taken a lot of
09:01 - code from so there is this great blog
09:04 - post i need to paste it inside of here
09:07 - so you guys can see it on towards data
09:09 - science that says image scraping with
09:11 - python there's a ton of stuff in here i
09:13 - kind of just extracted some of the code
09:15 - that we actually need for this tutorial
09:17 - and i modified it but if you scroll down
09:18 - here it has a whole section on scraping
09:21 - images from google so a lot of the code
09:23 - i'm going to write comes right from here
09:25 - i've just kind of modified it and made
09:26 - it simpler but i just want to give
09:28 - credit to him i will leave this in the
09:29 - description in case you guys want to see
09:31 - the original source of a good amount of
09:33 - this code again i've just modified it
09:35 - and made a bit simpler because there was
09:36 - a ton and a ton of stuff in there that
09:38 - was kind of unnecessary for this
09:39 - tutorial regardless let's continue here
09:42 - so we have download image we have the
09:44 - url of the image we want to download the
09:46 - path to download it to and then the file
09:48 - name that we want to save the image as
09:50 - so what i'm going to do here is just say
09:52 - that my image underscore content is
09:55 - equal to and this is going to be
09:56 - requests dot get now that means i need
09:59 - to import requests so let's go up here
10:01 - and say import request now this allows
10:04 - us to make an http get request to the
10:06 - url so we're going to say url like that
10:09 - and then we're going to say dot content
10:11 - and this will actually give me the
10:12 - content of the image right because if we
10:14 - go to the url where the cat is this is
10:16 - well the image content so now that we
10:18 - have the content of the image i want to
10:20 - save the content of this image in a byte
10:22 - i o file type or in memory as bytes io
10:26 - data type so i'm going to say that my
10:28 - image underscore file is equal to i o so
10:31 - i need to import i o
10:33 - like this and then dot bytes i o
10:36 - and then inside of here i'm just going
10:38 - to put image content now what this is
10:40 - going to do is kind of convert
10:42 - this content right here into a bytes io
10:45 - data type now this is pretty much kind
10:47 - of like storing a file in memory i won't
10:49 - really explain it much more than that
10:51 - but we're storing pretty much the image
10:53 - file right here directly inside of
10:55 - memory now that we have that though i
10:57 - need to actually convert this directly
10:58 - to an image so that i can save it so
11:01 - right now we're just storing some binary
11:02 - data that's essentially what bytes i o
11:04 - is so i'm going to convert this now
11:06 - properly to an image using the pillow
11:08 - library and then save it so i'm going to
11:09 - say
11:10 - from capital pil
11:13 - import image like this
11:15 - and then i'm going to go here and say
11:16 - that my image is equal to and this is
11:19 - going to be image dot open and then
11:21 - inside of dot open we're just going to
11:23 - put the image file like this which will
11:25 - be our bytes i o data type so this
11:27 - allows us to actually load this in as an
11:29 - image now what i can do is actually save
11:31 - this image but first i need to generate
11:33 - the file path so i'm going to say the
11:35 - file path is equal to and this is going
11:37 - to be the download path plus and then
11:40 - this will be the file name okay
11:42 - so that is our file path now i'm going
11:44 - to say with
11:46 - open and this is going to be
11:49 - i guess we want the file path this is
11:52 - going to be in wb mode which stands for
11:54 - write bytes meaning we can actually
11:56 - write an image i'm going to say as f
11:59 - and then i will say
12:01 - image dot save i'm going to save it to f
12:05 - and i'm going to save it in a jpeg
12:06 - format okay let me look at my code i
12:09 - have some code on the right hand side of
12:10 - my screen or i guess to you guys that
12:12 - would be left but it's my right
12:14 - and just make sure this looks good
12:16 - everything looks good to me and we can
12:18 - actually go ahead and run this function
12:20 - now
12:21 - and see if this works so let's just
12:22 - print here success
12:25 - okay so let me just run through what i
12:26 - did here because i understand this is a
12:27 - bit complicated so first we actually get
12:29 - the content of the image this is pretty
12:31 - straightforward we're sending a get
12:32 - request to the url of the image that we
12:34 - want we then are saying the image file
12:36 - is equal to io.bytesio image content so
12:38 - we're taking the actual content from
12:40 - this request and we're going to now
12:42 - store this as a binary data type in our
12:44 - computer's memory this is very similar
12:46 - to storing an actual file in memory we
12:48 - then are going to convert this binary
12:50 - data to a pill image so a pillow image
12:53 - this just allows us to very easily save
12:55 - the image using image.save okay that's
12:57 - the first step we then generate the file
13:00 - path so we take the download path plus
13:02 - the file name combine those together
13:04 - that will give us the path to save the
13:05 - file and then we'll say okay we're going
13:07 - to open a brand new file that is at the
13:10 - file path so with whatever the name is
13:11 - there in wb mode which stands for write
13:14 - bytes so we can write bytes to this file
13:17 - we're going to load that as f and then
13:19 - we're going to say image.save we're
13:20 - going to save this image here to this
13:22 - file as a jpeg image and then print
13:25 - success so let's try this let's call
13:28 - download image
13:29 - let's go with download path just being
13:32 - nothing the reason why i'm going to put
13:34 - nothing is because i just want to
13:35 - download it in the current directory
13:37 - that i'm in so if you want to do that
13:38 - just don't put anything for the path and
13:39 - it will download it in the current
13:41 - directory for the url i'm going to pass
13:43 - the image url and then for the file name
13:47 - i'm just going to say
13:49 - test.jpg
13:50 - like that now make sure you add this as
13:52 - the extension otherwise it will not work
13:55 - okay so now that we have that let's go
13:57 - ahead and run the code
13:58 - so i'm going to run it like that let's
14:00 - give it a second to open up chrome
14:03 - i actually didn't even need to do that
14:04 - because we're not even using the web
14:06 - driver notice it says success and then
14:08 - if i go here to sublime you can see i
14:10 - have this test image and it's been
14:11 - downloaded to my computer
14:14 - great there we go okay so now we can
14:17 - download an image i'm just going to
14:18 - throw in a try and accept here though
14:21 - because sometimes this could fail so i'm
14:23 - just going to say try and i'm going to
14:24 - say accept
14:26 - and we'll say exception
14:28 - as e and i'm just going to print
14:32 - failed
14:33 - and then here we will print out e
14:36 - the point of this is just so that if
14:37 - this fails we can continue with the rest
14:39 - of our program we don't actually get an
14:41 - exception we just catch it and print it
14:42 - out
14:43 - okay so now that we've done that let's
14:45 - see how we can actually scrape a certain
14:47 - number of images from google images and
14:49 - then use the download image function to
14:51 - actually save the image now i'm just
14:53 - going to delete this images folder
14:55 - because this is what i was testing
14:56 - before so let's delete that
14:58 - and let's make a new folder
15:00 - so i'm going to go new folder
15:02 - like this
15:04 - we're going to call it images and now we
15:06 - can continue
15:07 - okay so we can get rid of this image url
15:10 - we can actually get rid of the call to
15:11 - download image because we're not going
15:12 - to use that right now now we can say
15:14 - define and we could say
15:16 - get images
15:18 - from google or whatever you want to call
15:20 - it doesn't really matter now inside of
15:22 - here we need to take in our web driver
15:23 - so i'm going to take in w not b wd for
15:27 - our chrome webdriver we're also going to
15:29 - need a delay and let me think if we need
15:32 - anything else
15:33 - we're going to need a
15:35 - max images as well so this is how many
15:38 - images we are going to download maximum
15:40 - or how many images we are going to get
15:42 - maximum okay so i'm going to hop over to
15:43 - google images here and i'm just going to
15:45 - run through the basic process of what we
15:47 - need to do here to actually click on
15:48 - these images and then grab the image
15:50 - source and download them so right now we
15:53 - see a bunch of images we also see some
15:55 - images up here okay like hidden whatever
15:57 - we see all of these images up here as
15:58 - well now when i click on the image i
16:01 - actually get the legitimate image source
16:03 - whereas when i'm just looking at them
16:05 - here this is just a thumbnail and it's
16:07 - kind of been resized it's not the actual
16:09 - image that i want and so what i would
16:11 - like to do is i would like to make it so
16:13 - that i click on these images and then i
16:15 - get the source of this image the large
16:17 - one that's showing up because that will
16:19 - be the real image i don't want to just
16:20 - download the thumbnails otherwise i'll
16:22 - get kind of the lower resolution images
16:24 - or just ones that are not the correct
16:26 - size hopefully you get what i mean so
16:28 - that's kind of part one that's what i
16:30 - want i want to be able to click on these
16:31 - images but then what's going to happen
16:33 - is as i continue to scroll down on this
16:35 - page we're going to load more images so
16:37 - notice how we get that kind of loading
16:39 - bar there so i need to actually have
16:41 - something that allows me to scroll down
16:42 - as well because if i want to download
16:44 - say a thousand images i'm going to have
16:46 - to scroll to the bottom of the page and
16:48 - then find all of the images now
16:50 - eventually you'll get to a point where
16:51 - you can actually click on load more
16:53 - results or it'll say you've reached the
16:55 - end so you do need to consider there is
16:56 - some edge cases here you might want to
16:58 - click a button that loads more results
17:00 - i'm not going to show you how to do that
17:01 - but that is something you may want to do
17:04 - and anyways that's kind of the first
17:05 - step so the thumbnails want to click on
17:07 - the thumbnails grab the image source and
17:08 - then download the image from the source
17:11 - however i need a way of actually finding
17:13 - all of these thumbnails and clicking on
17:14 - them so i need to find something that is
17:16 - similar between all of these images so i
17:18 - can look for something that represents
17:20 - all of these thumbnails images now some
17:23 - of you may be saying okay why don't you
17:24 - just search for all of the image tags on
17:26 - the page and if you're not familiar with
17:28 - selenium what you can do is you can
17:30 - search for class names you can search
17:31 - for specific tags you can search for
17:34 - text you can search for all kinds of
17:35 - stuff within an actual html document and
17:39 - so some of you may be saying why don't
17:40 - you just look for all of the img text
17:42 - right because if i click on this and
17:43 - click inspect notice this is img well
17:46 - the reason i can't do that is because
17:48 - that's going to give me these images at
17:49 - the top of the screen as well so instead
17:52 - what i actually want to look for is a
17:54 - class name that all of these thumbnails
17:56 - are going to have in common so if i go
17:58 - here
17:59 - notice that we have a class name here
18:02 - and i'll zoom in so you can see it but
18:03 - it's q4l uwd so that's the class name of
18:07 - this first image and if i inspect this
18:09 - second image right here so let's inspect
18:12 - it and go to it notice down here it has
18:14 - the same class name so what i'm going to
18:16 - do is search for this class name
18:19 - and any image that i find that has this
18:21 - class name i will actually try to
18:22 - download
18:23 - you'll notice if i go to this one here
18:25 - and i click inspect for some reason i
18:27 - have to keep clicking it two times this
18:29 - does not have that class name and so i
18:31 - won't get get those ones
18:33 - i will only get the actual thumbnails
18:35 - okay hopefully that makes sense but
18:37 - let's start off by doing that
18:39 - so i'm going to write a function here
18:41 - inside of this function
18:42 - i'm just going to call this scroll down
18:44 - and this is going to take in
18:46 - a web driver
18:48 - and does it need anything else i
18:49 - actually think that's all it needs okay
18:52 - then what i'm going to do is say
18:55 - dot wd.exe script
18:57 - now xq script means i can actually
18:59 - execute a javascript script and so i'm
19:01 - just going to execute command that
19:02 - scrolls me to the bottom of the screen
19:04 - now i believe this is window dot scroll
19:06 - and this will be scroll 2 and then we're
19:08 - going to put 0 and this will be document
19:11 - dot and then body
19:14 - dot and then what is it here i believe
19:16 - it's scroll height so we're just going
19:17 - to say scroll
19:19 - and height like that okay why'd it give
19:23 - me that i didn't want that okay so
19:25 - scroll height add our semicolon and
19:27 - there we go we now have the scroll down
19:29 - function i will also add something here
19:31 - i'm just going to say time dot sleep
19:34 - delay just so it gives me one second or
19:36 - whatever i make this delay to actually
19:38 - load the remainder of the images if i am
19:40 - scrolling down to the bottom of the
19:41 - screen
19:42 - okay so now that i have that inside of
19:44 - here i'm just going to paste a url now
19:47 - this url is going to be the url of the
19:49 - google images page that i actually want
19:51 - to scrape so what i'm going to do is
19:52 - just go to my browser tab here and i'm
19:54 - just going to copy this huge url which
19:56 - is for the search of cats if you want to
19:58 - search something else just search it
20:00 - copy the corresponding url and then just
20:02 - paste it inside of here
20:04 - there we go we now have our url and now
20:06 - i'm going to use my web driver to
20:08 - actually get the source the html source
20:11 - of this page so i'm going to say i guess
20:14 - wd dot get
20:16 - and then url this will actually load
20:18 - this page with my chrome web driver
20:21 - and then we can actually start looking
20:23 - through all of the images so first let's
20:24 - just actually run this function and see
20:26 - if this works so i'm just going to go
20:28 - down here and i'm going to say get
20:30 - images from google
20:32 - we need to pass to this a web driver a
20:34 - delay in max images so i'm going to pass
20:36 - my webdriver i'm going to pass a delay
20:38 - of two so two seconds and then i'm going
20:41 - to pass what was the last one i totally
20:43 - forgot max images is going to be 10.
20:45 - okay so let's run this and let's just
20:47 - see if it actually loads up this correct
20:48 - page notice it does it brings me to the
20:51 - cats page awesome
20:53 - okay so now that that is working i'm
20:54 - just going to add something here that
20:56 - closes my webdriver window because
20:58 - you'll notice that if you run this a
21:00 - bunch of times and you forget to close
21:01 - the chrome window you'll have like 100
21:02 - of them open so i'm just going to say
21:04 - wd.quit and this will just close the
21:06 - actual chrome window once this function
21:08 - is done
21:09 - great okay so let's continue here i'm
21:10 - going to write a variable this variable
21:13 - is going to be
21:14 - image underscore urls this is going to
21:16 - be equal to a set just to make sure we
21:18 - don't have duplicate urls here we only
21:20 - have the same image one time and then
21:23 - what i'm going to do is make a while
21:24 - loop i'm going to say while the len of
21:27 - image urls is less than and then this
21:30 - will be the max
21:32 - images like this then we will continue
21:34 - so the point being once we have as many
21:36 - of as max images as we've defined here
21:39 - then we will stop all right so now that
21:40 - we've done this what i'm going to do
21:42 - inside of here is i'm going to start by
21:44 - scrolling to the bottom of the screen
21:46 - once i scroll to the bottom of the
21:47 - screen then i'm going to find all of the
21:49 - image thumbnails on the screen i'm going
21:51 - to loop through all of them try to click
21:53 - on them and once i click on them get the
21:55 - source of the image and then continue so
21:57 - i'm going to say scroll to end we're
21:59 - going to pass our web driver i am then
22:01 - going to say that my thumbnails is equal
22:04 - to and this is going to be wd dot find
22:06 - elements and inside of here i need to
22:08 - pass something that i need to import so
22:10 - i'm going to say
22:11 - from selenium.webdriver.com.buy
22:17 - import buy you'll see why we need this
22:19 - in one second but just write this import
22:21 - line then here i'm going to say buy dot
22:24 - and this is going to be in all capitals
22:25 - class name and i'm going to put that
22:27 - class so let's go back here and remember
22:30 - what that class was that class was q4
22:33 - luwd
22:35 - again i'll zoom in so you guys can see
22:36 - that and let's paste that right here
22:38 - so this is the class name that i'm
22:40 - looking for this is going to give me any
22:42 - tags that contain this class name if any
22:44 - of this selenium stuff is confusing
22:46 - again i have an entire tutorial series
22:48 - on it so i'll leave a link to that in
22:49 - the description anyways what this is
22:51 - going to do is find all of the elements
22:52 - on the page that have a class name of
22:54 - this that's why i needed to import by so
22:56 - i could specify we're looking by the
22:58 - class name then what i can do is i can
23:00 - loop through all of the thumbnails and i
23:02 - can try to click on them so i'm going to
23:04 - say for image in thumbnails like this
23:07 - and actually what i'm going to do is go
23:09 - here and say the len of and this is
23:11 - going to be image urls
23:14 - to
23:15 - the max images
23:17 - now the reason why i'm doing this is
23:18 - because this while loop
23:20 - will continue to run until we've loaded
23:23 - and well got enough image urls so the
23:25 - point is when i'm looping through the
23:27 - thumbnails i don't want to be looping
23:28 - through thumbnails that i've already
23:30 - looped through and so if i say have 10
23:32 - thumbnails already
23:33 - when i run this command again it's going
23:35 - to give me those same 10 thumbnails plus
23:38 - any more additional thumbnails that were
23:40 - loaded after i scrolled to the bottom of
23:42 - the screen so what i will do is start
23:44 - looping only after the thumbnails that
23:47 - i've already added to the uh the
23:50 - thumbnails list or to the image urls
23:51 - list hopefully that makes a bit of sense
23:53 - i just don't want to be adding the same
23:54 - thumbnails multiple times so we start at
23:56 - whatever the len of this is to make sure
23:59 - we avoid doing that
24:00 - then of course we only go up to the
24:01 - number of max images so we're not adding
24:03 - more images than what we specified okay
24:06 - so that's why we have that slice there
24:08 - now inside of here i'm just going to do
24:09 - a try except and inside of try i'm going
24:11 - to say image dot click
24:14 - we're then going to wait
24:15 - by our delay so we're going to say time
24:17 - dot sleep and we're going to sleep by
24:20 - whatever the delay is now i need to
24:22 - import time because i realize i don't
24:24 - have that so let's go import time you
24:26 - don't need to install this this is a
24:27 - built-in module same with io as i'm sure
24:30 - you probably have realized by now so
24:31 - we'll try to click on the image we'll
24:33 - then sleep now we're just going to have
24:34 - an accept and say accept
24:37 - and then continue now the reason why i'm
24:39 - having this is because we could
24:40 - potentially get an error when we try to
24:42 - click on this image so if that happens
24:44 - we don't want to interrupt the whole
24:45 - script so we'll just continue which
24:47 - means go to the next item in the for
24:48 - loop so now that we've clicked on the
24:50 - image though we want to find that larger
24:53 - image and then get the source of that
24:55 - image and add it to our image urls so
24:57 - let's look at this now
24:59 - so at this point what we've done is if
25:02 - this will load here
25:03 - why is it so laggy
25:05 - come on fix yourself
25:07 - okay that's a bit better anyways what's
25:09 - going to happen is we would have
25:10 - scrolled to the bottom of the screen
25:11 - right and then we would have clicked on
25:13 - some image and this image now is load on
25:15 - the screen so the screen looks like this
25:17 - so if i go here and i click inspect we
25:19 - can see that this is inside of a div now
25:22 - it's inside of the image tag sorry
25:24 - chrome's just lagging really hard here
25:26 - but if i look at this image i want to
25:28 - find a class name or something i can use
25:30 - to identify this specific image and it
25:33 - turns out that if i go here and i look
25:35 - at the class names we have a class which
25:37 - is equal to n3vncb
25:40 - now this is the only image on this page
25:42 - that has this class so what i'm going to
25:45 - do is i'm going to use that class to
25:46 - access this larger image and then add
25:49 - the source of that image
25:51 - okay so let's do that so i'm just going
25:53 - to paste this in here just so we have
25:55 - this all right so now we will do is say
25:57 - that images is equal to and then this is
26:00 - going to be wd
26:01 - dot find underscore elements we're gonna
26:04 - do the same thing we did before we're
26:05 - gonna do by class underscore name in all
26:08 - capitals and then we're just going to
26:09 - pass as a string this guy right here
26:11 - which is the class name that we're
26:13 - looking for now ideally this should just
26:15 - give us one image but it could
26:16 - potentially return multiple and so what
26:18 - we're going to do is loop through all of
26:20 - the things that this returns just in
26:22 - case something else does have the same
26:23 - class name as this we're going to do
26:25 - some checks on all these images and
26:27 - we're going to see if they have a proper
26:28 - image source if they do have a proper
26:30 - image source then we will get that image
26:32 - source and add it to our image urls
26:36 - so i'm just going to say 4 img or 4
26:38 - image
26:39 - in images like that
26:42 - then what i will do is i will check the
26:44 - attributes of this image and to see if
26:46 - it has a source tag so i'm just going to
26:48 - say if image dot get underscore
26:50 - attribute and this will be src
26:54 - again the source of the image that we're
26:55 - looking for so if it does have that
26:57 - attribute and
26:59 - we will say
27:00 - http
27:02 - and this is going to just be http is in
27:05 - image dot get attribute src then rather
27:09 - than continuing what we want to do is
27:11 - actually add this source to r where is
27:14 - it image urls so again we're just
27:17 - checking if it actually has a source if
27:19 - it doesn't have a source then what's
27:20 - going to happen is this will return none
27:21 - and we'll just stop the if statement if
27:23 - it does have a source we'll make sure
27:25 - http is in the image source the reason
27:27 - we're doing that is to make sure that
27:28 - it's giving us a valid link that we can
27:30 - actually use to download the image so
27:33 - now what i'm going to do is say that my
27:35 - image underscore
27:37 - urls.add and i'm just going to add the
27:40 - image.getattribute
27:42 - and then this is going to be src after
27:44 - this i will simply print that i found an
27:46 - image so i'll print
27:48 - found image exclamation point like that
27:51 - great so now what we've done is we've
27:52 - added that to our where are we image
27:55 - urls so now all we need to do at the
27:57 - very end of the program here is just say
27:59 - return
28:00 - image urls now of course let me walk
28:02 - through this let me just zoom out a
28:03 - little bit so we can see this a bit
28:05 - better okay so we start up here we have
28:07 - our web driver our delay and the maximum
28:09 - number of images that we would like we
28:11 - then write our scroll down function
28:13 - which allows us to scroll down to the
28:14 - bottom of the screen we have our url
28:16 - this is the target url of the google
28:18 - images page that we want for now this
28:20 - has to be google images page if you
28:22 - wanted to change this to a different
28:23 - website you just have to look for
28:25 - different class names to find the actual
28:27 - images that you want we then are getting
28:29 - the web driver to go to this page we're
28:32 - going to make our image url set this is
28:33 - going to store all of the urls of images
28:35 - that we found we're then going to say
28:37 - while the lan of image urls is less than
28:39 - max images while we haven't found as
28:40 - many images as we want scroll to the
28:42 - bottom of the screen find all of the
28:45 - thumbnails of the images by this class
28:47 - name we then are going to loop through
28:49 - all of the images that we haven't
28:50 - currently looked at we're going to try
28:52 - to click on them we're going to give it
28:53 - a second to actually pop up the real
28:55 - image then what we will do is we will
28:57 - look for the real image in that kind of
28:59 - popped up window so something that has
29:01 - this class name we will then say for
29:03 - image and images this could potentially
29:05 - return multiple images so we want to
29:07 - look through all of these and find the
29:09 - valid image
29:10 - anyways we're going to say if
29:11 - image.getattributesrc
29:13 - so if it does have a source attribute on
29:15 - it and http is in this attribute that
29:18 - means this is a valid source for the
29:20 - image so we're going to add that to our
29:22 - image urls print found image and then
29:24 - finally once we go through the while
29:26 - loop we'll return image urls so now all
29:28 - we need to do is actually combine these
29:30 - two functions together and we should be
29:32 - able to download all of the images so we
29:34 - could theoretically inside of this
29:36 - function here just put download image
29:39 - and in fact if we do this we go download
29:41 - underscore
29:42 - image like this then we can just pass
29:45 - the image url that we found and we can
29:46 - download it but instead i'm going to do
29:48 - this outside of the function i'm first
29:50 - going to call
29:52 - this one get all of the urls and then i
29:54 - will loop through all the urls and call
29:56 - the download image function
29:58 - so we're going to say
29:59 - urls is equal to this and let's start by
30:02 - actually just printing this out and
30:03 - making sure this is giving us all of the
30:05 - valid urls that we want so i'm going to
30:07 - say print urls when i do this and i run
30:09 - the code we can sit back and we should
30:11 - be able to watch chrome go through here
30:13 - and do its thing and of course we get an
30:14 - error what is the error scroll to end is
30:16 - not defined
30:18 - okay
30:19 - i guess that's because i called this
30:20 - scroll down so let's just fix this name
30:22 - here to scroll down okay error one fixed
30:26 - let's try this now and let's see
30:31 - okay so it's scrolling down it then
30:32 - clicks on an image clicks on another
30:34 - image it should continue to click on
30:36 - images and it's going to wait two
30:38 - seconds in between this and i believe
30:40 - how many max images i put i think i put
30:42 - 10 as the max so we'll do this 10 times
30:45 - of course you can change the delay and
30:47 - you can change how many images you want
30:48 - and this will happen faster or slower
30:50 - depending on that okay we should almost
30:52 - be through 10 here
30:54 - looks like we are almost good
30:57 - ah and let's see here
31:01 - okay maybe not
31:03 - okay we clicked on another image
31:06 - it seems like we're clicking on the same
31:07 - images here so i'm gonna let this run
31:09 - for a second and see what's going on but
31:11 - we should be finished soon
31:13 - okay so i was letting that run for a
31:14 - second and it seemed like it was never
31:16 - ending so i'm just going to add a log
31:18 - here and just print
31:19 - found and we'll do an f string just to
31:22 - see how many images we've currently
31:23 - found to determine kind of the progress
31:25 - level we're at here so i'm going to go
31:26 - with found and then let's go with the
31:28 - len of and this will be image urls
31:34 - just to check why this is actually
31:35 - taking so long and then what i'm going
31:37 - to do is change the delay here to one
31:39 - and let's just make it five images to
31:41 - see if this is going to work so let's
31:43 - run the script now and see what we get
31:48 - okay so we scroll down
31:50 - click an image
31:51 - i want to see my logs here so found one
31:53 - found two found three found four and
31:57 - then it prints out all of the urls and
31:59 - okay it looks like we were good on that
32:00 - so let me change this to 10 now
32:02 - and let's see if we can actually find 10
32:04 - urls so let's run this now
32:07 - and see what we get let's move this over
32:11 - okay so found one found two
32:14 - three
32:15 - four
32:16 - five
32:19 - and for some reason it is stalling okay
32:21 - there we go found six found seven
32:23 - i guess it just takes longer than i was
32:25 - expecting
32:26 - still only found seven okay
32:29 - found seven again how is it possible oh
32:32 - i guess we're finding the same image
32:33 - multiple times okay that would make
32:35 - sense
32:36 - found seven
32:38 - ah okay so i think i see what's going on
32:41 - here we keep clicking on the same image
32:43 - so let me see if i can fix this and i'll
32:45 - be right back okay so we determined what
32:46 - the problem was is that we kept clicking
32:48 - on the same image and since we kept
32:50 - clicking on the same image what would
32:51 - happen is we would just be looping
32:52 - through the same image a bunch of times
32:54 - and then we would return back to the
32:55 - same image and while this while loop is
32:57 - just going to go infinitely because
32:58 - we're on the same image so it's actually
33:00 - really annoying to fix this problem but
33:03 - what i'm going to do is implement
33:04 - something inside of here that pretty
33:05 - much says if we found the same image
33:08 - then what we're going to do is increment
33:10 - whatever the line of image urls is and
33:13 - max images that we move on to the next
33:15 - image
33:16 - so you'll see what i mean here but i'm
33:17 - just going to put
33:18 - right here
33:19 - i'm going to say if
33:21 - the image.getattribute is inside of
33:24 - image urls so if we already have this
33:27 - source in the image urls then all we're
33:29 - going to do here is we're just going to
33:31 - break out of this for loop but first
33:34 - we're going to say
33:36 - image urls and we're just going to add
33:39 - to this uh actually i don't know if i
33:41 - can even add to this uh instead we'll do
33:43 - this we'll do
33:44 - max underscore images
33:46 - plus equals one and we're gonna say
33:48 - skips
33:49 - plus equals one we're going to write a
33:51 - variable skips is equal to zero and
33:54 - we're going to put the len of images
33:56 - image urls plus skips
33:59 - and then in the while loop condition
34:00 - same thing
34:01 - the idea being here that if we're
34:03 - skipping by one or we're skipping by two
34:05 - images
34:06 - then we'll account for that as we're
34:08 - looking for the next thumbnails and as
34:09 - we're doing the while loop condition so
34:10 - we do actually end up getting the number
34:13 - of max images that we want
34:15 - hopefully that makes a little bit of
34:16 - sense but this is kind of the quick fix
34:18 - hopefully for this so let's run this now
34:21 - and let's see if this works because
34:22 - again what was happening is we're just
34:24 - clicking on the same image a bunch of
34:26 - times and well that was not helpful
34:28 - okay found one found two found three
34:31 - found four found five
34:33 - all right let's see if we can find
34:35 - another one
34:37 - found six found seven
34:40 - all right give us a found eight here we
34:42 - keep alternating between the same image
34:44 - what the heck okay and now we've we've
34:47 - clicked into some completely different
34:48 - images found eight found nine and and
34:51 - there we go uh okay i don't know exactly
34:53 - what happened there but it looks like we
34:55 - ended up clicking on um
34:57 - some weird image that brought up an
34:59 - entirely new page i'm gonna count that
35:01 - as a success for right now let's run
35:03 - this now i'm just going to turn this
35:04 - down to 6 and what i'm going to do is
35:06 - use all of the urls now and download all
35:09 - of them so i'm just going to say 4 and
35:11 - we're going to say 4i comma and then url
35:14 - in enumerate we're going to enumerate
35:16 - over all the urls then we will download
35:18 - them we'll say download image we're
35:21 - going to pass what do we want download
35:23 - path url file name so this is going to
35:25 - be slash
35:26 - this is going to be images slash we then
35:29 - want the url and for the file name i'm
35:31 - just going to go with the string of i
35:33 - plus dot jpg
35:36 - and this needs to be in a string
35:38 - okay let me quickly explain this so we
35:40 - are just looping through all of the
35:41 - different urls that we have we'll get
35:43 - the index of the url as well as the
35:45 - actual url itself we're then going to
35:48 - say download image we'll download to the
35:50 - images folder that's why i'm doing
35:51 - images slash make sure you add the
35:53 - trailing slash here then i'm saying the
35:55 - url is well this is the image you want
35:56 - to download and then the name of this
35:58 - image is going to be string i plus jpeg
36:00 - just so i have a unique name for every
36:02 - single one of these images so let's run
36:05 - this now and let's see if we can
36:06 - successfully download six images to our
36:08 - computer
36:09 - you're going to note that it's going to
36:10 - find all of the urls first then once it
36:13 - finds all the urls it's going to
36:14 - download them one by one
36:17 - okay
36:18 - we should oh i guess so i guess it
36:20 - clicked on one of the top links which is
36:22 - what we were trying to avoid but
36:24 - regardless we're still getting some cats
36:25 - here so success success success now if i
36:28 - go to images you can see that we have
36:30 - all of these images downloaded to the
36:32 - computer starting at zero going to five
36:35 - okay so i'm going to call this a success
36:37 - for now uh again you probably have to
36:39 - tweak the script a little bit because
36:41 - what seems to be happening is it's
36:43 - clicking on images that we don't want it
36:44 - to click on but i think i've showed you
36:46 - enough to be able to kind of mess with
36:47 - this and adjust it to whatever website
36:49 - you're working with i'm not going to
36:51 - continue going through and trying to fix
36:52 - all the really tiny bugs i just think
36:54 - this is probably good enough and i will
36:56 - leave a link to this in the description
36:58 - if you want to download this code
36:59 - yourself and just go ahead and modify it
37:01 - and again a big shout out to that blog
37:03 - post i showed previously the link will
37:05 - be in the description but a lot of the
37:06 - code and the reason i was actually able
37:08 - to do this is because i followed along
37:09 - with a lot of the stuff that was inside
37:11 - of there all right so with that said i
37:13 - am going to end the video here i hope
37:15 - you found this helpful if you did make
37:16 - sure to leave a like subscribe to the
37:17 - channel i will see you in another one
37:21 - [Music]
37:27 - you

Cleaned transcript:

hello everybody and welcome to another youtube video so in today's video i'm going to show you how to web scrape and download images from the internet now what we'll actually be doing is going on google images we'll be looking for a certain number of images grabbing the source of all those images and then using the source of that image to download the image to our computer there's a variety of reasons you may want to do this the first that i could think of is you probably need testing or training data for some type of machine learning model and maybe you want hundreds of thousands of images or you want a ton of different pieces of data obviously it would not be efficient to go manually download those so you could use a script like this now of course there's a ton of other reasons and what i'm going to show you here will work for other websites it's not only going to work for google images but you will need to tweak the script slightly if you're going to apply it on a different site anyways i just want to mention before we dive into the code here that there is some legal concerns with doing this so if you're just doing you know 10 or 20 images or something you probably don't need to be concerned but if you're running really large bots that are scraping like tens of thousands of images you may get ipband you may have all kinds of things negatively occur to you and in fact if you want to potentially be able to avoid some of those issues with web scraping you should check out the sponsor of this video before we get started i need to thank smart proxy for sponsoring this video smart proxy is a smart but down to earth tech head platform that helps clients solve data access and entrepreneurship problems oftentimes you want to access or scrape data that is only accessible from a certain geographic location maybe you want to scrape and compare real estate prices data mine ecommerce products or acquire testing and training data for machine learning models well if that's the case smart proxy can help you do this smart proxy lets you bypass country restrictions and website blocks by providing the highest quality residential proxies in over 195 locations with over 40 million residential proxies you can connect to your target source as many times as you need from any type of device smart proxy also has advanced rotating proxies so you never need to worry about ip bands in addition smart proxy provides a no code smart scraper tool to perform data collection that you can use for no additional cost with a smart proxy subscription using the smart scraper is extremely simple just install the chrome extension open up a website start the scraper and select the items that you'd like to export check out smart proxy today from the link in the description to get access to the best proxies for web scraping and use the code tech with tim20 for 20 off residential and data center proxies thanks again to smart proxy for sponsoring this video alright so let's go ahead and get started the first thing we need to do here is download and set up a few dependencies for this project these are just python libraries so we're going to need pillow we're going to need requests and we're going to need selenium now we'll discuss what all of those do in a second but first let's just install them so go to your command prompt or terminal if you're on mac or linux and then you're going to type the following pip install and we'll start with pillow now you actually want a capital p here so pip install capital p pillow now for some reason that command doesn't work for you you can try doing pip 3 install pillow so just tack a 3 on right here and if that doesn't work for you i will leave two links in the description on how to fix the pip command for your system one for mac and one for windows okay so now that we have pillow we're going to install selenium so we want selenium like that notice that i already have all of these installed this is going to going to install a bunch of stuff but selenium is actually going to allow us to automate our web browser so that we can go and click on all of the images that we want to download get their source and then well download the source of the image okay so now that we have selenium the last thing that we want is requests like this this is going to be used to actually grab the data of the image that we want to download uh notice i'm getting some error here saying selenium 4.0 has requirement url lib you can just ignore that this will be fine in fact it actually fixed that error for me right here but everything should be good now okay so now that we have that we just need to install one thing that we need to use with selenium this is known as a web driver so just go to the link in the description i have it right here it is called chrome driver now i'm going to be doing this tutorial using google chrome i'm not going to show you how to do with a different web browser so just make sure you're using chrome otherwise this won't work anyways go to this link and then you want to click on one of these two versions chrome driver 95 or 94. now this is dependent on sorry the version of your google chrome so i believe i have google chrome version 94. if you had version 95 then you would download 95. anyways you can just try both of them if one of them doesn't work you can download the other one it's really easy to do this so i'm going to go with 94. again i'll leave this link in the description okay and then what you want to do is click on your operating system so i'm going to be win32 obviously you have mac and you have linux so win32 is going to download a zip folder for me so let me download that i'm going to open the zip folder and inside of here you will see that there is an executable so what i'm going to do is i'm going to cut this executable and i'm going to paste this in a location that i know so paste it pretty much anywhere on your computer so that i can use it and reference it from my python script so what i'm actually going to do is go to my desktop i have a folder here called web scripting images this is where the tutorial is going to be i'm just going to paste the executable right inside of here i know the path of this executable it would be this right here so i could just copy that path and now i'm able to actually reference this executable so just put it in a place where you are able to reference it you know the path to it because we're going to need that path in one second okay so now that the executable is installed the steps will be a little bit different for mac and linux but i trust you guys can figure that out just extract the zip folder move the executable to a path where you know the location of i can close this and this and i can go back to my python script and i'm just going to start by putting in the path of this web driver so i'm going to say path is equal to and then this now if you see something like this like this yellow highlight and kind of some errors here you just need to escape these slashes so you just put two slashes and then everything should be fine all right so let me just take a quick pause here and explain why we just did all of that so when we use selenium this allows us to automate our browser but we need a browser to automate so we need to download the web driver for whatever browser we want to use you could do this with firefox you could do this with safari but i want to use google chrome so i downloaded the chrome web driver which now allows us to use that executable file to automate chrome okay that's pretty much all we're doing here so you just need this you need to supply this to your actual what do you call it script for it to know where the executable is and then use that to automate the appropriate web browser so i have this here it's in web scraping images but i need to put the name of the driver which is chromedriver.exe so i'm going to put that like that now i'm going to go up here and i'm going to import selenium okay now i'm just going to show you how this driver works so actually i'm going to say from selenium i'm going to say import web driver like that and then i'm going to say wd standing for web driver is equal to selenium dot or actually i could just say web driver and let me check here i believe this is with no actually it's not with a capital that's fine and i'm going to say chrome because we're using google chrome and then i'm going to put the path right here to this executable file great so now that we have that what i can do is just run my code and let's see what happens here notice that we're getting this deprecation error you don't need to worry about that right now and you can see that actually opens up a google chrome window because i just started my web drive so hopefully that makes a bit of sense let me run this one more time and you can see here in google chrome it's saying chrome is being controlled by automated test software that would be selenium okay so we've got the first bit of setup done now that we've done that i want to show you simply how we can download an image so if we know the source of an image downloading it is quite simple so let me just go here to google chrome alright so you can see i'm in google chrome here notice that i was on images some google images and i searched dogs now let's just do cats and let's click on some cat okay let's right click and click inspect and then let's find the source of this image this is the source right here okay src is equal to this so this is actually the url it's using to display this image so src so what i'm going to do is paste this into a new tab and now notice it gives me the actual image itself that's great that's exactly what we want so if i just copy this here i can put this inside of my script i'll say image underscore url is equal to this and now i will show you how we can download this image all right so let's go ahead and write a function here that can download image so i'm going to say define download underscore image and then inside of here we are going to take the download path we are going to take the url and we're going to take the file name of the image that we want to download now before i go any further i do want to give credit to someone that i've kind of taken a lot of code from so there is this great blog post i need to paste it inside of here so you guys can see it on towards data science that says image scraping with python there's a ton of stuff in here i kind of just extracted some of the code that we actually need for this tutorial and i modified it but if you scroll down here it has a whole section on scraping images from google so a lot of the code i'm going to write comes right from here i've just kind of modified it and made it simpler but i just want to give credit to him i will leave this in the description in case you guys want to see the original source of a good amount of this code again i've just modified it and made a bit simpler because there was a ton and a ton of stuff in there that was kind of unnecessary for this tutorial regardless let's continue here so we have download image we have the url of the image we want to download the path to download it to and then the file name that we want to save the image as so what i'm going to do here is just say that my image underscore content is equal to and this is going to be requests dot get now that means i need to import requests so let's go up here and say import request now this allows us to make an http get request to the url so we're going to say url like that and then we're going to say dot content and this will actually give me the content of the image right because if we go to the url where the cat is this is well the image content so now that we have the content of the image i want to save the content of this image in a byte i o file type or in memory as bytes io data type so i'm going to say that my image underscore file is equal to i o so i need to import i o like this and then dot bytes i o and then inside of here i'm just going to put image content now what this is going to do is kind of convert this content right here into a bytes io data type now this is pretty much kind of like storing a file in memory i won't really explain it much more than that but we're storing pretty much the image file right here directly inside of memory now that we have that though i need to actually convert this directly to an image so that i can save it so right now we're just storing some binary data that's essentially what bytes i o is so i'm going to convert this now properly to an image using the pillow library and then save it so i'm going to say from capital pil import image like this and then i'm going to go here and say that my image is equal to and this is going to be image dot open and then inside of dot open we're just going to put the image file like this which will be our bytes i o data type so this allows us to actually load this in as an image now what i can do is actually save this image but first i need to generate the file path so i'm going to say the file path is equal to and this is going to be the download path plus and then this will be the file name okay so that is our file path now i'm going to say with open and this is going to be i guess we want the file path this is going to be in wb mode which stands for write bytes meaning we can actually write an image i'm going to say as f and then i will say image dot save i'm going to save it to f and i'm going to save it in a jpeg format okay let me look at my code i have some code on the right hand side of my screen or i guess to you guys that would be left but it's my right and just make sure this looks good everything looks good to me and we can actually go ahead and run this function now and see if this works so let's just print here success okay so let me just run through what i did here because i understand this is a bit complicated so first we actually get the content of the image this is pretty straightforward we're sending a get request to the url of the image that we want we then are saying the image file is equal to io.bytesio image content so we're taking the actual content from this request and we're going to now store this as a binary data type in our computer's memory this is very similar to storing an actual file in memory we then are going to convert this binary data to a pill image so a pillow image this just allows us to very easily save the image using image.save okay that's the first step we then generate the file path so we take the download path plus the file name combine those together that will give us the path to save the file and then we'll say okay we're going to open a brand new file that is at the file path so with whatever the name is there in wb mode which stands for write bytes so we can write bytes to this file we're going to load that as f and then we're going to say image.save we're going to save this image here to this file as a jpeg image and then print success so let's try this let's call download image let's go with download path just being nothing the reason why i'm going to put nothing is because i just want to download it in the current directory that i'm in so if you want to do that just don't put anything for the path and it will download it in the current directory for the url i'm going to pass the image url and then for the file name i'm just going to say test.jpg like that now make sure you add this as the extension otherwise it will not work okay so now that we have that let's go ahead and run the code so i'm going to run it like that let's give it a second to open up chrome i actually didn't even need to do that because we're not even using the web driver notice it says success and then if i go here to sublime you can see i have this test image and it's been downloaded to my computer great there we go okay so now we can download an image i'm just going to throw in a try and accept here though because sometimes this could fail so i'm just going to say try and i'm going to say accept and we'll say exception as e and i'm just going to print failed and then here we will print out e the point of this is just so that if this fails we can continue with the rest of our program we don't actually get an exception we just catch it and print it out okay so now that we've done that let's see how we can actually scrape a certain number of images from google images and then use the download image function to actually save the image now i'm just going to delete this images folder because this is what i was testing before so let's delete that and let's make a new folder so i'm going to go new folder like this we're going to call it images and now we can continue okay so we can get rid of this image url we can actually get rid of the call to download image because we're not going to use that right now now we can say define and we could say get images from google or whatever you want to call it doesn't really matter now inside of here we need to take in our web driver so i'm going to take in w not b wd for our chrome webdriver we're also going to need a delay and let me think if we need anything else we're going to need a max images as well so this is how many images we are going to download maximum or how many images we are going to get maximum okay so i'm going to hop over to google images here and i'm just going to run through the basic process of what we need to do here to actually click on these images and then grab the image source and download them so right now we see a bunch of images we also see some images up here okay like hidden whatever we see all of these images up here as well now when i click on the image i actually get the legitimate image source whereas when i'm just looking at them here this is just a thumbnail and it's kind of been resized it's not the actual image that i want and so what i would like to do is i would like to make it so that i click on these images and then i get the source of this image the large one that's showing up because that will be the real image i don't want to just download the thumbnails otherwise i'll get kind of the lower resolution images or just ones that are not the correct size hopefully you get what i mean so that's kind of part one that's what i want i want to be able to click on these images but then what's going to happen is as i continue to scroll down on this page we're going to load more images so notice how we get that kind of loading bar there so i need to actually have something that allows me to scroll down as well because if i want to download say a thousand images i'm going to have to scroll to the bottom of the page and then find all of the images now eventually you'll get to a point where you can actually click on load more results or it'll say you've reached the end so you do need to consider there is some edge cases here you might want to click a button that loads more results i'm not going to show you how to do that but that is something you may want to do and anyways that's kind of the first step so the thumbnails want to click on the thumbnails grab the image source and then download the image from the source however i need a way of actually finding all of these thumbnails and clicking on them so i need to find something that is similar between all of these images so i can look for something that represents all of these thumbnails images now some of you may be saying okay why don't you just search for all of the image tags on the page and if you're not familiar with selenium what you can do is you can search for class names you can search for specific tags you can search for text you can search for all kinds of stuff within an actual html document and so some of you may be saying why don't you just look for all of the img text right because if i click on this and click inspect notice this is img well the reason i can't do that is because that's going to give me these images at the top of the screen as well so instead what i actually want to look for is a class name that all of these thumbnails are going to have in common so if i go here notice that we have a class name here and i'll zoom in so you can see it but it's q4l uwd so that's the class name of this first image and if i inspect this second image right here so let's inspect it and go to it notice down here it has the same class name so what i'm going to do is search for this class name and any image that i find that has this class name i will actually try to download you'll notice if i go to this one here and i click inspect for some reason i have to keep clicking it two times this does not have that class name and so i won't get get those ones i will only get the actual thumbnails okay hopefully that makes sense but let's start off by doing that so i'm going to write a function here inside of this function i'm just going to call this scroll down and this is going to take in a web driver and does it need anything else i actually think that's all it needs okay then what i'm going to do is say dot wd.exe script now xq script means i can actually execute a javascript script and so i'm just going to execute command that scrolls me to the bottom of the screen now i believe this is window dot scroll and this will be scroll 2 and then we're going to put 0 and this will be document dot and then body dot and then what is it here i believe it's scroll height so we're just going to say scroll and height like that okay why'd it give me that i didn't want that okay so scroll height add our semicolon and there we go we now have the scroll down function i will also add something here i'm just going to say time dot sleep delay just so it gives me one second or whatever i make this delay to actually load the remainder of the images if i am scrolling down to the bottom of the screen okay so now that i have that inside of here i'm just going to paste a url now this url is going to be the url of the google images page that i actually want to scrape so what i'm going to do is just go to my browser tab here and i'm just going to copy this huge url which is for the search of cats if you want to search something else just search it copy the corresponding url and then just paste it inside of here there we go we now have our url and now i'm going to use my web driver to actually get the source the html source of this page so i'm going to say i guess wd dot get and then url this will actually load this page with my chrome web driver and then we can actually start looking through all of the images so first let's just actually run this function and see if this works so i'm just going to go down here and i'm going to say get images from google we need to pass to this a web driver a delay in max images so i'm going to pass my webdriver i'm going to pass a delay of two so two seconds and then i'm going to pass what was the last one i totally forgot max images is going to be 10. okay so let's run this and let's just see if it actually loads up this correct page notice it does it brings me to the cats page awesome okay so now that that is working i'm just going to add something here that closes my webdriver window because you'll notice that if you run this a bunch of times and you forget to close the chrome window you'll have like 100 of them open so i'm just going to say wd.quit and this will just close the actual chrome window once this function is done great okay so let's continue here i'm going to write a variable this variable is going to be image underscore urls this is going to be equal to a set just to make sure we don't have duplicate urls here we only have the same image one time and then what i'm going to do is make a while loop i'm going to say while the len of image urls is less than and then this will be the max images like this then we will continue so the point being once we have as many of as max images as we've defined here then we will stop all right so now that we've done this what i'm going to do inside of here is i'm going to start by scrolling to the bottom of the screen once i scroll to the bottom of the screen then i'm going to find all of the image thumbnails on the screen i'm going to loop through all of them try to click on them and once i click on them get the source of the image and then continue so i'm going to say scroll to end we're going to pass our web driver i am then going to say that my thumbnails is equal to and this is going to be wd dot find elements and inside of here i need to pass something that i need to import so i'm going to say from selenium.webdriver.com.buy import buy you'll see why we need this in one second but just write this import line then here i'm going to say buy dot and this is going to be in all capitals class name and i'm going to put that class so let's go back here and remember what that class was that class was q4 luwd again i'll zoom in so you guys can see that and let's paste that right here so this is the class name that i'm looking for this is going to give me any tags that contain this class name if any of this selenium stuff is confusing again i have an entire tutorial series on it so i'll leave a link to that in the description anyways what this is going to do is find all of the elements on the page that have a class name of this that's why i needed to import by so i could specify we're looking by the class name then what i can do is i can loop through all of the thumbnails and i can try to click on them so i'm going to say for image in thumbnails like this and actually what i'm going to do is go here and say the len of and this is going to be image urls to the max images now the reason why i'm doing this is because this while loop will continue to run until we've loaded and well got enough image urls so the point is when i'm looping through the thumbnails i don't want to be looping through thumbnails that i've already looped through and so if i say have 10 thumbnails already when i run this command again it's going to give me those same 10 thumbnails plus any more additional thumbnails that were loaded after i scrolled to the bottom of the screen so what i will do is start looping only after the thumbnails that i've already added to the uh the thumbnails list or to the image urls list hopefully that makes a bit of sense i just don't want to be adding the same thumbnails multiple times so we start at whatever the len of this is to make sure we avoid doing that then of course we only go up to the number of max images so we're not adding more images than what we specified okay so that's why we have that slice there now inside of here i'm just going to do a try except and inside of try i'm going to say image dot click we're then going to wait by our delay so we're going to say time dot sleep and we're going to sleep by whatever the delay is now i need to import time because i realize i don't have that so let's go import time you don't need to install this this is a builtin module same with io as i'm sure you probably have realized by now so we'll try to click on the image we'll then sleep now we're just going to have an accept and say accept and then continue now the reason why i'm having this is because we could potentially get an error when we try to click on this image so if that happens we don't want to interrupt the whole script so we'll just continue which means go to the next item in the for loop so now that we've clicked on the image though we want to find that larger image and then get the source of that image and add it to our image urls so let's look at this now so at this point what we've done is if this will load here why is it so laggy come on fix yourself okay that's a bit better anyways what's going to happen is we would have scrolled to the bottom of the screen right and then we would have clicked on some image and this image now is load on the screen so the screen looks like this so if i go here and i click inspect we can see that this is inside of a div now it's inside of the image tag sorry chrome's just lagging really hard here but if i look at this image i want to find a class name or something i can use to identify this specific image and it turns out that if i go here and i look at the class names we have a class which is equal to n3vncb now this is the only image on this page that has this class so what i'm going to do is i'm going to use that class to access this larger image and then add the source of that image okay so let's do that so i'm just going to paste this in here just so we have this all right so now we will do is say that images is equal to and then this is going to be wd dot find underscore elements we're gonna do the same thing we did before we're gonna do by class underscore name in all capitals and then we're just going to pass as a string this guy right here which is the class name that we're looking for now ideally this should just give us one image but it could potentially return multiple and so what we're going to do is loop through all of the things that this returns just in case something else does have the same class name as this we're going to do some checks on all these images and we're going to see if they have a proper image source if they do have a proper image source then we will get that image source and add it to our image urls so i'm just going to say 4 img or 4 image in images like that then what i will do is i will check the attributes of this image and to see if it has a source tag so i'm just going to say if image dot get underscore attribute and this will be src again the source of the image that we're looking for so if it does have that attribute and we will say http and this is going to just be http is in image dot get attribute src then rather than continuing what we want to do is actually add this source to r where is it image urls so again we're just checking if it actually has a source if it doesn't have a source then what's going to happen is this will return none and we'll just stop the if statement if it does have a source we'll make sure http is in the image source the reason we're doing that is to make sure that it's giving us a valid link that we can actually use to download the image so now what i'm going to do is say that my image underscore urls.add and i'm just going to add the image.getattribute and then this is going to be src after this i will simply print that i found an image so i'll print found image exclamation point like that great so now what we've done is we've added that to our where are we image urls so now all we need to do at the very end of the program here is just say return image urls now of course let me walk through this let me just zoom out a little bit so we can see this a bit better okay so we start up here we have our web driver our delay and the maximum number of images that we would like we then write our scroll down function which allows us to scroll down to the bottom of the screen we have our url this is the target url of the google images page that we want for now this has to be google images page if you wanted to change this to a different website you just have to look for different class names to find the actual images that you want we then are getting the web driver to go to this page we're going to make our image url set this is going to store all of the urls of images that we found we're then going to say while the lan of image urls is less than max images while we haven't found as many images as we want scroll to the bottom of the screen find all of the thumbnails of the images by this class name we then are going to loop through all of the images that we haven't currently looked at we're going to try to click on them we're going to give it a second to actually pop up the real image then what we will do is we will look for the real image in that kind of popped up window so something that has this class name we will then say for image and images this could potentially return multiple images so we want to look through all of these and find the valid image anyways we're going to say if image.getattributesrc so if it does have a source attribute on it and http is in this attribute that means this is a valid source for the image so we're going to add that to our image urls print found image and then finally once we go through the while loop we'll return image urls so now all we need to do is actually combine these two functions together and we should be able to download all of the images so we could theoretically inside of this function here just put download image and in fact if we do this we go download underscore image like this then we can just pass the image url that we found and we can download it but instead i'm going to do this outside of the function i'm first going to call this one get all of the urls and then i will loop through all the urls and call the download image function so we're going to say urls is equal to this and let's start by actually just printing this out and making sure this is giving us all of the valid urls that we want so i'm going to say print urls when i do this and i run the code we can sit back and we should be able to watch chrome go through here and do its thing and of course we get an error what is the error scroll to end is not defined okay i guess that's because i called this scroll down so let's just fix this name here to scroll down okay error one fixed let's try this now and let's see okay so it's scrolling down it then clicks on an image clicks on another image it should continue to click on images and it's going to wait two seconds in between this and i believe how many max images i put i think i put 10 as the max so we'll do this 10 times of course you can change the delay and you can change how many images you want and this will happen faster or slower depending on that okay we should almost be through 10 here looks like we are almost good ah and let's see here okay maybe not okay we clicked on another image it seems like we're clicking on the same images here so i'm gonna let this run for a second and see what's going on but we should be finished soon okay so i was letting that run for a second and it seemed like it was never ending so i'm just going to add a log here and just print found and we'll do an f string just to see how many images we've currently found to determine kind of the progress level we're at here so i'm going to go with found and then let's go with the len of and this will be image urls just to check why this is actually taking so long and then what i'm going to do is change the delay here to one and let's just make it five images to see if this is going to work so let's run the script now and see what we get okay so we scroll down click an image i want to see my logs here so found one found two found three found four and then it prints out all of the urls and okay it looks like we were good on that so let me change this to 10 now and let's see if we can actually find 10 urls so let's run this now and see what we get let's move this over okay so found one found two three four five and for some reason it is stalling okay there we go found six found seven i guess it just takes longer than i was expecting still only found seven okay found seven again how is it possible oh i guess we're finding the same image multiple times okay that would make sense found seven ah okay so i think i see what's going on here we keep clicking on the same image so let me see if i can fix this and i'll be right back okay so we determined what the problem was is that we kept clicking on the same image and since we kept clicking on the same image what would happen is we would just be looping through the same image a bunch of times and then we would return back to the same image and while this while loop is just going to go infinitely because we're on the same image so it's actually really annoying to fix this problem but what i'm going to do is implement something inside of here that pretty much says if we found the same image then what we're going to do is increment whatever the line of image urls is and max images that we move on to the next image so you'll see what i mean here but i'm just going to put right here i'm going to say if the image.getattribute is inside of image urls so if we already have this source in the image urls then all we're going to do here is we're just going to break out of this for loop but first we're going to say image urls and we're just going to add to this uh actually i don't know if i can even add to this uh instead we'll do this we'll do max underscore images plus equals one and we're gonna say skips plus equals one we're going to write a variable skips is equal to zero and we're going to put the len of images image urls plus skips and then in the while loop condition same thing the idea being here that if we're skipping by one or we're skipping by two images then we'll account for that as we're looking for the next thumbnails and as we're doing the while loop condition so we do actually end up getting the number of max images that we want hopefully that makes a little bit of sense but this is kind of the quick fix hopefully for this so let's run this now and let's see if this works because again what was happening is we're just clicking on the same image a bunch of times and well that was not helpful okay found one found two found three found four found five all right let's see if we can find another one found six found seven all right give us a found eight here we keep alternating between the same image what the heck okay and now we've we've clicked into some completely different images found eight found nine and and there we go uh okay i don't know exactly what happened there but it looks like we ended up clicking on um some weird image that brought up an entirely new page i'm gonna count that as a success for right now let's run this now i'm just going to turn this down to 6 and what i'm going to do is use all of the urls now and download all of them so i'm just going to say 4 and we're going to say 4i comma and then url in enumerate we're going to enumerate over all the urls then we will download them we'll say download image we're going to pass what do we want download path url file name so this is going to be slash this is going to be images slash we then want the url and for the file name i'm just going to go with the string of i plus dot jpg and this needs to be in a string okay let me quickly explain this so we are just looping through all of the different urls that we have we'll get the index of the url as well as the actual url itself we're then going to say download image we'll download to the images folder that's why i'm doing images slash make sure you add the trailing slash here then i'm saying the url is well this is the image you want to download and then the name of this image is going to be string i plus jpeg just so i have a unique name for every single one of these images so let's run this now and let's see if we can successfully download six images to our computer you're going to note that it's going to find all of the urls first then once it finds all the urls it's going to download them one by one okay we should oh i guess so i guess it clicked on one of the top links which is what we were trying to avoid but regardless we're still getting some cats here so success success success now if i go to images you can see that we have all of these images downloaded to the computer starting at zero going to five okay so i'm going to call this a success for now uh again you probably have to tweak the script a little bit because what seems to be happening is it's clicking on images that we don't want it to click on but i think i've showed you enough to be able to kind of mess with this and adjust it to whatever website you're working with i'm not going to continue going through and trying to fix all the really tiny bugs i just think this is probably good enough and i will leave a link to this in the description if you want to download this code yourself and just go ahead and modify it and again a big shout out to that blog post i showed previously the link will be in the description but a lot of the code and the reason i was actually able to do this is because i followed along with a lot of the stuff that was inside of there all right so with that said i am going to end the video here i hope you found this helpful if you did make sure to leave a like subscribe to the channel i will see you in another one you
