With timestamps:

00:00 - hey guys and welcome back so I actually
00:02 - just finished editing all the footage
00:03 - you're about to see and I want to give
00:04 - you a quick overview and quick recap of
00:06 - exactly what this video is gonna be
00:08 - about because is a bit of a longer video
00:10 - than I typically post so this video in
00:12 - this tutorial is about time complexity
00:14 - and big o-notation now I don't focus
00:17 - tremendously on exactly how to write big
00:19 - o-notation and go super in-depth but my
00:21 - main goal is to give you guys kind of a
00:23 - fundamental understanding so that you
00:24 - can use that knowledge to apply it to
00:26 - your own programming and your own code a
00:29 - lot of people aren't aware of the
00:30 - effects that their programming and those
00:32 - scripts their writing have on their code
00:34 - and how slow it can possibly rerunning
00:36 - so in this video what we do is the first
00:38 - 15-20 minutes we kind of go through and
00:40 - talk about what is big o-notation how it
00:42 - works quick summary and then we actually
00:44 - get into a bunch of algorithms that i've
00:45 - wrote and we analyze them and see how
00:48 - fast or how slow they are this should
00:50 - hopefully allow you to write better code
00:52 - faster code and if you don't know this
00:54 - obviously you're gonna learn so it's a
00:56 - really fundamental skill if you're in
00:57 - any kind of computer science field where
00:59 - a programmer in general it's something
01:00 - you definitely should know and if you
01:02 - don't I highly encourage you to watch
01:04 - through the entire video and make sure
01:06 - that you actually understand everything
01:08 - that I'm talking about so with that
01:09 - being said let's get into the video
01:11 - before I get too far into the content
01:13 - I'd like to announce that I'm actually
01:14 - partnering with Microsoft and they're
01:16 - sponsoring this video for me to talk to
01:18 - you guys but a new project they've
01:20 - started called the Microsoft dev
01:22 - collective now this is a really exciting
01:24 - and great opportunity for you guys and
01:26 - essentially the Microsoft dev collective
01:28 - is a community of developers where you
01:30 - can go to learn and collaborate right
01:33 - now by just simply signing up and
01:35 - becoming a part of the dev collective
01:37 - you're gonna gain access to over 30 free
01:39 - courses that's right completely free you
01:41 - don't have to pay for anything there's a
01:43 - link in the description and if you go
01:45 - there it's gonna bring you to a page
01:46 - that has a bunch of courses that look
01:48 - just like this let me show you okay guys
01:51 - so I'm on the Microsoft dev collective
01:52 - website here I'm just gonna click on
01:54 - Explorer and I can have a look at all of
01:56 - the different courses that they have to
01:57 - offer as of now so like I mentioned this
02:00 - is a brand new thing and there's gonna
02:01 - be new content added on here monthly so
02:03 - make sure you guys are continually
02:04 - having a look at this because since the
02:06 - first time I looked at it there's been
02:08 - some new courses and I know that they're
02:09 - adding a lot of different content that's
02:11 - gonna be super valuable
02:12 - so I just signed in here so I can gain
02:14 - access to all these courses but
02:16 - essentially I'm gonna go to topics and
02:17 - just go to languages and this is where
02:19 - my tutorial will be showing up and
02:21 - essentially you can have a look at just
02:23 - some of the stuff they have like
02:24 - programming foundations programming
02:25 - foundations object-oriented design and
02:28 - make your C shop sharp code more
02:29 - functional just a ton of awesome
02:31 - resources and I know if you guys have a
02:32 - look at here you're probably gonna find
02:34 - something that interests you and it's
02:35 - free so what's the parm and having a
02:37 - look at it and checking it out so
02:38 - anyways that's been it for this little
02:40 - odd thing I hope you guys did listen to
02:41 - this and I hope you're gonna get some
02:42 - value from this and now on to the video
02:44 - okay so what this tutorial is really
02:47 - gonna focus on is time complexity in Big
02:49 - O notation now I'm not trying to make
02:51 - you guys pros in this but I really want
02:53 - by the end of this video that you guys
02:55 - are gonna be able to look at certain
02:56 - algorithms maybe something that looks
02:58 - like this analyze them and get some kind
03:00 - of idea of how long it's gonna take for
03:02 - them to run now this is a really
03:04 - important skill it's taught a lot in
03:06 - computer science in general I don't
03:08 - really care if you guys know how to do
03:10 - like Big O of N or N squared or like n
03:13 - plus-1 I just want practically you would
03:15 - be able to look at an algorithm and be
03:17 - like okay so like based on my knowledge
03:19 - kind of time complex seeing how things
03:21 - work this is gonna take a long time to
03:23 - run and the reason why that's really
03:24 - important is because when you guys are
03:26 - writing code I see it a lot with
03:27 - beginners they have no idea about how
03:29 - long it actually takes for something to
03:31 - run and if you're trying to run things
03:33 - on like thousands and thousands of lines
03:35 - of input or less massive I don't know
03:38 - like text files or something like that
03:39 - and you have a really inefficient
03:41 - algorithm or inefficient code it's gonna
03:43 - take forever and it might not even run
03:45 - so I just want you to be conscious of
03:47 - the fact that your code really has an
03:49 - effect on how long it takes for the
03:51 - computer to execute something and
03:52 - typically the faster something is the
03:55 - better now we're gonna talk about a
03:57 - bunch of different algorithms here that
03:58 - I've personally just wrote myself some
04:00 - of them are like very well known but
04:02 - I've just created a few and I'm gonna be
04:04 - doing this in JavaScript but it doesn't
04:06 - really matter if you don't know
04:07 - JavaScript because this is just I'm not
04:09 - gonna be writing any code you're not
04:11 - gonna be we're just gonna be analyzing
04:12 - it so as long as you can kind of get an
04:14 - idea of what this code is doing and
04:15 - you've programmed before you're gonna
04:16 - have no problem following along with
04:18 - this if you don't know JavaScript okay
04:20 - so with that being said let's get
04:22 - started let's talk about Big O notation
04:23 - and
04:24 - complexity okay so what is Big O
04:27 - notation well Big O notation why is this
04:31 - not drawn I'm on the eraser that's why
04:32 - Big O notation is essentially just a
04:35 - fancy word or fancy notation for
04:37 - denoting how long it takes for certain
04:39 - algorithm to run so yeah I've already
04:41 - said algorithm like a hundred times but
04:42 - that's what we're gonna be focusing on
04:43 - algorithms now what is an algorithm
04:45 - essentially an algorithm is a set of
04:47 - instructions and typically in computers
04:50 - based on some input it takes like a
04:53 - certain amount of time to execute and
04:54 - that's what we're really gonna be
04:55 - focusing on here so algorithms set of
04:57 - instructions Big O notations how long
05:00 - does it take this set of instructions to
05:01 - run based on some kind of input so what
05:04 - we're mainly focusing on here is input
05:07 - okay so in a specifically input size and
05:10 - then that's gonna be related to time so
05:14 - based on some kind of input size how
05:17 - much time can we relatively expect this
05:19 - algorithm to take now I'm not saying
05:21 - we're gonna measure it in seconds we're
05:23 - actually just gonna measure it in like
05:24 - relative operations and what I mean by
05:27 - that is like an operation could be
05:29 - something like adding 1 to a number or
05:31 - like grabbing information from an array
05:33 - that's how we're gonna measure an amount
05:35 - of operations because obviously based on
05:37 - different computers things are gonna run
05:39 - a different time and there's a ton of
05:41 - different factors that affect the actual
05:43 - time but we just want to get some kind
05:44 - of idea like are we gonna sit here for
05:46 - hours or is it gonna happen in a few
05:47 - seconds and that's the main idea of Big
05:50 - O notation now quickly before I go on
05:53 - something that's important to understand
05:55 - is that when we talk about Big O
05:57 - notation we're typically talking about
05:58 - very large massive amount of information
06:01 - now what I mean by that is for example
06:04 - if you have an algorithm that needs to
06:06 - run something on like five numbers okay
06:09 - let's say we have like one two three
06:11 - four or five like this is our list okay
06:13 - you need to do something with this list
06:15 - well computers are super fast like they
06:18 - can do thousands of operations per
06:19 - second so if we have an algorithm it's
06:21 - like pretty inefficient but we're only
06:22 - taking like I don't know we're only
06:24 - using like five elements like we're not
06:26 - gonna be using that algorithm very often
06:28 - we just then it doesn't really matter
06:29 - how inefficient it is because it's still
06:32 - gonna happen almost instantly you know
06:34 - what I mean it's like if you write one
06:36 - line of code and it
06:38 - have been replaced with like five that
06:40 - was a lot faster well if we're only
06:41 - using like a really small amount of
06:43 - input it's kind of negligible because
06:45 - you're saving like maybe like a
06:46 - millisecond right so it's almost just we
06:49 - don't really care about smaller data
06:50 - sets we only care about large data sets
06:52 - and you guys will see what I mean as we
06:54 - go through here okay so now I'm hoping
06:58 - you guys have a little bit of a math
06:59 - background because I'm gonna start kind
07:01 - of just drawing some functions here and
07:03 - talking about growth and yeah so what
07:07 - we're gonna do is I'm gonna draw two
07:08 - axes here okay and I'm gonna call this
07:10 - my time axis okay and this is gonna be n
07:14 - now I haven't talked about and yet since
07:16 - we're gonna do now
07:17 - so essentially remember I was talking
07:19 - about we only really care about large
07:21 - data sets or like large amount of
07:23 - information essentially we're trying to
07:24 - figure out based on some kind of input
07:26 - how long is our algorithm gonna take
07:29 - relative to that input is gonna take
07:31 - like five times that input like how many
07:33 - operations are gonna do on that input
07:35 - that's what we want to know so our input
07:37 - like if we have let's say an array okay
07:40 - the length of that array is gonna be
07:43 - noted denoted by n so n you're gonna see
07:46 - me use this a lot this just means the
07:48 - length of the array so if we have an
07:49 - array like this we go from 1 comma dot
07:53 - dot dot to n so the length of this array
07:56 - is n that's really important we're gonna
07:58 - be that's gonna be brought up a lot so
07:59 - let's get rid of all this now this
08:02 - eraser is not that easy to use okay
08:04 - there we go
08:05 - so based on some kind of input and we're
08:08 - gonna be figuring out how many
08:09 - operations in other words like how much
08:11 - time is it gonna take us to run so I'm
08:12 - just gonna draw two functions on here
08:14 - and I want you guys just to think about
08:16 - which one you would rather have okay
08:17 - keep in mind everything we want is like
08:19 - super efficient like that's what we're
08:21 - aiming for
08:21 - okay so let's draw this and let's draw a
08:27 - purple one that looks something like
08:30 - this
08:31 - okay so we kind of have these this
08:33 - intersection point here at this purple
08:35 - dot but these are three different
08:36 - functions now if you guys know anything
08:38 - about math you should know what these
08:40 - functions might be so for example if
08:42 - this function could be something like
08:44 - time equals n this function can be
08:48 - something like time equals log
08:52 - and and this function could be something
08:55 - like time equals and then maybe
08:59 - something like N squared okay like a
09:01 - quadratic function which mean it would
09:03 - go like that too but we're not we don't
09:04 - care about the negative side okay so
09:06 - three different functions now I'm gonna
09:09 - ask you if you're running an algorithm
09:11 - and you want it to run as fast as
09:13 - possible based on like massive amount of
09:15 - input which function would you take like
09:17 - let's say these are three algorithms
09:18 - these are how long they take do you want
09:20 - this one
09:21 - do you want this one or do you want this
09:22 - one for how much time they're gonna take
09:24 - just based on their graphs expecting
09:26 - that this is gonna continue on to
09:28 - infinity right which one would you want
09:29 - well I would hope that you guys would
09:31 - say this purple one right that you guys
09:33 - would want this purple function which is
09:35 - login now the reason you'd want that is
09:37 - obviously because as the size of the
09:39 - input increases the time is very slowly
09:42 - increasing like look have a look at it
09:44 - here right so at the beginning it
09:45 - increases faster than all the other ones
09:47 - but once we get to this point here it
09:50 - starts slowing down and the slope is
09:52 - actually decreasing as we continue to go
09:54 - all right let's have a look at the red
09:56 - one in comparison well the red one is
09:58 - actually wait it's it's faster up until
10:00 - this point right because the time is is
10:01 - slower but as soon as we hit here you
10:04 - can see it starts exponentially
10:05 - increasing increasing increasing and
10:07 - keeps going and this green one
10:09 - well this one's fine but it's just a
10:11 - straight line it's linear so essentially
10:12 - it increases at the same rate the entire
10:14 - time based on n time is gonna be exactly
10:18 - n right so just we want this this log n
10:21 - now some people would say though well
10:23 - what if our input size is like let's say
10:26 - this is like N equals 5 okay let's just
10:28 - say that's the number I know it's not
10:29 - let's say that's number well if we had
10:31 - an input of like size 3 so maybe like
10:34 - somewhere here which function would you
10:36 - want we'd probably want this red one
10:38 - because the time is the shortest but the
10:40 - thing is yes you would want that for the
10:43 - shorter amount of input but as this
10:45 - input gets larger larger larger larger
10:47 - larger you can see that this goes way
10:49 - faster so that's why we really care
10:52 - about when n approaches infinity so when
10:55 - n is like a massive number as opposed to
10:57 - anything on kind of the left side of
11:00 - this like intersection point between
11:01 - different algorithms and different
11:02 - functions I hope that kind of made
11:04 - this is the visual right of the speeds
11:06 - for our time okay
11:09 - so we've just kind of found out now that
11:12 - log n right this is this is a way we're
11:14 - gonna use Big O notation with log in as
11:16 - well we'll talk about that in a second
11:17 - is way faster you can do way more
11:20 - operations with log n than N squared
11:23 - right or then time at not more operation
11:26 - sorry it's just faster in terms of time
11:28 - so these are kind of a few standard
11:31 - function times like how algorithms run
11:34 - in these certain times okay so let's now
11:36 - start I guess maybe analyzing some
11:38 - algorithms talking about how we actually
11:40 - write Big O notation and stuff like that
11:42 - okay so remember I said our input size
11:45 - is n so n is our input okay
11:48 - now when we write Big O notation so
11:51 - we're trying to figure out how long
11:52 - something's gonna take to run or we know
11:54 - how long it takes to run what we do is
11:56 - we write a Big O we put brackets and
11:58 - then in the brackets we put some kind of
12:01 - function based on our n so the function
12:04 - could be like n plus 1 or n plus 2 sorry
12:07 - it could be like N squared it could be
12:09 - log n it could be anything like that now
12:12 - remember how I was saying we only really
12:15 - care about massive inputs right so when
12:18 - n approaches infinity well if you've
12:20 - ever done anything with limits you
12:22 - understand what I'm about to do here but
12:23 - let's say we have a function R let's say
12:26 - the amount of operations that some
12:27 - algorithm does is like 3n plus 7 okay
12:31 - like this is the function like if I were
12:33 - to draw it then we would have like a
12:34 - little grid this would be 7 we would go
12:37 - like that okay that's what our function
12:38 - would look like now we only care about
12:41 - massive input sizes so what we can
12:44 - actually do is we have a function that
12:46 - looks something like 3 n plus 7 we can
12:48 - actually simplify this and what we can
12:51 - do is we can remove all of the constants
12:53 - now what are constants in this what's a
12:57 - constant a constant is something that
12:58 - doesn't change it stays the same so
13:01 - let's have a look at this this +7 this
13:04 - is a constant so essentially whatever
13:06 - the size of n is so like n could be
13:08 - infinity we're gonna do that
13:10 - times 3 so 3 times infinity plus 7 now
13:15 - let's let's think about this right so if
13:16 - n is infinity because that's
13:18 - care about massive inputs does adding 7
13:20 - to infinity really change how long this
13:24 - is gonna take like imagine imagine 10
13:27 - billion add 7 to it it's still pretty
13:31 - close to 10 billion right like that 7
13:34 - didn't really make a massive difference
13:35 - so what we can actually do is we can
13:38 - omit this 7 we can delete it and why can
13:40 - we delete it because it's a constant
13:42 - even if the constant was something like
13:44 - like 10,000 we can get rid of it we can
13:48 - delete it and the reason we can do that
13:50 - is because we only care about the input
13:52 - size at massive numbers so we can get
13:55 - rid of those constants all right listen
13:58 - let's now we have 3n so what about what
14:01 - about 3 there any other constants left
14:02 - well 3 is actually a constant as well
14:04 - and the reason it's a constant is
14:06 - because it's not a variable like any
14:07 - number that's not a variable is a
14:09 - constant or a function so we have 3 okay
14:12 - so this is a constant as well so let's
14:13 - think about this now so what we've done
14:15 - is we've simplified this to 3 times
14:17 - infinity now 3 times infinity what is
14:20 - that equal well that actually equals
14:22 - infinity 3 anything times infinity plus
14:25 - infinity divided by infinity is still
14:27 - infinity because it's just an arbitrary
14:29 - term we don't really know what infinity
14:31 - is so what we can actually do is we can
14:33 - remove this 3 as well so we went from a
14:36 - function that was 3 n plus 7 to simply n
14:40 - right so if we compared them on a grid
14:43 - we would have had this one which was
14:45 - that original function and now we have a
14:47 - function that looks kind of like that
14:48 - right so maybe this one had like a
14:50 - higher slope like that but now we have
14:51 - one that looks like this now the reason
14:53 - we can do that you're like well these
14:54 - functions are different I agree
14:56 - functions are different but the thing is
14:57 - they're both linear meaning that as n
15:00 - increases
15:02 - what do you code the time increases
15:04 - linearly not exponentially it doesn't
15:06 - grow any faster it grows at the same
15:08 - rate and that's what we care about the
15:09 - rate of growth of our function we don't
15:12 - really care about how like the exact
15:15 - number that it is we just care if it's
15:17 - linear if it's quadratic if it's
15:19 - exponential if it's cubic that's what we
15:22 - care about and we're gonna go through a
15:23 - bunch of examples of different ones
15:24 - right now ok so that's how we kind of
15:26 - simplify our things we can remove the
15:29 - constants meaning we don't really care
15:31 - but like it was plus tens or this plus
15:32 - fifteen to the three times we only care
15:35 - about the actual kind of variable value
15:37 - and what that means in terms of growth
15:39 - so just the type of function really so
15:42 - let's do let me just draw a few examples
15:44 - of some pretty common what do you call
15:47 - it like Big O notation there's some
15:49 - pretty common like runtime complexities
15:51 - alright so let's do a grid and we
15:53 - already did the linear one right we
15:56 - already did the log and we already did
15:58 - the quadratic which looks like that okay
16:01 - these are three very very common Big O
16:04 - notation Zoar like runtime analysis that
16:06 - you're gonna see a lot and when we start
16:08 - going into actually analyzing algorithms
16:09 - you guys should understand this a lot
16:11 - better okay so those are three common
16:13 - ones but there's two more that we want
16:15 - to talk about and we're gonna rank them
16:17 - in terms of like how long they take
16:20 - which one is slower which one is faster
16:21 - so we didn't log in but what about what
16:25 - do you call it let's see what about two
16:27 - to the N so we did um what was it we did
16:30 - N squared but we also did two to the N
16:33 - so who knows what's faster two to the N
16:35 - or N squared well two to the N is
16:38 - actually way way way slower than N
16:42 - squared so this is 2 to the N okay and
16:46 - if we do N squared N squared looks
16:50 - something like that so they both grow
16:52 - exponentially but 2 to the n grows way
16:54 - faster than N squared so if I gave you
16:57 - two algorithms and I said Al gwon well
16:59 - it's time it takes two to the N to run
17:02 - and I said how to that takes N squared
17:05 - which one would you pick you'd pick N
17:08 - squared okay so that's just important to
17:09 - understand cuz a lot of people don't
17:10 - know to the end although it seems like
17:12 - oh and to the N is a way it takes a lot
17:14 - longer and a lot more operations than N
17:16 - squared I'm gonna show you an example of
17:18 - two at the end of the second as well
17:19 - okay so there we go so that's another
17:21 - example of one some other common ones
17:23 - can use more than one variable so
17:26 - sometimes when we do algorithms we might
17:28 - have more than one list or more than one
17:30 - I don't know input right we could have
17:32 - two inputs like say we have a function
17:33 - and it takes two inputs so let's say we
17:36 - have an input and one and we have an
17:38 - input and two now a common runtime
17:42 - analysis for two inputs is something
17:43 - like big
17:44 - of n1 plus n2 now can we simplify this
17:50 - any further
17:51 - right so remember I was saying like if
17:52 - we have 3n plus 7 we can just scratch
17:55 - out the 7 we can scratch out the 3 we
17:57 - only care about the end because that's
17:58 - kind of the rate of growth right and
18:00 - then I guess we can do the same thing if
18:02 - we have something like 3 and squared
18:05 - well we can get rid of the 3 and we'll
18:08 - just keep the N squared because that
18:09 - shows us kind of the shape of growth
18:10 - which what is what we care about ok what
18:13 - if we have n 1 plus n 2 well the thing
18:16 - is these are different lists right are
18:18 - different size inputs so we need to keep
18:21 - both of them because this one could be
18:24 - like way larger than the other one so we
18:27 - need to keep both of these so whenever
18:28 - you have kind of two variables you have
18:30 - to keep them both alright so now we've
18:33 - kind of talked about that a bit we're
18:35 - gonna show I'm gonna show some more
18:36 - advanced examples of like big way
18:38 - notations on how you kind of simplify
18:39 - them and then we'll actually start
18:40 - analyzing and hopefully they'll start
18:41 - making more sense okay so now I'm just
18:44 - gonna look at a more advanced example
18:46 - and how we can simplify this and
18:47 - remember we really care about the shape
18:49 - of the function right so what we're
18:51 - gonna do now is this might be a bit
18:52 - complicated you guys you might not
18:54 - understand why I'm doing this but I'm
18:55 - gonna say if we have a function that's
18:56 - like 3 n cubed plus n ok how do we
19:02 - simplify this well first of all you'll
19:03 - say ok we can get rid of the 3 correct
19:05 - so now we have n cubed plus n now the
19:09 - thing is what term in here defines the
19:13 - growth of the function which one
19:14 - increases the quickest well n cube is
19:17 - like like that whereas n is just a
19:20 - straight line so obviously n cubed is
19:23 - the faster term so it's the more
19:24 - important term it really dictates how
19:27 - large we the inputs gonna get like a
19:30 - thousand cubed is a large number and
19:32 - then you're gonna add a thousand to it
19:34 - right so what we can actually do here is
19:37 - we can simplify this to just be n cubed
19:41 - now why can we do that well first of all
19:43 - these are the same variable ok that's
19:45 - important to know if this was n cubed
19:46 - plus like n/2 so N 1 cubed plus n 2 we
19:50 - couldn't do that because n 2 could be
19:52 - like a massive number which would
19:53 - actually change this right so different
19:56 - variables to meet both of them
19:57 - but if we have the same variable so n
20:00 - cubed plus n n cubed really dictates how
20:03 - the functions gonna grow and that's the
20:05 - principal term that's what they call it
20:07 - so we can simplify this so n cubed plus
20:09 - n to just be n cubed and that's
20:12 - important understand we're not gonna
20:13 - this is like a bit more advanced when
20:14 - you desert doing stuff like this but
20:16 - that's just important understand that we
20:18 - really like this is the term that's
20:19 - gonna dictate how fast the function
20:21 - grows and that's what we care about so
20:23 - we would just say this is Big O of N
20:25 - cubed because that's what dictates how
20:28 - fast it grows ok so now we're done with
20:31 - all the drawing let's start getting into
20:33 - actually the real analysis actually
20:36 - we're probably gonna have to still draw
20:37 - but all like well we're gonna read
20:39 - through some of these algorithms or
20:40 - should hopefully be a bit more exciting
20:41 - and entertaining
20:42 - ok so close that so this is our first
20:45 - algorithm and this is known as the
20:47 - linear search algorithm and essentially
20:48 - what this algorithm does is it give in
20:51 - some input so of size n so in this case
20:54 - we're giving it a list or an array it's
20:57 - gonna find a given number so for example
20:59 - here we have this list or this array all
21:02 - right that has how many elements one two
21:03 - three four five six seven eight nine ten
21:06 - so we have N equals 10 right 10 elements
21:10 - and then what we're doing is we're gonna
21:12 - pass to our function the array and the
21:14 - number that we're looking for and it's
21:16 - gonna attempt to find this number the
21:17 - index where it occurs so what this does
21:20 - it does it has a for loop and it looks
21:23 - and it says if we find like we loop
21:26 - through the array if we find it will log
21:28 - that index so let's just first run this
21:29 - you can see I've been testing them here
21:31 - so I'll just call this one linear search
21:36 - okay and you see found at index 4 so
21:39 - essentially it found 32 at index 4 which
21:41 - would be the correct index for 32 all
21:44 - right so how do we figure out the Big O
21:45 - notation of this function this is our
21:47 - algorithm right and we're just we're
21:49 - using the algorithm down here but this
21:50 - is our algorithm how do we figure out
21:51 - the Big O notation well let's try okay
21:55 - so this is our algorithm obviously the
21:57 - stuff that's highlighted what we want to
21:58 - do is figure out how long this is gonna
22:00 - take to run in terms of n so arr so this
22:03 - right here is n ok and this can change
22:05 - obviously we could have more elements we
22:07 - get have less elements so ARR up in this
22:09 - parameter is going
22:10 - the length of n right that's what we're
22:15 - saying
22:15 - so that's length of n this list down
22:18 - here's what we're passing and what we're
22:20 - doing let's actually let me undo all
22:21 - this so we can actually see everything
22:23 - that's happening here is uh
22:25 - see we're gonna loop through the entire
22:27 - array so essentially we're gonna say I
22:29 - is gonna go from zero dot dot dot to n
22:33 - minus 1 right because we're gonna loop
22:35 - through the entire array so if the
22:35 - length is ten will be only go to 9
22:37 - because index 9 hopefully guys get that
22:39 - so how many operations are we doing
22:42 - based on an input n well we're gonna do
22:45 - all of this stuff n times so what are we
22:48 - doing in here right because it's gonna
22:49 - happen end times well what we're gonna
22:51 - do is we're gonna log something and then
22:53 - we're possibly if we find that we're
22:55 - gonna break so we're gonna end the loop
22:56 - right we're gonna check something and
22:58 - then we're gonna log something so we
23:00 - could say that this is like one
23:01 - operation because we're checking
23:02 - something we could say this is two
23:03 - operations you'd say this is three
23:05 - operations but really right like we're
23:08 - just doing one thing on each loop so
23:10 - what we would say is well for our input
23:13 - n we're gonna do one thing each so we're
23:15 - essentially we're gonna do end things
23:16 - that's what we're gonna do we're gonna
23:18 - do n operations on our input end so we'd
23:21 - say that our Big O notation is of n now
23:23 - some of you might realize though that we
23:25 - might not necessarily do n operations
23:29 - like let's see if if I erase all this
23:31 - right so we're looping through the
23:33 - entire array but notice that if we find
23:35 - the element that we're looking for we're
23:37 - gonna break which means we're gonna stop
23:38 - looping now this is another important
23:40 - concept with Big O notation so right now
23:43 - we loop we go to 4 right so we're saying
23:45 - ARR dot length which is what 10 so we're
23:48 - gonna do this 10 times so n times but if
23:51 - we happen to find the element before we
23:53 - reach the end of the loop we're done
23:55 - we're gonna break out of it and we're
23:56 - not gonna continue looping so why
23:58 - wouldn't you say that this is Big O of
24:00 - like a constant like let's say 5 right
24:02 - because we only need to run that loop 5
24:04 - times until we reach 32 and we end well
24:07 - the thing is we don't know how many
24:09 - times we might have to loop in a worst
24:11 - case this element 32 could have been at
24:14 - the end of the list right and in that
24:15 - case it would have taken us well n times
24:18 - and loops to find that element so we're
24:21 - always looking at the worst case which
24:24 - is
24:24 - what is the worst case that this
24:27 - algorithm gruntin so for example the
24:29 - worst case for this is that if we have a
24:30 - list where 32 is at the end that would
24:34 - be the worst case for this algorithm it
24:35 - would take longer why would it take
24:37 - longer well because we're gonna break
24:39 - once we find the element but if we don't
24:40 - find the element until it's at the very
24:42 - last index that means we had to look
24:44 - through the entire list so we had to do
24:46 - n times we had to loop end times until
24:49 - we eventually found the element now the
24:50 - best case would be if the element was at
24:52 - the beginning so if we had 32 instead of
24:54 - 1 right here then we would simply loop
24:56 - once well we would say 32 equals 32 and
25:00 - that we printed out we would break and I
25:02 - would only take one time there'll be one
25:03 - operation but the thing is we don't know
25:05 - where our elements gonna be because this
25:07 - list could change right this list could
25:09 - be any size it could have a different
25:11 - amount elements so we're always caring
25:12 - about the worst case which is Big O of n
25:15 - because we could at most loop end times
25:17 - so it's like it's unlikely that we'll
25:19 - loop end times that'll be at the end but
25:21 - it could happen so we need to account
25:23 - for that and that's how we do this it's
25:24 - always the worst case you're never
25:26 - thinking about the best case you're
25:27 - always thinking about the worst case I
25:29 - wish there was like a clear for this
25:31 - because this eraser isn't really working
25:34 - well okay let's just close this all
25:37 - right close okay apparently it doesn't
25:39 - want to close so give me a second guys
25:43 - let's try figure this out
25:53 - ok so I got that closed anyways so this
25:55 - is that's our first algorithm and this
25:57 - runs in will put a comment here Big O of
26:01 - n which is also known as the linear time
26:04 - so essentially the longer the list gets
26:06 - longer it's gonna take and it's linear
26:09 - so like if the list increases by 1 it's
26:11 - gonna be at most one more operation we'd
26:13 - have to do so this is Big O of n
26:14 - hopefully you guys understand this and
26:16 - we're looking at this right it's one for
26:17 - loop which means that this loop could
26:20 - run at most n times inside the loop we
26:23 - do a few things if we find the element
26:26 - but we really only care about how many
26:27 - times the loop is gonna run because
26:29 - that's what's gonna dictate how long it
26:30 - takes for this algorithm to to actually
26:32 - execute ok alright so next one that was
26:35 - our first one linear search binary
26:37 - search so you guys might have heard of
26:38 - this before but essentially what this
26:40 - does is given a sorted list it's gonna
26:43 - find it's gonna do the same thing as
26:45 - before it's gonna find the first
26:46 - occurrence of any element that we give
26:49 - it and tell us where it is in the list
26:51 - so let's just run this first of all so I
26:53 - say by the way I'm just using nodejs to
26:56 - run this stuff I don't know if you guys
26:57 - care but anyways the binary search Jas
27:01 - you can see what it found one finds one
27:03 - at index zero if I change it to be like
27:05 - 8 I should find one of these eights for
27:07 - us so let's run this and you see it
27:10 - finds it at index 9 and I mean you can
27:12 - count the index if you don't believe me
27:13 - so essentially it just finds the element
27:15 - but the thing why is this different than
27:17 - this they do the same thing right given
27:20 - given an array and given a number they
27:22 - tell us where that number appears why is
27:26 - this different well this runs a lot
27:29 - faster than the last algorithm and why
27:32 - does it run faster well we're gonna
27:33 - we're gonna talk about this right now
27:35 - and how this works so this is known as
27:37 - the binary search algorithm and why it's
27:40 - called binary is because it every time
27:44 - it runs it decreases the size of our
27:46 - list and you guys will see how this
27:48 - works in a second so essentially what
27:50 - this does is it looks at so we looks at
27:53 - the middle index of our sorted list and
27:55 - think about if you have a sorted list
27:57 - and you're looking for some kind of
27:58 - element so we're gonna look at the
28:00 - middle index and we're gonna determine
28:01 - if that middle index is greater than or
28:04 - less than the
28:05 - so in this case we're looking for eight
28:06 - okay the middle index in our list would
28:08 - actually be okay let me change this to
28:10 - be like ten so it makes more sense so
28:11 - we're looking for ten okay the middle
28:13 - index in our list would be something
28:14 - like eight so we know this list is
28:16 - sorted meaning it's going from least to
28:18 - greatest so if we look at the middle
28:20 - index which is eight we say well is 10
28:23 - greater than or less than eight well 10
28:25 - is greater than eight which means that
28:27 - we know that 10 cannot actually be in
28:29 - this left half of the list or the array
28:31 - why can't it be there well because it's
28:33 - sorted and if 8 is the middle and 10 is
28:36 - greater than 8 there's no way it can be
28:38 - behind 8 so why would we bother looking
28:40 - at any of these elements well we
28:42 - wouldn't and we're not going to okay so
28:45 - let's say we cut that portion of the
28:47 - list right so the highlighted portion
28:48 - we're no longer looking in and now we're
28:50 - now what happens is our list turns into
28:52 - this the highlighted portion we have 8 8
28:55 - 9 9 9 9 right and we're still looking
28:57 - for 10 so what we're gonna do is now our
28:59 - list is simply this in just this part
29:01 - with the brackets so we're gonna do the
29:03 - same thing we just did except with this
29:06 - list we're gonna find the middle index
29:08 - of this list which in this case would be
29:09 - 9 and we're gonna say is 10 greater than
29:11 - or less than 9 again tens the element
29:13 - we're looking for we say well it's
29:15 - greater than 9 which means that all the
29:18 - elements to the left here are gone we
29:20 - can remove them so our new list becomes
29:23 - this and now we say well YP look why
29:26 - would we bother looking at this portion
29:27 - when we know it can't be there right so
29:29 - now we have this list and now what we do
29:31 - is we look at the middle index in this
29:33 - case is 10 and one of our checks is is
29:35 - it greater than is it less than or is it
29:36 - equal to and we find that 10 is equal to
29:39 - 10 we know what this index is and we
29:41 - return that to our what do you call it
29:44 - to our like from our function so that's
29:46 - how the binary search algorithm works so
29:48 - now let's try to figure out how many
29:50 - operations this takes so let's bring our
29:53 - up our drawing thing here all right
29:56 - that's not the one I wanted sorry one
29:57 - second I want this one and let's let's
30:01 - dissect this okay right so we have a
30:03 - list let's say we have a list of like 1
30:05 - 2 3 4 and every time we run this loop
30:11 - right every time this runs so the while
30:13 - loop here which is right here we split
30:15 - the list in half so our first loop we
30:17 - look something like this
30:18 - our second loop looks something like
30:21 - this and our third loop would look like
30:23 - this right because every time we
30:24 - essentially cut off half until we get
30:27 - down to a one element and the worst case
30:29 - for this algorithm is that we look
30:31 - through every single possible what he
30:34 - call it like we look through the entire
30:35 - list until there's only one element left
30:37 - left and then if there's one element
30:39 - left
30:39 - it's either the element we're looking
30:40 - for or the element doesn't exist that
30:43 - we're trying to find right that's the
30:44 - worst case for this algorithm because
30:46 - technically like say we pick the middle
30:47 - index of two and that's equal to what
30:50 - we're looking for let's say we're
30:51 - looking for two then we'll just return
30:52 - that index right away so it could happen
30:54 - faster than possibly splitting it up all
30:56 - the way okay so we split this up split
30:58 - this up and then we're left with this so
31:00 - our input size was four right okay but
31:04 - we only bran at most three operations
31:07 - really really only two because this like
31:10 - the first operation brought us to this
31:12 - we really only did two operations as
31:14 - operation one this is operation two
31:15 - right we just ran the loop two times
31:17 - loop ran two times so what is that
31:20 - actually equal to well I want you guys
31:22 - to figure it out so I'm gonna do one
31:23 - more example okay so let's increase this
31:25 - list now to be five six seven eight okay
31:30 - so now we've just doubled the size so it
31:32 - was four so it was two there but now
31:34 - we've doubled the size and we've added
31:35 - those what operations do we know do now
31:37 - so we start and we split the list in
31:40 - half so we're either gonna take the left
31:42 - side of the right side so I mean we can
31:43 - pick it doesn't really matter we'll say
31:44 - we'll say we take the left side so now
31:46 - we're at 1 2 3 4 okay now what do we do
31:50 - split this list in half again 1 2 what
31:54 - do we do we split it and we get 1 so
31:57 - notice that now we have 1 2 3 operations
32:00 - we doubled the size of our list and we
32:03 - only added one operation or one more run
32:05 - of this while loop okay cuz this is what
32:07 - this while loop does essentially but how
32:09 - does that work well where what function
32:12 - is this we talked about it this is
32:14 - actually log base 2 of n and what that
32:19 - means essentially is based on whatever
32:20 - the size of our input is we can find how
32:23 - many operations that most will run by
32:25 - doing a log base 2 of N and log base 2
32:27 - MN is a function like this that actually
32:30 - decreases in slope as it
32:32 - as and gets larger so this is a super
32:35 - fast algorithm right and we would you
32:37 - want to use this if we want to find
32:38 - something in a massive list the only
32:40 - disadvantage of it is you need a sorted
32:42 - list otherwise you can't really do
32:44 - something like this right if you don't
32:46 - have a sorted list and that is
32:47 - essentially how it works in terms of
32:49 - binary search and that's why it's log
32:51 - base 2 of n now I want to talk about
32:54 - quickly I really wish there was a clear
32:56 - thing for this men so I could alright
32:59 - well that's fine it's flawed in the app
33:00 - maybe I'll make one myself but what we
33:02 - do here right is like these are all the
33:05 - operations that could run each wallet
33:08 - right so every time we loop through like
33:10 - this while if essentially is gonna
33:11 - happen at most log log base 2 of n times
33:15 - ok but we do like a bunch of different
33:17 - operations in the fall to plague let's
33:19 - say we do this let's just say we do like
33:20 - 5 operations every time it loops well
33:23 - wouldn't you say that that's like 5
33:26 - times log base 2 event well you'd be
33:30 - correct we do five operations log base
33:32 - two times right because this happens log
33:34 - base two times or mmm sorry but we do
33:37 - five operations but the thing is five is
33:39 - a constant right and we don't care about
33:41 - constants so we just remove it and we
33:42 - say that this is then Big O of log base
33:46 - two of n and that's how that works okay
33:48 - so we'll go a bit faster now for these
33:49 - next ones so now we're going to example
33:52 - one and this one is just one that I
33:53 - wrote myself and essentially what it
33:54 - does is account duplicate elements so
33:56 - let's try to analyze this and figure out
33:58 - how long this is going to take so the
34:00 - important thing to look at when you're
34:02 - analyzing something is the amount of
34:03 - loops right because remember we don't
34:05 - care about the constants so all the
34:06 - stuff inside of these loops it doesn't
34:09 - matter how much you're really doing cuz
34:10 - we're just gonna omit the constants
34:12 - anyways like say you're doing something
34:13 - like n times but you do like every end
34:16 - you do five things that's five n well we
34:17 - just get rid of the 5 so we don't care
34:19 - about the constants right so how many
34:21 - times does this happen we're gonna count
34:22 - the duplicate elements so it's actually
34:24 - given some kind of array we're gonna
34:26 - find how many elements appear more than
34:29 - once so for example be like this one
34:31 - there's two duplicate elements because
34:32 - two is duplicate and six is duplicate
34:34 - even though there's like three twos just
34:36 - because two appears more than once like
34:39 - that counts us once you know what I mean
34:40 - like that it's a duplicate element
34:42 - that's what we count so I mean I'll show
34:44 - you that this works first didn't mean to
34:46 - that example one okay and you see that
34:50 - we get three duplicate elements and
34:52 - that's because seventy seven six and two
34:54 - two two right so how long how many how
34:58 - long does this take to rotten well let's
34:59 - look at it so what we're doing is we're
35:01 - looping through the array dot length
35:02 - okay so that's gonna happen what n times
35:05 - right cuz array the length of our array
35:08 - is n that's our input size this is
35:09 - length and whatever that length is so
35:11 - this is gonna happen n times this first
35:13 - for loop but then inside of that for
35:16 - loop what do we do we loop again n times
35:20 - we say we're gonna loop again through
35:23 - the entire list so we're looping once
35:25 - and then every time we loop once we're
35:28 - looping through the entire list again so
35:30 - essentially every one of these four
35:31 - loops we're looping end times so every
35:34 - time that this runs we loop end times
35:36 - again so this run this runs n times but
35:40 - this run is n times and this runs every
35:43 - time that this runs so we say that this
35:45 - runs n times like that and this runs end
35:48 - times but since this for loop is inside
35:51 - of the other one it means that every
35:53 - time that this runs this is gonna run so
35:56 - you might be seeing what I'm getting out
35:57 - here how what it like how long does this
36:00 - take to run well this actually runs an N
36:03 - squared and why does that happen
36:05 - well because for every n we do something
36:09 - end times so essentially if that's n
36:11 - multiplied by N and n by n is N squared
36:14 - so this is quadratic and as the length
36:17 - of our input increases this is going to
36:19 - take a lot longer to run these are
36:22 - things we want to avoid is embedded for
36:25 - loops and embedded while loops because
36:26 - well it takes a really long time to run
36:29 - and if I were to put another for loop in
36:32 - here like this and say it does something
36:34 - well then this would run if it ran n
36:36 - times right so this runs n times this
36:38 - runs n times this runs n times so we're
36:40 - gonna run n cubed times which is a crazy
36:43 - amount of times to be running right so
36:45 - that's how we kind of do that so I think
36:46 - that's I mean that one's pretty
36:48 - straightforward I don't need to really
36:49 - do too much for that
36:50 - ok so let's go to example two example 2
36:53 - ok so all this one is doing and it's
36:54 - really it's similar to last one if we're
36:56 - just gonna print X Y Z and this is a
36:58 - good example
37:00 - actually I don't want to print it yes
37:01 - it's gonna give it away what we do is we
37:03 - take three variables like ABC as our
37:06 - input and what we're going to do is we
37:07 - gonna loop a times B times and C times
37:10 - okay ABC times so this one's a bit more
37:14 - complicated actually how what's the big
37:17 - o-notation of this how long does this
37:19 - take to run right so we can say a B and
37:22 - C is like our n like our input how long
37:24 - it's gonna take to run well what we do
37:27 - is we run a times we run B times a times
37:30 - I know it's confusing but we run this
37:32 - for loop B times every a time so that's
37:36 - a times B right so we run these two for
37:38 - loops a times B times now what about
37:42 - this third one there's another for loop
37:43 - inside of another for loop so this runs
37:47 - C times so every time B runs this runs C
37:50 - times and every time B runs this every
37:52 - time a runs this runs B times so this is
37:55 - actually a times B times C now what can
37:59 - we simplify it to be like n cubed well
38:02 - you can't because they're three
38:03 - different variables right if it was one
38:05 - variable and it was like a a a then we
38:07 - would say a cubed because it's eight
38:08 - times eight times a but since it's three
38:10 - different variables we say this runs an
38:12 - a times B times C and I'll prove it to
38:14 - you so I'm gonna run this now example
38:18 - two Jas and watch my watch my screen
38:20 - okay so we get a bunch of output let's
38:24 - scroll through it so this little lot
38:26 - these lines of code ran like this many
38:28 - times and then you'll see so we have X
38:31 - it starts at 0 Y is 1 x is 0 Y is 1 sad
38:35 - is 1 x is 0 Y is 1 set is 2 x is 0 Y is
38:38 - 1 that is 3 so you see that essentially
38:41 - Zed goes 1 2 3 4 0 1 2 3 4 0 1 2 3 4 and
38:45 - that runs a ton of times whereas X stays
38:47 - at zero and goes to 1 goes to 2 goes to
38:50 - 3 and then once it's done it's done so
38:52 - you can this kind of gives you an idea
38:53 - of exactly how this works right so you
38:56 - have X 0 y 0 0 0 right and then Y will
38:59 - change to 1 and then Zed will change
39:02 - right and that's exactly how it works
39:03 - so that's how we can kind of determine
39:05 - that this runs a times B times C times
39:07 - and I mean if you want it to count these
39:08 - amount of inputs you would get 5 times 5
39:10 - times 5 which is essentially 125 lines
39:13 - ok
39:14 - that's how long that runs I don't want
39:15 - to close that ok example 3 so this one
39:18 - okay so this one actually is gonna
39:20 - generate all of the binary numbers from
39:24 - that are of length 16 so it's gonna
39:26 - start from 0 and go to length 16 so all
39:28 - of the binary numbers that are of length
39:30 - 0 to length 16 does anyone know how many
39:33 - numbers that is it's a lot of numbers
39:35 - I'll tell you that right now
39:36 - now this works using something called a
39:38 - queue based algorithm I'm not gonna
39:40 - explain what that is because it's a bit
39:41 - confusing but essentially I'll run the
39:44 - program and then let's try to figure out
39:45 - how how long this runs it ok so let's go
39:48 - down here
39:49 - it's example 3 J s alright ready I'm
39:51 - gonna round this watch my screen this is
39:54 - gonna take a second to happen and that's
39:56 - what I'm talking about with the time
39:57 - complexity right I'm only making all of
40:00 - the binary numbers that are of length 16
40:02 - but look how long this is taking to run
40:05 - and if we didn't know anything about
40:07 - time complexity and we weren't printing
40:08 - this out to the screen we would not
40:10 - probably have realized how long this
40:12 - algorithm that I created takes it's
40:13 - super inefficient but it's really the
40:15 - only way to generate all of these
40:17 - different numbers so you can see I mean
40:18 - if you like if you scroll through we
40:20 - have a ton of different binary numbers I
40:22 - can't even reach the end the the last
40:24 - input like the start one so this how
40:27 - long does this take to run well this
40:30 - actually takes two to the N to the N
40:33 - times where n is essentially like the
40:36 - length of the binary number which is
40:37 - going to be 16 in this case okay because
40:39 - that's how many possibilities of binary
40:41 - numbers there are 2 to the 16 and I mean
40:43 - we can prove that pretty straightforward
40:45 - I'll draw this to you if you guys know
40:47 - anything about binary I don't want to
40:49 - use that I want to use this right so
40:52 - binary numbers you can either be 0 or
40:54 - you can be 1
40:55 - it's 1 or 2 and they can obviously have
40:57 - like an infinite length so we are doing
40:59 - all the binary numbers of length 16
41:01 - which means that we can well I'm not
41:04 - going to draw them all out but let's do
41:05 - an example with 3 so if we have 3 digits
41:07 - for a binary number then we have we can
41:09 - have 0 0 0 we have 0 0 1 0 1 0 0 1 1 so
41:18 - you are and then this sorry this goes 1
41:20 - 0 0 1 1 1
41:26 - No 1:01 sorry why is this so difficult
41:30 - to do 1 1 0 and then 1 1 1 so we have 1
41:35 - 2 3 4 5 6 7 8 different binary numbers
41:40 - for 3 digits
41:41 - ok for 2 digits like let's just scrap
41:45 - what row should we scrap I'm trying to
41:49 - ok let's grab this row alright and then
41:52 - have a look like these zero zeros use it
41:54 - so these are all the same as the ones
41:55 - above so we get 4 so 4 2 digits we get 4
41:58 - 4 3 digits we get 8 4 4 we get 16 and we
42:01 - essentially get 2 to the amount of
42:03 - digits so in this case we get 2 to the
42:05 - 16 so that takes a really long time to
42:08 - run right our input size was only 16
42:10 - because we only doing 16 digits but 2 to
42:12 - the 16 is a massive number and that's
42:14 - why I took us so long to run that
42:16 - program so you know if we had had an
42:18 - algorithm that could do that in linear
42:19 - time then we would only have ran at 16
42:22 - times and that would have happened
42:23 - instantly but it was happening in 2 to
42:24 - the 16 which means that it took a long
42:26 - time and that's another reason obviously
42:27 - we need to understand time complexity
42:29 - and how long these things are taking now
42:31 - again notice right like I'm doing all of
42:33 - this stuff in this loop like I'm doing 1
42:37 - 2 3 4 5 6 7 8 operations every loop and
42:42 - this loop is gonna happen well 2 to the
42:45 - 16 times okay this happens to the 16
42:47 - times multiplied by how many operations
42:49 - is this 8 now here's the thing right
42:51 - like 2 to the 16 is a massive massive
42:53 - number multiplying it by 8 yeah it makes
42:56 - it 8 times larger but really like we can
42:59 - just neglect this because it doesn't
43:00 - really tell us anything more about the
43:02 - shape we know the shape is exponential
43:05 - and it's happening like very taking a
43:07 - really long time so by multiplying it by
43:09 - 8 doesn't really give us much value it
43:11 - just kind of tells us it's 8 times
43:13 - larger it doesn't tell us the shape of
43:15 - the increase which is what we care about
43:17 - we just care about the shape of the
43:18 - increase ok so that's kind of it for
43:20 - that one what was the other example I
43:22 - did ok so this is one with two input
43:25 - variables we're going to talk about now
43:26 - how we do this alright so we have array1
43:29 - and a rate too now how do we do this
43:32 - with two input variables well
43:33 - essentially what we do is we just say
43:35 - we're gonna look at the first for loop
43:36 - we're gonna look at the second for loop
43:38 - and then we'll just see what happens in
43:39 - here
43:40 - and this first for loop well what what
43:42 - is this run it well this runs in length
43:45 - one okay so it like array one has length
43:48 - of n one array two has length of n 2 so
43:50 - this first for loop is gonna happen
43:52 - what and one times and this for loop the
43:54 - second for loop happens and two times
43:56 - but it happens every time that N one
43:59 - happens so we say this happens and one
44:02 - this happens n two so since this four
44:05 - loops inside of the other four loop we
44:06 - simply say this is happening in n1 times
44:09 - n2 time in other words Big O of n 1
44:12 - times n 2 and that's how we determine
44:16 - that so this runs in n 1 times n 2 and
44:18 - the reason we can't just simplify this
44:20 - is because obviously these variables are
44:21 - different and with this list was like
44:23 - way bigger than the other one it would
44:24 - affect how long it was gonna take so
44:27 - yeah so that has kind of been it for Big
44:30 - O notation introduction I hope that you
44:32 - guys at least have some sense of kind of
44:34 - the speed of some different algorithms
44:36 - how you can kind of look at them and
44:38 - getting a very brief idea of how long
44:41 - they're gonna take this is super useful
44:42 - and I highly encourage you guys to be
44:45 - critical of yourself if you're writing
44:47 - efficient code or not if you're writing
44:48 - code that runs an N squared just know
44:51 - it's gonna take a long time to run right
44:53 - if you're writing something like this
44:55 - that happens in 2 to the N understand
44:57 - that that's gonna take a massive amount
44:59 - of time to run and if you're writing
45:01 - something like binary search you're
45:02 - gonna be like well if I have massive
45:03 - list it might make sense to use a binary
45:05 - search on them
45:06 - because it's gonna be so much faster to
45:08 - find elements right so as I wrap up this
45:10 - video just a reminder that this video
45:12 - was sponsored by Microsoft if you're not
45:14 - already you guys should head over to
45:15 - their YouTube channel and hit subscribe
45:17 - and remember to check out dev collective
45:19 - in the link in the description ton of
45:21 - awesome courses completely for free I
45:22 - know you guys are gonna find a lot of
45:24 - value from that so with that being said
45:25 - thank you guys for watching the video
45:27 - and I will see you again in another one
45:29 - [Music]

Cleaned transcript:

hey guys and welcome back so I actually just finished editing all the footage you're about to see and I want to give you a quick overview and quick recap of exactly what this video is gonna be about because is a bit of a longer video than I typically post so this video in this tutorial is about time complexity and big onotation now I don't focus tremendously on exactly how to write big onotation and go super indepth but my main goal is to give you guys kind of a fundamental understanding so that you can use that knowledge to apply it to your own programming and your own code a lot of people aren't aware of the effects that their programming and those scripts their writing have on their code and how slow it can possibly rerunning so in this video what we do is the first 1520 minutes we kind of go through and talk about what is big onotation how it works quick summary and then we actually get into a bunch of algorithms that i've wrote and we analyze them and see how fast or how slow they are this should hopefully allow you to write better code faster code and if you don't know this obviously you're gonna learn so it's a really fundamental skill if you're in any kind of computer science field where a programmer in general it's something you definitely should know and if you don't I highly encourage you to watch through the entire video and make sure that you actually understand everything that I'm talking about so with that being said let's get into the video before I get too far into the content I'd like to announce that I'm actually partnering with Microsoft and they're sponsoring this video for me to talk to you guys but a new project they've started called the Microsoft dev collective now this is a really exciting and great opportunity for you guys and essentially the Microsoft dev collective is a community of developers where you can go to learn and collaborate right now by just simply signing up and becoming a part of the dev collective you're gonna gain access to over 30 free courses that's right completely free you don't have to pay for anything there's a link in the description and if you go there it's gonna bring you to a page that has a bunch of courses that look just like this let me show you okay guys so I'm on the Microsoft dev collective website here I'm just gonna click on Explorer and I can have a look at all of the different courses that they have to offer as of now so like I mentioned this is a brand new thing and there's gonna be new content added on here monthly so make sure you guys are continually having a look at this because since the first time I looked at it there's been some new courses and I know that they're adding a lot of different content that's gonna be super valuable so I just signed in here so I can gain access to all these courses but essentially I'm gonna go to topics and just go to languages and this is where my tutorial will be showing up and essentially you can have a look at just some of the stuff they have like programming foundations programming foundations objectoriented design and make your C shop sharp code more functional just a ton of awesome resources and I know if you guys have a look at here you're probably gonna find something that interests you and it's free so what's the parm and having a look at it and checking it out so anyways that's been it for this little odd thing I hope you guys did listen to this and I hope you're gonna get some value from this and now on to the video okay so what this tutorial is really gonna focus on is time complexity in Big O notation now I'm not trying to make you guys pros in this but I really want by the end of this video that you guys are gonna be able to look at certain algorithms maybe something that looks like this analyze them and get some kind of idea of how long it's gonna take for them to run now this is a really important skill it's taught a lot in computer science in general I don't really care if you guys know how to do like Big O of N or N squared or like n plus1 I just want practically you would be able to look at an algorithm and be like okay so like based on my knowledge kind of time complex seeing how things work this is gonna take a long time to run and the reason why that's really important is because when you guys are writing code I see it a lot with beginners they have no idea about how long it actually takes for something to run and if you're trying to run things on like thousands and thousands of lines of input or less massive I don't know like text files or something like that and you have a really inefficient algorithm or inefficient code it's gonna take forever and it might not even run so I just want you to be conscious of the fact that your code really has an effect on how long it takes for the computer to execute something and typically the faster something is the better now we're gonna talk about a bunch of different algorithms here that I've personally just wrote myself some of them are like very well known but I've just created a few and I'm gonna be doing this in JavaScript but it doesn't really matter if you don't know JavaScript because this is just I'm not gonna be writing any code you're not gonna be we're just gonna be analyzing it so as long as you can kind of get an idea of what this code is doing and you've programmed before you're gonna have no problem following along with this if you don't know JavaScript okay so with that being said let's get started let's talk about Big O notation and complexity okay so what is Big O notation well Big O notation why is this not drawn I'm on the eraser that's why Big O notation is essentially just a fancy word or fancy notation for denoting how long it takes for certain algorithm to run so yeah I've already said algorithm like a hundred times but that's what we're gonna be focusing on algorithms now what is an algorithm essentially an algorithm is a set of instructions and typically in computers based on some input it takes like a certain amount of time to execute and that's what we're really gonna be focusing on here so algorithms set of instructions Big O notations how long does it take this set of instructions to run based on some kind of input so what we're mainly focusing on here is input okay so in a specifically input size and then that's gonna be related to time so based on some kind of input size how much time can we relatively expect this algorithm to take now I'm not saying we're gonna measure it in seconds we're actually just gonna measure it in like relative operations and what I mean by that is like an operation could be something like adding 1 to a number or like grabbing information from an array that's how we're gonna measure an amount of operations because obviously based on different computers things are gonna run a different time and there's a ton of different factors that affect the actual time but we just want to get some kind of idea like are we gonna sit here for hours or is it gonna happen in a few seconds and that's the main idea of Big O notation now quickly before I go on something that's important to understand is that when we talk about Big O notation we're typically talking about very large massive amount of information now what I mean by that is for example if you have an algorithm that needs to run something on like five numbers okay let's say we have like one two three four or five like this is our list okay you need to do something with this list well computers are super fast like they can do thousands of operations per second so if we have an algorithm it's like pretty inefficient but we're only taking like I don't know we're only using like five elements like we're not gonna be using that algorithm very often we just then it doesn't really matter how inefficient it is because it's still gonna happen almost instantly you know what I mean it's like if you write one line of code and it have been replaced with like five that was a lot faster well if we're only using like a really small amount of input it's kind of negligible because you're saving like maybe like a millisecond right so it's almost just we don't really care about smaller data sets we only care about large data sets and you guys will see what I mean as we go through here okay so now I'm hoping you guys have a little bit of a math background because I'm gonna start kind of just drawing some functions here and talking about growth and yeah so what we're gonna do is I'm gonna draw two axes here okay and I'm gonna call this my time axis okay and this is gonna be n now I haven't talked about and yet since we're gonna do now so essentially remember I was talking about we only really care about large data sets or like large amount of information essentially we're trying to figure out based on some kind of input how long is our algorithm gonna take relative to that input is gonna take like five times that input like how many operations are gonna do on that input that's what we want to know so our input like if we have let's say an array okay the length of that array is gonna be noted denoted by n so n you're gonna see me use this a lot this just means the length of the array so if we have an array like this we go from 1 comma dot dot dot to n so the length of this array is n that's really important we're gonna be that's gonna be brought up a lot so let's get rid of all this now this eraser is not that easy to use okay there we go so based on some kind of input and we're gonna be figuring out how many operations in other words like how much time is it gonna take us to run so I'm just gonna draw two functions on here and I want you guys just to think about which one you would rather have okay keep in mind everything we want is like super efficient like that's what we're aiming for okay so let's draw this and let's draw a purple one that looks something like this okay so we kind of have these this intersection point here at this purple dot but these are three different functions now if you guys know anything about math you should know what these functions might be so for example if this function could be something like time equals n this function can be something like time equals log and and this function could be something like time equals and then maybe something like N squared okay like a quadratic function which mean it would go like that too but we're not we don't care about the negative side okay so three different functions now I'm gonna ask you if you're running an algorithm and you want it to run as fast as possible based on like massive amount of input which function would you take like let's say these are three algorithms these are how long they take do you want this one do you want this one or do you want this one for how much time they're gonna take just based on their graphs expecting that this is gonna continue on to infinity right which one would you want well I would hope that you guys would say this purple one right that you guys would want this purple function which is login now the reason you'd want that is obviously because as the size of the input increases the time is very slowly increasing like look have a look at it here right so at the beginning it increases faster than all the other ones but once we get to this point here it starts slowing down and the slope is actually decreasing as we continue to go all right let's have a look at the red one in comparison well the red one is actually wait it's it's faster up until this point right because the time is is slower but as soon as we hit here you can see it starts exponentially increasing increasing increasing and keeps going and this green one well this one's fine but it's just a straight line it's linear so essentially it increases at the same rate the entire time based on n time is gonna be exactly n right so just we want this this log n now some people would say though well what if our input size is like let's say this is like N equals 5 okay let's just say that's the number I know it's not let's say that's number well if we had an input of like size 3 so maybe like somewhere here which function would you want we'd probably want this red one because the time is the shortest but the thing is yes you would want that for the shorter amount of input but as this input gets larger larger larger larger larger you can see that this goes way faster so that's why we really care about when n approaches infinity so when n is like a massive number as opposed to anything on kind of the left side of this like intersection point between different algorithms and different functions I hope that kind of made this is the visual right of the speeds for our time okay so we've just kind of found out now that log n right this is this is a way we're gonna use Big O notation with log in as well we'll talk about that in a second is way faster you can do way more operations with log n than N squared right or then time at not more operation sorry it's just faster in terms of time so these are kind of a few standard function times like how algorithms run in these certain times okay so let's now start I guess maybe analyzing some algorithms talking about how we actually write Big O notation and stuff like that okay so remember I said our input size is n so n is our input okay now when we write Big O notation so we're trying to figure out how long something's gonna take to run or we know how long it takes to run what we do is we write a Big O we put brackets and then in the brackets we put some kind of function based on our n so the function could be like n plus 1 or n plus 2 sorry it could be like N squared it could be log n it could be anything like that now remember how I was saying we only really care about massive inputs right so when n approaches infinity well if you've ever done anything with limits you understand what I'm about to do here but let's say we have a function R let's say the amount of operations that some algorithm does is like 3n plus 7 okay like this is the function like if I were to draw it then we would have like a little grid this would be 7 we would go like that okay that's what our function would look like now we only care about massive input sizes so what we can actually do is we have a function that looks something like 3 n plus 7 we can actually simplify this and what we can do is we can remove all of the constants now what are constants in this what's a constant a constant is something that doesn't change it stays the same so let's have a look at this this +7 this is a constant so essentially whatever the size of n is so like n could be infinity we're gonna do that times 3 so 3 times infinity plus 7 now let's let's think about this right so if n is infinity because that's care about massive inputs does adding 7 to infinity really change how long this is gonna take like imagine imagine 10 billion add 7 to it it's still pretty close to 10 billion right like that 7 didn't really make a massive difference so what we can actually do is we can omit this 7 we can delete it and why can we delete it because it's a constant even if the constant was something like like 10,000 we can get rid of it we can delete it and the reason we can do that is because we only care about the input size at massive numbers so we can get rid of those constants all right listen let's now we have 3n so what about what about 3 there any other constants left well 3 is actually a constant as well and the reason it's a constant is because it's not a variable like any number that's not a variable is a constant or a function so we have 3 okay so this is a constant as well so let's think about this now so what we've done is we've simplified this to 3 times infinity now 3 times infinity what is that equal well that actually equals infinity 3 anything times infinity plus infinity divided by infinity is still infinity because it's just an arbitrary term we don't really know what infinity is so what we can actually do is we can remove this 3 as well so we went from a function that was 3 n plus 7 to simply n right so if we compared them on a grid we would have had this one which was that original function and now we have a function that looks kind of like that right so maybe this one had like a higher slope like that but now we have one that looks like this now the reason we can do that you're like well these functions are different I agree functions are different but the thing is they're both linear meaning that as n increases what do you code the time increases linearly not exponentially it doesn't grow any faster it grows at the same rate and that's what we care about the rate of growth of our function we don't really care about how like the exact number that it is we just care if it's linear if it's quadratic if it's exponential if it's cubic that's what we care about and we're gonna go through a bunch of examples of different ones right now ok so that's how we kind of simplify our things we can remove the constants meaning we don't really care but like it was plus tens or this plus fifteen to the three times we only care about the actual kind of variable value and what that means in terms of growth so just the type of function really so let's do let me just draw a few examples of some pretty common what do you call it like Big O notation there's some pretty common like runtime complexities alright so let's do a grid and we already did the linear one right we already did the log and we already did the quadratic which looks like that okay these are three very very common Big O notation Zoar like runtime analysis that you're gonna see a lot and when we start going into actually analyzing algorithms you guys should understand this a lot better okay so those are three common ones but there's two more that we want to talk about and we're gonna rank them in terms of like how long they take which one is slower which one is faster so we didn't log in but what about what do you call it let's see what about two to the N so we did um what was it we did N squared but we also did two to the N so who knows what's faster two to the N or N squared well two to the N is actually way way way slower than N squared so this is 2 to the N okay and if we do N squared N squared looks something like that so they both grow exponentially but 2 to the n grows way faster than N squared so if I gave you two algorithms and I said Al gwon well it's time it takes two to the N to run and I said how to that takes N squared which one would you pick you'd pick N squared okay so that's just important to understand cuz a lot of people don't know to the end although it seems like oh and to the N is a way it takes a lot longer and a lot more operations than N squared I'm gonna show you an example of two at the end of the second as well okay so there we go so that's another example of one some other common ones can use more than one variable so sometimes when we do algorithms we might have more than one list or more than one I don't know input right we could have two inputs like say we have a function and it takes two inputs so let's say we have an input and one and we have an input and two now a common runtime analysis for two inputs is something like big of n1 plus n2 now can we simplify this any further right so remember I was saying like if we have 3n plus 7 we can just scratch out the 7 we can scratch out the 3 we only care about the end because that's kind of the rate of growth right and then I guess we can do the same thing if we have something like 3 and squared well we can get rid of the 3 and we'll just keep the N squared because that shows us kind of the shape of growth which what is what we care about ok what if we have n 1 plus n 2 well the thing is these are different lists right are different size inputs so we need to keep both of them because this one could be like way larger than the other one so we need to keep both of these so whenever you have kind of two variables you have to keep them both alright so now we've kind of talked about that a bit we're gonna show I'm gonna show some more advanced examples of like big way notations on how you kind of simplify them and then we'll actually start analyzing and hopefully they'll start making more sense okay so now I'm just gonna look at a more advanced example and how we can simplify this and remember we really care about the shape of the function right so what we're gonna do now is this might be a bit complicated you guys you might not understand why I'm doing this but I'm gonna say if we have a function that's like 3 n cubed plus n ok how do we simplify this well first of all you'll say ok we can get rid of the 3 correct so now we have n cubed plus n now the thing is what term in here defines the growth of the function which one increases the quickest well n cube is like like that whereas n is just a straight line so obviously n cubed is the faster term so it's the more important term it really dictates how large we the inputs gonna get like a thousand cubed is a large number and then you're gonna add a thousand to it right so what we can actually do here is we can simplify this to just be n cubed now why can we do that well first of all these are the same variable ok that's important to know if this was n cubed plus like n/2 so N 1 cubed plus n 2 we couldn't do that because n 2 could be like a massive number which would actually change this right so different variables to meet both of them but if we have the same variable so n cubed plus n n cubed really dictates how the functions gonna grow and that's the principal term that's what they call it so we can simplify this so n cubed plus n to just be n cubed and that's important understand we're not gonna this is like a bit more advanced when you desert doing stuff like this but that's just important understand that we really like this is the term that's gonna dictate how fast the function grows and that's what we care about so we would just say this is Big O of N cubed because that's what dictates how fast it grows ok so now we're done with all the drawing let's start getting into actually the real analysis actually we're probably gonna have to still draw but all like well we're gonna read through some of these algorithms or should hopefully be a bit more exciting and entertaining ok so close that so this is our first algorithm and this is known as the linear search algorithm and essentially what this algorithm does is it give in some input so of size n so in this case we're giving it a list or an array it's gonna find a given number so for example here we have this list or this array all right that has how many elements one two three four five six seven eight nine ten so we have N equals 10 right 10 elements and then what we're doing is we're gonna pass to our function the array and the number that we're looking for and it's gonna attempt to find this number the index where it occurs so what this does it does it has a for loop and it looks and it says if we find like we loop through the array if we find it will log that index so let's just first run this you can see I've been testing them here so I'll just call this one linear search okay and you see found at index 4 so essentially it found 32 at index 4 which would be the correct index for 32 all right so how do we figure out the Big O notation of this function this is our algorithm right and we're just we're using the algorithm down here but this is our algorithm how do we figure out the Big O notation well let's try okay so this is our algorithm obviously the stuff that's highlighted what we want to do is figure out how long this is gonna take to run in terms of n so arr so this right here is n ok and this can change obviously we could have more elements we get have less elements so ARR up in this parameter is going the length of n right that's what we're saying so that's length of n this list down here's what we're passing and what we're doing let's actually let me undo all this so we can actually see everything that's happening here is uh see we're gonna loop through the entire array so essentially we're gonna say I is gonna go from zero dot dot dot to n minus 1 right because we're gonna loop through the entire array so if the length is ten will be only go to 9 because index 9 hopefully guys get that so how many operations are we doing based on an input n well we're gonna do all of this stuff n times so what are we doing in here right because it's gonna happen end times well what we're gonna do is we're gonna log something and then we're possibly if we find that we're gonna break so we're gonna end the loop right we're gonna check something and then we're gonna log something so we could say that this is like one operation because we're checking something we could say this is two operations you'd say this is three operations but really right like we're just doing one thing on each loop so what we would say is well for our input n we're gonna do one thing each so we're essentially we're gonna do end things that's what we're gonna do we're gonna do n operations on our input end so we'd say that our Big O notation is of n now some of you might realize though that we might not necessarily do n operations like let's see if if I erase all this right so we're looping through the entire array but notice that if we find the element that we're looking for we're gonna break which means we're gonna stop looping now this is another important concept with Big O notation so right now we loop we go to 4 right so we're saying ARR dot length which is what 10 so we're gonna do this 10 times so n times but if we happen to find the element before we reach the end of the loop we're done we're gonna break out of it and we're not gonna continue looping so why wouldn't you say that this is Big O of like a constant like let's say 5 right because we only need to run that loop 5 times until we reach 32 and we end well the thing is we don't know how many times we might have to loop in a worst case this element 32 could have been at the end of the list right and in that case it would have taken us well n times and loops to find that element so we're always looking at the worst case which is what is the worst case that this algorithm gruntin so for example the worst case for this is that if we have a list where 32 is at the end that would be the worst case for this algorithm it would take longer why would it take longer well because we're gonna break once we find the element but if we don't find the element until it's at the very last index that means we had to look through the entire list so we had to do n times we had to loop end times until we eventually found the element now the best case would be if the element was at the beginning so if we had 32 instead of 1 right here then we would simply loop once well we would say 32 equals 32 and that we printed out we would break and I would only take one time there'll be one operation but the thing is we don't know where our elements gonna be because this list could change right this list could be any size it could have a different amount elements so we're always caring about the worst case which is Big O of n because we could at most loop end times so it's like it's unlikely that we'll loop end times that'll be at the end but it could happen so we need to account for that and that's how we do this it's always the worst case you're never thinking about the best case you're always thinking about the worst case I wish there was like a clear for this because this eraser isn't really working well okay let's just close this all right close okay apparently it doesn't want to close so give me a second guys let's try figure this out ok so I got that closed anyways so this is that's our first algorithm and this runs in will put a comment here Big O of n which is also known as the linear time so essentially the longer the list gets longer it's gonna take and it's linear so like if the list increases by 1 it's gonna be at most one more operation we'd have to do so this is Big O of n hopefully you guys understand this and we're looking at this right it's one for loop which means that this loop could run at most n times inside the loop we do a few things if we find the element but we really only care about how many times the loop is gonna run because that's what's gonna dictate how long it takes for this algorithm to to actually execute ok alright so next one that was our first one linear search binary search so you guys might have heard of this before but essentially what this does is given a sorted list it's gonna find it's gonna do the same thing as before it's gonna find the first occurrence of any element that we give it and tell us where it is in the list so let's just run this first of all so I say by the way I'm just using nodejs to run this stuff I don't know if you guys care but anyways the binary search Jas you can see what it found one finds one at index zero if I change it to be like 8 I should find one of these eights for us so let's run this and you see it finds it at index 9 and I mean you can count the index if you don't believe me so essentially it just finds the element but the thing why is this different than this they do the same thing right given given an array and given a number they tell us where that number appears why is this different well this runs a lot faster than the last algorithm and why does it run faster well we're gonna we're gonna talk about this right now and how this works so this is known as the binary search algorithm and why it's called binary is because it every time it runs it decreases the size of our list and you guys will see how this works in a second so essentially what this does is it looks at so we looks at the middle index of our sorted list and think about if you have a sorted list and you're looking for some kind of element so we're gonna look at the middle index and we're gonna determine if that middle index is greater than or less than the so in this case we're looking for eight okay the middle index in our list would actually be okay let me change this to be like ten so it makes more sense so we're looking for ten okay the middle index in our list would be something like eight so we know this list is sorted meaning it's going from least to greatest so if we look at the middle index which is eight we say well is 10 greater than or less than eight well 10 is greater than eight which means that we know that 10 cannot actually be in this left half of the list or the array why can't it be there well because it's sorted and if 8 is the middle and 10 is greater than 8 there's no way it can be behind 8 so why would we bother looking at any of these elements well we wouldn't and we're not going to okay so let's say we cut that portion of the list right so the highlighted portion we're no longer looking in and now we're now what happens is our list turns into this the highlighted portion we have 8 8 9 9 9 9 right and we're still looking for 10 so what we're gonna do is now our list is simply this in just this part with the brackets so we're gonna do the same thing we just did except with this list we're gonna find the middle index of this list which in this case would be 9 and we're gonna say is 10 greater than or less than 9 again tens the element we're looking for we say well it's greater than 9 which means that all the elements to the left here are gone we can remove them so our new list becomes this and now we say well YP look why would we bother looking at this portion when we know it can't be there right so now we have this list and now what we do is we look at the middle index in this case is 10 and one of our checks is is it greater than is it less than or is it equal to and we find that 10 is equal to 10 we know what this index is and we return that to our what do you call it to our like from our function so that's how the binary search algorithm works so now let's try to figure out how many operations this takes so let's bring our up our drawing thing here all right that's not the one I wanted sorry one second I want this one and let's let's dissect this okay right so we have a list let's say we have a list of like 1 2 3 4 and every time we run this loop right every time this runs so the while loop here which is right here we split the list in half so our first loop we look something like this our second loop looks something like this and our third loop would look like this right because every time we essentially cut off half until we get down to a one element and the worst case for this algorithm is that we look through every single possible what he call it like we look through the entire list until there's only one element left left and then if there's one element left it's either the element we're looking for or the element doesn't exist that we're trying to find right that's the worst case for this algorithm because technically like say we pick the middle index of two and that's equal to what we're looking for let's say we're looking for two then we'll just return that index right away so it could happen faster than possibly splitting it up all the way okay so we split this up split this up and then we're left with this so our input size was four right okay but we only bran at most three operations really really only two because this like the first operation brought us to this we really only did two operations as operation one this is operation two right we just ran the loop two times loop ran two times so what is that actually equal to well I want you guys to figure it out so I'm gonna do one more example okay so let's increase this list now to be five six seven eight okay so now we've just doubled the size so it was four so it was two there but now we've doubled the size and we've added those what operations do we know do now so we start and we split the list in half so we're either gonna take the left side of the right side so I mean we can pick it doesn't really matter we'll say we'll say we take the left side so now we're at 1 2 3 4 okay now what do we do split this list in half again 1 2 what do we do we split it and we get 1 so notice that now we have 1 2 3 operations we doubled the size of our list and we only added one operation or one more run of this while loop okay cuz this is what this while loop does essentially but how does that work well where what function is this we talked about it this is actually log base 2 of n and what that means essentially is based on whatever the size of our input is we can find how many operations that most will run by doing a log base 2 of N and log base 2 MN is a function like this that actually decreases in slope as it as and gets larger so this is a super fast algorithm right and we would you want to use this if we want to find something in a massive list the only disadvantage of it is you need a sorted list otherwise you can't really do something like this right if you don't have a sorted list and that is essentially how it works in terms of binary search and that's why it's log base 2 of n now I want to talk about quickly I really wish there was a clear thing for this men so I could alright well that's fine it's flawed in the app maybe I'll make one myself but what we do here right is like these are all the operations that could run each wallet right so every time we loop through like this while if essentially is gonna happen at most log log base 2 of n times ok but we do like a bunch of different operations in the fall to plague let's say we do this let's just say we do like 5 operations every time it loops well wouldn't you say that that's like 5 times log base 2 event well you'd be correct we do five operations log base two times right because this happens log base two times or mmm sorry but we do five operations but the thing is five is a constant right and we don't care about constants so we just remove it and we say that this is then Big O of log base two of n and that's how that works okay so we'll go a bit faster now for these next ones so now we're going to example one and this one is just one that I wrote myself and essentially what it does is account duplicate elements so let's try to analyze this and figure out how long this is going to take so the important thing to look at when you're analyzing something is the amount of loops right because remember we don't care about the constants so all the stuff inside of these loops it doesn't matter how much you're really doing cuz we're just gonna omit the constants anyways like say you're doing something like n times but you do like every end you do five things that's five n well we just get rid of the 5 so we don't care about the constants right so how many times does this happen we're gonna count the duplicate elements so it's actually given some kind of array we're gonna find how many elements appear more than once so for example be like this one there's two duplicate elements because two is duplicate and six is duplicate even though there's like three twos just because two appears more than once like that counts us once you know what I mean like that it's a duplicate element that's what we count so I mean I'll show you that this works first didn't mean to that example one okay and you see that we get three duplicate elements and that's because seventy seven six and two two two right so how long how many how long does this take to rotten well let's look at it so what we're doing is we're looping through the array dot length okay so that's gonna happen what n times right cuz array the length of our array is n that's our input size this is length and whatever that length is so this is gonna happen n times this first for loop but then inside of that for loop what do we do we loop again n times we say we're gonna loop again through the entire list so we're looping once and then every time we loop once we're looping through the entire list again so essentially every one of these four loops we're looping end times so every time that this runs we loop end times again so this run this runs n times but this run is n times and this runs every time that this runs so we say that this runs n times like that and this runs end times but since this for loop is inside of the other one it means that every time that this runs this is gonna run so you might be seeing what I'm getting out here how what it like how long does this take to run well this actually runs an N squared and why does that happen well because for every n we do something end times so essentially if that's n multiplied by N and n by n is N squared so this is quadratic and as the length of our input increases this is going to take a lot longer to run these are things we want to avoid is embedded for loops and embedded while loops because well it takes a really long time to run and if I were to put another for loop in here like this and say it does something well then this would run if it ran n times right so this runs n times this runs n times this runs n times so we're gonna run n cubed times which is a crazy amount of times to be running right so that's how we kind of do that so I think that's I mean that one's pretty straightforward I don't need to really do too much for that ok so let's go to example two example 2 ok so all this one is doing and it's really it's similar to last one if we're just gonna print X Y Z and this is a good example actually I don't want to print it yes it's gonna give it away what we do is we take three variables like ABC as our input and what we're going to do is we gonna loop a times B times and C times okay ABC times so this one's a bit more complicated actually how what's the big onotation of this how long does this take to run right so we can say a B and C is like our n like our input how long it's gonna take to run well what we do is we run a times we run B times a times I know it's confusing but we run this for loop B times every a time so that's a times B right so we run these two for loops a times B times now what about this third one there's another for loop inside of another for loop so this runs C times so every time B runs this runs C times and every time B runs this every time a runs this runs B times so this is actually a times B times C now what can we simplify it to be like n cubed well you can't because they're three different variables right if it was one variable and it was like a a a then we would say a cubed because it's eight times eight times a but since it's three different variables we say this runs an a times B times C and I'll prove it to you so I'm gonna run this now example two Jas and watch my watch my screen okay so we get a bunch of output let's scroll through it so this little lot these lines of code ran like this many times and then you'll see so we have X it starts at 0 Y is 1 x is 0 Y is 1 sad is 1 x is 0 Y is 1 set is 2 x is 0 Y is 1 that is 3 so you see that essentially Zed goes 1 2 3 4 0 1 2 3 4 0 1 2 3 4 and that runs a ton of times whereas X stays at zero and goes to 1 goes to 2 goes to 3 and then once it's done it's done so you can this kind of gives you an idea of exactly how this works right so you have X 0 y 0 0 0 right and then Y will change to 1 and then Zed will change right and that's exactly how it works so that's how we can kind of determine that this runs a times B times C times and I mean if you want it to count these amount of inputs you would get 5 times 5 times 5 which is essentially 125 lines ok that's how long that runs I don't want to close that ok example 3 so this one okay so this one actually is gonna generate all of the binary numbers from that are of length 16 so it's gonna start from 0 and go to length 16 so all of the binary numbers that are of length 0 to length 16 does anyone know how many numbers that is it's a lot of numbers I'll tell you that right now now this works using something called a queue based algorithm I'm not gonna explain what that is because it's a bit confusing but essentially I'll run the program and then let's try to figure out how how long this runs it ok so let's go down here it's example 3 J s alright ready I'm gonna round this watch my screen this is gonna take a second to happen and that's what I'm talking about with the time complexity right I'm only making all of the binary numbers that are of length 16 but look how long this is taking to run and if we didn't know anything about time complexity and we weren't printing this out to the screen we would not probably have realized how long this algorithm that I created takes it's super inefficient but it's really the only way to generate all of these different numbers so you can see I mean if you like if you scroll through we have a ton of different binary numbers I can't even reach the end the the last input like the start one so this how long does this take to run well this actually takes two to the N to the N times where n is essentially like the length of the binary number which is going to be 16 in this case okay because that's how many possibilities of binary numbers there are 2 to the 16 and I mean we can prove that pretty straightforward I'll draw this to you if you guys know anything about binary I don't want to use that I want to use this right so binary numbers you can either be 0 or you can be 1 it's 1 or 2 and they can obviously have like an infinite length so we are doing all the binary numbers of length 16 which means that we can well I'm not going to draw them all out but let's do an example with 3 so if we have 3 digits for a binary number then we have we can have 0 0 0 we have 0 0 1 0 1 0 0 1 1 so you are and then this sorry this goes 1 0 0 1 1 1 No 101 sorry why is this so difficult to do 1 1 0 and then 1 1 1 so we have 1 2 3 4 5 6 7 8 different binary numbers for 3 digits ok for 2 digits like let's just scrap what row should we scrap I'm trying to ok let's grab this row alright and then have a look like these zero zeros use it so these are all the same as the ones above so we get 4 so 4 2 digits we get 4 4 3 digits we get 8 4 4 we get 16 and we essentially get 2 to the amount of digits so in this case we get 2 to the 16 so that takes a really long time to run right our input size was only 16 because we only doing 16 digits but 2 to the 16 is a massive number and that's why I took us so long to run that program so you know if we had had an algorithm that could do that in linear time then we would only have ran at 16 times and that would have happened instantly but it was happening in 2 to the 16 which means that it took a long time and that's another reason obviously we need to understand time complexity and how long these things are taking now again notice right like I'm doing all of this stuff in this loop like I'm doing 1 2 3 4 5 6 7 8 operations every loop and this loop is gonna happen well 2 to the 16 times okay this happens to the 16 times multiplied by how many operations is this 8 now here's the thing right like 2 to the 16 is a massive massive number multiplying it by 8 yeah it makes it 8 times larger but really like we can just neglect this because it doesn't really tell us anything more about the shape we know the shape is exponential and it's happening like very taking a really long time so by multiplying it by 8 doesn't really give us much value it just kind of tells us it's 8 times larger it doesn't tell us the shape of the increase which is what we care about we just care about the shape of the increase ok so that's kind of it for that one what was the other example I did ok so this is one with two input variables we're going to talk about now how we do this alright so we have array1 and a rate too now how do we do this with two input variables well essentially what we do is we just say we're gonna look at the first for loop we're gonna look at the second for loop and then we'll just see what happens in here and this first for loop well what what is this run it well this runs in length one okay so it like array one has length of n one array two has length of n 2 so this first for loop is gonna happen what and one times and this for loop the second for loop happens and two times but it happens every time that N one happens so we say this happens and one this happens n two so since this four loops inside of the other four loop we simply say this is happening in n1 times n2 time in other words Big O of n 1 times n 2 and that's how we determine that so this runs in n 1 times n 2 and the reason we can't just simplify this is because obviously these variables are different and with this list was like way bigger than the other one it would affect how long it was gonna take so yeah so that has kind of been it for Big O notation introduction I hope that you guys at least have some sense of kind of the speed of some different algorithms how you can kind of look at them and getting a very brief idea of how long they're gonna take this is super useful and I highly encourage you guys to be critical of yourself if you're writing efficient code or not if you're writing code that runs an N squared just know it's gonna take a long time to run right if you're writing something like this that happens in 2 to the N understand that that's gonna take a massive amount of time to run and if you're writing something like binary search you're gonna be like well if I have massive list it might make sense to use a binary search on them because it's gonna be so much faster to find elements right so as I wrap up this video just a reminder that this video was sponsored by Microsoft if you're not already you guys should head over to their YouTube channel and hit subscribe and remember to check out dev collective in the link in the description ton of awesome courses completely for free I know you guys are gonna find a lot of value from that so with that being said thank you guys for watching the video and I will see you again in another one
