With timestamps:

00:00 - all right so now it's time to compile
00:02 - and train our model now the first thing
00:04 - we have to do is just define the model
00:06 - give it an optimizer give it a loss
00:08 - function and then I think we have to
00:09 - define the metrics as well so we're
00:12 - gonna do is gonna say model equals in
00:13 - this case or so not model equals model
00:16 - dot compile if I spell compile correctly
00:20 - and then here we're gonna say optimizer
00:23 - we're gonna use the atom optimizer again
00:25 - I'm not really going to talk about what
00:27 - these are that much if you're interested
00:28 - in the optimizer just look them up and
00:30 - then for the loss function where you're
00:33 - going to use the binary underscore cross
00:35 - and Trippi
00:37 - now what this one essentially is is well
00:39 - binary means like two options right and
00:42 - our case we want to have two options for
00:44 - the output neuron which is 0 or 1 so
00:47 - what's actually happening here is we
00:49 - have the sigmoid function which means
00:51 - our numbers gonna be between 0 & 1 but
00:53 - what the loss function will do is pretty
00:55 - well calculate the difference between
00:57 - for example say our output neuron is
01:00 - like 0.2 and the actual answer was 0
01:02 - well it will give us a certain function
01:04 - that can calculate the loss so how much
01:07 - of a difference a zero point two is from
01:09 - zero and that's kind of how that works
01:13 - again I'm not gonna talk about them too
01:15 - much and they're not like I mean they
01:17 - are important but nots really like
01:19 - memorize per se like you kind of just
01:21 - mess with different ones but in this
01:22 - case binary cross-entropy works well
01:24 - because we have two possible values 0 1
01:27 - so rather than using the other one that
01:29 - we used before which I don't even
01:31 - remember what it was called something
01:32 - cross-entropy we're using binary cross
01:34 - entropy okay so now what we're gonna do
01:36 - is we're actually gonna split our
01:37 - training data into two sets and the
01:40 - first set of our training data is gonna
01:42 - be called validation data or really I
01:44 - asked you can think of it as a second
01:45 - the word it doesn't really matter but
01:46 - what we're gonna do is just get some
01:48 - validation data and what validation data
01:50 - is is essentially we can check how well
01:53 - our model is performing based on the
01:55 - tunes and tweaks we're doing on the
01:57 - training data on new data now the reason
01:59 - we do that is so that we can get a more
02:01 - accurate sense of how well our model is
02:03 - because we're gonna be testing new data
02:06 - to get the accuracy each time rather
02:09 - than testing it on data that we've
02:11 - already seen before which again means
02:13 - that the
02:13 - can't simply just memorize each review
02:15 - and give us either a zero or one for
02:17 - that it has to actually have some degree
02:19 - of I don't know like thinking or
02:21 - operation so that it can work on new
02:23 - data so we're gonna do is gonna say X
02:25 - underscore Val equals and all we're
02:27 - gonna do is just grab the train data and
02:29 - we're just gonna cut it to a thousand or
02:31 - ten thousand entries so there's actually
02:33 - twenty five thousand entries or I guess
02:36 - reviews in our training data so we're
02:38 - just gonna take ten thousand of it and
02:39 - say we're going to use that as
02:40 - validation data now in terms of the size
02:43 - of validation data it doesn't really
02:44 - matter that much this is what tensorflow
02:48 - is using so I'm just kind of going with
02:49 - that but again mess with these numbers
02:51 - and see what happens to your model
02:52 - everything with our neural networks and
02:54 - machine learning really is gonna come
02:56 - down to very fine what's known as hyper
02:58 - parameters or like hyper tuning which
03:01 - means just changing individual
03:02 - parameters each time until we get a
03:04 - model that is well just better and more
03:06 - accurate so we're gonna say that X value
03:09 - equals that but then we're also gonna
03:11 - have to modify our X train data to be
03:13 - Train underscore data and in this case
03:15 - we're just gonna do the other way around
03:17 - so ten thousand : now I'll just copy
03:19 - this and we're just gonna replace this
03:21 - again with instead of test actually oh
03:25 - we have to do this with labels sorry
03:26 - what am I thinking so we're just gonna
03:28 - train change this to be labels and then
03:31 - instead of X value is just gonna be Y
03:33 - value and then wide train um so yeah
03:36 - we're not touching the test static
03:37 - because we're gonna use all that test
03:39 - data to test our model and then we're
03:41 - just gonna use the the training stuff
03:43 - for the validation data to validate the
03:46 - model alright so now that we've done
03:47 - that it is actually time to fit the
03:49 - model so I'm just gonna say uh like fit
03:52 - model and you'll see what I'd name this
03:55 - something different in a second who's
03:56 - gonna be equal to model dot fit and in
03:59 - this case what we're gonna do is going
04:00 - to say X underscore train Y underscore
04:03 - train we're gonna say epochs is equal to
04:08 - angle tights about 40 and again you can
04:10 - mess with this number and see what we
04:12 - get based on that and then say batch
04:13 - underscore size equals 512 which I'll
04:16 - talk about in a second and then finally
04:18 - we're gonna say validation underscore
04:20 - data equals and in here we're gonna say
04:23 - X underscore Val
04:25 - why underscore Valley and I think that's
04:28 - it let me just check here quickly a one
04:30 - last thing that I forgot to do we're
04:32 - gonna say verbose equals one verbose
04:37 - equals one now I'm not gonna lie I
04:39 - honestly don't know what verbose is I
04:41 - probably should look it up before the
04:42 - video but I have no idea what that is so
04:43 - someone knows please let me know but the
04:45 - badge size is essentially how many what
04:49 - do you call it um
04:50 - movie reviews we're gonna do each time
04:54 - or how many we're gonna load in at once
04:55 - because this thing is it's kind of I
04:58 - mean we're loading all of our reviews
05:00 - into memory but in some cases we won't
05:03 - be able to do that and we won't be able
05:05 - to like feed the model all of our
05:07 - reviews on each single cycle so we just
05:09 - set up a batch size that's gonna define
05:12 - essentially how many at once we're gonna
05:14 - give and I know I'm kind of horribly
05:16 - explaining what a batch sizes but we'll
05:18 - get into more on batch sizes and how we
05:21 - can kind of do like buffering through
05:23 - our data and like going taking some from
05:26 - a text file and reading into memory in
05:28 - later videos when we have like hundreds
05:29 - of gigabytes of data that we're gonna be
05:31 - working with okay so finally we're gonna
05:33 - say results equals and in this case I
05:35 - believe it is model dot evaluates and
05:39 - then we're gonna evaluate this obviously
05:41 - on our test data so we're gonna give it
05:43 - test data and test labels so test
05:46 - underscore data test underscore labels
05:49 - like that and then finally what I'm
05:52 - gonna do is just actually print out the
05:55 - results so we can see what our accuracy
05:57 - is so say print results and then get
06:01 - that value so let me run this quickly
06:04 - neural networks text classification
06:07 - let's go see MD and then python text or
06:12 - that's not even when we're using a
06:13 - reasoning tutorial - sorry and let's see
06:16 - what we get with this this will take a
06:17 - second to run through the epoch so I'll
06:18 - fast-forward through that so you guys
06:20 - don't have to wait alright so we just
06:23 - finished doing the epochs now and
06:25 - essentially our accuracy was 87% and
06:30 - this first number I believe is the loss
06:32 - which is 0.33 and then you can see that
06:34 - actually here we get the accuracy values
06:38 - and know
06:38 - to set the accuracy from our last epoch
06:41 - was actually greater than the accuracy
06:43 - on the test data which again shows you
06:45 - that sometimes you know when you test it
06:48 - on new data you're gonna be getting a
06:50 - less accurate model or in some cases you
06:52 - might even get a more accurate model it
06:53 - really just you can't strictly go based
06:55 - off what you're getting on your training
06:57 - data you really do need to have some
06:59 - test and validation data to make sure
07:01 - those models correctly working so that's
07:04 - essentially what we've done there and
07:07 - yeah I mean that that's the model we
07:10 - tested it's 87 percent accurate so now
07:13 - let's actually have let's interpret some
07:14 - of these results a little bit better and
07:16 - let's show some reviews let's do a
07:19 - prediction on some of the reviews and
07:20 - then see like if this our model kind of
07:22 - makes sense for what's going on here so
07:25 - what I'm going to do is I'm just going
07:26 - to actually just copy some output that I
07:27 - have here just save us a bit of time
07:30 - because I am gonna wrap up the video in
07:31 - a minute here but essentially what this
07:33 - does it just takes the first review from
07:35 - test data gets the model to predict that
07:38 - because we obviously we didn't train it
07:40 - on the test data so we can do that fine
07:42 - we're gonna say review and then we print
07:45 - out the decoded review we're gonna print
07:47 - out what the model predicted and then
07:49 - we're gonna print out what the actual
07:51 - label of that was so if I run this now
07:53 - I'll fast forward through the kind of
07:55 - training process and we will see the
07:56 - other all right so this is what
07:59 - essentially our review looks like so at
08:01 - least the one that we were testing it on
08:02 - and you can see that we have these
08:03 - little start tag and it says please give
08:05 - this one a Miss for and then B R stands
08:07 - for like brake line or go to the next
08:09 - line so we could have actually added
08:11 - another tag for B R if we notice that
08:14 - this was used a lot in the review but we
08:18 - didn't do that so you see B R unless
08:20 - this is actually part of the review but
08:21 - I feel like that should be like brake
08:23 - line in terms of HTML anyways and we
08:25 - have some unknown characters which could
08:27 - be anything that we just didn't know it
08:28 - was and it says and the rest of the cast
08:30 - rendered terrible performance as the
08:32 - show is flat flat flat brbr i don't know
08:35 - how Michael Madison could have allowed
08:38 - this one on his plate he almost seemed
08:39 - he what does it seem to know this wasn't
08:42 - going to work out and his performance
08:43 - was quite unknown so all yeah so anyways
08:46 - you can see that this probably had like
08:48 - some emojis and or something and that's
08:49 - why we have all these unknowns and then
08:51 - obviously we made this
08:52 - which was pretty short to be the full
08:54 - length of 250 so we see all these pads
08:57 - that did that for us
08:58 - and then we have a prediction and an
09:00 - actual value of zero so we did end up
09:02 - getting this one correct now I think
09:05 - it'd be interesting actually to write
09:06 - your own review and test it on this so
09:09 - in the next video what I'm gonna do is
09:11 - show you how we can save the model to
09:12 - avoid doing like all of this every time
09:15 - we want to run the code because
09:17 - realistically we don't wanna wait like a
09:18 - minute or two before we can predict a
09:21 - movie review every time we just wanted
09:23 - to happen instantly and we definitely
09:26 - can do that I just haven't showed that
09:27 - yet in the series because that's kind of
09:29 - in like later what you do after you have
09:31 - machine learning and obviously like this
09:34 - this model trained pretty quickly like
09:35 - we only had about what was it like fifty
09:38 - thousand test data set which I it seems
09:41 - like a large number but it's really not
09:42 - especially when you're talking about
09:44 - string data so in future videos we're
09:46 - gonna be training models that take like
09:49 - maybe a few days to train at least
09:52 - that's the goal or maybe a few hours or
09:54 - something like that so in that case
09:56 - you're probably not gonna want to train
09:57 - it every time before you predict some
09:58 - information so that'll be useful to know
10:00 - how to save that so that being said I'm
10:02 - gonna end the video here I hope you guys
10:03 - enjoyed this and in the next video I
10:05 - will be showing you guys how to save the
10:08 - model and how to make predictions on our
10:09 - own written reviews
10:12 - [Music]

Cleaned transcript:

all right so now it's time to compile and train our model now the first thing we have to do is just define the model give it an optimizer give it a loss function and then I think we have to define the metrics as well so we're gonna do is gonna say model equals in this case or so not model equals model dot compile if I spell compile correctly and then here we're gonna say optimizer we're gonna use the atom optimizer again I'm not really going to talk about what these are that much if you're interested in the optimizer just look them up and then for the loss function where you're going to use the binary underscore cross and Trippi now what this one essentially is is well binary means like two options right and our case we want to have two options for the output neuron which is 0 or 1 so what's actually happening here is we have the sigmoid function which means our numbers gonna be between 0 & 1 but what the loss function will do is pretty well calculate the difference between for example say our output neuron is like 0.2 and the actual answer was 0 well it will give us a certain function that can calculate the loss so how much of a difference a zero point two is from zero and that's kind of how that works again I'm not gonna talk about them too much and they're not like I mean they are important but nots really like memorize per se like you kind of just mess with different ones but in this case binary crossentropy works well because we have two possible values 0 1 so rather than using the other one that we used before which I don't even remember what it was called something crossentropy we're using binary cross entropy okay so now what we're gonna do is we're actually gonna split our training data into two sets and the first set of our training data is gonna be called validation data or really I asked you can think of it as a second the word it doesn't really matter but what we're gonna do is just get some validation data and what validation data is is essentially we can check how well our model is performing based on the tunes and tweaks we're doing on the training data on new data now the reason we do that is so that we can get a more accurate sense of how well our model is because we're gonna be testing new data to get the accuracy each time rather than testing it on data that we've already seen before which again means that the can't simply just memorize each review and give us either a zero or one for that it has to actually have some degree of I don't know like thinking or operation so that it can work on new data so we're gonna do is gonna say X underscore Val equals and all we're gonna do is just grab the train data and we're just gonna cut it to a thousand or ten thousand entries so there's actually twenty five thousand entries or I guess reviews in our training data so we're just gonna take ten thousand of it and say we're going to use that as validation data now in terms of the size of validation data it doesn't really matter that much this is what tensorflow is using so I'm just kind of going with that but again mess with these numbers and see what happens to your model everything with our neural networks and machine learning really is gonna come down to very fine what's known as hyper parameters or like hyper tuning which means just changing individual parameters each time until we get a model that is well just better and more accurate so we're gonna say that X value equals that but then we're also gonna have to modify our X train data to be Train underscore data and in this case we're just gonna do the other way around so ten thousand now I'll just copy this and we're just gonna replace this again with instead of test actually oh we have to do this with labels sorry what am I thinking so we're just gonna train change this to be labels and then instead of X value is just gonna be Y value and then wide train um so yeah we're not touching the test static because we're gonna use all that test data to test our model and then we're just gonna use the the training stuff for the validation data to validate the model alright so now that we've done that it is actually time to fit the model so I'm just gonna say uh like fit model and you'll see what I'd name this something different in a second who's gonna be equal to model dot fit and in this case what we're gonna do is going to say X underscore train Y underscore train we're gonna say epochs is equal to angle tights about 40 and again you can mess with this number and see what we get based on that and then say batch underscore size equals 512 which I'll talk about in a second and then finally we're gonna say validation underscore data equals and in here we're gonna say X underscore Val why underscore Valley and I think that's it let me just check here quickly a one last thing that I forgot to do we're gonna say verbose equals one verbose equals one now I'm not gonna lie I honestly don't know what verbose is I probably should look it up before the video but I have no idea what that is so someone knows please let me know but the badge size is essentially how many what do you call it um movie reviews we're gonna do each time or how many we're gonna load in at once because this thing is it's kind of I mean we're loading all of our reviews into memory but in some cases we won't be able to do that and we won't be able to like feed the model all of our reviews on each single cycle so we just set up a batch size that's gonna define essentially how many at once we're gonna give and I know I'm kind of horribly explaining what a batch sizes but we'll get into more on batch sizes and how we can kind of do like buffering through our data and like going taking some from a text file and reading into memory in later videos when we have like hundreds of gigabytes of data that we're gonna be working with okay so finally we're gonna say results equals and in this case I believe it is model dot evaluates and then we're gonna evaluate this obviously on our test data so we're gonna give it test data and test labels so test underscore data test underscore labels like that and then finally what I'm gonna do is just actually print out the results so we can see what our accuracy is so say print results and then get that value so let me run this quickly neural networks text classification let's go see MD and then python text or that's not even when we're using a reasoning tutorial sorry and let's see what we get with this this will take a second to run through the epoch so I'll fastforward through that so you guys don't have to wait alright so we just finished doing the epochs now and essentially our accuracy was 87% and this first number I believe is the loss which is 0.33 and then you can see that actually here we get the accuracy values and know to set the accuracy from our last epoch was actually greater than the accuracy on the test data which again shows you that sometimes you know when you test it on new data you're gonna be getting a less accurate model or in some cases you might even get a more accurate model it really just you can't strictly go based off what you're getting on your training data you really do need to have some test and validation data to make sure those models correctly working so that's essentially what we've done there and yeah I mean that that's the model we tested it's 87 percent accurate so now let's actually have let's interpret some of these results a little bit better and let's show some reviews let's do a prediction on some of the reviews and then see like if this our model kind of makes sense for what's going on here so what I'm going to do is I'm just going to actually just copy some output that I have here just save us a bit of time because I am gonna wrap up the video in a minute here but essentially what this does it just takes the first review from test data gets the model to predict that because we obviously we didn't train it on the test data so we can do that fine we're gonna say review and then we print out the decoded review we're gonna print out what the model predicted and then we're gonna print out what the actual label of that was so if I run this now I'll fast forward through the kind of training process and we will see the other all right so this is what essentially our review looks like so at least the one that we were testing it on and you can see that we have these little start tag and it says please give this one a Miss for and then B R stands for like brake line or go to the next line so we could have actually added another tag for B R if we notice that this was used a lot in the review but we didn't do that so you see B R unless this is actually part of the review but I feel like that should be like brake line in terms of HTML anyways and we have some unknown characters which could be anything that we just didn't know it was and it says and the rest of the cast rendered terrible performance as the show is flat flat flat brbr i don't know how Michael Madison could have allowed this one on his plate he almost seemed he what does it seem to know this wasn't going to work out and his performance was quite unknown so all yeah so anyways you can see that this probably had like some emojis and or something and that's why we have all these unknowns and then obviously we made this which was pretty short to be the full length of 250 so we see all these pads that did that for us and then we have a prediction and an actual value of zero so we did end up getting this one correct now I think it'd be interesting actually to write your own review and test it on this so in the next video what I'm gonna do is show you how we can save the model to avoid doing like all of this every time we want to run the code because realistically we don't wanna wait like a minute or two before we can predict a movie review every time we just wanted to happen instantly and we definitely can do that I just haven't showed that yet in the series because that's kind of in like later what you do after you have machine learning and obviously like this this model trained pretty quickly like we only had about what was it like fifty thousand test data set which I it seems like a large number but it's really not especially when you're talking about string data so in future videos we're gonna be training models that take like maybe a few days to train at least that's the goal or maybe a few hours or something like that so in that case you're probably not gonna want to train it every time before you predict some information so that'll be useful to know how to save that so that being said I'm gonna end the video here I hope you guys enjoyed this and in the next video I will be showing you guys how to save the model and how to make predictions on our own written reviews
