With timestamps:

00:00 - let's talk about one of the most
00:01 - controversial features in Python the Gil
00:04 - or Global interpreter lock in essence
00:07 - this feature disallows parallel
00:09 - processing and restricts your program
00:10 - such that it can only run one thread at
00:13 - a time to better understand this let's
00:15 - have a look at how traditional programs
00:16 - are executed by your CPU in 2023 a
00:20 - typical CPU has four cores and between
00:22 - four to eight threats to keep our
00:24 - example simple we'll imagine that each
00:26 - core only has one Hardware thread each
00:29 - CPU core is a physical processing unit
00:31 - that is capable of handling one task at
00:34 - a time the more cores we have the more
00:36 - tasks we can process at the same exact
00:38 - time the types of tasks that CPU cores
00:41 - handle are called software threads it
00:43 - can get confusing but software threads
00:45 - are created by applications while
00:47 - Hardware threads exist on the physical
00:49 - CPU from now on we'll only be referring
00:52 - to software threats now software threads
00:54 - are portions of applications or programs
00:56 - that can be run independently by a CPU
00:59 - core the more cores we have the more
01:01 - threads we can execute at the same time
01:03 - this means that we can speed up our
01:05 - programs by splitting them into multiple
01:07 - threads
01:08 - so let's take an example where we want
01:10 - to sum the numbers from 1 to 20. well if
01:12 - we do this with a single thread we're
01:14 - only utilizing one of our four CPU cores
01:17 - to speed up this operation we can split
01:19 - our program into four threads where each
01:21 - thread is responsible for summing a
01:23 - portion of the numbers thread one can
01:25 - sum the numbers one to five thread two
01:28 - sum six to ten thread 3 sums 11 to 15
01:31 - and thread 4 some 16 to 20. now that
01:34 - we're using four threads we can use four
01:37 - CPU cores and we sped up our program by
01:39 - four times now this adds a bit of
01:41 - complexity but overall it's worth the
01:43 - trade-off now here comes the bad news in
01:46 - Python it doesn't quite work this way
01:48 - whenever we execute code we use
01:49 - something called an interpreter to keep
01:51 - it simple this is what's capable of
01:53 - understanding the code and processing
01:55 - the instructions that we wrote that
01:57 - means that in the previous example each
01:59 - one of our threads will need to access a
02:01 - code interpreter whenever it's executing
02:03 - instructions in most languages this is
02:05 - fine multiple threads can use the same
02:07 - interpreter at the exact same time but
02:10 - in Python we have something called a
02:12 - lock now a lock is essentially a gate
02:14 - that only lets one thread through at a
02:16 - time since we have a lock on our python
02:18 - interpreter that means that even though
02:20 - we have four threads only one can use
02:22 - The Interpreter at a time if a thread is
02:25 - using The Interpreter it can release the
02:27 - lock allowing another thread to access
02:28 - it but only one thread can be using The
02:31 - Interpreter at the same time that in
02:33 - essence is the python Global interpreter
02:36 - lock now at this point you might be
02:38 - asking yourself why would I ever use
02:40 - multiple threads in Python well the
02:42 - answer is when you're working with
02:43 - network or input output type operations
02:45 - now imagine a simple example where a
02:48 - user visits your app the app may need to
02:50 - load the user's friends and chat history
02:52 - from a file or from some API now while
02:55 - this loading is happening you still want
02:56 - your user to be able to interact with
02:58 - the app if you were to place all of this
03:00 - logic in one single thread the app would
03:03 - freeze waiting on the data to be loaded
03:05 - before the user can do anything else on
03:07 - the app or before you can load load
03:09 - additional data now if you split this
03:11 - operation into three threads even though
03:13 - only one thread can execute at a time
03:15 - you can execute a different thread while
03:17 - one thread is waiting on a result from
03:19 - the file system or the server or Network
03:22 - so what we'll do here is we'll make a
03:24 - thread to load the chat history a thread
03:26 - to load the friends and a thread that
03:28 - runs the user interface we start by
03:30 - running the chat history thread which
03:32 - quickly sends a request to a server for
03:34 - some results This Thread then hangs
03:37 - waiting on a result now as soon as it
03:39 - starts waiting we can switch to execute
03:41 - a different thread in this case the
03:43 - friends thread same here as soon as it
03:45 - starts waiting we execute the user
03:47 - interface thread allowing the app to run
03:49 - while the data is loading now once we
03:51 - receive the data we can quickly switch
03:53 - back to the other threads process that
03:55 - data and move on this allows us to
03:57 - execute data concurrently so the CPU can
04:00 - always be working and never waiting on a
04:02 - result that we don't have control over
04:04 - creating multiple threads allows us to
04:06 - switch between those different threads
04:07 - so we're always utilizing the CPU so now
04:10 - that we have a good understanding of
04:11 - threading let's briefly discuss
04:13 - multi-processing python has a
04:15 - multi-processing module which allows us
04:17 - to create separate processes now as a
04:19 - simplification you can imagine that each
04:21 - process spawns its own instance of the
04:23 - Python interpreter this means that we
04:25 - can sidestep the global interpreter lock
04:27 - and run a truly parallel application now
04:30 - multi-processing is not as easy to
04:32 - handle as multi-threading but this is a
04:34 - solid solution to avoid the global
04:36 - interpreter lock so now at this point
04:38 - you know about one of the most
04:39 - controversial features in Python the
04:41 - global interpreter lock if you want to
04:43 - learn more about python make sure to
04:45 - subscribe to this channel I look forward
04:46 - to seeing you in another one
04:51 - foreign
04:52 - [Music]

Cleaned transcript:

let's talk about one of the most controversial features in Python the Gil or Global interpreter lock in essence this feature disallows parallel processing and restricts your program such that it can only run one thread at a time to better understand this let's have a look at how traditional programs are executed by your CPU in 2023 a typical CPU has four cores and between four to eight threats to keep our example simple we'll imagine that each core only has one Hardware thread each CPU core is a physical processing unit that is capable of handling one task at a time the more cores we have the more tasks we can process at the same exact time the types of tasks that CPU cores handle are called software threads it can get confusing but software threads are created by applications while Hardware threads exist on the physical CPU from now on we'll only be referring to software threats now software threads are portions of applications or programs that can be run independently by a CPU core the more cores we have the more threads we can execute at the same time this means that we can speed up our programs by splitting them into multiple threads so let's take an example where we want to sum the numbers from 1 to 20. well if we do this with a single thread we're only utilizing one of our four CPU cores to speed up this operation we can split our program into four threads where each thread is responsible for summing a portion of the numbers thread one can sum the numbers one to five thread two sum six to ten thread 3 sums 11 to 15 and thread 4 some 16 to 20. now that we're using four threads we can use four CPU cores and we sped up our program by four times now this adds a bit of complexity but overall it's worth the tradeoff now here comes the bad news in Python it doesn't quite work this way whenever we execute code we use something called an interpreter to keep it simple this is what's capable of understanding the code and processing the instructions that we wrote that means that in the previous example each one of our threads will need to access a code interpreter whenever it's executing instructions in most languages this is fine multiple threads can use the same interpreter at the exact same time but in Python we have something called a lock now a lock is essentially a gate that only lets one thread through at a time since we have a lock on our python interpreter that means that even though we have four threads only one can use The Interpreter at a time if a thread is using The Interpreter it can release the lock allowing another thread to access it but only one thread can be using The Interpreter at the same time that in essence is the python Global interpreter lock now at this point you might be asking yourself why would I ever use multiple threads in Python well the answer is when you're working with network or input output type operations now imagine a simple example where a user visits your app the app may need to load the user's friends and chat history from a file or from some API now while this loading is happening you still want your user to be able to interact with the app if you were to place all of this logic in one single thread the app would freeze waiting on the data to be loaded before the user can do anything else on the app or before you can load load additional data now if you split this operation into three threads even though only one thread can execute at a time you can execute a different thread while one thread is waiting on a result from the file system or the server or Network so what we'll do here is we'll make a thread to load the chat history a thread to load the friends and a thread that runs the user interface we start by running the chat history thread which quickly sends a request to a server for some results This Thread then hangs waiting on a result now as soon as it starts waiting we can switch to execute a different thread in this case the friends thread same here as soon as it starts waiting we execute the user interface thread allowing the app to run while the data is loading now once we receive the data we can quickly switch back to the other threads process that data and move on this allows us to execute data concurrently so the CPU can always be working and never waiting on a result that we don't have control over creating multiple threads allows us to switch between those different threads so we're always utilizing the CPU so now that we have a good understanding of threading let's briefly discuss multiprocessing python has a multiprocessing module which allows us to create separate processes now as a simplification you can imagine that each process spawns its own instance of the Python interpreter this means that we can sidestep the global interpreter lock and run a truly parallel application now multiprocessing is not as easy to handle as multithreading but this is a solid solution to avoid the global interpreter lock so now at this point you know about one of the most controversial features in Python the global interpreter lock if you want to learn more about python make sure to subscribe to this channel I look forward to seeing you in another one foreign
