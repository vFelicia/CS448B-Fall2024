00:00 - what is sqlite it's different from most
00:03 - other database engines it's
00:04 - it's a library it's not a system
00:07 - it's not a process if you've done if
00:09 - you've done a lot of database
00:10 - if you've worked with any other database
00:12 - it's probably a system
00:13 - it's running in the data center
00:15 - somewhere sql is a library that just
00:17 - links into your application
00:19 - it's a very different thing it's what
00:20 - it's delivered as a single file
00:23 - of ansi c code now this is a large file
00:26 - and we don't actually develop by editing
00:29 - that one big file
00:30 - we have hundreds of files and then part
00:33 - of our make process kind of concatenates
00:35 - them all together in the right order
00:36 - but that makes it very easy to deploy it
00:38 - compiles down to
00:40 - roughly 500 kilobytes it's very small
00:43 - and compact small footprint
00:46 - low dependencies it's designed to run on
00:47 - embedded systems i've
00:49 - i've got here uh the minimum set of
00:52 - dependencies i mean just standard
00:53 - library things that's all it is you
00:54 - don't have to import
00:56 - a bunch of other libraries to get this
00:58 - thing to work so it can work on embedded
01:00 - systems
01:01 - a complete database file is stored
01:05 - a complete database is stored in on disk
01:08 - as a single file
01:10 - which is an interesting thing most other
01:11 - database systems
01:13 - store the content in a directory full of
01:16 - files
01:17 - and in a lot of systems that directory
01:20 - is known only to the system
01:21 - administrator it's some
01:23 - weird place that nobody entered where is
01:25 - but with sqlite the entire database is
01:27 - just an ordinary file
01:28 - and that means you can take that file
01:30 - and put it on a flash drive
01:32 - or email it to a colleague it's really
01:34 - easy to move around
01:36 - it's a full featured sql implementation
01:39 - with you know things like
01:40 - um common table expressions partial
01:43 - indices
01:43 - full text search archery indices it
01:47 - features
01:47 - power safe serializable transactions by
01:50 - power safe i mean
01:52 - you can be in the middle of a
01:54 - transaction or in the middle of doing a
01:56 - commit
01:57 - and the system will lose power and you
02:00 - know under the assumption that the
02:01 - hardware behaves as advertised
02:03 - which is not always an accurate
02:06 - assumption but
02:07 - assuming that hardware does what it's
02:08 - supposed to do
02:10 - you won't lose any work
02:13 - very simple api easy to program to it's
02:17 - designed to be able to drop in
02:18 - it's designed for for application
02:20 - developers to be able to take this code
02:22 - drop it into their application and have
02:24 - a full featured database
02:26 - with no other work um
02:29 - and the source code is in the public
02:30 - domain so you can
02:32 - grab the source code and do whatever you
02:34 - want with it you can grab a copy of the
02:36 - source code relabel it andydb
02:38 - and go with it i mean that's whatever
02:40 - you want to do
02:43 - it's called sqlite people think oh it's
02:45 - just a little tiny toy database it does
02:47 - have its limits but they're
02:48 - pretty big we support multiple uh
02:51 - concurrent riders and one
02:53 - reader or what multiple concurrent
02:55 - readers and one rider all the same time
02:57 - now you know that's not huge but that
02:59 - but that's usually enough
03:01 - for your embedded device uh we
03:05 - take strings and blobs up to a gigabyte
03:07 - in size
03:09 - which is actually more than a lot of
03:11 - large-scale databases we'll do
03:13 - a single database can be up to 140
03:15 - terabytes
03:17 - we've never actually tested that limit
03:19 - because we've never actually come up
03:20 - with a file system that
03:22 - could give us a 140 terabyte file but
03:25 - that's the theoretical limit 64-way
03:27 - joins 2000 columns per table
03:29 - there aren't any real arbitrary limits
03:31 - other than these
03:33 - it it's actually a full-featured
03:35 - database engine
03:36 - so what is the forcing function for 140
03:40 - terabytes
03:40 - what limits it uh the the limiting
03:43 - factor on the size of the database file
03:45 - 140 terabytes
03:46 - is that it's it the the we use a 32-bit
03:51 - integer to count uh the pages
03:55 - actually it's a signed integer so we
03:57 - have to leave the top bit off
03:58 - and so we have 31 bits and the maximum
04:01 - page size is 64k
04:03 - so you do the math so um
04:06 - how did this get started this was um i'm
04:09 - not
04:09 - you know i didn't start out as a
04:10 - database person i was doing some
04:12 - application development
04:13 - uh solving some hard problems and i was
04:16 - doing these client programs that were
04:17 - doing a really interesting theoretical
04:19 - calculation
04:20 - and but i had to get my data from a
04:22 - database engine and the client
04:24 - that i was working for provided the
04:25 - database engine and it was informix and
04:27 - that
04:28 - hey it worked great when it worked
04:31 - but sometimes they would power cycle the
04:33 - database or power cycle the machine
04:35 - and the database engine wouldn't come
04:36 - back up and when that would happen
04:40 - that would mean that my application
04:42 - couldn't do its job because it couldn't
04:44 - read the data
04:45 - because it had to talk to the database
04:46 - engine and so my application would bring
04:49 - up that dialog box
04:51 - and that's what an error dialog box
04:54 - actually looked like in the late 1990s
04:55 - that's an actual screenshot
04:57 - they look better now don't they yeah a
04:59 - little bit grainy
05:01 - yeah yeah but you know back in you know
05:03 - back in 1998 we thought this was so cool
05:05 - this was so state of the art you know
05:08 - do you remember that um so i had this
05:11 - idea well look
05:12 - uh this particular application it's not
05:14 - doing a lot of heavy
05:16 - transaction stuff in fact it's read only
05:19 - and it's not doing any elaborate joins
05:21 - or queries why can't i just read this
05:23 - data directly from the disk
05:24 - why do i need this server
05:28 - sitting in between me and my data which
05:30 - is just
05:31 - another potential point of failure
05:34 - so after that project was finished i
05:38 - you know i had a couple months off and i
05:40 - wrote sqlite
05:41 - and that was in that started in 2000 and
05:44 - in may of 2000 was first code and the
05:46 - first release was a few months later
05:49 - so that's how it got started and that
05:51 - sort of shows you the motivation behind
05:53 - it
05:53 - so it's a little bit different from what
05:55 - you're kind of used to seeing
05:57 - it has different use cases sqlite is not
05:59 - trying to
06:01 - to replace all these other databases
06:03 - that you're more familiar with
06:04 - it sqlite ends up being very useful in
06:06 - embedded devices
06:07 - in the internet of things it's in your
06:09 - cell phone it's in
06:11 - you know the you know the smart
06:13 - thermostats it's in your microwave oven
06:15 - it's in your tv set
06:17 - these sorts of things don't need to be
06:18 - doing a bazillion transactions
06:21 - how many such devices is it uh it's hard
06:25 - to count because it is
06:26 - open because it's public domain a lot of
06:28 - people don't tell us
06:30 - so for and you know until a few minutes
06:32 - ago i did not know that sqlite was
06:33 - flying on the space station
06:35 - you missed the intro no sorry you missed
06:37 - the internet so um
06:41 - so yeah aol was one an early adopter
06:44 - do you remember back in early in the
06:46 - early part of this millennium where
06:48 - you know you get the aol install cds you
06:51 - know ten dollars a month or something
06:53 - do you remember those i never was the
06:54 - aol sqlite was always on those
06:56 - very few people
07:00 - so um but sqlite is also good as an
07:03 - application file format if you're doing
07:05 - a traditional desktop application of
07:06 - some sort
07:07 - and instead of doing file save and
07:10 - writing out a bunch of xml make it a
07:13 - database
07:13 - you get all this powerful query language
07:16 - and and
07:17 - and transactions uh it's great for uh
07:20 - what i call the lingua franca of a
07:22 - federation of programs you got a bunch
07:23 - of graduate students working on a
07:24 - problem
07:25 - you know and you're writing in python
07:28 - and you over here you're doing c
07:30 - plus plus and you're doing ruby and this
07:33 - guy over here is doing php
07:35 - oh you're doing lisp you know all these
07:37 - guys are doing different programs
07:38 - because that's what they want to do
07:40 - but they all got to talk to each other
07:42 - why not use an sqlite database
07:44 - file as your means of your common mode
07:45 - of communication
07:48 - um it's often used as a local cache for
07:50 - an enterprise database
07:51 - so you're on a device you want to
07:53 - download data that's
07:54 - relevant to the device so that the
07:56 - device can continue to operate
07:59 - while you're off network you're you're
08:01 - on your phone you're going through a
08:03 - tunnel and you've lost reception
08:04 - you're off network for a while and it
08:07 - works well it's also good as an
08:09 - interchange format so
08:10 - for example um you know the uh
08:14 - the the the program guide on your cable
08:17 - tv
08:17 - and it comes down to the set top box in
08:20 - a lot of cases
08:21 - it's being being bound from the
08:22 - satellite to your setup box
08:24 - as an sqlite database
08:27 - and then you know and then the little
08:29 - the window that shows you what that's
08:31 - that's just an archery query
08:34 - so uh here's your decision checklist
08:36 - about when to use
08:38 - or what data storage engine to use for
08:40 - your project
08:41 - is the data remote if the data is on a
08:43 - different device
08:44 - from the one that your program is
08:46 - application is running on
08:48 - use one of the traditional client server
08:50 - databases if it's big data if it's
08:52 - more data than you're comfortable
08:53 - putting in a single file
08:56 - use one of the traditional client server
08:58 - database you've got concurrent writers
09:00 - if you're trying to do a gazillion
09:02 - transactions per second
09:04 - use a client server database that's what
09:06 - they're for and these are all very
09:08 - important problems and these client
09:09 - server databases are all very good at
09:10 - solving them
09:11 - but there's a lot of problems that don't
09:13 - fit any of those categories and for all
09:14 - those other cases
09:16 - just use sqlite and where people mess
09:19 - this up
09:21 - is that they they do the first part of
09:24 - that checklist right
09:25 - and they get down to the bottom says oh
09:26 - well i don't have any of these problems
09:28 - i'm just going to open a file and write
09:32 - a bunch of
09:32 - json into it or some binary format that
09:36 - i made up
09:37 - and this happens a lot and that's the
09:39 - use case for sqlite
09:41 - sqlite is not really competing against
09:43 - these other
09:44 - database engines that you study all the
09:46 - time it's competing with f open
09:49 - that's it's that's its goal um
09:52 - so sqlite is found in lots of different
09:55 - things
09:55 - as andy was saying it's in all the
09:57 - phones it's in your mac
09:59 - it's in your windows 10 machine it's in
10:02 - the web browser it's in lots of
10:04 - applications
10:04 - it's built into a lot of programming
10:06 - languages and it's just appearing in
10:08 - devices all over
10:09 - we we're pretty sure we can't measure
10:13 - this because it is public domain
10:14 - but we're pretty sure it is the most
10:16 - widely used database engine in the world
10:19 - i think that it is probably the number
10:22 - two
10:23 - most used piece of software in the world
10:25 - i'm thinking that number one
10:27 - is the zlide compression library
10:30 - it's probably more deployments than
10:32 - sqlite but other than that i'm not aware
10:34 - of anything that does more
10:35 - okay i've got one marketing slot
10:37 - actually two this is the first of two
10:38 - mark i got a question in the back
10:40 - what percentage of the code base deals
10:43 - with the sql
10:44 - part i've got a slide coming up so hold
10:46 - the question
10:47 - okay so this is my i've got two
10:49 - marketing slides i just want to point
10:50 - you this is a
10:51 - this is a graph of apple's stock price
10:54 - from there when they originally went
10:55 - public
10:56 - in 1981 up until about 2012 and from
11:00 - there it's gone up
11:02 - uh uh this is before the split they had
11:04 - an 8-1 split
11:05 - but adjusted for the split it would be
11:07 - now at about a thousand
11:09 - and you can notice how the stock stayed
11:11 - around 10
11:12 - or 15 dollars per share for over 20
11:15 - years
11:16 - and then it suddenly started this rise
11:18 - up to a thousand
11:20 - okay absolutely true sqlite was
11:23 - introduced into the mac platform
11:25 - there okay i'm just saying i'm just
11:28 - saying but
11:29 - did you buy a bunch of apple stock then
11:31 - unfortunately no
11:34 - um so so what i'm going to talk about
11:36 - here is i'm going to go over how
11:37 - sqlite is implemented because you're all
11:40 - database people i assume
11:41 - and even if you're not even if you're
11:43 - working on you know one of these
11:44 - systems that does a gazillion
11:46 - transactions per second and that's
11:48 - really not what you're into it's an
11:50 - important database and you need to
11:51 - understand it
11:52 - and so i'm going to talk i'm going to
11:53 - give you an overview of the
11:54 - implementation so that you
11:56 - understand what it's doing and so that
11:58 - if you want to go and look at the code
12:00 - you've got kind of a road map
12:03 - the code is available online here's how
12:05 - you get it there's two places that you
12:07 - can get it
12:07 - and it's readable code we put a lot of
12:09 - comments in the code and the readable
12:11 - comments we get
12:12 - we see tweets about how oh you should
12:15 - re-ask your light code it's really easy
12:17 - so you can actually study this my goal
12:19 - is to give you a road map so that
12:20 - when you just pull a random bit of code
12:23 - out
12:24 - you you have some inkling of what it's
12:25 - trying to do
12:27 - um so any
12:30 - database engine i like to think of them
12:33 - in terms of a compiler
12:35 - and a virtual machine so
12:39 - you've got sql that comes in and you've
12:41 - got a part of the program that's going
12:42 - to compile
12:44 - part of the database engine that's going
12:45 - to compile the sql into a
12:48 - a prepared statement this is um uh
12:52 - i think of think of every statement of
12:54 - sql as a miniature program
12:56 - and the prepared statement is the
12:58 - executable and so this is just like this
13:00 - is like gcc
13:02 - and then you get a prepared statement
13:04 - and then you run the prepared statement
13:06 - that's like just executing the binary
13:09 - that's the way we like to think of it
13:12 - this is the stack
13:13 - of sqlite there's a parser code
13:15 - generator virtual machine b3 layer pager
13:17 - and an os interface i'm going to talk
13:18 - about each of these in turn
13:20 - uh at the top there's a parser it's
13:24 - a standard kind of parser we did the the
13:26 - tokenizer is written by hand it's only a
13:28 - couple hundred lines of code
13:30 - you know when you're when you're
13:31 - studying compiler construction everybody
13:33 - you have these big chapters about
13:34 - you know lex and lectures and stuff and
13:36 - they use a lot
13:37 - i've never understood that because it is
13:39 - so so easy
13:41 - to write a tokenizer and a couple
13:44 - hundred lines of c code
13:45 - that is at least two orders of magnitude
13:47 - faster than anything flex will ever
13:49 - generate
13:50 - so i i don't know why they do that but
13:52 - never heard anybody writing their own
13:54 - parser by hand that's crazy no
13:57 - no the the this just the tokenizer this
13:59 - is just splitting it up into tokens
14:01 - now the parser is a traditional la lr1
14:04 - parser
14:05 - it doesn't use yak i wrote my own
14:07 - partial generator when i was a graduate
14:09 - student
14:10 - okay and
14:13 - and it has the advantage of react that
14:15 - it generates a partial that is
14:17 - re-entrant
14:18 - and thread safe and back back when i was
14:21 - doing this
14:22 - bison and yak parsers wouldn't were
14:24 - neither of these things
14:26 - they may have fixed that now i don't
14:27 - know i haven't kept up with it
14:30 - so but it's a traditional parser these
14:32 - are the files where you can find this
14:34 - stuff if you if you want to look at the
14:35 - code
14:38 - the the source code to the lemon parser
14:40 - generator is included in the source tree
14:42 - and documentation is included in the
14:44 - source tree so you can learn about lemon
14:47 - and then the the structures that define
14:50 - the asset
14:51 - abstract syntax tree are in that header
14:54 - file
14:55 - and the tokenizers in that file up there
14:58 - so moving on down further we have the
14:59 - code generator
15:01 - which does semantic analysis of the
15:04 - parsed code
15:05 - transforms the parse tree and ways to
15:07 - try to make things
15:09 - more efficient does query planning and
15:11 - then generates byte code
15:13 - the output of this is the prepared
15:15 - statement so these two things implement
15:17 - the compiler
15:18 - think of these two steps as gcc
15:22 - they take raw program text and turn it
15:24 - into something the machine can
15:25 - understand
15:27 - and of course the rest of the stack is
15:29 - going to be implementing
15:30 - the machine um
15:34 - so the virtual machine in sqlite is it's
15:37 - a it's a bytecode interpreter
15:39 - a lot of other database engines they
15:41 - will um
15:43 - they just walk the parse tree and that's
15:45 - how they execute
15:47 - but i wanted to do a bytecode
15:49 - interpreter
15:50 - the original bytecode interpreter was a
15:53 - stack base where you push
15:55 - things onto a stack and then operate on
15:56 - the stack just like jvm
15:59 - and all the others seems like every
16:01 - virtual machine always starts as a stack
16:02 - based
16:03 - machine but we changed it to a three
16:06 - address machine because that actually
16:08 - turns out to be more efficient and much
16:10 - easier to write
16:11 - optimal code for so it's really simple
16:14 - it's a big for loop
16:16 - program counter equals zero you know
16:19 - program counter plus plus and inside the
16:21 - floor there's a switch and switches on
16:23 - the op code and there's a case for every
16:24 - op code
16:26 - uh and part of the virtual machine i
16:28 - also include
16:29 - the implementation of the built-in sql
16:32 - functions
16:33 - so they're included there talk more
16:35 - about that later so here's an example
16:37 - of what the byte code looks like i won't
16:39 - walk you through this
16:42 - but you can you can look at the bytecode
16:44 - for any sql statement
16:46 - that sql lite can generate by just
16:49 - putting explain up front
16:53 - like this and the the documentation for
16:55 - the op codes is available online
16:57 - if you want to want to try and decode
16:58 - that this is doing a full table scan so
17:00 - this one's
17:01 - pretty simple and i could fit on one
17:02 - slide for a join
17:04 - with sub queries and lots of conditions
17:07 - this might go on for hundreds or even
17:08 - thousands of instructions
17:10 - but a simple table scan it pretty quick
17:15 - if you want to to study this you want to
17:18 - look at what the bytecode sqlite
17:19 - generates
17:20 - is let me tell you how to do that you
17:22 - get you need you need to do a custom
17:24 - custom build and so to get the tar
17:27 - i'll get the source code do configure
17:30 - and i like to do disabled shared because
17:33 - auto comp if you don't do that it does
17:35 - all this freaky shell script stuff to do
17:38 - shared libraries and and you can do that
17:40 - if you want to it'll work but
17:42 - i find finding confusing so i always
17:43 - disable it and
17:45 - when you before you do make there's an
17:47 - extra
17:48 - c pre processor to find that you need to
17:50 - give it and
17:51 - then that's going to um add these
17:54 - comments i'm going to go back a slide
17:56 - over here on the far right we've got
17:58 - comments
18:00 - that help explain what each op code is
18:03 - doing
18:04 - and and by default those are not
18:07 - generated because they take up space
18:09 - and it takes cpu cycles to generate them
18:11 - so in a production environment we
18:13 - don't want to do that but if you're
18:14 - debugging they're very useful
18:16 - to help you quickly see what's going on
18:18 - and so
18:21 - you'll probably want to include those so
18:23 - once you get that thing compiled
18:25 - what you've compiled then is a command
18:28 - line shell
18:29 - it's just a simple program that reads
18:31 - sql statements and then sends them to
18:33 - sqlite to be executed
18:35 - and this this command line shell
18:39 - sqlite3 uh
18:42 - if you if you give it a line that starts
18:43 - with a dot period
18:45 - that's special the shell doesn't send
18:47 - that to sqlite it does some special
18:49 - processing
18:49 - and the dot explain sets up the output
18:52 - formatting
18:53 - so that you have nice neat columns and
18:56 - it automatically indents
18:58 - loops so that you can spot the loops
19:00 - more easily
19:02 - and so that's a nice thing you want to
19:03 - do so you want to be sure and type that
19:05 - and then you just type in explain
19:07 - and then the rest of your query and
19:08 - you'll get to see the bytecode
19:12 - so moving on down the stack
19:17 - this is kind of the boundary between
19:21 - to the storage engine and you know a lot
19:24 - of places that go and i talk to people
19:26 - and about databases and when i say
19:28 - databases
19:29 - to them the storage engine is the
19:31 - database this is their focus
19:33 - how can i get as many writes to disk as
19:36 - possible
19:38 - my view is a little different i think
19:39 - that
19:41 - this whole stack is the database and and
19:43 - the bottom part is just the storage
19:45 - engine
19:45 - and if you've got just a key value pair
19:47 - type thing you only have half a database
19:50 - that's my opinion
19:51 - really in my view the interesting stuff
19:53 - is happening up above
19:54 - all the query planning and the the the
19:58 - analysis of the declarative programming
20:00 - language that's where the interesting
20:01 - parts are
20:01 - the bottom is just a storage engine now
20:03 - there is a a reasonably clean interface
20:05 - for this in sqlite
20:07 - and what a lot of people have done
20:10 - including some people who will be
20:11 - speaking to you in
20:12 - the in this lecture series is um
20:16 - they have taken the default sqlite
20:18 - storage engine out just
20:19 - stripped it out and plugged in their own
20:22 - so then they've got an sql
20:24 - system on top and then they put their
20:27 - own
20:28 - whiz-bang storage system underneath
20:31 - because you see in a minute my storage
20:32 - engine is is not like
20:35 - cool and has the latest algorithms it's
20:36 - it's it's old tech
20:38 - it's old school so um
20:42 - the bee tree layer uh we support b trees
20:44 - and b plus trees there's multiple b
20:46 - trees per disk file one b tree for table
20:49 - for each table one b
20:50 - tree for each index variable length
20:52 - records
20:53 - uses a very efficient coding mechanism
20:56 - um it's accessed via cursor so when
21:00 - you're working with b trees you open a
21:01 - cursor into a
21:02 - into a b tree and then you can seek the
21:04 - cursor and advance the cursor backwards
21:06 - and forwards
21:08 - and it allows for multiple cursors to be
21:11 - open on the same b tree at the same time
21:13 - and including cursors that are changing
21:15 - the b tree and
21:16 - and it takes care automatically that
21:19 - people don't
21:20 - write things out from underneath each
21:21 - other i'm going to go back over this is
21:22 - just the
21:23 - i don't know if i made clear this is
21:25 - just sort of the 30 000 foot view
21:27 - i'm going to go back over all of this in
21:29 - more depth
21:30 - after i finish the quick overview
21:34 - next on down is the pager layer and this
21:36 - is the part that implements
21:38 - your transactions your atomic commit and
21:40 - your rollback
21:41 - the pager views the database as
21:45 - a bunch of pages then they're numbered
21:47 - starting with one
21:48 - because page zero is like our null
21:50 - pointer
21:52 - and the page size is a power of two
21:55 - between 512 and 64k
21:57 - the pager has no idea what what the
21:59 - content of the page is it doesn't care
22:02 - it's just managing the pages handing
22:04 - them to the b tree and then dealing with
22:06 - transactions
22:08 - it also provides concurrency control
22:09 - because with sqlite you can have
22:11 - multiple processes
22:12 - talking to the same database file at the
22:14 - same time and
22:16 - there's not a server controlling this
22:18 - they're all peers and
22:19 - and so there's got to be a mechanism to
22:21 - make sure they don't step on each other
22:23 - and and that's handled by the pager
22:24 - layer
22:24 - and then at the bottom we have the
22:26 - operating system interface this is the
22:27 - portability layer this is how we
22:29 - allow sqlite to operate on windows
22:32 - on mac on a various embedded database or
22:37 - various embedded operating systems
22:39 - including some custom operating systems
22:42 - uh this is you can plug in new os
22:45 - interfaces at runtime
22:48 - which is an interesting feature which
22:49 - i'll talk about in the next slide
22:51 - and you know i say an os interface
22:55 - uh people have substituted we have an
22:57 - example of this
22:58 - an os interface that talks directly to
23:00 - hardware bypasses the operating system
23:02 - completely
23:03 - so you can actually buy commercial off
23:05 - the shelf devices little gadgets
23:08 - that are using sqlite
23:11 - and they plug in their own os interface
23:13 - that talks directly to the flash
23:14 - controller
23:16 - and they use sqlite as their file system
23:19 - they have no file system on the device
23:20 - that you only have the database
23:23 - interesting concept now because it's
23:25 - runtime plugable we have this concept
23:26 - above
23:27 - shim where you can you can
23:30 - plug in your own os interface that
23:33 - doesn't really do a complete os
23:34 - interface
23:35 - it just uh maybe changes the
23:38 - the calls around a little bit and then
23:40 - passes it on down to the real os
23:41 - interface
23:42 - and this could do things like you could
23:43 - add encryption or compression
23:46 - you could do logging we use this a lot
23:48 - for testing because we can plug in a
23:50 - shim
23:51 - that can simulate hardware failures
23:54 - and that we can we can prove that sqlite
23:56 - is going to be able to recover
23:58 - gracefully from a hardware failure
24:00 - and there's some examples uh
24:02 - implementations of this sort of thing if
24:04 - you want to play around with it
24:06 - so uh there was a question in the back
24:08 - of what the percentage was here is the
24:09 - graph here is the chart
24:11 - uh the parser is the little green this
24:13 - is source code
24:14 - uh if you looked at compiled binary the
24:17 - ratios are going to be a little bit
24:18 - different but it's
24:19 - this is roughly the same um and in
24:22 - particular the parts are going to grow a
24:23 - little bit because
24:24 - uh the la lr1 language is a very compact
24:27 - notation
24:29 - but um not a whole lot and then the the
24:31 - code generator is the bulk of it
24:33 - coach rendering and the virtual machine
24:35 - and the partial together are over half
24:36 - of it
24:38 - the b tree layer is this thin little
24:40 - slice right here
24:42 - it's really not that much
24:45 - um
24:50 - so that is that is the 30 000 foot view
24:54 - of sqlite now what i'm going to do now
24:56 - my plan is to go back
24:58 - through this whole thing again but this
25:00 - time from the bottom up and get into a
25:01 - little bit more detail about how things
25:02 - work
25:03 - so that you better understand what
25:05 - sqlite is doing behind the scenes
25:06 - so let's start with the pager again this
25:08 - is what handles power save transactions
25:10 - and currency control this is the thing
25:12 - that makes sure that you can roll back
25:14 - your transactions
25:14 - or that if you crash in the middle of a
25:16 - transaction your database is consistent
25:19 - that transactions are atomic across
25:21 - power failures it also handles current
25:23 - control and provides an in-memory cache
25:25 - for the disk controller
25:27 - so when you start out you're getting
25:28 - ready to read the database here's a
25:29 - little diagram i've got
25:31 - i guess uh it's labeled disk now it
25:34 - means nand flash right because
25:36 - i don't think i even own a computer that
25:38 - has spinning rust anymore
25:39 - if they're all but but you know what i
25:42 - mean so all the data is on disk
25:44 - there's an os cache an operating system
25:46 - cache but it's empty right now
25:48 - there's no content there the cache is
25:50 - cold
25:52 - and you want to read from the database
25:54 - and so the first thing you have to do is
25:55 - get a shared lock
25:56 - and that's drawn on the in ram because
25:59 - you know you think about these locks
26:00 - they don't really persist
26:02 - if the system crashes all the locks go
26:03 - away
26:05 - so you get a shared lock and that
26:06 - prevents other processes
26:09 - from from changing the data out from
26:11 - under you while you're trying to read it
26:14 - and then you read a few pages that you
26:15 - need in order to do your work
26:17 - and everybody's happy now suppose you
26:19 - want to make some changes you want to
26:21 - change the data but you want to write
26:23 - you want to insert some data
26:25 - the first thing first thing it does is
26:27 - it gets a reserve lock
26:28 - on the database file which says you know
26:30 - what i'm getting ready to write
26:32 - nobody and we can only have one writer
26:34 - at a time
26:35 - i i call dibs it's not writing yet other
26:37 - people can continue to read
26:39 - but this guy has dibs he's he's claiming
26:43 - the right to
26:44 - the the reservation to make a right and
26:47 - once he does that
26:48 - then he stores the um
26:51 - original unchanged content of the
26:54 - database
26:55 - files who's going to database pages is
26:56 - going to change in a rollback journal
26:58 - and this is a file in the same directory
27:00 - as the original database
27:02 - but with the name dash journal appended
27:06 - it's a rollback journal this should be
27:08 - familiar to all of you i'm just giving
27:10 - you details
27:12 - and then after he's done that he's free
27:15 - to make
27:16 - changes to the individual pages in user
27:19 - space
27:19 - nobody else can see this yet other
27:21 - processes continue to read the old
27:23 - original data
27:25 - now we're ready to commit so the first
27:27 - thing we have to do is
27:28 - fsync or flush the rollback journal to
27:31 - disk
27:33 - this is important because if you lose
27:34 - power that stuff's got to be there in
27:36 - order to recover
27:38 - um sometimes people don't
27:42 - care about recovering after power
27:44 - failure in which case you can turn that
27:45 - step off
27:46 - and you know what to a first
27:48 - approximation
27:50 - this step of forcing it out to disk is
27:52 - what takes all of the time
27:54 - everything else is free this is what
27:56 - costs time
27:58 - so you can turn that off and you'll make
27:59 - the things run a whole lot faster
28:02 - many many many times faster but if you
28:05 - lose power
28:07 - and and the rights to hardware occurred
28:09 - out of order it could corrupt your
28:10 - database
28:11 - so anyway it flushes it out to memory
28:13 - then it gets an exclusive lock on the
28:14 - database file which prevents
28:16 - anybody from being able to read the
28:17 - database file because we're getting
28:19 - we're getting ready to write on the
28:20 - database and we can't
28:22 - write to it while somebody else is
28:24 - reading because that would read it out
28:25 - from underneath them
28:27 - so then we write to the we do the right
28:30 - system calls
28:31 - and then we have to flush that out to
28:32 - disk with another fsync
28:35 - and then
28:38 - the the moment of commit we delete the
28:41 - rollback journal
28:44 - or maybe we we truncated or set it to
28:47 - zero or what
28:48 - somehow we make the rollback journal
28:49 - unusable and that's what causes the
28:51 - commit to occur
28:53 - before this point if we lose power the
28:55 - rollback journal is always sitting there
28:58 - so here we here we've lost power and
29:01 - in the middle of writing to the dis
29:03 - database file we didn't get the complete
29:04 - write done we've lost power
29:06 - and now power's been restored we're
29:08 - coming back up and somebody gets ready
29:09 - to read
29:10 - and they get the shared lock and they
29:11 - immediately notice oh we've got a hot
29:13 - journal over here it's a journal that
29:14 - didn't get
29:15 - processed correctly so it immediately
29:18 - goes to an exclusive lock and rolls the
29:19 - whole thing back restoring the database
29:21 - to its original condition
29:23 - so this will always happen until you
29:24 - delete the rollback journal so the
29:26 - delete is when the transaction commits
29:29 - that's rollback mode that's the default
29:32 - that's
29:33 - the most reliable but it's
29:36 - it's kind of slow it only it you can
29:39 - have multiple readers
29:40 - or one rider but you can't have a reader
29:42 - and a writer going at the same time
29:44 - so we have another way of doing this
29:46 - called um
29:49 - right ahead log mode this is not the
29:51 - default
29:52 - and i'll get i'll explain why this is
29:54 - not the default in a second
29:56 - but with the right-hand log mode it
29:57 - starts at the same you get a shared lock
29:58 - on the database file
30:00 - you read it into user space but you go
30:03 - ahead
30:03 - it's okay to go ahead and make changes
30:05 - in user space right away you don't have
30:06 - to
30:07 - log the old original content and you
30:10 - don't have to upgrade your lot from
30:12 - shared other people can continue to read
30:14 - and then when you want to commit you
30:16 - just write the changes
30:18 - out to a write ahead log which
30:21 - is the name of the database file with
30:24 - minus wall appended
30:26 - and you're done you didn't have to fsync
30:29 - you're finished this is not durable i'll
30:32 - get to that
30:33 - but it is but it is atomic and i've got
30:36 - a little dot here in the last record
30:37 - of course all of these pages have a
30:40 - header which says which page number it
30:42 - is
30:42 - and there's a check sum and some other
30:44 - things and one of them is marked
30:46 - oh this is the last record of the commit
30:48 - so
30:49 - now i know the transaction's finished so
30:51 - that's great
30:52 - and then another process can come along
30:55 - and it wants to read too
30:57 - and it's reading some of the pages of
31:00 - some fresh pages off the database that
31:02 - the other guy didn't touch
31:04 - but it also wants to read one of the
31:05 - pages that the the first user
31:08 - has changed and it has to read that
31:09 - change out of the writing head log
31:12 - you see so this this page came out of
31:14 - the write ahead log
31:15 - so that it reflects the change whereas
31:17 - these others were unchanged as it read
31:19 - them directly from the database file
31:21 - so you can see that we have some readers
31:23 - that were reading completely out of the
31:24 - database they're looking at a snapshot
31:26 - in history
31:27 - whereas this guy's looking at what the
31:28 - current version is
31:31 - and and then this guy might want to make
31:33 - some changes and then he just appends to
31:34 - the log as well
31:36 - and so you can have multiple readers
31:37 - going at the same time
31:39 - looking at different reading from
31:41 - different points of the right head log
31:43 - in the database file
31:44 - and have snapshot isolation um
31:47 - the the reason that we don't do this by
31:49 - default is that
31:52 - when you're trying to get a page you
31:53 - have to know if if um
31:56 - that page is first in the right ahead
31:58 - log before you read it from the database
32:00 - and the way we do that is that we have a
32:02 - little hash table that's in shared
32:03 - memory
32:05 - but if the hash table's in shared memory
32:07 - and you have multiple processes
32:09 - trying to access the database and it's
32:11 - on a network file system and on their
32:12 - different computers
32:14 - that's not going to work and so for the
32:17 - other
32:17 - scheme works fine if you've got
32:20 - processes on separate computers
32:22 - accessing it over network files this one
32:23 - does not
32:25 - it also does not work on some operating
32:27 - systems that
32:28 - have dodgy memory mapping because we use
32:32 - memory mapping for the
32:33 - shared memory so um
32:37 - uh not on tape
32:40 - it's once that you've heard of actually
32:42 - um
32:44 - they they claim to have fixed it we've
32:45 - reported the bugs and i think they may
32:47 - have fixed it but whatever
32:48 - uh so so this is an option a lot of
32:52 - people use it and so
32:53 - and if you're using firefox if you're
32:55 - using an iphone if you're using android
32:57 - they normally enable this because this
32:59 - works a lot better
33:00 - but it's just an option oh wait but you
33:03 - know but
33:04 - this wall file can grow without bound at
33:06 - some point you've got to get this data
33:07 - back into the
33:09 - the um the original database file
33:12 - so we have a checkpoint operation that
33:14 - runs automatically
33:15 - or you can you can set up a separate
33:17 - thread or separate process to run
33:18 - checkpoints but if you don't do that
33:20 - it'll do it automatically when the wall
33:22 - file gets big enough and to do a
33:24 - checkpoint the first thing we have to do
33:25 - is
33:26 - make sure the wall gets persisted to
33:27 - disk this gives you durability
33:30 - and you can also set it up so that it
33:32 - automatically does this fsync after
33:34 - every transaction if durability is
33:36 - important to you
33:36 - turns out most applications if you lose
33:39 - power
33:40 - uh and you and and you lose
33:44 - if you lost power when you come back up
33:46 - if you miss the last three
33:47 - transactions most people don't care
33:50 - they'd rather have the performance
33:52 - but if you if you really have to have
33:53 - the durability you can set it up that it
33:55 - flushes the disk after every transaction
33:59 - so then periodically we will take the
34:01 - content
34:02 - of the wall file roll it back onto the
34:05 - disk
34:06 - and that is um
34:10 - and then we truncate the wall file and
34:12 - start over and that's a checkpoint
34:14 - operation question in the back of the
34:15 - room
34:17 - in the situation described with multiple
34:19 - computers reading over nfs or something
34:21 - like that
34:22 - um how do you do it you have to make
34:25 - sure you have to think a lot today
34:26 - the question is how does how do we
34:27 - handle multiple computers reading the
34:29 - same database file over like nfs
34:32 - yeah the whatever your network file
34:33 - system has to support posix advisory
34:35 - locking or
34:37 - the windows equivalent and if it doesn't
34:39 - and a lot of them don't
34:41 - you run the risk of some corruption
34:45 - put into the database file we no the the
34:48 - locking is
34:49 - posix advisory actually we have multiple
34:52 - you know we got the plugable os layer
34:54 - you can you can
34:55 - there's a different os layer that will
34:58 - substitute
34:59 - creating dot files in place of posix
35:02 - advisory locking for cases where
35:03 - but but that's a lot heavier slower
35:07 - and if you crash in the middle the the
35:09 - lock doesn't automatically go away so
35:10 - you've got to go back and clean it up
35:12 - so either way i'm running behind i'm
35:15 - running badly behind so i'm going to go
35:16 - faster
35:17 - so that's kind of the the discussion of
35:20 - the pager we didn't talk about nested
35:21 - transactions pluggable page cache or how
35:23 - we test this thing for crashes how do
35:25 - you know that this really works
35:26 - how do you know that this is really
35:28 - going to recover on a power
35:30 - failure that's an interesting problem i
35:31 - haven't talked about it
35:33 - uh v3 layer is next multiple yes about
35:37 - the granularity so
35:38 - so it's like all the transactions are in
35:42 - units that are the full page size yes is
35:45 - that a problem for any of your users
35:47 - that
35:47 - they say oh i'm only changing a little
35:49 - little uh you know so the question is uh
35:51 - when when we're logging in either the
35:53 - rollback journal or
35:54 - in the right ahead log we're logging
35:56 - complete pages rather than just
35:59 - the change and i know that some other
36:00 - like berkeley b just does the change
36:03 - and uh we benchmarked it it's not a big
36:06 - performance hit
36:07 - and it sure makes things a whole lot
36:09 - simpler and more reliable if you've got
36:10 - the complete page there
36:12 - rather than just the change so i'm you
36:14 - know
36:15 - i the berkeley db people will be here in
36:18 - a few weeks and you can
36:19 - ask them they might have a different
36:21 - they might have a different opinion of
36:22 - this i don't know
36:24 - um so in the b tree layer we do there's
36:27 - multiple b trees per file
36:30 - we use b plus trees for tables with a
36:32 - 64-bit integer key
36:34 - and regular b trees for indexes
36:39 - a table that looks like this it's a it's
36:40 - a key with arbitrary data
36:42 - the format of the data the b3 doesn't
36:44 - know what what that data is it's just
36:46 - binary to it the format is actually
36:48 - interpreted by the next layer up
36:51 - and of course you've got a root page and
36:52 - it points to child pages
36:54 - by pointer i mean it's just a page
36:56 - number it's a 32-bit page number
36:59 - and all the data and it's a b-plus tree
37:01 - so all the data is in the leaves
37:03 - of the tree
37:06 - the keys can appear more than once in a
37:08 - b plus tree
37:10 - but um because they're small integers
37:13 - it's not a problem
37:15 - and we because our b tree is used for
37:17 - the tables it's
37:18 - optimized for a pending
37:22 - rather than for arbitrary inserts oh uh
37:26 - i did want to point it amazing fan out
37:29 - uh
37:29 - you know uh because i'm only showing a
37:31 - fan out of three in this simple diagram
37:33 - but
37:33 - you're really paying out on the order of
37:35 - a thousand so
37:36 - it works rest we use variable length
37:38 - integers and this is the variable length
37:40 - integer encoding where
37:42 - um it just it reads bytes that have zero
37:45 - in the high order bit and uses the seven
37:47 - lower bits
37:48 - or it uses the entire ninth byte in
37:51 - order to construct your
37:53 - integers and this was a mistake and i
37:56 - give you this this is this is a failure
37:58 - so if you're ever doing something like
38:00 - this and you need variable length
38:01 - integers
38:02 - don't do them this way instead do them
38:05 - like this where the first
38:06 - byte tells you you know the magnitude of
38:09 - the integer somehow or another
38:11 - so here's here's an example where if the
38:13 - first byte is less 240 or less than
38:15 - that's just the value
38:16 - if it's between 241 and 248 there's some
38:18 - little formula that gives you larger
38:19 - values
38:19 - and so forth if the first body is 255
38:22 - then it just takes the next eight bytes
38:23 - and that's your
38:24 - your value and the reason for doing it
38:26 - this way
38:27 - is when the first body determines the
38:29 - size of the variable linked integer
38:30 - which is very important
38:32 - for efficiency and parsing and the other
38:34 - thing is that you can actually compare
38:36 - two integers using mem compare without
38:39 - having to decode them
38:42 - okay so this was a mistake always do it
38:45 - the way i did it was a mistake always do
38:47 - it this way the other thing i want to
38:48 - point out is how the pages are laid out
38:50 - there's a header on each page and then i
38:52 - have a section in here
38:54 - which are two byte offsets to each row
38:57 - within that page and then down over here
39:00 - i have all the the rows
39:02 - i did this backwards as well if you ever
39:05 - are doing a b tree
39:07 - let me suggest that you flip it around
39:09 - the other way
39:11 - put the header at the end
39:14 - and the pointers to the offset before
39:17 - that and then the content here and the
39:18 - reason for this is
39:19 - is you've got variable length rows in
39:21 - here
39:22 - and if you're having to parse this stuff
39:26 - out and and it could potentially have
39:28 - been handed a corrupt database file
39:30 - because remember
39:30 - sqlite is used to pass information
39:33 - around
39:34 - on sticks and stuff somebody could have
39:36 - deliberately given you a corrupted
39:37 - database file in attempting to crash
39:38 - your system
39:39 - so when we're parsing this and we're
39:41 - doing these variable length fields
39:44 - we don't want to do a buffer over run
39:47 - and the way i've got it now because the
39:49 - content area goes all the way to the end
39:51 - of the page
39:52 - i have to be very very precise in making
39:54 - sure i don't overrun the buffer
39:56 - whereas if i had done it the other way
39:58 - around and put this header and this
39:59 - other stuff at the beginning
40:00 - i've got kind of an overrun area so a
40:02 - little bit of slop and it
40:03 - you could save a lot of performance that
40:04 - way
40:07 - just some hints okay um it's not so much
40:10 - for performance it's for
40:12 - safety right it's it's
40:15 - it's the question um it's for
40:18 - performance
40:19 - in an environment where we want to
40:20 - guarantee safety because
40:22 - sqlite right now has to spend a lot of
40:24 - cpu cycles making sure that we never
40:26 - overrun that buffer
40:27 - when in fact in practice you never do
40:30 - unless somebody's trying to break into
40:31 - your program
40:32 - so that's those are essentially wasted
40:35 - cycles
40:36 - okay so um indexes
40:40 - uh are stored as regular b trees and we
40:42 - think we treat an index as just the key
40:45 - there's no data on an index
40:46 - it's just a key and it's binary data the
40:49 - b tree doesn't know how to sort these
40:51 - things because
40:52 - it's binary but the the next layer up
40:54 - hands at a point or a comparison
40:56 - function
40:56 - that allows it to sort these and we'll
40:58 - talk about in a minute b trees there's
41:00 - no
41:00 - there's no um uh the
41:04 - the data is distributed throughout the
41:05 - tree or
41:07 - the keys are distributed throughout the
41:08 - key the key is the data
41:10 - but the keys are not duplicated remember
41:12 - in a b plus three the keys are
41:13 - duplicated here
41:14 - it's not duplicated there's only one key
41:16 - one instance of the key in the table for
41:17 - each one which is important because now
41:18 - the keys are much larger
41:20 - yup but you have reduced fan out so
41:23 - searching
41:24 - takes longer because the keys are larger
41:25 - fewer of them fit on one page
41:27 - it doesn't fan out as fast search takes
41:29 - a little bit longer we've got sqlite set
41:31 - up so that there's
41:32 - always a minimum of four keys on every
41:34 - page
41:35 - so i'm going to skip that slide in the
41:36 - interest of time now we've got a bunch
41:38 - of b trees in the same file
41:40 - and these these individual pages can be
41:42 - interleaved all through the file
41:46 - and the only thing that you need to know
41:48 - is what the root page of each b tree is
41:52 - um if you want to see where the pages
41:54 - are you can download the
41:56 - the source code do configure do make
41:59 - show db
42:00 - show dv is a little utility that we
42:01 - wrote that kind of decodes the file
42:03 - format
42:03 - and they do show db database page index
42:07 - and it will actually show you what each
42:09 - page of the database file is used for
42:11 - and we can see here that the first page
42:13 - is is both a root and a leaf
42:15 - so that that particular table fit on a
42:17 - single page
42:18 - and in both the and it all fit there and
42:21 - you can see a bunch of other tables
42:24 - down here at the bottom i want to point
42:25 - out we've got overflow pages
42:27 - because i mentioned earlier that sqlite
42:30 - handles
42:31 - up to a gigabyte of content in a row but
42:34 - the pages are like 1k
42:36 - how do we do that well if it doesn't fit
42:39 - on one page
42:41 - it puts a little bit on the on the
42:42 - original page and then puts a pointer to
42:44 - another an overflow chain
42:46 - and this is just a linked list and when
42:49 - i was designing sqlite i looked around
42:50 - at all the sql databases i could find
42:53 - and i didn't find any that really had
42:54 - large blobs or strings
42:57 - and so i thought you know i'm going to
42:58 - support this but it's rarely used it
43:00 - doesn't have to be efficient i didn't
43:01 - try to make this fast
43:03 - but amazingly enough it turns out to
43:05 - work very well even for
43:08 - megabyte size strings and blobs um
43:12 - adobe discovered this for us uh the and
43:15 - the lightroom the adobe lightroom
43:16 - product um
43:18 - they uh they they have to store a lot of
43:21 - uh thumbnails of images
43:22 - and they were one and they use sqlite as
43:24 - their application file format
43:26 - and they're wondering do i store
43:28 - thumbnails
43:29 - directly in the database or do i just
43:31 - store the file name
43:32 - and then write the the image out to a
43:34 - separate file and they they ran it and
43:36 - it turns out for
43:38 - for blobs less than about 50 or 100k
43:42 - it's actually faster to write it into
43:44 - the database than it is to write it to
43:46 - the file system
43:48 - i believe this is because if you write
43:49 - it to the file system you have to open
43:52 - and close and it's the overhead of the
43:54 - open and closed system calls that slows
43:56 - you down whereas the database file is
43:58 - continuously open so we're faster
44:01 - with that all right the beep tree print
44:03 - is again it's you access the b trees by
44:05 - cursor you open a cursor you
44:09 - seek on the cursor forward and back ask
44:12 - for the date or the key
44:13 - close the cursor um how do we find out
44:16 - where the root pages are
44:19 - for each of the b trees in the file so
44:21 - there's a
44:22 - a special table in every sqlite database
44:24 - called the sqlite master table
44:26 - and the schema looks like this it's
44:28 - there by default you can't change it
44:30 - and it has the the type which is
44:33 - table index view or trigger the name of
44:36 - the thing
44:37 - the sql that originally created the
44:39 - original sql text
44:41 - and it also has the root page so
44:44 - and this particular table always has a
44:47 - root at page one
44:49 - so we can go to page one there's a b
44:51 - tree there which is this thing we can
44:53 - read this b tree find the root page of
44:54 - every other table
44:56 - in the file and here's just an example
45:00 - of
45:01 - how you can actually see that table in
45:02 - action
45:06 - page the first page in your file like
45:08 - you just lose everything
45:09 - right so this means that if the like the
45:11 - first page gets clobbered
45:13 - it's going to be really hard to recover
45:14 - much from that database yes because
45:15 - you've lost the schema
45:17 - the scheme is stored on the first page
45:19 - or you know of course in overflow pages
45:21 - as well
45:22 - um so that's the b tree we didn't talk
45:25 - about freelance management auto
45:26 - vacuuming
45:27 - shared cache i'm looking at this clock
45:29 - here and i'm running way over so i'm
45:31 - just going to slip through this
45:33 - the virtual machine
45:36 - is it defines the format
45:41 - of the of the records and i'm going to
45:44 - very quickly go over this
45:45 - the the records sqlite has this
45:48 - interesting property that is is that it
45:50 - kind of ignores column types
45:52 - uh you can put anything you want any
45:54 - column you don't have to declare the
45:57 - have to clear type one column it it
45:59 - sqlite derives from the scripting
46:01 - language community from tickle
46:03 - anybody heard of the tickle programming
46:05 - language you used it
46:06 - sqlite is in fact a tickle extension
46:09 - that escaped into the wild
46:12 - this is the truth so you know kind of a
46:15 - typeless python
46:16 - type thing so we have to store the data
46:18 - type for everything and so we've got a a
46:19 - bunch of variable length integers
46:21 - that define the data type and then we
46:24 - have the actual data
46:26 - and so here's how the energy code like
46:28 - an integer of zero means that it's a
46:30 - null
46:31 - um you know integer six means an eight
46:33 - byte signed integer
46:35 - uh and then then for strings and blobs
46:37 - it's these values here and you've got a
46:38 - little formula that gives you the length
46:40 - so most of the time these type codes are
46:41 - a single byte
46:43 - here's an example in coding create table
46:45 - abc notice i didn't put any type
46:47 - information there
46:48 - just three columns abc and you can do
46:50 - that in sqlite
46:51 - and i'm inserting 177 and null and hello
46:55 - and so here's the header in these four
46:57 - bytes
46:58 - and then here's the the two byte integer
47:01 - for 177
47:02 - and the null doesn't take any data at
47:04 - all and then there's the string hello
47:06 - so that's the encoding
47:11 - uh the code generator it's in these
47:14 - files
47:15 - in the interest of time i'm going to
47:16 - skip over this really quick
47:18 - if you're going to work with the code
47:19 - generator i suggest you enhance your
47:22 - shell
47:23 - by downloading the tarball doing
47:25 - configure and then adding these extra
47:26 - sharp defines
47:28 - to the make file and then doing the
47:31 - build
47:32 - and now you get some extra command line
47:34 - tools that allow you to for example
47:36 - print out a parse tree in kind of ascii
47:39 - art
47:43 - the clock is just spinning around so
47:45 - fast so i'm just going to i'm going to
47:46 - flip
47:47 - slip right over this and you can go and
47:48 - read this at your leisure if you want to
47:50 - do this we've got really cool tools that
47:52 - if you're in the debugging you're single
47:53 - stepping and you want to look at a parse
47:54 - tree
47:55 - you can actually call some routines and
47:56 - it'll print them out for you
47:58 - you've also got lots of extra pragmas
48:00 - that allow you to
48:01 - trace it prints out each virtual machine
48:05 - opcode as it runs it
48:08 - so i want to get on into how the query
48:10 - actually
48:11 - runs so here's here's an example of how
48:14 - the data is stored in sqlite
48:16 - you've got the row id and then all the
48:19 - data
48:20 - for a simple little table here and
48:23 - if you want to query this table uh
48:26 - you know give me the price for
48:29 - peaches of course one way to do that
48:32 - would be to
48:33 - seek to the beginning of the table step
48:34 - through each row pull out the fruit
48:36 - field see if it's equal to peach and if
48:37 - it is output the price
48:39 - it's a full table scan that always works
48:42 - and of course but you know if there were
48:43 - like seven million rows that would be
48:45 - really slow
48:46 - so well you could also ask for it by row
48:49 - id and then it'll do a binary search and
48:51 - that's very fast
48:53 - but you know if you're if you're running
48:54 - a grocer you don't want to have to
48:56 - remember that
48:57 - the secret code for peach is four that's
48:59 - crazy you really want to ask for peach
49:01 - so for that we have an index and the way
49:03 - an index works is it just
49:04 - uh it creates this key over here that
49:06 - contains
49:07 - the the value being indexed and the row
49:10 - id and because the row id is unique this
49:12 - guarantees that each row in the index
49:13 - will also be unique
49:15 - so and in in cases where um
49:19 - uh the actual fruit is not unique you
49:21 - know the the row will this
49:22 - the row id will disambiguate it and so
49:24 - once you have that
49:26 - uh to query for the for the peach you
49:28 - can do a binary search
49:30 - for the entry that has peach you read
49:32 - off the row id
49:33 - use that to do a binary search in the
49:35 - original table
49:37 - that gives you the whole record and then
49:38 - you can pull out the price
49:41 - and that's great and if you do the same
49:43 - thing for orange and it goes to the
49:44 - first one
49:46 - into the orange gets the right and gets
49:48 - it second entry
49:50 - and and gets that one as well and this
49:52 - is just by stepping through the the bee
49:54 - tree
49:55 - but if i said um orange in california
49:59 - you know it has to do orange uh
50:02 - it gets one it gets one then after it
50:04 - does the look of row one it has to check
50:05 - to see well is it in the state of
50:07 - california
50:08 - no it's in florida i have to reject that
50:09 - row i did that i did that beach research
50:11 - that binary search for not and we we
50:14 - hate that
50:14 - you know that's extra work we like to
50:15 - avoid that and so you think well maybe
50:18 - i'll i'll do an index on state
50:20 - but that doesn't really help either
50:21 - because then you could look for
50:22 - california
50:23 - but then you'd have to check for for
50:25 - grape and
50:27 - and and then you'd miss one there too
50:28 - it's the same amount of work so what you
50:30 - need there is a two column index where
50:32 - you have both the fruit and the state in
50:33 - the index
50:35 - and where the fruits are tied the state
50:37 - breaks the tie
50:40 - it's the same type of thing but now you
50:41 - can look for orange and california
50:43 - get the 23 and immediately look it up
50:45 - and that's a lot faster that's a lot
50:46 - better to do that sort of thing
50:48 - um you could do even better than this
50:51 - though if you built an index that
50:52 - contains all the columns in there
50:56 - the fruit the state and the price and
50:57 - then when you do select price from
51:00 - table where fruit is orange you could do
51:03 - the
51:03 - do a binary search to find the first
51:05 - entry where it says orange california
51:08 - and the price is already there in the
51:09 - index and you just read it straight out
51:11 - the index you don't even have to look at
51:12 - the original table this is called a
51:13 - covering index
51:17 - um if it's an or of course you can
51:19 - always do a full table skin just
51:21 - stop start the beginning of the table
51:22 - read always read read
51:24 - column like row by row checking the the
51:27 - condition and the where clause to see
51:29 - if it's true and then outputting the
51:31 - price but we'd really like to use an
51:33 - index and in this case
51:34 - it will take two separate indexes one
51:36 - for fruit
51:38 - one for state do the lookup for the row
51:40 - ids take the union of those and then
51:43 - pull the prices out that way
51:48 - another thing it can do if you've got a
51:50 - two column index on state
51:51 - and fruit but you want to look at by
51:55 - fruit you think well i can't really do
51:56 - this because i can't do a binary search
51:58 - for the second field of an index
52:01 - but sqlite will do this and the way it
52:03 - does that
52:04 - is that it recognizes there are not many
52:06 - states there there's just not many
52:08 - values so it will iterate through all
52:10 - the possible values for state and then
52:11 - within each state
52:13 - look for the fruit orange we call this
52:16 - there's no official name to it for this
52:17 - as far as i'm aware we call it skip scan
52:20 - but it will try and do this if it knows
52:23 - that
52:23 - the cart that um there aren't many
52:26 - distinct values or
52:27 - just a few distinct values for for the
52:28 - first column
52:30 - so we can sort always do a sort of sort
52:33 - is the most expensive thing you can
52:34 - probably do in a database engine
52:36 - um if you if you if you give an order by
52:39 - clause in sqlite and it it knows that
52:41 - it's going to come out in the right
52:42 - order anyway it just
52:43 - throws the order by clause away it
52:44 - doesn't force you to sort so
52:46 - be generous with your order by clauses
52:49 - if you give an order by fruit and you've
52:50 - got an index on fruit it will
52:52 - walk the index and then do uh
52:56 - you know pull out the rods and then do
52:57 - the search and pull out the rows in the
52:59 - correct order and you think well you
53:00 - know that's still in log
53:01 - in i haven't saved anything well
53:03 - actually you have because
53:04 - it uses a lot less memory and also
53:07 - if you're you're looping through this
53:09 - and you get only a couple entries
53:10 - through and say okay i'm going to quit
53:12 - it didn't have to do all those other
53:13 - lookups before it did the search so this
53:15 - is a much more efficient way of doing it
53:17 - in practice and of course if you have a
53:20 - covering index it just spins right down
53:22 - the covering index
53:25 - if you have a covering index that's
53:27 - almost there but not quite
53:29 - uh here you know we want to sort by
53:31 - fruit and price but we've got this
53:32 - pesky state row in the middle which kind
53:34 - of messes up our sword order
53:35 - it will read down as much as it can
53:39 - uh it'll read all the all the unique
53:42 - values for fruit and then gather them
53:43 - and sort them separately so it does lots
53:45 - of little sorts
53:46 - which is more efficient because it can
53:48 - start outputting rows immediately before
53:50 - it scanned the whole table
53:51 - and the sorts are smaller if you've got
53:54 - something like a union
53:56 - with two order bodies it will actually
53:58 - break this up into two separate queries
54:00 - run them as co-routines and then take
54:04 - the union and the output
54:14 - yes who decides are you doing it blindly
54:18 - for all of these
54:19 - potential choices or there is some
54:21 - decision making
54:22 - right
54:26 - yeah so this requires a lot of memory a
54:28 - lot of maintenance
54:30 - uh with simple updates now it's not only
54:33 - just
54:34 - worrying about it well i mean the
54:36 - indices are maintained automatically
54:38 - you the programmer i'm skipping over
54:40 - some slides here because we are out of
54:41 - time
54:42 - you the programmer have to come up with
54:45 - the indices
54:45 - sqlite is not going to do that itself
54:48 - but you know this is the key advantage
54:49 - of having a query language and i want
54:51 - this is an important slide it's probably
54:52 - the last one i have
54:54 - um because if you've got a query
54:57 - language like this you can code you can
54:59 - design your application you can build it
55:00 - and spend weeks coding it up
55:02 - you get down to the end and you've got a
55:04 - performance problem
55:06 - oftentimes you can fix that performance
55:08 - problem just by doing create index and
55:10 - suddenly you've got completely different
55:11 - algorithms that are being used
55:13 - and you can do this the night before you
55:16 - release your product
55:18 - whereas if you if you if you're using a
55:21 - key value store or something else that
55:22 - doesn't have a query language like this
55:24 - and you get down to the end and and it's
55:27 - not working it's not performing well
55:29 - then um you've got you've got to spend
55:32 - some serious time recoding
55:34 - you can't do that on the day before you
55:35 - release you've got to re-code and
55:37 - re-test
55:38 - that's the beauty that's why it's so
55:40 - important that's what this top half
55:42 - the part above the storage engine is so
55:44 - important because it gives you that
55:46 - flexibility
55:54 - do you combine those in order to help
55:56 - you to identify
55:58 - next into the tune so the question is do
56:01 - i would provide utilities to help
56:02 - programmers identify bottlenecks and do
56:05 - the tuning
56:06 - that's true no that is a frequent
56:07 - request it's on our to-do list
56:10 - i mean there are things there we provide
56:12 - mechanism but it's not an
56:13 - and especially intuitive thing to do you
56:16 - have to kind of know what you're doing
56:18 - but we need an automatic tool that looks
56:20 - at the schema looks at your query and
56:21 - say
56:22 - hey you should consider this index we
56:24 - don't have that yet that's on the to-do
56:26 - list
56:28 - so code generator we didn't talk about
56:29 - joint order selection i also skipped
56:31 - some slides
56:32 - there's a lot of other cool things in
56:34 - here this query planner stability
56:36 - guarantee this is an important part of
56:37 - an embedded database
56:39 - is that you know there's all these
56:40 - different algorithms that it can choose
56:42 - but in in a commercial uh database in a
56:46 - data center you want it to adjust its
56:48 - algorithms as the data changes
56:49 - to to select the best algorithm for the
56:52 - current state of the data
56:53 - if you're doing an embedded product and
56:55 - shipping millions of these things
56:57 - you don't want the query planner
56:58 - changing its mind
57:00 - for some small percentage of the users
57:02 - out in the field because usually it will
57:04 - do a good job
57:05 - but sometimes it might choose a bad plan
57:07 - and then you're going to get bug reports
57:09 - you want the query planner to always do
57:10 - the same thing and sqlite can be set up
57:12 - in fact in this default
57:14 - situation it's always going to choose
57:16 - the same query plan for a given schema
57:19 - it won't change that unless you run
57:20 - analyze or change the schema around no
57:25 - it's actually
57:26 - a cost-based system but the costs are
57:28 - fixed they don't
57:29 - automatically recompute do you maintain
57:34 - when you run analyze the analyze command
57:37 - so if you rerun analyze it's going to
57:39 - get different statistics
57:40 - and then it might choose different plans
57:42 - so don't do that if you're concerned
57:43 - about
57:44 - query plans changing out front of you
57:46 - okay other topics i haven't talked about
57:48 - virtual tables
57:49 - i haven't talked about the full text
57:51 - search engine and this is a really cool
57:52 - thing because it actually implements lsm
57:54 - trees
57:55 - on top of b plus trees and it's a really
57:57 - cool idea and it's actually very
57:58 - efficient it's faster than
57:59 - scene our trees memory management how we
58:02 - test this thing
58:03 - it's we got a really impressive test
58:05 - suite and that's very important to us um
58:08 - that is i'm i'm slightly over time and
58:11 - and i'm happy to talk about any of this
58:13 - this is the
58:13 - this is a slightly we've gone to a
58:15 - slightly lower orbit and i've given you
58:17 - sort of an overview of how the system
58:18 - works
58:19 - there's a lot of details here love to
58:21 - hear your questions
58:23 - um and your feedback and
58:26 - uh and you can also go to the mailing
58:28 - list and visit us there
58:31 - thank you very much for your attention
58:32 - i'm sorry for running five minutes over
58:34 - if people have to leave
58:36 - you're welcome to step away otherwise if
58:38 - are there questions i'll be happy to
58:39 - take them now
58:40 - all right thanks richard
58:46 - i replied yes ma'am
58:54 - it means how minimal or how
59:02 - long
59:07 - and do you think that you have reached
59:09 - the optimal points of
59:11 - our big variables our
59:14 - internet of things there is a
59:21 - all right so if i understand the
59:23 - question you're asking
59:25 - um yeah there's trade-offs in any system
59:28 - because
59:28 - uh you know on a full-scale data center
59:31 - oriented database
59:33 - you've got a lot more power and it's
59:35 - doing lots of fancy things and we don't
59:36 - do that
59:38 - and and we do and and so the trade-off
59:40 - is because we're using less power
59:41 - and it's easier to maintain and we want
59:44 - it consistent across millions of devices
59:48 - have we found that right balance well
59:50 - we're constantly adjusting that balance
59:54 - we take a lot of input from people who
59:55 - are actually using this stuff
59:57 - and we try and adjust it i talked about
60:00 - the
60:00 - query planner stability guarantee and
60:02 - how it doesn't recompute
60:04 - plans based on evolving data there's a
60:06 - compile time option that will make it do
60:07 - that
60:09 - and so if you if if you have a very
60:12 - specific need where you want it to
60:14 - violate that guarantee but but work more
60:16 - like a a mainframe database
60:18 - you can make it do that and so we
60:20 - provide a lot of options that way
60:23 - have we found the best blend
60:26 - i i think so because uh there used to be
60:30 - a lot of these embedded sql databases
60:32 - and now there's just sqlite and maybe
60:34 - sql anywhere and
60:36 - uh the rest of them have kind of gone
60:38 - away so um and
60:39 - the java ones oh yeah the java ones does
60:42 - anybody ever use those really
60:45 - yeah um
60:48 - so uh yeah i think
60:51 - the market seems to be saying that we're
60:52 - doing well maybe we're just lucky i
60:54 - don't know but
60:55 - uh i think we're it is you're but you're
60:57 - right there's a balance here you got to
60:58 - find the right
60:59 - mixture of features and capabilities and
61:03 - i think we've got a niche and we're
61:05 - trying to do that yes sir