00:00 - this is the video on how to get data
00:01 - into SAS so that you can analyze it you
00:05 - must have the data into SAS before you
00:06 - can analyze it there's lots of different
00:09 - types of data we're gonna look at three
00:11 - types of data that we can get into SAS
00:13 - one is when you have a small data set
00:16 - you can hard code the data into the SAS
00:18 - code too you can import the data from
00:20 - your computer from a CSV file or some
00:23 - other data file and three we're gonna
00:25 - import from the Internet so let's go
00:27 - ahead and start SAS 9.4 English make
00:34 - this nice and big blank editor down
00:37 - there so let's begin
00:39 - option one is going to be hard code the
00:43 - data into SAS and this is an option that
00:45 - you would use if perhaps you had a small
00:48 - data set or you wanted to share this
00:52 - script across between you and your
00:55 - collaborators so here's the here's how
00:58 - it starts all always when you load data
01:01 - into SAS you start with the data
01:03 - statement it's gonna be data doesn't
01:06 - have to be capital dat a but I like to
01:08 - capitalize my staffs commands and then
01:11 - the name of the data set and we're gonna
01:12 - call this tree data for obvious reasons
01:15 - the next line is your input line
01:19 - it starts with a keyword input and then
01:22 - it's followed by every variable that
01:24 - you're going to input block is one
01:26 - variable
01:26 - TRT MNT for treatment is a second and
01:29 - growth is the third this dollar sign
01:33 - follows treatment because treatment is
01:35 - going to be a character variable it's
01:37 - not gonna be in America it's gonna be in
01:38 - this case an a B or C although any
01:41 - string that you would use and at the
01:43 - very end we've got two at signs what
01:46 - that means is it tells SAS to keep
01:49 - reading in in block treatment growth
01:53 - block treatment growth block treatment
01:55 - growth block treatment growth block
01:58 - treatment growth until the end of the
01:59 - line without that it's just going to
02:02 - read the first block treatment growth
02:04 - then go to the next line of block
02:05 - treatment growth the double apps at the
02:08 - end it says just keep reading until the
02:10 - end of the line now we don't just have
02:13 - to import the data we can actually
02:14 - create data as we work with in what and
02:18 - this is called a data step that's where
02:19 - we take care of all of our data so I'm
02:22 - going to define the variable year it's
02:24 - gonna be 1997 so for every single record
02:29 - the year is gonna be 1997 it's a pretty
02:32 - good year there have been better there
02:34 - have been worse I can also create a
02:37 - variable and I'm gonna call it LG growth
02:39 - and it's gonna be the log of the growth
02:42 - value and growth is in the data set so
02:46 - in the data step you can create a new
02:48 - variable all by itself or you can create
02:51 - a new variable that's based on a
02:53 - variable in the data set
02:55 - okay once you've got that taken care of
02:58 - you go to the data lines command and
03:03 - that says okay this is going to be the
03:05 - start of the data that we're reading in
03:07 - these are going to be lines of the data
03:11 - alternatively instead of data lines you
03:13 - could use the command cards CA RDS as a
03:17 - throwback to when the data actually was
03:19 - stored on little punch cards but we're
03:23 - gonna use data lines here and I just
03:26 - typed in the data block treatment growth
03:31 - block treatment growth block treatment
03:34 - growth so this is one record block one
03:38 - treatment see the growth level is six
03:40 - point seven nine this is another record
03:43 - block for treatment C with the growth of
03:47 - 6.43 notice there are no semicolons here
03:52 - but there is one at the end of all the
03:55 - data semicolons are very important for
03:59 - SAS every line has to have a semicolon
04:03 - on it unless it's a very special line
04:06 - and then we're gonna end this with run
04:09 - so I'm gonna highlight all of this and
04:12 - I'm gonna run it or I guess submit again
04:16 - SAS was originally a server language so
04:19 - and you'd be working on your little
04:21 - dummy terminal at your computer so
04:23 - always talks about in terms of cards and
04:26 - submitting to your server and it gives
04:29 - you server times etc now I can either
04:32 - click on this little running person up
04:34 - here or just submit or I can hit f3 on
04:37 - my cat my keyboard I'm going to use f3
04:40 - boom here's the log of everything that
04:44 - just went down line 1 2 3 4 5 6 all the
04:52 - data is in lines is associated with a
04:55 - data line statement of 6 and then 10 is
04:59 - the end of it then we ran it I don't see
05:02 - any red here red would indicate that
05:04 - there's some error so everything looks
05:06 - like it worked well or did it it's kind
05:10 - of hard to tell because I really would
05:13 - like to see the data as SAS sees it and
05:16 - so to do that in order to print out the
05:19 - data I'm gonna run our first proc it's
05:23 - called proc print proc
05:30 - canceled
05:35 - okay I'm back
05:43 - I'm not sure what's going on with the
05:45 - keyboard
05:54 - okay proc is short for process but it's
05:58 - just proc and print and again you don't
06:02 - have to make these uppercase I tend to
06:04 - do all my proxy an uppercase now proc
06:08 - print says you want to print something
06:09 - out what do you want to print out want
06:11 - to print out your data and what data do
06:12 - we have it's tree data so data equals
06:18 - tree data and again end it with a
06:21 - semicolon
06:23 - run
06:25 - and then f3 and then here's
06:29 - resultsviewer and this is our data block
06:34 - treatments growth year which is
06:38 - something we created that wasn't
06:40 - originally a part of this data set and
06:42 - log of growth which again we calculated
06:45 - based on the growth so this one point
06:46 - eight eight eight five eight it's just
06:48 - the natural log of six point six one
06:52 - notice that up here in the results side
06:56 - we've got our results data set you can
07:00 - click on that and we get back to our
07:02 - data so that's Method one it's to hard
07:06 - code the data into SAS and there's some
07:08 - advantages to that and the main
07:10 - advantage is if you look I can email
07:13 - this to you and you've got this exact
07:14 - same data as I have now option two is
07:17 - you're going to import the data from a
07:19 - local file so let's go ahead and do that
07:22 - option I'm going to minimize this window
07:26 - I'm going to go into my H Drive
07:34 - my H Drive actually has that 50 13
07:39 - there's the data set I want to use
07:41 - Fischer 38 it's a CSV file how do I know
07:44 - it's a CSV file Microsoft Excel comma
07:48 - separated values file and if I just want
07:51 - to look at the data I can double click
07:52 - it and again I'm here on my desktop it's
07:55 - gonna open up into whatever program I
07:59 - have that defaults to opening up CSV
08:01 - files and this case it just happens to
08:05 - be Excel consists of two variables
08:07 - variable one is the sample number and
08:09 - it's one through four and Roman numerals
08:12 - and variable two is colonies notice
08:15 - again variables are the hit our columns
08:19 - records our rows okay so we got sample
08:22 - and colonies is our two variables let's
08:27 - get back into SAS
08:31 - so now I want to import that data set so
08:37 - here's how we can do it
08:42 - yeah
08:45 - again we start the data step with the
08:47 - keyword data specify the name of our
08:50 - data set in this case it's back to data
08:52 - which is short for bacterial data now
08:56 - the first new part here is the in file
08:59 - statement in file means you're bringing
09:01 - in to SAS memory the file that follows
09:06 - and again it's in quotation marks and I
09:10 - said it's a and because I'm working on
09:13 - this on the on the server this has to be
09:15 - an absolute path which means it starts
09:18 - with the H : because it's on my H Drive
09:20 - and it ends up with the name of the data
09:23 - set it's Fisher 38 dot CSV I have to
09:27 - specify the delimiter is a comma and
09:30 - that the first observation that I want
09:32 - is in Row 2 because in this data set Row
09:37 - 1 was the data that was the variable
09:40 - names so we're skipping over that and
09:42 - going straight to Row 2 second is the
09:46 - input notice we had an input back here
09:49 - on the when we hard-code the data input
09:51 - was followed by the variable names in
09:53 - order you can do the same thing here
09:55 - sample and colonies sample remember was
09:58 - 1 through 4 in Roman numerals so it's
10:01 - got to be followed by a dollar sign we
10:03 - really don't have to call it sample and
10:05 - colonies but that's what the data set
10:08 - has it we might as well well with a run
10:11 - and just to double check everything's
10:13 - working correctly that we got everything
10:15 - in we followed up with a proc print now
10:19 - again as before we could create a new
10:21 - variable here we could call it year is
10:25 - equal to 1938 which I believe was when
10:29 - this data was done and we could do law
10:32 - colony
10:34 - while call is it log of colonies
10:40 - remembering to end each line with a
10:43 - semicolon go ahead and run all this f3
10:47 - here's the data sample colonies year ln
10:54 - call so this is 4.0 604 4 is the natural
10:59 - log of 58 now notice something in SAS it
11:04 - prints out in a sans-serif font which
11:07 - means it's very difficult to tell what
11:08 - is this a lowercase L and an uppercase I
11:13 - so keep that in mind at times this could
11:16 - be a lowercase L this could be an
11:18 - uppercase I we we do know it's an
11:20 - uppercase I so keep that in mind when
11:22 - you're using variable names so that was
11:26 - option 2 importing it from a local file
11:28 - option 3 is importing the data from the
11:31 - internet itself
11:33 - and this is a popular option you're able
11:36 - to store your data on the Internet and
11:38 - have everybody in the group work with
11:40 - that data this requires a little bit
11:45 - more when one more line requires the
11:48 - file name statement the file name
11:52 - statement
11:55 - we'll save the URL that you specify to
12:00 - the right and store it in the variable
12:02 - data location so at the end of running
12:06 - this line the variable data location
12:09 - will have this string this your L in it
12:13 - notice it's a URL a full URL it starts
12:17 - with HTTP colon backslash backslash and
12:20 - then the rest of the address this line
12:27 - must be run before you can in file this
12:31 - data then we start with the data step
12:35 - call this data stat data I don't know
12:38 - why but we'll call it stat data for fun
12:40 - followed by the in file statement in
12:43 - file data location that and that have to
12:48 - be exactly the same
12:51 - then again the delimiter in the first
12:53 - observation and this in this file the
12:56 - first line belongs to the variable names
12:59 - so first all of this will be equal to
13:02 - two we r gonna skip that first line and
13:03 - just import the data itself then again
13:07 - as with the last remember the last
13:09 - started with data then in file the input
13:11 - its data then in file the input name of
13:15 - the variables gender we see is a
13:18 - character variable it's gonna be M Neffs
13:20 - or males and females college is also
13:23 - character variable it's going to be CAS
13:26 - be us etc those are dollar signs the
13:30 - annotate indicate character variable
13:32 - it's a very strong way of specifying
13:34 - that you're working with categorical
13:36 - variables and again we can actually
13:39 - create a new variable GPA purse and
13:42 - we'll just be the GPA divided by four or
13:44 - you do just about anything we want same
13:46 - as the same as always all the fiddling
13:48 - with the data it takes place within the
13:49 - data step and then we run it all
13:59 - if you notice we had some errors there
14:01 - so let's go ahead and scroll up on the
14:03 - log and see what those errors were see
14:05 - if we can interpret what SAS is telling
14:07 - us this is a good place to actually show
14:10 - you how SAS gives us error codes or in
14:14 - this case doesn't and you have to kind
14:16 - of guess what it means error 'invalid
14:19 - logical name error in the file name
14:21 - statement so I know something's wrong
14:23 - with line 24 file name data location URL
14:29 - HTTP everything looks pretty good error
14:32 - in the file name statement hmm whatever
14:36 - should we do and at this point you
14:40 - realize that SAS really doesn't give you
14:42 - good hints and what's wrong with your
14:45 - code which is unfortunate so what I do
14:49 - is I always hop on to Google and Google
14:53 - something like in this case SAS filename
14:57 - statement and then I'll find out
14:59 - oh this data location really can't be
15:03 - just any old via variable name has to be
15:06 - a very specific variable name that
15:08 - variable name has to be data file so
15:12 - instead of data location it's got to be
15:13 - data file and the only reason I know
15:15 - that is because I went to Google and
15:18 - googled SAS filename statement
15:22 - so do that right now go to go to Google
15:26 - and search for SAS file name statement
15:30 - and read up on it you'll see it there's
15:33 - a lot of help files out there both
15:35 - within SAS and at other places very very
15:39 - useful so we fixed it changed it from
15:42 - data location to data file changed it
15:45 - here and on the in file statement let's
15:48 - go ahead and run it and here's our data
15:51 - set ID grade gender was males and
15:56 - females GPA sat math age college and GPA
16:01 - PCT which is % GPA divided by 4
16:08 - pretty basic right there so here's what
16:11 - we did in this and let's go ahead and
16:12 - just finish it off with a nice little
16:14 - quit just to give us a feeling of
16:18 - satisfaction so he did three things in
16:22 - this little video thing number one was
16:24 - we showed how to import how to get the
16:27 - data into SAS by hard-coding it and this
16:32 - is where he did that this always started
16:36 - with data and then input and the input
16:38 - told us what the variables were and when
16:40 - we hard-code the data and we did it
16:41 - after the data line statement option two
16:46 - was to import the data from a local file
16:49 - we started with the data then in file
16:52 - and here's where we specified the local
16:55 - file it is the absolute path and I have
16:59 - to use the absolute path because I'm
17:00 - using this shared desktop
17:03 - and then followed by the input again
17:05 - note that the dollar sign means that the
17:07 - proceeding variable is a is a character
17:10 - variable and then the third way is to
17:13 - import from the internet the new line
17:16 - there is the file name statement you
17:19 - must start with file name the word data
17:21 - file the word URL and then the actual
17:26 - URL in quotation marks and then the data
17:30 - step the in file the input etc so three
17:34 - ways of getting data into sass and you
17:36 - really do need to have data into sass
17:38 - before you can actually do anything with
17:40 - the data I hope this was oh and one last
17:44 - thing we did was discover that sass
17:46 - error commands or error codes are not
17:49 - always that helpful let's go ahead and
17:51 - start sass this one actually covers how
17:53 - to do univariate and bivariate sample
17:55 - statistics so we'll open up sass as
17:57 - usual maximize it editor this is where
18:02 - we do all of our typing
18:05 - first step in anytime anytime that you
18:08 - want to analyze data the first step is
18:10 - to get the data in to SAS because if SAS
18:14 - doesn't have the data in its memory it's
18:16 - not gonna be able to do any analysis so
18:19 - we're going to import this data from the
18:20 - internet it's gonna be the stat grades
18:23 - data set remember your key word file
18:27 - name followed by the word data file URL
18:30 - and then in quotation marks the URL for
18:34 - the data there's a CSV data set then we
18:38 - start the data stat data step we're
18:40 - gonna call the data set stat data follow
18:44 - it with in file input and again remember
18:49 - these are the variables in the data file
18:52 - gender is a character variable that's
18:54 - why there's a dollar sign after gender
18:56 - College is also character variable
19:00 - categorical variable we're gonna create
19:02 - a new variable called GPA PC tln which
19:05 - is just the natural log of the GPA
19:07 - percent natural log at the GPA percent
19:10 - GPAs run from 0 to 4 there we go and
19:13 - this will load in the data so after
19:16 - running these and remember we can either
19:17 - do it by the running person up here or
19:19 - f3 on the keyboard let's do it the
19:21 - running person
19:24 - okay I see no errors in the log nothing
19:28 - red up there so we're good to go
19:31 - of course one thing that we really do
19:34 - want to do is actually look at our data
19:37 - just to make sure that we got it in
19:39 - there correctly so to do that we're
19:41 - gonna do a proc print proc again is for
19:45 - processed print is the actual process we
19:47 - want to use here tells the SAS that we
19:50 - want to print something so what are we
19:51 - gonna print we're gonna print the data
19:53 - set stat data here's the data set stat
19:59 - data
20:00 - now it may be more helpful than instead
20:03 - of calling this the SAS system we call
20:05 - it stat data to do that we're gonna
20:08 - change the title
20:21 - title 1 is equal to data : stat data so
20:25 - let's run that
20:31 - that's out of the proper order oh
20:33 - there's no equal sign
20:40 - you know we had the error up there it
20:42 - said it's not valid reminded me that
20:44 - there shouldn't OB it should not be an
20:45 - equal sign there
20:46 - now let's rerun the proc print notice up
20:50 - here on the results side the first time
20:53 - we ran proc print we got print which is
20:55 - the proc name the SAS system the second
20:58 - time we ran it after we did the title we
21:01 - got print then whatever the title was
21:03 - now the title again is up at the top
21:05 - instead of the SAS system
21:11 - okay let's start doing some univariate
21:13 - statistics
21:16 - here the variable of the process you're
21:20 - going to use its proc univariate which
21:23 - kind of makes sense because it's a
21:24 - univariate statistics that you're doing
21:26 - and what are you gonna do it on you're
21:28 - gonna do it on the data and then run you
21:32 - run this and here's what you get you're
21:37 - gonna get univariate statistics for the
21:39 - ID variable the grade the GPA the SAT
21:42 - Math the age and the GPA percent Ln
21:45 - that's not all the variables this is
21:48 - just all of the numeric variables these
21:50 - are just the variables that have numbers
21:52 - associated with them what are the
21:56 - universe --tx that you're given well for
22:00 - instance for the GPA PC tln variable
22:02 - you're given sample size you're given
22:05 - the mean you're given the standard
22:08 - deviation the skewness the kurtosis the
22:11 - variance the sum of all the observations
22:14 - we're not waiting so this some weights
22:17 - and an are gonna be the same you're
22:20 - given the coefficient of variation
22:23 - you're given the uncorrected sum of
22:25 - squares which is just squaring all of
22:30 - the values and adding them up you're
22:32 - given the corrected sum of squares which
22:34 - is just squaring all squaring the
22:36 - difference between the value and its
22:39 - mean adding it all up actually the
22:44 - corrected sum of squares is going to be
22:45 - equal to n times the variance I'll let
22:48 - you figure out why
22:52 - you got me media mode also listed here
22:54 - IQR range variant standard deviation
22:59 - skip the test for location we'll deal
23:01 - with that in a later chapter we're given
23:05 - the quantiles
23:08 - q1 q3 q2 min Max and we're given the 10
23:17 - extreme observations the five lowest and
23:20 - the five highest a lot of information
23:23 - given here just from one simple line of
23:26 - code or I guess two simple lines of code
23:28 - and that do that for every single
23:31 - variable but we don't have to if all we
23:34 - care about is the GPA variable then we
23:39 - could specify we just want it from the
23:43 - GPA variable or maybe we want the GPA
23:46 - variable and the SAT math variable
23:48 - notice there's no comma here and notice
23:52 - this line starts with var again that
23:55 - could be lowercase var or uppercase var
23:58 - since it's a SAS command I like to use
24:00 - uppercase let's run that and we just get
24:06 - you know very statistics with GPA and
24:09 - SAT math
24:16 - okay so that's for all of the numerical
24:18 - variables what do we do for the
24:21 - categorical variables it's a new process
24:24 - it's a new proc it's proc FR eq f req is
24:29 - for frequency data equals stat data they
24:33 - have to specify the tables when it was
24:37 - numeric variables or numeric data we
24:40 - specified the bar that was optional when
24:43 - its categorical we specify tables and
24:45 - it's not optional we must specify the
24:48 - tables at tables for gender and college
24:53 - here's the frequency tables for gender
24:55 - and for college forty five in the sample
24:59 - were female fifty-five for male that's
25:01 - forty five percent fifty five percent
25:04 - since gender is not ordinal the
25:08 - cumulative frequency and the cumulative
25:09 - percent don't make sense college also is
25:12 - not ordered an ulcer the cumulus also
25:14 - don't make sense thirteen business
25:16 - majors fifty-seven colored from the
25:18 - College of Arts and Sciences Lebanon
25:19 - from the College of Agricultural Science
25:21 - and Natural Resources nine from
25:23 - education one from lasso and nine from
25:25 - other again the percents for each of
25:28 - those so the difference is for numeric
25:33 - data
25:34 - you can't specify the variable as you
25:36 - want but you don't have to for
25:37 - categorical variables you must specify
25:40 - the variables you want so that's all of
25:43 - the univariate statistics now we can
25:47 - look at correlations bivariate
25:49 - statistics and again a new proc for you
25:53 - to learn this reason be proc cor cor R
25:58 - stands for correlation specify the data
26:01 - let's see what we got
26:05 - tells us there's six variables that it
26:08 - can run correlations on these are the
26:09 - six numeric variables ID grade GPA SAT
26:13 - math age GPA PCT LM gives us some simple
26:17 - statistics for each of those six and
26:19 - then this table is the correlations
26:23 - technically it's just the first or the
26:26 - top number that's the correlation so the
26:29 - correlation between GPA and grade is
26:32 - point three three five five eight top
26:36 - number the correlation between age and
26:40 - SAT Math is point zero eight four two
26:44 - four the correlation between GPA and GPA
26:48 - PC tln is 0.99 144 those are the
26:54 - correlations between those variables and
26:56 - remember that correlations are the order
27:00 - doesn't matter so the correlation
27:02 - between GPA and grade three three five
27:07 - five eight is the same as the
27:08 - correlation between gray than GPA three
27:11 - three five five eight the correlation
27:15 - between grade and grade is gonna be one
27:17 - so it's gonna be ones down the diagonal
27:19 - guaranteed and the upper part of the
27:23 - matrix is going to be the mirror of the
27:25 - bottom part also guaranteed
27:28 - the bottom numbers will ignore that
27:30 - until we get to hypothesis testing which
27:33 - will take place later one last way of
27:38 - comparing two variables notice that
27:39 - these were comparing numeric or
27:43 - quantitative variables we can do it
27:45 - using we can do something similar but
27:49 - not quite similar we can also do what's
27:54 - called cross tabulation with the
27:55 - categorical variables if we look up here
27:59 - it's proc freq when we're dealing with
28:01 - categorical variables tables gender and
28:03 - college just a space between the two
28:06 - meant that we want a table of gender and
28:08 - a table of college if we do gender x
28:11 - college then it's going to give us a
28:13 - cross tabulation of gender by college so
28:16 - up here we got the number of males
28:18 - number of females here we got the number
28:20 - of business majors number of college of
28:23 - Arts and Science people etc doing it
28:25 - this way we're gonna get the number of
28:27 - males who are males her business males
28:30 - are College of Arts and Sciences females
28:33 - her business females who are College of
28:35 - Arts and Sciences etc
28:38 - so we're able to look at some sort of
28:41 - correlation between these two variables
28:43 - now to test that correlation again we're
28:46 - gonna have to wait until later in the
28:47 - course so there are in this sample there
28:50 - are five female business majors eight
28:54 - male business majors three female edy
28:58 - majors six male ed majors five male
29:02 - others eight female castner's college of
29:05 - agricultural science nature resources so
29:08 - the whole numbers are going to be the
29:11 - frequency
29:15 - the numbers right below it are going to
29:17 - be the percent of the entire data set so
29:20 - female casts people are 25% of the
29:25 - entire data set and the frequency is 25
29:29 - the data set is of size 100 so this is
29:32 - going to be 25 divided by a hundred
29:34 - times hundred percent
29:37 - the third is going to be the row percent
29:40 - which means of all females level females
29:45 - fifty five point five six forecasts
29:48 - belonged to College of Arts and Sciences
29:50 - of all females eight point eight nine
29:53 - belonged to other of all females 11.11
29:57 - one two business of all males ten point
30:02 - nine 1% were education so the third row
30:08 - third number is going to be the row
30:10 - percent it's gonna be of all whatever
30:13 - the row variable is that's the percent
30:16 - that belonged to the column compare that
30:19 - with the fourth variable or fourth
30:22 - number this is the column percent so
30:25 - this would be of all education so give
30:29 - that the persons in education of all the
30:31 - education 66.67% were male all college
30:38 - of arts and science forty three point
30:41 - eight six were female well business
30:44 - sixty one point five for were male
30:48 - so this is a conditional probability the
30:52 - fourth number is going to be the column
30:55 - percent third will be the row percent so
30:59 - given male 14.5 five percent we're
31:03 - business as opposed to given business
31:06 - sixty one point five four percent were
31:09 - male we will cover conditional
31:13 - probability in Chapter two you're gonna
31:15 - see that it's very important here and
31:18 - that's it
31:20 - you know very statistics let's go ahead
31:23 - and just call this quit
31:26 - just for the satisfaction we're done
31:28 - felt good this quick little video on SAS
31:30 - this one covers graphics so let's start
31:33 - up SAS
31:38 - they were into sass first step when
31:41 - we're doing graphics is to import the
31:43 - data make sense cuz you can't do much
31:45 - with the data unless it's in sacis
31:47 - memory we're gonna import the stat
31:49 - grades data set again run this recall to
31:55 - run it we can either do f3 or click on
31:57 - the running person so here's the data
32:00 - that was imported should look pretty
32:02 - familiar notice up here there's no red
32:07 - so there was no errors okay so the data
32:11 - is in their first step or the next step
32:14 - let's go ahead and do a bar plot
32:19 - for all of these charts categorical
32:23 - variables that function is gonna be G
32:25 - chart
32:28 - Proc G chart specify your data specify
32:33 - what chart you want H bar will be for
32:35 - horizontal bar chart and the variable
32:39 - notice College is a categorical variable
32:42 - then run so here is the result it's a
32:47 - horizontal bar chart Business College of
32:51 - Arts and Sciences etc the length or the
32:55 - width I guess of the bar is going to
32:57 - correspond to the frequency or to the
32:59 - relative frequency there's thirteen
33:02 - business majors in that stat class
33:04 - that's 13% IDI there's nine ed majors
33:09 - which is nine percent now one thing we
33:12 - can do to tidy this up a little bit is
33:14 - to get rid of these statistics on the
33:16 - right to do that instead of H bar
33:20 - College will just do slash no stats
33:29 - no difference this is without the no
33:31 - stats this is with the no stats that's
33:34 - the difference there's no stats makes
33:37 - the bar chart a little bit wider
33:41 - we could also group this according to
33:45 - gender since that's our only other
33:47 - categorical variable so group equals
33:52 - gender
33:56 - and that
33:58 - oh it's kind of hard to tell the
34:00 - difference we're but these first ones
34:02 - are female so this is the frequency of
34:05 - female business students this is the
34:07 - frequency of male business students
34:09 - female college of arts and science
34:11 - students male College of Arts and
34:13 - Science students it would be better if
34:15 - there is a bigger space between these
34:16 - two so let's go ahead and get a space in
34:18 - there to increase the space we're gonna
34:22 - call it G space and make it 10
34:27 - that will increase the spacing between
34:29 - the groups
34:31 - hence the g and g space so here's
34:34 - without the g space here's with the g
34:37 - space big space between the males and
34:41 - the females allows you to better see
34:43 - where the break is between males and
34:44 - females and instead of a horizontal bar
34:48 - chart we could do vertical bar charts
34:50 - horizontal would be H bar vertical would
34:53 - be V bar and we can also change the
34:58 - space between the individual bars call
35:01 - it space equals one
35:06 - so now we got vertical instead of
35:08 - horizontal we got this space between the
35:11 - groups the G space we got the space
35:13 - between each of the categories in the
35:16 - group pictures space equals one female
35:19 - on the Left male on the right
35:23 - it's go groups bar chart
35:28 - you could also do instead of frequencies
35:31 - we could make it percents
35:35 - type equals percent
35:41 - so here it was frequencies here it's
35:45 - just percents
35:47 - since the data set is of size 100
35:49 - doesn't look like there's much of a
35:51 - change
35:53 - we could also do pie charts
35:57 - so instead of V bar for vertical bar
36:00 - chart or H bar for horizontal bar chart
36:01 - maybe just PI go ahead and get rid of
36:06 - all that and look at a pie chart
36:12 - gives us the level and the frequency of
36:17 - that level and then graphically puts it
36:19 - into a pie chart we could also split
36:22 - this by male and female if you want
36:29 - same way group equals gender
36:33 - but instead of putting the two pies on
36:35 - one graphic it just splits it over two
36:40 - so this is for the females because it
36:42 - says gender equals female and this is
36:45 - for the males gender equals males and
36:47 - this is for everything together
36:54 - three histogram the bar charts the pie
36:58 - charts etc all come are all used to
37:01 - illustrate categorical variables
37:04 - histogram can be used to illustrate or
37:07 - to look at the distribution of a numeric
37:11 - or quantitative variable histograms are
37:15 - found in the proc univariate again it's
37:20 - proc univariate specify the data specify
37:24 - the variable that you want the histogram
37:25 - of in this case we wanted at the grade
37:27 - and then the keyword histogram you
37:31 - notice every one of those Lyons Anne's
37:33 - with a semicolon
37:35 - here's what the histogram looks like
37:40 - notice that you also get univariate
37:42 - statistics on the variable grade because
37:44 - you're using proc univariate if you want
37:48 - to overlay this with the normal curve
37:51 - it's not too difficult
37:56 - after histogram I got a slash than
37:58 - normal
38:02 - and there it is
38:05 - now when you overlay it with a normal
38:07 - curve usually what you're saying is that
38:09 - you want to test if the variable in this
38:12 - case grade comes from a normal
38:14 - distribution again we'll talk about
38:16 - testing later but this last part does
38:20 - that it checks to see or provide several
38:23 - tests to determine if the grade variable
38:26 - would actually did come from a normal
38:27 - distribution we'll cover that later in
38:30 - hypothesis testing
38:36 - that was three the histogram for is
38:38 - gonna be the Box in whiskers plot this
38:42 - is gonna be a tricky one so you want to
38:44 - pay close attention here
38:45 - it's a box plot so a new process box
38:50 - plot specify the data again plot tells
38:55 - you what you want to plot GPA is going
38:58 - to be the dependent variable it's gonna
39:02 - be the numeric variable gender is the
39:05 - independent variable it's going to be
39:07 - your independent variable and specify a
39:11 - box style equals schematic that allows
39:14 - the the usual style of box plot where
39:17 - you actually show the outliers if you
39:21 - leave the box style equals schematic off
39:23 - the whiskers will run from the minimum
39:26 - to the maximum as opposed to the inner
39:28 - the lower inner fence to the upper inner
39:31 - fence as usual
39:34 - so here's the boxplots oh my goodness
39:37 - something's wrong here
39:40 - got male female male female male female
39:43 - what what what gives one of the quirks
39:46 - of sass is you have to sort your data
39:49 - before you can do a proper box plot on
39:51 - it and that sorting is done using proc
39:57 - sort it's a new process
40:04 - Prock sort give it the data specify what
40:09 - variable you're going to sort by we're
40:11 - going to sort by gender because we're
40:13 - gonna plot our box plot by gender now
40:17 - when we run this we get the box plot
40:22 - that we expected female on the Left male
40:25 - on the right these are outliers for the
40:28 - females
40:29 - these are maximums this is a minimum for
40:32 - the males this is the lower inner fence
40:36 - for the females horizontal line again is
40:39 - going to be the median this is Q 3 Q 1
40:43 - here the diamond is actually the mean so
40:46 - SAS gives you automatically the mean for
40:49 - your box plot which is kind of help
40:55 - the fifth is going to be the CDF plot
41:00 - ZDF plot uses proc univariate much the
41:03 - same way that the histogram does so
41:08 - instead of histogram you'll type in cdf
41:12 - plot if you want the normal overlay
41:15 - you'll keep the slash normal if you
41:17 - don't you'll leave it off
41:21 - here's your CDF plot with the normal
41:23 - overlay
41:28 - and finally the scatterplots
41:32 - scatterplot belongs to a different proc
41:36 - it's not proc G chart it's proxy plots
41:42 - data equals that data plot
41:47 - dependent variable star independent
41:50 - variable if you want to have different
41:52 - symbols for the different genders you'll
41:54 - do equal gender if you want them all to
41:57 - have the same symbol you'll leave that
41:58 - off
42:03 - here's the default Bock a scatter chart
42:06 - pluses are used blue pluses for female
42:09 - red pluses for male like guess that
42:12 - makes sense in some way I'm having
42:15 - trouble seeing the difference between
42:17 - the blues and the Reds must be my eyes
42:19 - and the symbols are kind of small so
42:22 - it's not too helpful I guess to make it
42:26 - better we could make the pluses bigger
42:31 - or change the symbols all together and
42:33 - here's we're gonna change the symbols
42:36 - we're gonna call symbol 1 we're gonna
42:39 - make it red its value is going to be a
42:41 - star that's an asterisk mm-hmm and its
42:45 - height is gonna be 2 so hi equals 2
42:47 - we'll make it twice as big
42:48 - then height equals 1 then simple 2 is
42:52 - gonna be blue that's value is going to
42:54 - equal a greater than sign hmm it's
42:58 - interesting just so happens that value
43:02 - equals star will give you the symbol for
43:04 - females and the value equals greater
43:08 - than will give you the symbol for males
43:10 - which is very natural for this type of
43:12 - plot
43:16 - made the females a little bit bigger
43:18 - just to show you that size can be
43:21 - created there you can do height equals
43:27 - to to make the males just as big
43:31 - hmm it's much easier to see or at least
43:33 - this one is much easier to see than the
43:35 - default where everything seemed to be
43:38 - the same color to me now we made it much
43:42 - more obvious and we really don't even
43:44 - need the legend at the bottom telling us
43:46 - female and male because we know that
43:48 - this is the symbol for females and this
43:50 - is a symbol for males I do want to
43:54 - emphasize there is a really nice little
43:57 - website that shows you all of the
44:01 - special marks that you could have
44:04 - it's the UCLA website and that's the end
44:07 - of this those were the six basic
44:09 - graphics that you can do so let's go
44:11 - ahead and quit
44:13 - we quit it
44:17 - and that's everything and again those
44:19 - six graphics that we looked at the first
44:22 - one we looked at was the bar plot both
44:24 - the horizontal and the vertical second
44:27 - was the pie chart first in the second
44:30 - the bar plots and the pie charts to use
44:32 - for categorical variables univariate
44:35 - histogram was the third for quantitative
44:40 - variables fourth the box and whiskers
44:42 - plot also quantitative fifth was the CDF
44:46 - plot the cumulative distribution
44:48 - function plot teachers in SAS these
44:51 - would be tests and confidence intervals
44:53 - these are going to include the t-test
44:56 - the median test the wilcoxon test those
44:59 - three are for the population mean or
45:01 - median it's going to also include the
45:03 - proportions test and the binomial test
45:05 - those will be for the population
45:08 - proportion and the variance test which
45:11 - would be for obviously the population
45:13 - variance so let's start SAS
45:26 - and since we have to analyze data the
45:29 - first thing we have to do is import the
45:31 - data so let's go ahead and import the
45:34 - stat grades data file
45:46 - file name is as usual data step again
45:50 - we're gonna call our dataset stat data
45:52 - we're gonna in file the data file that
45:55 - we defined above its comma delimited so
45:58 - delimiter is a comma first obsequious
46:03 - since the data set is in canonical form
46:06 - that first row is going to be the
46:07 - variable names then the input line which
46:11 - has the names of the variables that were
46:13 - inputting and these are names of the
46:16 - variables as we want them to be ID grade
46:19 - gender remember the dollar sign tells us
46:22 - that the preceding variable in this case
46:24 - gender is a categorical variable SAT
46:28 - math age college and again college is
46:31 - going to be categorical in this data
46:34 - step let's also define the variable term
46:41 - now we're gonna find to be fall 2014
46:46 - because that's when that data when the
46:51 - data were collected
46:53 - and while we're at it we'll go ahead and
46:56 - create a title for this and do a proc
46:59 - print and run all this just to make sure
47:03 - that we've inputted the data correctly
47:05 - I remember when you're running it you
47:08 - can either do f3 on your keyboard or
47:10 - click on this little running person on
47:14 - this little running person we ran it the
47:18 - results are listed over here in the
47:19 - results window they're also provided and
47:21 - provided down here on the results viewer
47:23 - here's the data everything looks like it
47:28 - checked out fine term is our new
47:30 - variable fall of 2014
47:33 - notice it does not change at all for
47:35 - this data set that's fine
47:39 - since we're doing one population
47:42 - procedures we really should get to know
47:45 - our data one of the best ways to get to
47:47 - know our data especially if we're
47:49 - focusing on the mean or the median of
47:50 - the data is to create a box plot
47:55 - if we recall from activity 1b she create
48:02 - a box plot in sass its proc box plot
48:06 - specify the data then in the second line
48:10 - statement its plot GPA is your dependent
48:13 - variable star or asterisk term remember
48:18 - here term is just fall of 2014 that
48:21 - doesn't change so this should give us a
48:24 - single box plot since we specified box
48:27 - style equals schematic we're going to
48:29 - get the whiskers going to the inner
48:31 - upper fence and the inner lower fence
48:32 - and circles will be the outliers let's
48:36 - run this
48:40 - and there's your box plot
48:42 - we have three low outliers there's the
48:45 - inner lower fence the inner upper fence
48:47 - that Dimond again is the mean according
48:51 - to SAS this bar is the median third
48:55 - quartile first quartile looks like it
48:59 - may be slightly skewed negative we could
49:03 - of course determine that using the
49:06 - Hildebrand rule if we wanted to so first
49:13 - it's going to be a one sample t-test
49:19 - it's a new procedure we're going to
49:22 - Apophis eyes that the mean GPA is equal
49:25 - to three
49:28 - and so the setup for this test is proc
49:32 - t-test specify the data and then for
49:38 - that null hypothesis which is h0 we're
49:40 - gonna say it's equal to 3.0 so this line
49:44 - right here at this part of the line
49:46 - specifies the null hypothesis and the
49:51 - next line tells us what variable we want
49:53 - to test in this case it'll be GPA
49:57 - variable now will you run these three
50:00 - lines now we get a lot of output that
50:05 - seems to be SAS is modus operandi was to
50:08 - give a lot of output three tables and to
50:12 - graphics so let's look at the first
50:13 - table and this is a sample size mean
50:17 - this will be the sample mean standard
50:19 - deviation sample standard deviation set
50:23 - a standard error this is gonna be the
50:24 - sample standard deviation divided by the
50:27 - square root of an
50:29 - the minimum and maximum GPAs in the
50:32 - sample simple
50:35 - sample statistics second it's gonna be
50:41 - similar we're given the mean we've also
50:44 - got a 95% confidence interval for the
50:46 - mean we're 95% confident that the mean
50:49 - of the population is between two point
50:53 - nine seven seventy five and three point
50:56 - one seven three one we're given the
50:59 - standard deviation and we've got a 95%
51:02 - confidence interval for the standard
51:04 - deviation we're 95% confident that the
51:08 - population standard deviation is between
51:11 - point four three to nine and point five
51:13 - seven to eight that was table to table
51:19 - three gives results of the t-test
51:21 - degrees of freedom is DF this is equal
51:24 - to n minus one in this case Anna's one
51:28 - hundred one hundred minus one is that
51:30 - ninety nine T value is the test
51:33 - statistic value for this data
51:37 - pyaare greater than absolute value of t
51:39 - this will be the two-tailed test the
51:43 - p-value for that because P is greater
51:46 - than alpha we fail to reject the null
51:47 - hypothesis in other words if the t-test
51:51 - is appropriate for this data then
51:54 - concluding that the average GPA for all
51:58 - students in this population being 3 is
52:03 - reasonable
52:05 - we do not have sufficient evidence to
52:07 - say that it is unreasonable now note
52:13 - that the T test requires normality of
52:16 - the measurements that is it assumes that
52:18 - the GPAs came from a normal distribution
52:22 - this first graphic helps to illustrate
52:25 - or to graphically test that the
52:31 - histogram is from the data the blue
52:35 - curve is of the normal distribution and
52:38 - the pinkish reddish brownish whatever
52:41 - color that is ish curve is what's being
52:44 - observed so we're trying to compare the
52:46 - normal curve with the kernel curve if
52:49 - they perfectly overlap then it's
52:51 - guaranteed that this data came from a
52:54 - normal distribution
52:55 - they will never perfectly overlap but is
53:01 - it close enough and that's really what
53:03 - we're after here is is it close enough
53:05 - and I don't know just by looking at this
53:09 - I'd say now it really looks to be
53:11 - heavily skewed to the left so I don't
53:14 - think it's close enough I'm not positive
53:16 - though if this graphic doesn't do it for
53:20 - you here's the second graphic this is
53:22 - the quantile quantile plot of GPA if the
53:27 - data came from a normal distribution
53:28 - then those dots should line up along
53:30 - that diagonal line these dots along this
53:34 - diagonal line they won't ever perfectly
53:38 - be along the diagonal line but they
53:39 - should be close enough looking at this
53:42 - and it looks like there's a definite
53:44 - pattern here starts low goes high ends
53:49 - low this is a misses this indicates that
53:53 - the data are also left skewed so both of
53:57 - these indicate the data or are left
54:00 - skewed now the question is is are the
54:03 - data significantly less skewed
54:06 - and as we talked about in class one way
54:10 - that we can test that is using the
54:14 - Shapiro bulk test now to do that we have
54:19 - to run our proc univariate and we
54:21 - actually did do the Shapiro bulk tests
54:23 - but it was back in activity 1a it's proc
54:27 - univariate data equals stat data and
54:30 - then we add in normal VAR GPA because
54:35 - we're testing normality for the GPA
54:37 - variable so let's go ahead and run these
54:42 - lines
54:48 - here's the moments that should look
54:50 - familiar to us basic statistical
54:52 - measures should look familiar to us test
54:54 - for location remember last in in 1a I
54:57 - told you let's go ahead and skip over
54:58 - that test for normality is the new stuff
55:01 - Shapiro will test test statistic is w
55:05 - its value is 0.9 three eight seven nine
55:08 - eight the p-value is point zero zero
55:11 - zero two because the p-value is less
55:15 - than alpha in this case it's a lot less
55:17 - than alpha we reject the null hypothesis
55:20 - for the Shapiro Wilk test the null
55:24 - hypothesis is that the data came from a
55:26 - normally distributed population we
55:30 - reject that include the data did not
55:31 - come from a normally distributed
55:33 - population that means that the t-test is
55:36 - not appropriate
55:38 - since the t-test is not appropriate we
55:42 - may want to use the wilcoxon test which
55:45 - is also called the signed-rank test
55:50 - same null hypothesis we're testing that
55:53 - the mean is equal to three for the GPA
55:55 - to do the wilcoxon test or the
55:59 - signed-rank test use proc univariate
56:02 - specify the data add in two additional
56:07 - items on this line loc count and our
56:13 - null hypothesis here it's mu zero equals
56:16 - three for the t-test it was H zero
56:20 - equals three
56:21 - here it's mu zero equals three then on
56:26 - the next line specify the variable that
56:28 - you're interested in
56:32 - running that again since it is
56:35 - univariate procedure we're gonna get a
56:37 - lot of information the moments basic
56:40 - statistical measures test for location
56:43 - of mu zero equals three this is the
56:47 - table we want remember we're doing the
56:52 - wilcoxon test SAS calls it the
56:55 - signed-rank test signed-rank test is the
57:00 - bottom of the three it's value for the
57:04 - test statistic is 657 point five the
57:08 - p-value is 0.02 0.03 y is equal to three
57:20 - so if the wilcoxon test is appropriate
57:24 - we can reject the null hypothesis
57:27 - note that this conclusion is different
57:29 - than the one we had with the t-test but
57:32 - we concluded the t-test was not an
57:33 - appropriate test because the data were
57:36 - not normally distributed here we've got
57:38 - the wilcoxon test we reject the null
57:41 - hypothesis but we really do need to test
57:45 - if the data come meet the requirements
57:49 - of the wilcoxon test or meet the
57:51 - assumption of the wilcoxon test which is
57:57 - the simple symmetry the data must come
58:00 - from a symmetric distribution now how
58:03 - can we do that well we choose the
58:06 - Hildebrand rule hildebrand rule is the
58:09 - mean minus the median and the absolute
58:14 - value of that divided by the standard
58:16 - deviation if that is less than 0.2 then
58:22 - the data are sufficiently symmetric it
58:25 - was greater than point to the data are
58:28 - not sufficiently symmetric in doing this
58:31 - calculation we find out that that ratio
58:33 - is 0.2 to 2 4 8 3 6 2 3 since that is
58:39 - greater than point to the data are not
58:41 - sufficiently symmetric the wilcoxon test
58:45 - is not appropriate
58:47 - if the wilcoxon test is not appropriate
58:50 - we're done we cannot test the mean of or
58:57 - learn about the mean of this of the
58:59 - population that gave us this data that
59:02 - is unless we actually know the
59:03 - distribution that gave us the data we
59:05 - don't but we can start doing some tests
59:08 - on the median and so the one that we're
59:11 - going to use is the median test what SAS
59:14 - calls the sign test
59:18 - it's also a part of proc univariate fact
59:22 - let's have the wilcoxon test up here and
59:26 - the code for the median test down here
59:30 - compare the two they should be exactly
59:34 - the same why should they be exactly the
59:38 - same because the code that gave us
59:41 - through cells for the wilcoxon test with
59:42 - the signed-rank test also gave us the
59:44 - results for the sign test the median
59:47 - test so let's run those
59:54 - signed-rank test was the wilcoxon test
59:57 - the sign test is the median test test
60:00 - statistic for the median test in this
60:02 - case is 12.5 the p-value is 0.01 54
60:07 - because the p-value is less than alpha
60:11 - we reject the null hypothesis conclude
60:14 - that the median is not 3
60:19 - and that's it
60:26 - we have gone through all that notice the
60:30 - process we followed we started with the
60:33 - t-test we looked at the assumption of
60:35 - the t-test which was that the data came
60:37 - from a normally distributed population
60:38 - we tested that assumption had the data
60:42 - passed the assumption we'd report the
60:44 - results of the t-test in this case the
60:47 - data did not pass that assumption so he
60:49 - moved on to the next more general test
60:52 - which was the wilcoxon test or the
60:54 - signed-rank test we looked at the
60:58 - assumption of the wilcoxon test which
61:00 - was that the data came from a symmetric
61:02 - distribution we tested that using the
61:05 - Hildebrand rule we rejected that
61:08 - assumption
61:08 - therefore the wilcoxon test or the
61:11 - signed-rank test was not appropriate so
61:13 - he moved on to the next more general
61:15 - test and this one actually was for the
61:16 - median also called the sign test no
61:20 - assumptions involved in this and from
61:23 - the results of the median test for the
61:26 - scientists we reject the null hypothesis
61:28 - that the median is indeed 3 and that's
61:31 - the median of the population is not 3 so
61:36 - those were the tests of center
61:42 - now let's look at tests of proportions
61:50 - proportions tests Leslie's it let's
61:53 - examine the gender variable and start
61:58 - out with typical graphic this will be a
62:01 - horizontal bar plot of gender we're not
62:04 - going to include the stats on it there
62:08 - we go
62:09 - female goes out that far male goes out
62:11 - that far and for all of these let's have
62:14 - our null hypothesis be that the
62:16 - proportion of females at Oklahoma State
62:19 - University is 40% so the first test for
62:24 - proportions is going to be called the
62:26 - binomial test no I'm sorry it's gonna be
62:29 - called the proportions test
62:35 - code for that it's proc freq
62:40 - not really surprising because we're
62:41 - dealing with categorical variable proc
62:44 - freq deals a lot with the categorical
62:46 - variables specifying the data set again
62:49 - the next line is can be tables gender /
62:57 - binomial P equals point four zero and
63:01 - this will make it this will actually
63:03 - give us the proportions test results run
63:07 - that
63:09 - we're given sample statistics for the
63:13 - gender variable in this sample there's
63:16 - 45 females 55 males that's the first
63:22 - table second table gives us the results
63:26 - of the test of the proportions test
63:30 - we'll use the for the I'm sorry this
63:36 - gives us the confidence interval so
63:37 - we'll go with the confidence intervals
63:39 - first we'll use the proportion ASC ASC
63:43 - stands for asymptotic standard error and
63:45 - the 95 lower and 95 upper so we're 95%
63:49 - confident that the true proportion of
63:51 - females at OSU Stillwater is between
63:54 - point three five two five and point five
63:57 - 475 the third table gives the results of
64:02 - our hypothesis test we hypothesized that
64:05 - P was equal to 0.4
64:10 - two-sided test gives a p-value of 0.3 0
64:13 - 74 because this is greater than alpha we
64:16 - conclude that it's reasonable to
64:18 - conclude that the proportion of females
64:21 - at OSU Stillwater is 40% pretty
64:26 - straightforward you get the computer to
64:30 - do the calculations you interpret the
64:34 - results the one sample proportions test
64:38 - is actually an approximate test the
64:42 - exact test is called the binomial test
64:47 - the difference between the binomial test
64:49 - and the proportions test in SAS is
64:53 - simply the inclusion of a second line or
64:56 - an additional line exact binomial not
65:02 - for this line the two pieces of code
65:06 - will look exactly the same the output is
65:09 - going to be very similar as well this
65:14 - table is common between the two this
65:17 - table is common between the two and most
65:20 - of this table is common between the two
65:22 - the only difference is when you do the
65:24 - exact binomial test you also get the
65:27 - p-values for the exact test these four
65:31 - numbers were from the proportions test
65:33 - these two are from the binomial test
65:37 - least these four numbers are for the
65:40 - confidence interval for the proportions
65:42 - test these are for the confidence
65:44 - interval for the exact binomial tests so
65:47 - we're 95% confident that the true
65:49 - proportion of females at OSU Stillwater
65:52 - is between 0.35 zero three and point
65:55 - five five to seven that's all there is
65:59 - to it those are the only two one sample
66:03 - proportions tests available
66:07 - the main difference between the two is
66:09 - that the binomial test assumes the data
66:11 - come from a binomial distribution that
66:15 - may or may not be true that's completely
66:19 - up to you and the definition of that
66:21 - binomial distribution the third set of
66:26 - tests that we're going to look at it's
66:28 - going to be the variance test for
66:30 - various reasons and I'll let you read
66:32 - that in the handout there is no built-in
66:35 - variance test in SAS you have to create
66:38 - your own so that's what we do here
66:42 - this is SAS programming this is actually
66:45 - very simple part of SAS programming I do
66:48 - not expect you to be able to program SAS
66:51 - just to use it
66:54 - and you know reality one sample variance
66:57 - test is rarely going to be done so
67:01 - consists of three blocks of code the
67:04 - first block of code calculates the
67:08 - sample variance and the sample size
67:14 - sample variance we're gonna call s VAR
67:18 - sample size we're gonna call n this line
67:22 - the output line actually saves that
67:26 - information from the proc univariate no
67:30 - print means we're not going to print
67:31 - anything out so you're just going to use
67:33 - it to save the sample variance and the
67:35 - sample size the second block uses the
67:40 - sample variance and sample size and your
67:43 - hypothesized variance to calculate the
67:46 - p-value and the confidence interval
67:49 - these formulas come from the textbook by
67:52 - the way
67:54 - this is all done within a data step and
67:56 - at the end of this data step we're going
67:58 - to have a data set called VAR test
68:00 - results and then we print out of our
68:06 - test results the data set that we just
68:08 - created when we print it out we're gonna
68:11 - get values for the sample variance the
68:15 - sample size hypothesized value of the
68:17 - variance
68:18 - the test statistic the p-value the lower
68:22 - confidence level and the upper
68:23 - confidence level highlight run
68:30 - and this is what prints up sample size
68:33 - is 100 sample variance was 0.243 1/2 the
68:39 - hypothesized variance was 0.33 test
68:43 - statistic calculated was 72 point nine
68:46 - three six zero corresponds to a p-value
68:49 - of 0.05 eight to five and a confidence
68:55 - interval a 95% confidence interval
68:58 - ranging from 0.18 74 to two point three
69:02 - to eight zero nine so we're 95%
69:04 - confident that the true population
69:07 - variance is between these two numbers we
69:11 - hypothesized it was 0.33 that's just
69:16 - outside the interval that gives us a
69:19 - p-value point zero four five which is
69:21 - less than our usual alpha of 0.05 we
69:24 - reject the null hypothesis we conclude
69:27 - that according to the data it's unlikely
69:31 - that the population has a variance of
69:33 - 0.33
69:36 - had we thought or believed or
69:41 - hypothesized at the population variance
69:43 - was 0.25 we could test that by going
69:47 - down here to the VAR zero line change
69:50 - that to 0.25 and rerun the whole set so
69:56 - for the second for the test that the
69:59 - population variance is 0.25 p-value is
70:04 - 0.88 so we fail to reject that null
70:08 - hypothesis in fact every value between
70:11 - point 1 8 7 4 2 and point 3 2 809 is
70:15 - reasonable as a population variance and
70:19 - that's the end of this code this covers
70:24 - all of the one sample test that you
70:26 - would want to run and so while we're at
70:30 - it let's just go ahead and feed in
70:32 - acquit I'm showing you how to do two
70:34 - population procedures using SAS so
70:38 - that's go ahead and open up SAS
70:49 - again the log screen at the top the
70:52 - script screen down here so it's whatever
70:55 - is in this window is what you'll submit
70:57 - in your appendix let's go ahead and load
71:00 - the data it's going to be the stat
71:03 - grades data as expected you should be
71:07 - familiar with how to do all of this I'm
71:10 - going to add one more thing I'm gonna
71:12 - create a variable called got pass and
71:15 - we're gonna call it got pass because
71:18 - it's going to indicate whether or not
71:19 - the student passed or failed the course
71:22 - so we're gonna cut got PA SS I'm gonna
71:27 - say failed for everyone okay now when
71:33 - does a student actually fail
71:35 - well student fails if the grade is less
71:39 - than 70% so if the students grade is
71:43 - greater than or equal to 70% then got
71:48 - pass
71:51 - is going to be value passed
72:00 - we'll give her a title
72:05 - we'll be grades for stat 401 3 hopefully
72:14 - my fingers start working will proc print
72:18 - it just make sure everything's done and
72:24 - end with a run so we'll go ahead and
72:28 - highlight all this run it again remember
72:31 - you can either run it by clicking on the
72:33 - little running person at the top or f3
72:36 - on the keyboard and here's what was
72:38 - printed out looks like everything's
72:41 - working right student got a 56 didn't
72:45 - pass student got a 72 passed so that's
72:51 - one way of creating or that's another
72:53 - way of creating new variables or new
72:55 - types of variables for your data set
72:59 - it's a very handy way at times so let's
73:03 - get a look at our data let's go ahead
73:05 - and say for everything we're going to do
73:09 - today or at least for the means part
73:12 - we're going to compare GPAs for males
73:15 - and females so first step side by side
73:19 - box plot
73:21 - remember to sort it first we're going to
73:26 - sort it by gender
73:30 - we're going to sort it by gender because
73:32 - our box plot is going to be one box plot
73:36 - for males on box plot for females
73:46 - instead of the forum GPA which is our
73:49 - measurement variable our dependent
73:51 - variable asterisk and then our grouping
73:54 - variable
73:58 - and as usual our box style it's going to
74:02 - be schematic that will allow the dots to
74:06 - indicate outliers let's run this
74:13 - and those are side by side box plots two
74:17 - outliers for females the little diamond
74:20 - is the met as the mean looks like the
74:23 - mean and the median for females bit
74:25 - higher than it is for males but the
74:28 - question is is it significantly higher
74:33 - we can also do the same thing or or look
74:36 - at the distribution of the data using
74:39 - histogram so here's how to do histograms
74:44 - again we got to make sure we sort it by
74:46 - gender its proc univariate the very
74:50 - variable we're gonna use is GPA and
74:52 - histogram and since and and let's go
74:55 - ahead and break it up by gender so this
74:58 - is going to give us two histograms one
74:59 - for females one for males here's the
75:05 - histogram for females this gram for
75:09 - males females look to be a bit more left
75:13 - skewed than the distribution males will
75:17 - find out if that's important
75:20 - so that was looking at the data the next
75:23 - step is to actually perform the tests so
75:26 - we're going to start with a two sample
75:28 - t-test
75:35 - and is expected it uses proc t-test
75:40 - data stated the variable is GPA and if
75:45 - we stop here with just proc t-test and
75:47 - var GPA we're gonna get the one sample
75:49 - t-test from the last video but if we
75:53 - specify class is gender then we're also
75:56 - going to be able to break it up between
75:58 - the two genders and get a two sample
76:00 - t-test output is a lot as usual let's go
76:07 - through the four tables first table
76:10 - gives statistic sample statistics for
76:14 - GPA for the females the mean is sick
76:18 - three point one six GPA for the male's
76:21 - whose mean is three point zero zero
76:23 - standard deviations errors men's maxes
76:26 - etc and also for the difference between
76:28 - females and males females are for this
76:32 - sample or females have for this sample
76:34 - an average GPA of 0.15 6:8 higher than
76:38 - that of males so first table gives us
76:42 - the sample statistics second table gives
76:46 - us some confidence intervals for the GPA
76:50 - for females we're 95% certain that the
76:54 - population mean is between 3.0 3 and
76:58 - 3.30 for males we're 95% confidence
77:03 - between 2.86
77:04 - and three point 1 4
77:08 - we can do that we have the same
77:10 - information for the standard deviation
77:11 - for the there are now two methods for
77:17 - the two sample t-test in the handout I
77:20 - explain what both of these methods are
77:23 - I'm going to highly suggest that you
77:25 - only use the Satterthwaite and I give
77:30 - some idea as to why with so using the
77:33 - Satterthwaite method the 95% confidence
77:37 - interval for the difference in means is
77:40 - from negative point zero three five
77:42 - seven two positive point three four nine
77:44 - three since zero is a part of that
77:47 - confidence interval we cannot state that
77:50 - there is a significant difference or a
77:52 - detected difference between the mean GPA
77:56 - for the two genders
77:59 - here this third table is a result of the
78:02 - t-test
78:04 - for both the pooled and the
78:06 - Satterthwaite method again I highly
78:08 - suggest using the Satterthwaite method
78:11 - degrees freedom for the Satterthwaite is
78:14 - ninety seven point five seven nine test
78:16 - statistic is one point six two the
78:19 - p-value is 0.1 0.2 because P is greater
78:22 - than alpha we failed to reject the null
78:24 - hypothesis conclude that we did not
78:26 - detect a difference in GPA or an average
78:28 - GPA between the two genders then Table
78:32 - four gives us a statistical test for the
78:35 - Equality of variances
78:36 - it's the folded F test it's one of the
78:40 - available variance tests probably the
78:45 - p-value is 0.35 0 4 3 5 0 3 because
78:50 - that's greater than alpha we fail to
78:52 - reject the null hypothesis conclude that
78:54 - the we did not detect any difference in
78:56 - the two variances the GPA variance for
78:59 - males and the GPA variance for a few
79:01 - minutes
79:02 - now as with the one sample t-test there
79:07 - is a requirement that the observations
79:11 - or the data are normally distributed in
79:13 - each of the two populations let me
79:16 - emphasize that it's in each of the two
79:18 - populations not all the GPAs are
79:21 - normally distributed but they're
79:22 - normally distributed for females and for
79:25 - males
79:29 - now we can do a normality test and again
79:34 - I recommend the Shapiro book test
79:36 - I'm notice again that this is very
79:38 - similar to what it was in the last video
79:40 - slash handout the only difference again
79:43 - is the class gender is added we're
79:46 - specifying that we want to break these
79:48 - up these these normality tests up along
79:51 - the gender
79:57 - again lots and lots of output okay for
80:01 - gender equals female Shapiro Wilk tests
80:05 - p-value is less than alpha so we can
80:08 - conclude that the GPAs do not come from
80:11 - a normal distribution for females now if
80:15 - we scroll down for the male's look at
80:17 - the same thing Shapiro will test
80:20 - p-values point zero five one six that's
80:22 - pretty close we do not have evidence
80:27 - that the male GPAs come from anything
80:29 - other than a normal distribution so
80:32 - females were a failure in terms of
80:35 - distribution males were not a failure in
80:37 - terms of distribution but both male GPAs
80:41 - and female GPAs have to come from a
80:44 - normal distribution in order for the
80:46 - t-test to be appropriate since the
80:49 - females do not we cannot use the two
80:52 - sample t-test so what do we do we use
80:56 - the mann-whitney wilcoxon test you can
80:59 - compare this code with it's a analogy
81:04 - from the last handout
81:07 - and the difference is only the class
81:08 - gender
81:15 - and par stands for nonparametric one-way
81:18 - procedure statistics about the males and
81:22 - the females here's the test SAS calls
81:26 - that the wilcoxon two sample test test
81:30 - statistic is 2500 four point five
81:36 - the test statistic
81:39 - for since we were testing difference
81:41 - it's gonna be two-sided or two-tailed
81:43 - test p-value is 0.1 0 8 5 since P is
81:48 - greater than alpha we fail to reject the
81:49 - null hypothesis we don't have evidence
81:52 - that males and females have different
81:54 - average GPAs here
82:00 - we could also use the kruskal-wallis
82:01 - test which is a little bit less powerful
82:04 - but a bit more exact that p-value is
82:07 - point one oh seven eight and even though
82:09 - it's called the kruskal-wallis test this
82:12 - is actually the mann-whitney wilcoxon
82:14 - test in this box
82:16 - they were approximations this is the
82:19 - exact so p-values 0.107 eight again
82:23 - failed to reject the null hypothesis do
82:27 - not be surprised that this p value for
82:29 - the kruskal-wallis test the p value for
82:32 - the t approximation and the p value for
82:35 - the normal approximation are pretty
82:36 - close large sample size means that those
82:39 - three are going to start becoming closer
82:41 - and closer and closer and there's our
82:44 - paired t-test
82:48 - so those were the two ways of testing
82:51 - whether or not the means the two
82:53 - distributions were equal or the means of
82:56 - the two measurements are equal the mean
82:59 - of GPA for males versus mean of GPA for
83:02 - females let's move on to proportions
83:06 - test now and let's look at the pass rate
83:09 - for males versus the pass rate for
83:11 - females so let's start as usual with
83:15 - looking at our data it's a two-way
83:17 - graphic the bar it's gonna be vertical
83:20 - bars I'm gonna group it by got pass so
83:26 - for those who failed overwhelmingly male
83:28 - for those who passed overwhelmingly
83:31 - female just by looking at this graphic
83:34 - we have an idea that there is a
83:35 - significant difference the test we're
83:39 - going to use is in some areas called the
83:42 - two sample proportions test in other
83:44 - areas it's called a chi-squared test
83:47 - we'll call it both tables gender star
83:53 - got pass
83:56 - and chi-squared goes after that Zhi sq
84:00 - because this is a chi-squared test
84:06 - get three tables this will be our
84:09 - frequency table this will be for the
84:14 - chi-squared table and the one that
84:15 - you'll want to look at is just the
84:17 - chi-squared that's the first row and if
84:20 - you want to you can look up Fisher's
84:22 - exact test to see what that's all about
84:25 - the test statistic for the chi-square
84:27 - test is twenty-seven point two four zero
84:29 - three that corresponds to a p-value of
84:32 - less than one in ten thousand since the
84:34 - p-value is less than alpha we reject the
84:36 - null hypothesis and we conclude that
84:39 - there is a significant difference in
84:41 - pass rates between males and females we
84:46 - have to go to this table to interpret it
84:48 - even more of those who passed so we're
84:52 - calling looking at this column and it'll
84:55 - be the third fourth yes the fourth value
84:59 - of the Cole percent of those who passed
85:02 - thirty six sixty three sorry sixty three
85:06 - percent were female and 36% were male
85:11 - if the number of mails and number of
85:14 - females are equal that has meaning we
85:18 - can look at the Roper sense which means
85:19 - that females of all the females ninety
85:22 - three point three three percent passed
85:24 - and of all the males forty three point
85:27 - six four percent passed that's a little
85:32 - bit more meaningful in general terms the
85:36 - column percents really do require that
85:39 - the number of males and number of
85:40 - females are equal the row persons do not
85:45 - and the last test that we're gonna look
85:48 - at is the variance test we're gonna
85:50 - compare the variance of males versus the
85:52 - variances of females GPAs and if we've
85:57 - actually saw seen this test already its
85:59 - back in the pre tests
86:04 - this is that fourth table the Equality
86:08 - of variances test here SAS wants us to
86:11 - use the folder def test the test
86:13 - statistic is one point three two
86:15 - the p-value is 0.35 zero three because P
86:19 - is greater than alpha we fail to reject
86:20 - the null hypothesis we have not detected
86:23 - a difference in the variances of GPAs
86:25 - between males and females now honestly
86:29 - variants of GPA not that important but
86:33 - variance is also measure of risk in the
86:35 - stock market so instead of thinking of
86:37 - male and female GPAs think of price of
86:41 - IBM versus price of Apple you would want
86:45 - the you would generally all things being
86:47 - equal you would generally want the lower
86:50 - variance stock but do analysis variance
86:53 - and multiple comparisons using SAS this
86:56 - really is just an introduction to it so
86:58 - the first thing we've got to do as usual
86:59 - is import the data we're going to use
87:03 - the usual data set the stat grades data
87:06 - set
87:15 - and again click on the little running
87:17 - person appear or f3 on your keyboard
87:21 - looks like everything came in crack
87:24 - Lee's do a proc print
87:32 - just to double-check just to get a feel
87:35 - for the data and remember you always
87:37 - want to get a feel for the data
87:39 - observations and identical identify our
87:42 - grade gender or GPA college one thing
87:46 - you'll notice is that there's only one
87:48 - lasso person in this group so if we're
87:53 - trying to determine the effect of
87:55 - college on grade or see if there's
87:57 - different grades for different colleges
88:00 - having one person from lasso is not
88:03 - going to give us enough information
88:05 - about lasso so let's take less oh and
88:08 - bundle it with all the other group now
88:12 - let me show you how to do that to recode
88:14 - lasso into other so we'll go back up
88:19 - here to the data step so what are we
88:23 - going to do we're going to see which of
88:24 - those have College equal to lasso and
88:27 - then change those color college to other
88:29 - that's all we're doing
88:35 - there we go so if the college value is
88:39 - less so then we're going to make the
88:41 - college value other if college isn't
88:46 - less so that it's not going to do
88:48 - anything and notice down here the last
88:51 - so person is now an other person
88:54 - so we just recoated part of our data
88:58 - that will be very useful in the future
89:01 - for you and all of your data analysis
89:04 - there are many ways of doing it this is
89:06 - just one of them okay
89:10 - get to know your data so let's go ahead
89:11 - and look at some graphics
89:15 - histogram we're gonna do histograms by
89:17 - college so we're going to have five
89:19 - history M's
89:24 - hmmm that doesn't look right
89:28 - what's wrong
89:29 - it's not sorted in ascending sequence ah
89:33 - that's right we have to sort by college
89:37 - before we can do a histogram so it's
89:40 - just proc sort
89:44 - now we've got it so here's business
89:51 - here's arts and sciences that looks
89:54 - really normal
89:55 - here's college of agricultural science
89:59 - and natural resource education
90:03 - either that one looks pretty normal too
90:08 - we could also do box plots
90:12 - side-by-side boxplots
90:18 - get a little feel looks like the average
90:21 - for Kassner and EDR higher than
90:25 - everything else well this is GPA we're
90:29 - looking at grade
90:36 - let's rerun those there we go
90:39 - looks like castner's average which is
90:43 - the Dimond is much higher than any
90:46 - others looks like business is much lower
90:49 - than all the others so already we have
90:51 - an idea that perhaps there is an effect
90:54 - or a differential effect of college on
90:56 - grade that Kasner students seem to do
91:00 - much better than business students well
91:03 - let's figure this out let's do one way
91:07 - ANOVA and it's called one way ANOVA
91:12 - because we have one independent variable
91:15 - its proc GL m GL M stands for
91:20 - generalized linear models give it data
91:24 - specify the class and class again is the
91:28 - categorical variable college and then
91:31 - the model the model is going to be the
91:33 - dependent variable equal sign
91:36 - independent variable or in this
91:39 - framework it's going to be the
91:41 - measurement equal sign grouping variable
91:46 - and then we run it and then because of
91:50 - some internal features with the GLM
91:54 - process we're gonna have to do a quit
91:56 - immediately after I guess half two is
91:58 - not the right word but that's all there
92:01 - is to it here's the results of the GLM
92:04 - procedure here's the first page tells us
92:07 - there are five levels in the College
92:09 - Business Arts and Sciences Casner
92:11 - education and other there were 100
92:14 - observations that are read and we were
92:15 - able to use all of them this is the
92:19 - usual ANOVA table the source the degrees
92:24 - of freedom sum of squares the main
92:27 - square the F value all those we
92:29 - calculated in class and then the p-value
92:32 - p-value is less than alpha therefore we
92:34 - reject the null hypothesis again in this
92:37 - case the null hypothesis is that all the
92:40 - means are equal
92:44 - these two tables give different types of
92:48 - sums of squares since we're doing
92:50 - one-way analysis of variance these will
92:52 - give an absolutely no additional
92:54 - information if you move on to two-way
92:57 - and above analysis variance these will
93:01 - give additional information but since we
93:03 - only do one way in this course we'll
93:05 - have to postpone discussing that until
93:07 - statistics for experimenters to here's
93:12 - the histogram I mean I'm sorry box plots
93:14 - side-by-side box plot again the diamonds
93:16 - are the means the horizontal bar here is
93:19 - the median this also gives the test
93:22 - statistic F is ten point one eight F is
93:25 - ten point one eight and the p-value in
93:29 - this case again less than alpha so we've
93:32 - now concluded that assuming an analysis
93:35 - of variance is the correct procedure to
93:37 - use here we've we're able to conclude
93:40 - that at least one of the five colleges
93:42 - has a different average grade
93:45 - [Music]
93:46 - so let's test the assumptions remember
93:50 - that there are two main assumptions
93:52 - above and beyond the usual assumption of
93:54 - Independence the first is the assumption
93:57 - of normality we remember how to do that
94:01 - from earlier sort it by college proc
94:07 - univariate and then give it normal
94:09 - now Oprah give the normality tests
94:12 - several normality test I call it the one
94:15 - that we're going to be using will be the
94:16 - Shapiro Wilk test also note that there's
94:20 - five tests being performed here one for
94:24 - each of the colleges therefore you
94:26 - should multiply the p-values for this
94:28 - pure Wilk test by five here's the
94:31 - p-value for the Shapiro will test for
94:33 - college business we don't have evidence
94:37 - that it's non normal the next one is for
94:41 - college of Arts and Sciences there's a
94:43 - p-value 0.3 multiply that by five that's
94:47 - also greater than alpha therefore no
94:50 - evidence of non normality for the
94:52 - College of Arts and Sciences college of
94:55 - agricultural science and natural
94:57 - resource multiply that p-value by five
95:00 - again because there's five tests five
95:02 - normality test we're running
95:04 - there's no evidence of non normality for
95:07 - Kasner education 0.347 seven times five
95:13 - also greater than alpha and finally the
95:16 - other group point nine one five five
95:19 - again greater than alpha you multiply
95:21 - that by five greater than alpha so no
95:25 - evidence of non normality which means
95:27 - that this model and this data passed
95:29 - that assumption test the other
95:32 - assumption test is equality of variance
95:35 - in the populations and the five
95:38 - populations here there's many ways of
95:42 - testing for equality of variances what's
95:44 - actually called homogeneity of variance
95:48 - we're going to use the basic Levine test
95:51 - to do the Levine tests notice that the
95:54 - first three lines again are just the
95:56 - same as the proxy lemma from above we're
96:00 - really just adding this new line the
96:02 - means line states the grouping variable
96:08 - HOV test is homogeneity of variance test
96:11 - and we're gonna have sastra and Levine
96:14 - tests being offers several types
96:18 - I'm we're gonna be used type equals
96:19 - square so it's going to be squares of
96:22 - the measurements instead of the absolute
96:25 - values we'll run that
96:32 - output from the GLM procedure
96:37 - starts way up here five levels that's
96:41 - familiar this is also familiar from the
96:44 - last GLM proc that we ran this is well
96:47 - here's the new line Levine's test for
96:51 - homogeneity of grade variance so it
96:54 - tells us immediately that the null
96:56 - hypothesis is that the variances are the
97:00 - same
97:01 - how much Genie experiences are the same
97:03 - so we look to see if we can reject that
97:05 - null hypothesis
97:07 - there's the p-value it's 0.8 0.8 is
97:11 - greater than point zero five which is
97:13 - our alpha therefore we fail to reject
97:15 - the null hypothesis therefore this data
97:19 - and model passed this assumption test as
97:21 - well so it passed the normality tests
97:25 - and it passed the Levine homogeneity
97:29 - test so it passes all of those
97:31 - assumption tests which means that
97:34 - analysis variance actually was the
97:36 - correct procedure or we are allowed to
97:39 - use it and we're able to conclude that
97:41 - at least one of the means is different
97:43 - from the others
97:46 - that's all we're able to conclude right
97:48 - now one of the means is different from
97:50 - the others we don't know which means we
97:53 - just know that at least one could be two
97:55 - could be three but at least one is
97:57 - different from all the others all that
98:00 - work and that's all we're able to
98:01 - conclude that's fine the next step is to
98:06 - determine which is different and not
98:09 - just which is different but which is
98:11 - different and in which way how are we
98:13 - going to do that gannets the proxy LM
98:16 - these three lines are going to be
98:18 - exactly the same as before we add in
98:21 - this new line means college is going to
98:25 - be the categorical variable and then
98:28 - after the slash is going to be the multi
98:30 - multiple comparison test we want to use
98:32 - we're gonna use the Tukey HSD test
98:37 - let me run those lines we get a lot of
98:40 - output
98:44 - let's see where do we start we start
98:47 - back here same output same output for
98:50 - the GLM's same output for the cheap
98:51 - Prachi LM nothing there is difference
98:54 - here's the new part two key studentized
98:57 - range HS d test four great specifies at
99:03 - alpha is 0.05 error degrees of freedom
99:07 - error means square we calculated it
99:09 - those in class critical value we also
99:12 - calculated in class that was a lot of
99:14 - work SAS does it all for you but the
99:18 - drawback is you've got this incredibly
99:20 - large table that you have to interpret
99:23 - so how do you do that the way that I do
99:27 - it is I look to see they look for the
99:30 - stars the stars indicate that the
99:33 - difference is statistically significant
99:35 - at the 0.05 level in other words for
99:39 - this one we know that Kassner - cast is
99:44 - significantly different from zero which
99:48 - means since the difference actually is
99:50 - positive Kasner has a statistically
99:53 - higher average grade than cast students
99:57 - since Castro - caste is positive Kastner
100:00 - is greater than kiss and a statistically
100:04 - significant level and since that
100:07 - difference is eleven point three nine
100:08 - one I'd say that's the practically
100:10 - significant level as well
100:12 - Kassner is also greater than other
100:15 - Kassner is greater than business buy a
100:18 - whole lot Kassner is not significantly
100:22 - higher than education
100:25 - no stars here therefore this difference
100:28 - is not significantly different from zero
100:32 - there's no detected difference between
100:34 - the average caster grade and the average
100:36 - education grade so Kasner is not
100:40 - significantly different from education
100:42 - but it is higher significantly higher
100:44 - than Arts and Sciences other in business
100:47 - we know from here that education is
100:50 - significantly higher than business
100:52 - we know that Arts and Sciences is
100:56 - significantly less than Casner which we
100:59 - knew from above
101:01 - you know Arts and Sciences is
101:03 - significantly higher than business other
101:06 - is significantly lower than Kasner which
101:09 - we also know from above and business is
101:13 - significantly less than every other
101:16 - college
101:20 - so here's what we can conclude from this
101:25 - business is significantly less in terms
101:28 - of average grade than all the other
101:29 - colleges Kazon area is significantly
101:32 - more than all the other colleges in
101:35 - terms of average grade except for
101:36 - education and there's no significant
101:39 - difference between the education arts
101:42 - and sciences and other
101:46 - it's kind of interesting business the
101:49 - lowest Kastner the highest except it may
101:52 - not be higher than education so that was
101:56 - multiple comparisons
101:58 - and we can do multiple comparisons if we
102:01 - reject the null hypothesis of analysis
102:05 - of variance if after and we do analysis
102:08 - of variance in the p-value is greater
102:09 - than alpha we conclude that there's no
102:11 - detected two difference amongst the
102:13 - several pop subpopulations if we failed
102:18 - to detect a difference it doesn't make
102:19 - sense to then go and look for a
102:21 - difference by doing multiple comparisons
102:25 - finally
102:28 - remember there were two assumptions for
102:32 - analysis of variance there's equality
102:34 - variances and the normality if any of
102:37 - those are violated by the data in the
102:39 - model you can't use analysis variance
102:42 - you'll use what's called the critical
102:46 - Wallis test here's what you would run
102:51 - this looks very familiar to us it's very
102:54 - similar to what we've done with the two
102:56 - sample tests Act I think the code is
102:59 - exactly the same the only difference is
103:01 - the class variable college in this case
103:04 - has more than two levels so SAS knows to
103:08 - run a kruskal-wallis tests on it P is
103:12 - less than alpha reject the null
103:15 - hypothesis of equal means and therefore
103:18 - conclude that at least one of the means
103:20 - is different from the others
103:24 - we do multiple comparisons with
103:27 - kruskal-wallis test absolutely and I
103:30 - encourage you to take the nonparametric
103:31 - scores where we covered how to do that
103:34 - new short little video on SAS where we
103:36 - talk about correlation and regression at
103:39 - times we may be faced with examining the
103:41 - relationship between two quantitative or
103:43 - numeric variables the relationship
103:46 - between them not the variables
103:47 - themselves but their relationship
103:49 - correlation can be used to determine if
103:51 - such a relationship exists and linear
103:54 - regression can be used to say the nature
103:56 - of that relationship we're gonna use SAS
103:59 - to do just that so let's go ahead and
104:01 - begin by importing the usual stat grades
104:04 - data set nothing special file name data
104:08 - step don't need to change state at all
104:11 - of course we should probably determine
104:14 - if we import it correctly
104:20 - and do a proc print
104:32 - let's run it and make sure everything
104:34 - looks good no errors at the top and it's
104:39 - gonna pop up with the HTML page
104:41 - everything looks fine notice we didn't
104:44 - change the other we didn't change the
104:47 - lasso to other we're not studying the
104:49 - colleges so we don't need to do that if
104:51 - we were studying the colleges we may
104:54 - need to do that in the future but we're
104:56 - not so we don't as always let's go ahead
105:00 - and plot our data
105:04 - I'm going to do a really massive block
105:07 - of code here just to show you some of
105:09 - the strengths of sass and its graphing
105:12 - it's kind of odd up until recently
105:14 - saying sass is good at graphing would
105:17 - get you laughed at but I'll go ahead and
105:20 - highlight all this and run it let's look
105:23 - at the graphic we got x-axis this will
105:26 - be the independent variable here is the
105:28 - initial grade point average y-axis is
105:31 - the dependent variable course grade
105:34 - earned we've got this broken up into red
105:37 - female figures for the females and blue
105:40 - male figures for the males if we look
105:42 - there looks to be a positive correlation
105:44 - between the two I'm not sure that it is
105:46 - statistically significant but it looks
105:48 - like there is notice that both the
105:50 - initial grade point average and the
105:52 - course grade earned start at zero and it
105:55 - starts exactly at zero so how did I get
105:58 - this happen let's go through this code a
106:00 - little bit line by line these two lines
106:04 - look familiar from 1b you can find two
106:08 - symbols symbol one we're called we're
106:10 - gonna make red make it a little bit you
106:12 - a bigger than usual 75% bigger than
106:14 - usual
106:14 - now we're gonna give it the value star
106:16 - which actually is the female figure and
106:19 - we're going to find simple 2 is blue
106:21 - make it also 75% bigger and that'll be
106:25 - the value is equal to the greater than
106:26 - sign which is the male figure symbol 1
106:30 - symbol 2 so when we do the plotting and
106:32 - down here we set it equal to gender so
106:35 - it's going to split up into the two
106:36 - genders symbol 1 will correspond to the
106:39 - first gender symbol 2 will correspond to
106:41 - the second gender y is female the first
106:44 - male the second the alphabet
106:48 - these two lions are going to be new they
106:51 - define two different axes axis one we're
106:54 - going to define as being ranging from
106:56 - zero to ten to 100 and marks every ten
107:00 - and we're going to actually start it at
107:02 - zero we're not going to have any padding
107:04 - on the top of the bottom axis two is
107:07 - going to range from zero to four I'm
107:09 - gonna have Mark's major marks every one
107:11 - and again it's going to go directly to
107:12 - the edges offset is zero we're gonna
107:16 - utilize those two axes in the plot
107:18 - statement the vertical axis is X is 1
107:24 - the horizontal axis that's H axis is
107:27 - access to
107:29 - the next thing that you'll notice it's
107:31 - the legend command here we're just
107:34 - saying where we're going to put the
107:36 - legend we're at the position we're gonna
107:37 - place it'll be the top center and on the
107:39 - outside of the plot and we're going to
107:43 - use that in the plot statement down here
107:47 - we're going to define where the legend
107:49 - is now the proxy plot also also came
107:54 - from sass 1b and this part came from
108:01 - sass 1b
108:03 - what the no frame does in the plot
108:05 - statement is gets rid of the box around
108:07 - the plotting region now if you notice I
108:12 - actually have initial grade point
108:14 - average stated down here and course
108:16 - grade earned stated up there and student
108:19 - gender stated up there if we didn't this
108:22 - would just be little cheat loopy delay
108:24 - and little grade and little gender to
108:28 - make it a bit more reader friendly we're
108:32 - going to say okay that GPA is actually
108:34 - going to be replaced by initial grade
108:35 - point average grade is going to be
108:38 - replaced by course grade earned and
108:40 - gender is going to be replaced by
108:42 - student gender so that's what all those
108:44 - parts mean when you put them together
108:47 - produces this really interesting graphic
108:53 - I think it's worth the extra steps
108:58 - okay now we've looked at it we do think
109:01 - there may be a correlation if there is a
109:04 - correlation it's positive as the G
109:06 - initial GPA increases the course grade
109:10 - earned also increases let's go ahead and
109:13 - test that we're gonna use the proc Corps
109:16 - which we saw back in one a proc Corps
109:20 - specify the data I'm gonna specify there
109:23 - are two variables that we want to find
109:25 - the correlation between and Fisher is
109:28 - going to allow us to get some more
109:29 - statistics off of it
109:31 - highlight run here's the one-page output
109:36 - two variables grade and GPA we have some
109:40 - summary statistics for both of those two
109:42 - variables we have the correlation
109:45 - coefficient based on Fisher for the two
109:48 - variables grade and GPA have a
109:52 - correlation of 0.33 5 5 8 the p-value
109:57 - for the tests that that correlation is
110:00 - actually zero is point zero zero zero
110:04 - six since that is less than alpha we
110:07 - failed we reject the null hypothesis
110:09 - conclude that there is a relationship
110:12 - between these two variables
110:14 - we have a 95% confidence interval from
110:17 - point 1 4 7 to 0.49
110:20 - 8 where 95% confident that the true
110:22 - relationship between those two is
110:25 - between those two values again since the
110:28 - p-value for the test of H not Rho equals
110:31 - zero is less than alpha we know that it
110:33 - is not zero back in one a we talked
110:39 - about the correlation and looked only at
110:41 - the value of the correlation we didn't
110:44 - talk about that test statistic or the
110:47 - confidence it rules because it didn't
110:49 - make sense we didn't understand those
110:50 - terms back then now we do so it's kind
110:53 - of nice to go back over some things that
110:55 - we've done in the past and look at it
110:57 - with new eyes because we've learned
110:59 - stuff since then so we've got something
111:03 - quarter we got a quart a significant
111:05 - correlation between the two but we're
111:07 - not exactly sure I mean that's that's
111:11 - good information but we'd like to go to
111:13 - the next step we'd like to model that
111:15 - dependent variable the great earned in
111:18 - the class using the independent variable
111:20 - the initial GPA to do that we'll use
111:24 - linear regression we've seen this before
111:27 - proc GLM state the data the model grade
111:32 - is the dependent variable the Y variable
111:35 - GPA is the independent variable and we
111:40 - could just run it see L parm gives us
111:42 - confidence intervals for the parameters
111:46 - where have we seen proc GLM before we've
111:50 - seen it when we were dealing with
111:51 - analysis of variance the last in the
111:54 - last video the difference between this
111:57 - use of GLM proc GLM and that use of Park
112:00 - GLM is this use approach GM is missing a
112:03 - line there is no class line here or
112:07 - class statement because neither great
112:10 - nor GPA are categorical variables so
112:15 - let's run this the output should be
112:17 - pretty familiar to us since we've
112:19 - already seen proc GLM's
112:23 - page 1 number of observations number of
112:27 - observations used it's been an entire
112:30 - page on that page 2 is the big one
112:36 - here's the ANOVA table
112:40 - P values point zero zero zero six since
112:43 - P is less than alpha we know that this
112:45 - model does tell us something about the
112:47 - relationship between the dependent
112:51 - variable and the independent variable
112:53 - if this p value were greater than alpha
112:55 - we'd say that this model was not useful
113:01 - next table gives us the r-squared
113:04 - negotiate coefficient of variation and a
113:06 - couple other things that are useful for
113:08 - a different snack course we've got the
113:13 - two types of we got two types of sums of
113:16 - squares if we had more than one
113:18 - independent variable this might be
113:20 - useful we don't notice that these two
113:23 - tables will give us exactly the same
113:25 - information as the first row of the top
113:28 - table only because we have one
113:30 - independent variable one dependent
113:32 - variable this table is the new table
113:36 - this gives us parameter estimates the
113:39 - estimates are here this is b0
113:43 - it's the estimate for beta naught and
113:45 - this is b1 the estimate for beta 1
113:50 - there's the test statistics the p-values
113:54 - both are less than alpha therefore
113:56 - neither of these are 0 and we got
114:00 - confidence interval if we didn't have
114:03 - the CL parm we would not have these
114:05 - confidence limits
114:08 - we also have the graphic nice little
114:11 - basic graphic the line it's going to be
114:14 - the line of best fit the equation for
114:17 - this line of best fit is forty six point
114:19 - four one five plus eight point four two
114:23 - zero two times X is equal to Y B not
114:28 - plus b1 x equals y the shaded area is
114:33 - the confidence interval or the
114:34 - confidence band for the line the best
114:38 - fit for TS stat 40:43 discusses that and
114:43 - the dashed line gives us prediction
114:46 - limits which are also discussed in stat
114:48 - 40 43
114:52 - so based on that those two tests we know
114:55 - that there is a linear there is a
114:58 - relationship between these two variables
115:00 - in fact we were able to determine what
115:03 - that relationship was
115:09 - this these two numbers give us the line
115:12 - of best fit which means for every one
115:14 - increase in GPA the expected value of
115:17 - the grade in the class goes up by eight
115:19 - point four two points on average
115:28 - now if we look back at our plot
115:32 - see if I can pull up the plot
115:35 - if we look back at this there seems to
115:37 - be some difference between females and
115:40 - males in terms of course grade earned it
115:43 - seems as though females did better than
115:45 - males so let's add gender as one of our
115:49 - independent variables
115:54 - that's called multiple linear regression
115:56 - because we have more than one
115:59 - independent variable and since we are
116:05 - doing this by gender we need to sort it
116:08 - first proc GLM by gender means that
116:13 - we're going to first fit the model with
116:14 - females then fit the model with males
116:16 - and then we'll be able to compare the
116:18 - two everything else is exactly the same
116:21 - as the simple linear regression above go
116:24 - ahead and run that scroll to the top
116:30 - okay GLM for procedure for females 45
116:34 - females red 45 were used p-value for the
116:39 - model of point zero zero seven one model
116:42 - is useful
116:45 - scroll down to the parameter estimates
116:49 - 53.1 nine is the estimate for beta not
116:52 - eight point six to six is the estimate
116:55 - for beta one on average for every one
116:59 - increase in GPA for females the grade
117:03 - goes up by eight point six two both of
117:06 - these are statistically significant that
117:08 - is that they are different from zero for
117:12 - the GPA that test actually has some
117:15 - meaning for the intercept usually it's
117:18 - not from a science standpoint it's not
117:21 - interesting if the intercept is
117:23 - different from zero but almost always
117:25 - it's interesting if the slope or the
117:27 - effect is different from zero so that
117:31 - was it for females let's scroll down see
117:33 - what happens with males 5555 p-value is
117:36 - 0.07 6-3 which means this model doesn't
117:40 - really do much for the males
117:44 - we do still have the estimate of our
117:47 - estimate of beta naught and beta 1 on
117:50 - average for this sample as you increase
117:53 - the GPA by 1 the grade goes up by four
117:55 - point six seven but if we look at the
117:59 - p-value that p-value for the effect is
118:01 - greater than alpha which means that it
118:04 - is not significantly different from zero
118:08 - meaning that we cannot conclude GPA has
118:13 - an effect on grade four males
118:16 - scrolling up we do see that it has an
118:19 - effect on grade four females it just
118:23 - does not have an effect on grade four
118:25 - males in fact we're 95% confident that
118:28 - the effect is similar between a negative
118:30 - one-half and a positive nine point nine
118:34 - in other words as the great as the GPA
118:37 - goes up by one for males it could
118:41 - actually go the grade could actually go
118:43 - down by 0.5 points or it could go up by
118:46 - about 10 points rather interesting
118:50 - rather contrary to what you may think -
118:53 - it seems as though the GPA has sheep a
118:56 - goes up the grade should go up now
118:59 - notice that what I haven't said here I
119:02 - have not said that increasing GPA causes
119:05 - the grade to go go up I'm just stating
119:08 - it there is a very strong relationship
119:10 - between the two it is quite likely that
119:13 - there is a third variable what's called
119:16 - a confounding variable that causes both
119:19 - GPA to go up and grade to go up now if
119:22 - you sit and think about it for a moment
119:23 - you'll think hmm that makes sense maybe
119:27 - work ethic would cause the GPA to go
119:30 - higher and the grade in snack class to
119:32 - go higher could be natural gifts that
119:36 - would cause both to go up not sure
119:39 - that's for different analysis for this
119:42 - analysis we just looked at GPA and grade
119:45 - and we did all this using sass
119:50 - notice the important processes procore
119:56 - gives us the correlations at times we
119:59 - may be faced with examining the
120:01 - relationship between two categorical
120:02 - variables the relationship not the
120:05 - variables themselves in such case we
120:07 - want to do a chi-square test of
120:08 - Independence
120:09 - other times we're looking at one
120:11 - categorical variable with more than two
120:13 - possible outcomes and we want to
120:15 - hypothesize something about the
120:16 - relationship of those outcomes in those
120:19 - cases we've used the chi-squared
120:20 - goodness fit test so we're gonna start
120:23 - with the chi-square goodness-of-fit test
120:24 - then we'll move on to the chi-squared
120:25 - test of independence well technically
120:27 - first thing we're gonna do is start up
120:29 - SAS and load in our data it's gonna be
120:32 - the usual stat grades data we are going
120:35 - to need to use the dichotomous variable
120:37 - so we're gonna use got pass can be
120:39 - defined as whether or not the students
120:40 - grade was greater than 70 also we're
120:43 - gonna be dealing with the college
120:44 - variable so we need to recode that
120:46 - student who was glass--oh into other
120:50 - that's proc print it just make sure we
120:52 - did it correctly it looks like
120:54 - everything's working got past is their
120:56 - college we're all good to go
121:01 - and so the next next thing to do as
121:04 - always is to learn about your data to
121:07 - see your data to plot your data so we're
121:11 - gonna look at gender so that next
121:13 - question here is gender gender across
121:15 - the colleges this would be an
121:18 - interesting question
121:20 - some beta somebody may hypothesize that
121:22 - certain genders prefer different
121:24 - colleges over others so to do this we'll
121:27 - do a proc G chart it's gonna be a
121:29 - horizontal bar plot of gender we're
121:31 - gonna group it by college and we're
121:34 - gonna put spaces between the college
121:36 - groups of size five and those here's
121:41 - what we get it looks like overall
121:44 - there's not much difference between
121:46 - males and females
121:47 - in each of the colleges there could be
121:50 - but it doesn't look like there is much
121:52 - of a significant difference looks like
121:54 - maybe males over females in college of
121:58 - business and maybe females or males and
122:01 - our Kasner but I'm not exactly sure
122:04 - those differences are statistically
122:06 - significant
122:07 - to test if the distribution of genders
122:12 - across the different colleges is equal
122:15 - we'd use a chi-squared test of
122:18 - Independence which will be part three
122:20 - but on the way there we can go ahead and
122:23 - look at distribution of the colleges
122:26 - perhaps we want to look at the
122:27 - distribution of the genders hypothesized
122:30 - about those so let's look at the
122:32 - distribution of the colleges now since
122:37 - we're looking at the distribution of the
122:39 - college is we're not grouping by
122:40 - anything at this point
122:42 - that's that'll be the code looks like
122:48 - Arts and Sciences has a lot of students
122:50 - which doesn't really surprise us because
122:52 - in most colleges most University is the
122:55 - College of Arts and Sciences is the most
122:57 - populous but we could test the null
123:01 - hypothesis that the proportion of
123:03 - students in business is equal to the
123:05 - proportion of students in Arts and
123:06 - Sciences is equal to the proportion of
123:08 - students in Kastner is able as a
123:10 - proportion of students in education is
123:11 - able to proportion of students and
123:13 - others that is a student is equally
123:16 - likely to choose any of those five
123:18 - colleges or groupings of colleges
123:22 - since we're testing if the student is
123:27 - equally likely on this one categorical
123:31 - variable we're gonna do a chi-square
123:33 - goodness-of-fit test as a proc freq
123:37 - because we're dealing with the
123:38 - categorical variable tables college saw
123:42 - this back in 1a
123:43 - the new thing is /ky C stands for
123:48 - chi-squared that tells SAS that you want
123:50 - to you do a chi-square goodness-of-fit
123:52 - test it knows it's a chi-squared test
123:56 - because you told a chi-square it knows
123:58 - it's a goodness of fit test because it
124:00 - is a single variable since we specify
124:05 - nothing beyond the keisker then it's
124:08 - going to by default test equal
124:10 - probabilities we'll run this we get this
124:15 - output first table gives us the raw
124:19 - frequencies for sense the second gives
124:22 - us the result with the hypothesis test
124:25 - this is a chi-square tests for equal
124:27 - proportions p-value is less than alpha
124:30 - therefore we reject the null hypothesis
124:33 - of equal proportions
124:36 - test statistics 86 degrees freedom is
124:39 - for because there were five groups this
124:43 - graph shows the deviations from equal
124:47 - probabilities arson science is very very
124:51 - large deviation positive that is they
124:54 - have many many more students than they
124:57 - would if the null hypothesis were true
124:59 - and the other four colleges have fewer
125:02 - if the null hypothesis were true but
125:06 - because P is less than alpha we reject
125:08 - the null hypothesis hypothesis and
125:11 - conclude that the colleges do not have
125:14 - students in equal proportions
125:19 - it doesn't surprise us ours and sciences
125:22 - tends to have six times the students of
125:25 - any other college
125:29 - in most universities so to test that
125:33 - let's hypothesize that arts and sciences
125:36 - does have six times more students than
125:38 - any other college still proc freq still
125:42 - tables of college still keiskei but the
125:46 - new part we're adding in is this the
125:48 - testing proportions is 0.1 or 10% 0.6
125:53 - point one point one point one these have
125:55 - to add up to 1 the order is based on the
126:01 - table
126:04 - business first arts and science the
126:06 - second Kasner followed by ad followed by
126:08 - other so where I pas the sizing business
126:11 - is 10% Arts and Sciences is 60 Kassner
126:15 - 60 ad is 60 others I'm sorry 10% 10% and
126:21 - others 10% and we would make this null
126:25 - hypothesis just by our experience that
126:29 - Arts and Sciences tends to have six
126:30 - times the students as any other college
126:35 - running it
126:42 - we running it if I push the right button
126:50 - there you go
126:54 - frequency distribution chi-squared test
126:57 - test for the specified proportions the
127:02 - test percent is given up here 10% 60% 10
127:05 - 10 10 the p-value is greater than alpha
127:07 - therefore we fail to reject the null
127:10 - hypothesis this distribution of percents
127:14 - is reasonable given our data notice I
127:19 - did not say this is the correct
127:22 - proportion distribution only that this
127:25 - distribution is reasonable given our
127:26 - data and while it may look like business
127:31 - has a very large deviation compared to
127:35 - what we had under Arts and Sciences Arts
127:39 - and Sciences was off by 2 on this
127:41 - relative deviation on these businesses
127:44 - only off by 0.3 it says off by it even
127:48 - less than 1/6 this model is a much
127:51 - better fit these proportions these
127:54 - hypothesized proportions fit the data
127:56 - much better than did the equal
127:58 - proportions again I have to emphasize we
128:03 - are not saying that these proportions
128:04 - are the correct proportions we're saying
128:07 - that they're reasonable given our data
128:13 - statistics is usually about what is
128:16 - likely not what is possible
128:23 - think about that for a moment
128:26 - let's move on to tests of Independence
128:30 - test of Independence happen between two
128:32 - variables let's go ahead and look at
128:35 - gender versus college create a nice
128:37 - little cross tabulation it's gonna be a
128:42 - proc freq tables notice there's no slash
128:44 - or anything after it because we just
128:46 - want those cross tabulations
128:50 - here's cross-tabulation referred to 1a
128:54 - as how to read these numbers
128:59 - now to tests if those two categorical
129:04 - variables are independent what do you
129:06 - think we're going to do yes we're going
129:09 - to add on that slash and keisker
129:15 - this gave us a cross tabulation up here
129:17 - this gives us the test for independence
129:19 - notice the only difference is the slash
129:22 - and the
129:32 - here's the cross tabulation again here
129:35 - the here is the results for the test of
129:37 - Independence between the two variables
129:39 - the one I want you to pay attention to
129:42 - is this chi-squared test statistic the
129:46 - value is four point two six seven four
129:48 - in class we saw how to calculate that
129:51 - the p-value is 0.37 100 because p-value
129:57 - is greater than alpha we fail to reject
129:59 - the null hypothesis we cannot conclude
130:01 - that there is a relationship between
130:04 - these two categorical variables another
130:08 - way of saying that is we cannot conclude
130:10 - that different genders choose the
130:14 - different colleges at different rates
130:17 - that's proportion of males to females
130:19 - and Arts and Sciences is not
130:22 - significantly different than the
130:23 - proportion of males to females in
130:25 - business or in Kasner or an education or
130:29 - in the other group we don't have
130:31 - evidence that females choose one over
130:34 - the other or males avoid one over the
130:37 - other
130:40 - another way of thinking of this is if I
130:43 - asked you to predict somebody's college
130:46 - I'm just telling you this is a college
130:48 - student your prediction is most likely
130:50 - the College of Arts and Sciences 57
130:54 - percent of our sample chose Arts and
130:56 - Sciences and now I say okay given that
131:00 - the person is female what's the most
131:02 - likely given that the student is female
131:06 - well we just showed that given that
131:08 - additional information gives us no new
131:10 - information in terms of predicting
131:12 - college it's just as useful for
131:16 - predicting college as the number of toes
131:18 - on the left foot the two variables are
131:20 - independent
131:25 - okay what may be interesting or more
131:28 - interesting it's not gender versus
131:29 - college but remember this is classroom
131:32 - these are students in my class and we
131:36 - can also look at whether or not how
131:39 - students pass a different rate in
131:42 - different colleges so instead of gender
131:46 - by college I've got got passed by
131:47 - college
131:52 - here's the crosstabulation chi-squared
131:55 - tests couldn't have is 0.0 0.2 null
132:03 - hypothesis therefore these two
132:05 - categorical variables are not
132:07 - independent they are not independent
132:11 - which means that the pass rate differs
132:15 - across the colleges
132:18 - the pass rate differs across the
132:21 - colleges or technically at least one
132:24 - college has a pass rate that differs
132:26 - from the others that really doesn't
132:30 - surprise us if we look at the cross
132:33 - tabulation almost 77% of the business
132:36 - students failed to pass almost 70% of
132:41 - the Arts and Science students passed
132:42 - ninety one percent almost of Kassner
132:45 - students passed so just by looking at
132:48 - the cross tabulation it doesn't surprise
132:51 - us to think that we're going to conclude
132:53 - that there's a differential pass rate
132:56 - not at all
133:00 - kind of makes you think why do business
133:03 - students pass at a much lower rate than
133:06 - the other colleges hmm but that's a
133:12 - question for science not statistics for
133:16 - statistics we just said there's that
133:17 - differential pass rate science needs to
133:20 - come along and explain why and that's
133:23 - the end in this we loaded the data we
133:27 - looked at the data