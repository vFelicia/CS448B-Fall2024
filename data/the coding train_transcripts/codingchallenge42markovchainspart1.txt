00:00 - hello welcome to another coding
00:03 - challenge this coding challenge is part
00:05 - of the programming from A to Z course
00:07 - which is all about programming with text
00:10 - and so in this coding challenge I am
00:12 - going to implement from scratch a Markov
00:14 - generator so I need to talk about what
00:16 - it this thing called an Engram is I need
00:18 - to talk about what a Markov chain is and
00:20 - then how I use a Markov chain to
00:22 - generate text so we do all that and
00:24 - write the code from it in JavaScript
00:25 - from scratch in this video one thing I
00:28 - want to just plug our reference is this
00:29 - wonderful article online by Victor
00:32 - Powell Markov chains visually explained
00:35 - if you're looking for a supplemental
00:36 - resource to sort of think about Markov
00:38 - chains and how they work this is really
00:40 - terrific and I recommend you check it
00:42 - out so I'm going to come over to the
00:43 - white board first a Markov chain is a
00:47 - sequence of states so what could those
00:50 - states be actually in Victor powers
00:53 - article he references you could think of
00:56 - the states of a baby playing crying
01:00 - eating sleeping and you could imagine
01:03 - well what's the sort of typical sequence
01:05 - it does the baby first play then the
01:07 - baby eats then the baby sleeps and then
01:10 - the baby will cries and that's kind of
01:11 - like a typical sequence but sometimes it
01:13 - happens in other ways right we could
01:14 - kind of boil this all down and make the
01:17 - states you know we could think of sort
01:19 - of this very like in a sort of cold
01:21 - mathematical sense a B and the idea of a
01:27 - sequence means there's always a
01:28 - transition a moment where the state goes
01:31 - from one state to another so we could
01:33 - think about here that ah a could become
01:38 - B or maybe a could stay as a and B could
01:43 - become a or B could stay as B so if
01:50 - these are all the possible states and
01:53 - their transition to another state and we
01:56 - said that there is a 50% chance of this
02:00 - happening or a 50% chance of this
02:03 - happening or a 50% chance of this
02:06 - happening or a 50% chance of
02:08 - is happening we could then create a
02:10 - sequence that matches these
02:12 - probabilities I could say start with a I
02:15 - could flip a coin heads it's a I could
02:18 - flip a coin heads it's a I could flip
02:21 - the coin tails it's B I could flip a
02:23 - coin heads it's a I could flip a coin
02:26 - tails
02:27 - it's B right so this idea here is that I
02:30 - am generating that sequence of states
02:32 - based on existing States and probability
02:36 - of an outcome after that so this is used
02:40 - for a lot of different kinds of systems
02:42 - you could imagine looking at financial
02:45 - data as a sequence of state scientific
02:47 - data weather patterns predicting an
02:49 - earthquake based on some set of sensor
02:52 - readings in and how they sequence that's
02:54 - this sort of thing so Markov chains are
02:57 - used in a variety of fields to analyze a
02:59 - sequence of states and also generate or
03:02 - predict outcomes based on that sequence
03:05 - now what I want to use them for in this
03:08 - video is to think of text as a sequence
03:11 - of states so let's say I wrote the
03:14 - sentence this rainbow has a unicorn
03:23 - flying over it so on the one hand I
03:31 - could think of each character as a state
03:33 - so how many possible states are there
03:36 - well maybe there's 26 lowercase
03:38 - characters 26 uppercase characters
03:41 - different kinds of punctuation and I
03:43 - could say the state is T followed by H
03:47 - followed by I followed by s right
03:50 - followed by space followed by r fall by
03:52 - a fall by right so I could think of this
03:54 - as a sequence of states on the character
03:56 - level I could also think of this as a
03:58 - sequence of states on the word level
04:00 - well maybe there are however many tens
04:03 - of thousands or hundreds of thousands of
04:04 - words and in the English language each
04:07 - one of those could be a state the state
04:09 - is this followed by rainbow followed by
04:11 - has followed by a now in a small corpus
04:15 - in a small source text I won't
04:17 - see that many possibilities the word
04:19 - rainbow is the only word that ever
04:21 - follows this but if I were to evaluate a
04:24 - large body of text I would see this
04:28 - followed by rainbow followed by unicorn
04:31 - followed by this dot for JavaScript
04:35 - programming right and I might be able to
04:36 - say you know what comes after this a lot
04:38 - this rainbow and I could start to adjust
04:42 - these probabilities based on an existing
04:45 - source text and this is the idea if we
04:48 - can read in a text look at what kinds of
04:51 - characters come after a given character
04:53 - and how frequently I can start to
04:55 - generate a text based on those
04:56 - probabilities but there's one more
04:59 - element to this right now I'm talking
05:01 - about just each state being a single
05:04 - character or each state being a single
05:06 - word but there is a concept known as an
05:09 - Engram an Engram being a contiguous
05:16 - sequence of characters or words a
05:19 - continuous sequence of text and an
05:22 - Engram has something associated with it
05:25 - called an order we could say by Graham's
05:29 - being engrams of 2r trigrams being
05:32 - engrams of three and when I say that I
05:35 - mean let's look at all of the trigrams
05:38 - in this particular sentence this rainbow
05:41 - has a unicorn
05:42 - here's a trigram thi the next trigram is
05:46 - H is the next trigram is AI s space I'm
05:51 - doing an underscore for space the next
05:53 - trigram is s underscore R so what I
05:57 - could do is actually consider the states
06:00 - not to be single characters not to be
06:03 - single words but by Gramps our trigrams
06:07 - our engrams with an order of four or
06:08 - five or six in other words I could say
06:10 - if the state is th thi what are all the
06:15 - possible characters that could follow
06:17 - that so what I want to do is read in the
06:19 - text make a list of all of the engrams
06:22 - in that text let's just say an order of
06:24 - three to start with all of the trigrams
06:26 - in that text
06:27 - and then for each trigram make a list of
06:30 - all the possible outcomes then I have a
06:33 - statistical model of how the text is put
06:35 - together on a character level and I can
06:38 - use that statistical model to generate
06:39 - new text with those same probabilities
06:42 - and properties so this is what I'm to
06:44 - start to build right now and the I'm
06:47 - going to build it on the character level
06:49 - and maybe I'll do a second video where I
06:51 - adjust it to work on the word level
06:54 - okay so what's stepped on something so
06:57 - let's start programming this so I have a
07:00 - completely empty p5 sketch and I want to
07:04 - start with putting some text at the top
07:06 - where I will say this rainbow as a
07:10 - unicorn flying over it and I don't need
07:16 - draw and I don't need a canvas so the
07:19 - first thing I want to do is simply make
07:21 - a list of all of the trigrams so I'm
07:25 - going to include a variable called order
07:27 - and I'm gonna say order equals 3 and
07:29 - that's the thing we could adjust if
07:31 - later I want it to be by grams or in
07:33 - grams of order 5 that sort of thing and
07:35 - I'm going to just loop through the text
07:37 - so what I first want to do is just look
07:39 - at every single character one at a time
07:43 - text length I plus plus and then what I
07:48 - want to do is pull out the trigram so I
07:51 - can see plainly that the first trigram
07:53 - is thi and the way that I can pull out a
07:56 - piece of a string from another string is
07:58 - with the function substring so I'm going
08:00 - to say VAR gram equals text substring
08:05 - and I could say this right 0 comma 3
08:08 - would give me thi now you might be
08:10 - wondering the index values are th is 0 1
08:15 - 2 3
08:16 - why doesn't 0 comma 3 give me this an
08:19 - important thing to remember is substring
08:21 - the first index is included the last
08:24 - index is excluded so actually 0 comma 3
08:27 - gives me thi 3 characters from 0 1 & 2
08:31 - which is accurate 1 but I don't actually
08:33 - want to say 0 comma 3 what I want to say
08:36 - is I and I plus 3 because what I want as
08:40 - I'm loop a
08:41 - is thi then H is then is space then s
08:44 - space are that sort of thing and I can
08:47 - make a variable called engrams and I can
08:50 - make it an array and then I can say
08:52 - engrams dot push gram and at the end
08:56 - here I could say console dot log and
08:58 - grams so let's run this code and this is
09:01 - just a simple piece of code give me a
09:03 - list of every trigram in this particular
09:06 - piece of text and we can see there it is
09:09 - I can make this a little bit bigger for
09:10 - you in case you can't see that and you
09:12 - can see there all those engrams now
09:14 - there's a little bit of a problem notice
09:15 - at the end T period and just period so
09:18 - those aren't trigrams those are just two
09:20 - characters than one character that's
09:22 - because I let it loop all the way to the
09:23 - end and I actually want to say - order
09:26 - plus one I think or I could just say
09:29 - less than or equal to text dot length -
09:32 - order so that should give me our space I
09:35 - space I T and I T period so now we can
09:38 - see there's the list now here's the
09:40 - thing this is not a unique list of only
09:44 - of the trigrams this is just a list of
09:47 - every single trigram but ultimately what
09:50 - I'm going to want to do and I'm come
09:54 - back over here is what I want to build
09:56 - is a big table I want to build a table
09:59 - where I have you know trigram ABC points
10:03 - at all the possible things that could
10:06 - come after it and trigram f EG all of
10:12 - the trigrams that's not the alphabet efg
10:15 - ABC I forgot D if you cdef all the I'm
10:19 - not putting numbers here I kind of lost
10:22 - my train of thought there but I want to
10:24 - I want to build I want to build this
10:28 - table so what I need to do is pair a
10:33 - trigram and Engram with an array and
10:36 - guess what remember when I made some
10:38 - video about word counting we said hey
10:40 - let's pair a string with a count and I
10:42 - use the JavaScript object as a
10:43 - collection of name value pairs we can do
10:46 - exactly this year only the and the name
10:48 - the fields the properties of that
10:51 - javascript object
10:52 - are the engrams and instead of having a
10:54 - count with how many times they appear I
10:55 - want to have an array with all the
10:57 - possible outcomes after that so let me
10:59 - come back over here and start
11:01 - implementing that in the code okay so so
11:06 - first instead of having an array of
11:08 - engrams
11:09 - I want to have a object yes an object
11:16 - and when I find a gram I want to ask
11:19 - does whoops does that gram already exist
11:27 - right if that gram already exists well
11:30 - let's just do a count for right now I
11:32 - could say you know increase its count
11:39 - otherwise otherwise set its count equal
11:48 - to one right if it doesn't exist says
11:51 - its count equal to one if it already
11:53 - does you know I this is kind of silly of
11:55 - me but I feel like it's a little bit
11:56 - more readable if I write it this way
11:58 - right because if it doesn't exist said
12:01 - its count to one if it does exist
12:03 - increase its count so let's go back over
12:05 - here and see what do I get
12:07 - now unfortunately the text that I wrote
12:09 - everything only appears once so what I'm
12:12 - going to do is I'm going to artificially
12:14 - create some text where there's a bunch
12:16 - of things that appear multiple times so
12:20 - let's try it I don't give you guys is
12:21 - there some people watching a live chat
12:22 - can suggest things for me to write so
12:24 - all right the theremin is theirs okay
12:32 - yes it is this is a theremin that's like
12:39 - the weirdest sentence but now at the
12:42 - very least if I run this again you can
12:44 - see that certain certain um certain
12:47 - trigrams appear many times like space is
12:50 - appears three times space th appears
12:53 - four times this is an alphabetic order
12:56 - th e appears four times s comma space
12:58 - appears twice so we're seeing the
13:00 - frequency of these trigrams these
13:03 - collections of three care
13:04 - characters so all I've done so far is
13:08 - make a nice little table which counts
13:10 - how many times the engrams appear but I
13:12 - want boy I want more what I want to do
13:15 - is what I've got over here I want to
13:19 - have a list of things that come after
13:23 - and what do I need my after is what what
13:25 - whenever this trigram appears what's the
13:27 - character that appears after it so if I
13:29 - come back over here what I want to do is
13:31 - when I have found a new brand that I
13:34 - haven't seen before make an array the
13:37 - key the key for this I'm sorry here the
13:41 - key for this the value for this key in
13:45 - the object is an array and then of
13:47 - course what I want to do is put
13:48 - something in that array like the next
13:52 - character and what is the next character
13:54 - the next character is I plus three
13:57 - push.txt car at I plus three right
14:01 - because I'm looking at this sequence of
14:03 - three characters and the one that
14:05 - appears right after it is number that is
14:08 - three later and then of course if I have
14:11 - already found it I don't need to make a
14:13 - new array I just need to push that care
14:16 - you can see there's some redundancy here
14:17 - so let's clean up that redundancy I can
14:20 - actually just say if it's not there make
14:22 - an array and then always push that other
14:25 - character in it so let's see what
14:26 - happens now if we look at what I'm
14:29 - storing them data okay look at this now
14:31 - look at this if I go down to th e and
14:34 - look at that we can see look what are
14:37 - the possible things so after th e I
14:40 - could have a space I could have an R or
14:43 - I could have an AI and look at this R
14:46 - appears twice now in some cases when I'm
14:50 - programming I'll see that are appearing
14:51 - twice and think this is not so good
14:54 - there's some redundancy here I should
14:56 - just have R and a count of two we did
14:58 - this forward counting right we didn't
14:59 - want a list of all the words with the
15:01 - words in there multiple times we wanted
15:02 - a list of unique words and their count
15:04 - but there's something going on here
15:06 - which is that if this is my set of
15:11 - possibilities space R I
15:14 - our what if I said to you pick one
15:17 - random possibility pick space or or our
15:20 - or I or R well R is actually going to be
15:25 - picked 50% of the time I only 25% of
15:29 - time and space only 25% of the time the
15:31 - mere fact that we are duplicating the
15:34 - possibilities over and over again into
15:36 - the array the more times they appear the
15:39 - more likely they'll get picked when we
15:40 - generate text so this is actually a side
15:43 - effect that having this redundancy that
15:45 - we actually want so this is really
15:47 - useful you could kind of say like oh
15:48 - this is inefficient it's wasting memory
15:50 - and I could store a number and I could
15:52 - do some other kind of math and all of
15:53 - that is true and I encourage you to go
15:56 - forward and go forth and make a more
15:58 - compact version of this but the ease of
16:01 - doing it this way and come on these are
16:02 - individual characters think about how
16:04 - your computer stores images of millions
16:06 - of pixels and videos it's not that much
16:08 - of a memory overload there's a question
16:10 - of scalability and how much data you
16:11 - know eccentric setter but I think we
16:13 - don't need to worry about that right now
16:14 - this is going to work beautifully so
16:16 - let's look at this I'm going to come
16:18 - back over here right now and we are
16:20 - getting there we have now space RI r we
16:24 - have this list of trigrams and the
16:27 - letters that come after it so what I'm
16:29 - going to do now is I am going to build
16:32 - into this I'm going to I'm going to add
16:34 - some stuff to this example I'm going to
16:36 - create a button because I what I want to
16:40 - do is have a button equals create button
16:43 - and I'm using some code from the p5 Dom
16:45 - library which allows me to quickly mock
16:47 - up some interface elements and I'll call
16:49 - that generate and then I must say a
16:51 - button dot mousepressed
16:53 - and I'm going to say a Markov it so now
17:00 - I'm going to run the marker I'm going to
17:01 - I now you to write an algorithm to
17:03 - generate the text and then we will say
17:09 - create P the result so right now of
17:12 - course let's just make sure this works
17:13 - right now all I'm getting is the result
17:16 - but ultimately of course what I need to
17:18 - do is right here I'm going to write an
17:20 - algorithm that generates text based on
17:23 - the input so we have a question I mean
17:27 - I have a question you might have a
17:28 - question where how do we start right
17:30 - this is the text the theremin is there's
17:33 - okay yes it is um how do diss my grammar
17:38 - okay what's up I'm getting worried but
17:41 - um what do we start with now this is a
17:46 - question that I will think about and
17:49 - talk about and maybe about and think
17:51 - later either later in this video or in
17:54 - the next video because there's lots of
17:55 - different kinds of ways you might use a
17:58 - Markov chain or using a Markov chain to
18:00 - generate short phrases or a long bodies
18:02 - of text or how are you reading in the
18:04 - text are you reading in a bunch of short
18:05 - phrases are you on the character level
18:06 - the word level but for right now the
18:08 - simplest thing I'm going to do is start
18:10 - just with the whatever the first three
18:13 - letters whatever the first Grand Graham
18:16 - is of this text so I'm going to go down
18:19 - here and say var current Graham equals
18:23 - text substring 0 comma order right I
18:28 - wanted from 0 to 3 that's what I want to
18:30 - start with now what I want to look is
18:34 - say what are the possibilities the
18:36 - possibilities are and
18:42 - right I want to look up what are the
18:45 - possible next characters with based on
18:48 - what the current Graham is and that's
18:50 - what I just built this whole object to
18:51 - have it has an array so now I can say
18:54 - next equals I want to pick a random
18:56 - element from that array and guess what
18:59 - p5 since I'm using the p5 library it has
19:01 - a function called random if I passed it
19:03 - an array it gives me a random element
19:07 - from that array so it's going to pick
19:09 - that random function if it's this array
19:11 - it's going to pick space our IRR
19:13 - randomly one of those ok so once I have
19:17 - that I can say the result is I can say
19:21 - the result is the current gram plus next
19:25 - and I can create P result so let's just
19:29 - look at this and do some generation
19:32 - there there there
19:33 - there the space there their commune I
19:35 - they thi so you can see I got ARF about
19:39 - 50% of the time I got space 25% of the
19:42 - time and I 25% of time not exactly of
19:45 - course because this is probability based
19:46 - and I could run this again we could see
19:48 - the you know R is going to come up more
19:50 - often but I'm getting all these
19:52 - possibilities and I'm standing in front
19:53 - of this so I'm going to move this over a
19:56 - little bit okay so now I only did it
20:00 - once though the point is once I've done
20:01 - this now I want to look at the grand h
20:04 - ER and see what are the possibilities
20:06 - next and generate a new character that I
20:07 - want to look at ER and whenever I pick
20:09 - there and then what are the
20:10 - possibilities after that so I want to do
20:12 - this I want to iterate and continue to
20:13 - do this over and over again so when do I
20:16 - stop doing this that's another question
20:18 - that has knows a bunch of different
20:20 - possible answers but I'm going to say
20:22 - right now basically what I want to do is
20:25 - let's just say I'm going to do this 10
20:26 - times I'm going to write a little loop
20:29 - to do this 10 times and what I'm going
20:32 - to do a result needs to be a kind of a
20:36 - variable that's declare right the things
20:38 - that I need to do before the loop are
20:40 - pick the starting frame starting Graham
20:42 - and Graham and start that result which
20:44 - is that starting and Graham then I will
20:47 - only have to add the next character so
20:50 - what I'm doing is saying 10 times
20:53 - give me the possibilities then pick a
20:56 - random one and then add it to the result
20:58 - but then I need to go and look at the
21:00 - next current Graham and what is the next
21:03 - try Graham it's the last three
21:05 - characters of whatever I've generated so
21:06 - far so I can say current Graham equals
21:10 - text dot substring text dot length minus
21:14 - 3 text blank oh not text the current
21:19 - result right what I've generated so far
21:22 - right yes excuse me sorry text is the
21:26 - original string which has plays no role
21:29 - anymore the original string was simply
21:31 - used to build the table of engrams and
21:34 - they're possible next States so now and
21:37 - I could um just to make this a little
21:41 - bit shorter just so you can kind of see
21:42 - it a little more easily I'm
21:45 - is going to write it like this so what
21:48 - I'm getting right is that I want the
21:49 - next gram to be the last three
21:51 - characters of the text so now if we do
21:54 - this whoops I have an error in line 30
21:58 - plus result up result plus equals next
22:05 - there I don't know what was going on
22:07 - there but there I'm in the theremin
22:08 - there's okay there there are many uh so
22:10 - we can see here instantly how I've got
22:13 - these sequences of ten characters that
22:15 - have the quality of the source text but
22:18 - they're randomly new let's grab some
22:21 - different text and see what happens so
22:23 - I've got already here prilep remade like
22:26 - text about unicorns from Wikipedia
22:29 - because I don't have any other ideas and
22:31 - I'm going to comment this out and just
22:34 - say VAR txt equals and paste this text
22:38 - in and keep the order at three let's
22:41 - allow the N great let's allow it to
22:44 - generate 50 characters in length and
22:47 - let's refresh and hit generate we can
22:52 - see what do we get the erroneously beast
22:54 - with the unicorn is of nature the yonce
22:57 - of narwhal with a symbol of the unicorn
22:59 - wha and you can see it just sort of cuts
23:01 - off I can I can um let me actually let
23:03 - it go for longer if it can as well as
23:07 - let's make the order 600 K so we got an
23:15 - error so this this is not so this is
23:18 - quite likely happened so first of all
23:20 - what there's all these crazy numbers in
23:22 - there so I can tell you what the error
23:23 - is which is that if it can never if if
23:28 - this possibility is to somehow undefined
23:32 - then this random function won't know how
23:35 - to pick something from an array there's
23:36 - no array and the rhythm function
23:38 - actually is meant to give you a random
23:39 - number so that's why I suddenly got a
23:40 - number random number in there so one
23:42 - thing I can do to just add a little
23:43 - protection here is say if if not
23:48 - possibilities meaning if it's not
23:50 - defined then break this is a way of
23:54 - having the Markov chain end if it had
23:56 - no more possibilities so let's do this
23:59 - and I think the issue that I've got here
24:02 - is oh you know what I did actually I
24:04 - hard-coded in the number three so this
24:08 - should really the order right because
24:11 - I'm change the order meaning the length
24:14 - of the Engram so I can't just have you
24:16 - know use the number three anymore down
24:19 - there that's a big problem okay so now
24:21 - let me run this generate whoops
24:24 - oops I also put the hard-coded number
24:27 - three in up here oh this is awful you
24:29 - guys in the chat are already telling you
24:30 - this so now I can hit refresh it's not
24:35 - over yet Oh else oh look I have it over
24:40 - here I think this is gonna work now yeah
24:45 - there we go so you can see here I'm
24:48 - getting with with an order of six I'm
24:51 - going to get much really get less
24:52 - nonsense right because it needs to have
24:55 - sequences of six characters that
24:57 - actually appear in the original source
24:59 - text and so but if I were to give it
25:01 - something like an order of two we can
25:04 - see we're gonna get a lot more nonsense
25:06 - like the in its growl the symbol we can
25:10 - soda parable
25:11 - olara kumali alley are empty by the
25:14 - unique in yahwah okay so this is my
25:17 - favorite word right here so tension
25:19 - choo-choo teamily anyone that's I got it
25:22 - that's the name for this channel so ten
25:24 - ten to nine milli coding rebou okay so
25:30 - laughs um so you can see that there's a
25:33 - lot to play with here so on the one hand
25:35 - this video is over and in fact it is
25:38 - over
25:39 - I'm good in the next video look at a few
25:42 - different scenarios of using a Markov
25:44 - chain to generate long text versus short
25:48 - text and in the next video what I'm
25:50 - going to do is um try to use a Markov
25:53 - chain to generate a new name for this
25:59 - YouTube channel so hopefully I'm going
26:00 - to publish the code with this obviously
26:02 - it'll be linked in the video's
26:04 - description and I look forward to seeing
26:07 - what kind of
26:08 - source text you might use that's
26:10 - different than the source text I'm using
26:11 - and what kind of how you might present
26:15 - the outcome is are you kind of
26:17 - appropriating another design to make it
26:19 - appear as if it's generating news
26:21 - headlines are you recreating a Twitter
26:23 - bot that generates text using a Markov
26:25 - chain there's a lot of possibilities
26:26 - there and I hope you will share with me
26:28 - your results thanks for watching