00:00 - I think I hear us right now by the way
00:04 - all right I better walk over here uh
00:07 - hello everyone happy Friday
00:09 - good morning good evening good night I
00:11 - know it's all different times of the
00:13 - work times a day all over
00:14 - look there are Legos here today this is
00:17 - super exciting I attempted to just go
00:18 - and play with these Legos right now but
00:20 - I have to pay attention to you the
00:21 - viewer and talk about what's gonna
00:23 - happen on today's coding Train episode
00:27 - for funked required what's the word I'm
00:29 - looking for train whistles I think all
00:32 - right so I'm very excited today is a
00:34 - special livestream for today this Friday
00:36 - with a guest kind of rapidly put
00:39 - together at the last minute I will be
00:41 - back next week with continuing my word
00:43 - to vet to toriel's and other things but
00:45 - today we're going to talk about kids and
00:47 - AI and education if you are a teacher or
00:50 - if you or someone who has kids or work
00:52 - with kids are a part of a family which a
00:54 - lot of you are probably then this might
00:56 - be of interest to you so today's guest
00:58 - and I'm gonna in a minute check the chat
01:01 - picture this is actually working so I
01:03 - apologize if you can't hear me or
01:04 - something is going wrong I actually
01:05 - don't know about it but I will look in a
01:07 - minute
01:08 - but everything looks okay okay so
01:11 - today's guest is Stefania Duga she is a
01:14 - recent alum of the MIT Media Lab she is
01:17 - from Transylvania and she has created a
01:21 - project called cognate switch is a open
01:23 - source platform for an AI education so I
01:26 - could say so much more because there's
01:28 - so much more to say about Stefan and her
01:31 - background but rather she present that
01:32 - to you and the you can always of course
01:36 - check this video's description which
01:38 - there's not a lot there right now but
01:39 - after this live stream ends we'll add
01:41 - more links and by ode but there is I
01:43 - think a link at least you should to find
01:45 - this website and a tweet about the
01:48 - cognates project from from MIT in the
01:51 - description right now that you can click
01:52 - on so what's happening this is like one
01:55 - of my regular live streams and we're
01:58 - just going to be here for an hour or so
02:01 - stephania will show a variety of
02:03 - different things we might have to take a
02:04 - break to figure out some technical thing
02:06 - it will be informal I will be monitoring
02:08 - the chat so if you have questions you
02:10 - can ask them in the chat
02:12 - and then sort of when we're done this
02:14 - will be an archive that will in theory
02:17 - live forever how long YouTube lives for
02:19 - on the internet that you can watch and
02:21 - there also might be so we might we may
02:23 - try to like pull out some of the
02:25 - tutorial portions of today in two
02:27 - separate videos that we can upload
02:29 - either on the coding train or in a
02:30 - different platform that stephania would
02:32 - choose okay so I think that's all I have
02:36 - to say did I forget anything so I'm just
02:38 - gonna bring stuff right here there she
02:39 - is I'm gonna go and wander the chat if
02:42 - there's a really important question you
02:43 - can ask it I'll interrupt otherwise I'll
02:45 - mostly like keep track of questions for
02:47 - the end okay Frankie I'm gonna talk wer
02:49 - decide over here come over here
02:52 - thank you so much for the kind
02:54 - introduction I'm actually amazed because
02:57 - then pronounce my name correctly she
02:58 - never happens
02:59 - I was defined yeah nice to meet you I am
03:03 - just graduated from MIT Media Lab and
03:06 - during two years there I've been working
03:09 - on this project called cockney maids
03:11 - which is like a playmate and a learning
03:13 - mate and the goal of this platform which
03:16 - is open-source by the way is to teach AI
03:19 - to kids and allow kids to customize
03:23 - train their own AI models and teach like
03:27 - program smart devices they have in home
03:29 - and learn more about this technology so
03:31 - the overall mission and goal of this
03:34 - project is really to democratize like
03:36 - who gets to create with AI and you're
03:38 - gonna ask me why are you doing this and
03:41 - it's kind of crazy to teach a high scum
03:44 - placated machine learning is complicated
03:46 - why should we teach it to kids and I'm
03:48 - going to say that it is necessary
03:50 - because for the first time we have a
03:52 - generation that is growing up with this
03:54 - technology just like I grew up with the
03:56 - Internet in my small town in
03:57 - Transylvania and we have more than 47
04:01 - million smart devices in homes right now
04:04 - that kids are talking to and when I
04:06 - started my my work at a media lab we did
04:09 - a lot of research to actually understand
04:11 - how do kids perceive these devices do
04:14 - they trust them do they want to learn
04:16 - from them do they want to program them
04:19 - and we published a lot of this research
04:21 - and then we figured out that actually a
04:23 - lot of the kids
04:25 - thought these devices like Alexa or I
04:29 - don't know go home are more intelligent
04:31 - than they are so we were like what if we
04:34 - give them tools to actually show them
04:37 - how they work and in that process they
04:40 - would learn how to demystify a little
04:43 - bit what artificial intelligence means
04:45 - and how smart are really this smart toys
04:48 - so we built this platform
04:50 - Cockney mates which is available online
04:51 - that's the link copy mates that I mean
04:54 - it's a research project some of the
04:57 - things I discovered while preparing the
04:59 - demo today don't work but some of things
05:01 - do work and it's open source so you can
05:03 - help me fix it it has it's building on
05:07 - scratch which was developed at MIT Media
05:10 - Lab as well and it's open source but we
05:13 - created an entire series of extensions
05:16 - specifically for AI education so when
05:19 - you load when you go to collimate the
05:23 - caca means that I mean you're gonna see
05:24 - this website let me make it a little bit
05:26 - bigger and then if you actually want to
05:29 - start programming straightaway and
05:31 - trying it you can click on this launch
05:33 - Cockney mates which will take you to the
05:35 - code lab and in the code lab on this
05:39 - plus button you can kind of see what are
05:41 - some of the extensions we created so
05:43 - anything from programming your Alexa if
05:46 - you have one at home to actually play
05:49 - with the camera your computer or tablet
05:52 - has to do color detection or just you
05:55 - know program a robot like Cosmo if you
05:57 - have one we wanted to provide extensions
06:01 - that are a lot of fun for kids and
06:03 - usually kids love Lego and we can do
06:05 - like like Lego we do as well but we also
06:08 - wanted to allow kids that don't have
06:10 - access to an Alexa or a Cosmo or a depo
06:15 - to be able to learn these skills as well
06:17 - so some of these extensions are just
06:19 - like web-based and others are also like
06:22 - for IOT and robotic platforms so before
06:26 - talking too much about this I can show
06:28 - you what are some of the things that we
06:30 - could do and on our website we have a
06:35 - collection of projects
06:37 - I'm gonna start with the first one which
06:39 - is like called make me happy and in this
06:42 - project if you click on on it you can
06:47 - download it download the starter project
06:49 - and then go to the code lab and upload
06:54 - it file upload and then let's see where
06:59 - did I put it
07:01 - and in here you will see what are like
07:05 - all the elements of this platform which
07:07 - as I mentioned it's building on scratch
07:09 - so on the left side you see what are all
07:13 - the blocks that we can use oh yeah I
07:15 - forgot to say that we the way we do
07:21 - coding and the way these platform works
07:23 - is by using this like blocks which is
07:27 - like visual programming language is
07:30 - called and it all builds on a block Li
07:33 - open source grammar from Google and it's
07:35 - very similar to Lego so just the way we
07:38 - plug and play with Lego we can plug and
07:40 - play with this blocks so the idea for
07:43 - the blocks is that you don't necessarily
07:45 - need to know how the syntax of
07:48 - programming language like JavaScript or
07:50 - Python but you can just read what's on
07:53 - the text of the block and start to
07:55 - create your program in here this is
07:57 - called like the stage in in the middle
08:01 - and then you can start to put them
08:04 - together and when they it's actually
08:06 - very satisfying when you put two blocks
08:09 - together you get a sound I don't know if
08:13 - you can hear it yeah you get that beep
08:15 - so on my left side I have all these
08:20 - different blocks let me see if I can
08:22 - zoom to show you yeah I cut I have like
08:27 - a library of different blocks that allow
08:29 - me to control my program in the middle
08:32 - I'm like the movie director I put these
08:34 - blocks together and I can start to
08:37 - create a story or a game or an animation
08:39 - and on the right side I have this output
08:45 - where right now you can see me and a
08:47 - character I am
08:49 - I don't know why that's the case but
08:50 - we'll figure it out I think we added too
08:52 - many extensions so right now what we're
08:56 - going to do is basically go through the
08:59 - steps of this project and I'm going to
09:01 - show it to you just the way I do it with
09:03 - kids so we have this character which is
09:06 - nari and nari is going to react to
09:12 - messages we're telling it so if we're
09:15 - telling nari like we're gonna start with
09:17 - something very very simple so then what
09:21 - should we tell that nari to make her
09:23 - happy like give me a phrase well I've
09:28 - determined would you like something to
09:53 - eat
09:53 - so right now we're going to go when we
09:59 - click the green stuff the green flag
10:01 - we're gonna have nari be thinking
10:04 - because she doesn't really know what
10:05 - we're gonna say yes first and then we
10:08 - have a block where she's asking us to
10:10 - tell her something and my answer I'm
10:13 - typing here is going to be would you
10:18 - like something to eat it's very
10:24 - thoughtful ya know it's very thoughtful
10:27 - we could do it like an entire chat pod
10:28 - and then let's see what happens when I
10:30 - click enter she should be happy and she
10:35 - is happy also if you want to have just
10:37 - the interaction we can make this bigger
10:39 - and and do it again but you know this
10:44 - kind of program only works if we say
10:46 - that specific phrase right would you
10:48 - like something to eat
10:50 - oh yes thank you
10:54 - eat I ate the letters because I would
10:59 - like some letter sweet yeah so this is
11:03 - like very limited in terms of like how
11:06 - much we can interact with nari what if
11:08 - we want to tell her all sorts of
11:10 - different things and make her react
11:12 - happy based on that so for that we
11:15 - actually made this other extension
11:17 - called feelings we used to call it
11:19 - sentiment and then we realize that kids
11:21 - don't know what sentiment is but they
11:24 - know what feelings are so that was
11:25 - interesting so we have this feeling
11:28 - extension and in here there is a block
11:31 - that it's saying what is the feeling of
11:34 - the text so in here I could just try it
11:39 - out let's see how this block works so if
11:41 - I would copy paste the example we just
11:44 - had in here and do we what do we think
11:47 - do we think this is going to be positive
11:49 - or negative or neutral what do people in
11:51 - the chat thing would you like something
11:57 - to eat is that positive or negative or
12:00 - neutral okay okay so usually like when I
12:12 - add a new block and I don't know what it
12:14 - does like I can just try it out so in
12:17 - this case I'm gonna try with a different
12:19 - phrase so I know for example that if I
12:21 - pour it awesome that should be positive
12:24 - so let me see if that works and yeah
12:26 - that says it's positive and if I say not
12:30 - great that's what happens then negative
12:35 - but if I say most people are positive
12:43 - okay
12:48 - okay next time okay so let's try it do
13:00 - you have a do you have a guess do you
13:02 - think it's positive negative or neutral
13:05 - neutral I'm gonna get a neutral true but
13:08 - let's see it's positive oh my god that
13:12 - means our library doesn't work very well
13:15 - no but it is like this is what we do
13:17 - with kids is like what do you think made
13:19 - it positive like what word and how can
13:22 - we probe that right so we see now that
13:25 - this block can actually pick up like
13:28 - sentiment of phrases we're typing or
13:30 - saying so in my program going back if I
13:34 - want nari to react to all sorts of
13:36 - things all sorts of messages I'm going
13:37 - to give her we can just go in here and
13:40 - instead of saying I want to see if the
13:44 - answer is a specific phrase I'm just
13:47 - going to always check what's the feeling
13:49 - of the different answers where we're
13:51 - getting and if that feeling is positive
13:57 - then I'm gonna make nari happy and if
13:59 - it's negative I'm gonna make her sad and
14:01 - you know this kind of conditional like
14:03 - all of these blocks we're using here
14:05 - it's already a bit complicated so
14:07 - sometimes when I start with kids
14:10 - I don't even start with this I just we
14:12 - have this block that is called a hat oh
14:14 - yeah I forgot to tell you that all of
14:16 - these blocks have names based on their
14:19 - functionality so this conditional I just
14:23 - use this is called pants because it has
14:25 - like you know looks like pants and then
14:28 - this other block here it's called a hat
14:30 - because that can trigger like an entire
14:32 - action so I could do this in many
14:34 - different ways like everything with code
14:36 - we can do it in many different ways so I
14:37 - could be when text is positive just make
14:40 - Mary happy and when text is negative
14:43 - make Neri sad or I could do it like with
14:46 - a conditional and the other cool thing
14:48 - with these blocks is that is very very
14:51 - fast to to remix so I can just duplicate
14:56 - that entire collection of blocks let me
14:59 - just make it a bit smaller
15:02 - so you can see so like this I can make
15:07 - nari react when it's positive oh I
15:10 - already have one else but I could also
15:12 - like right now we're only dealing with
15:14 - positive and negative we don't have
15:16 - anything with neutral so in that case we
15:20 - can say if the answer is neutral then
15:24 - there you should say something like oh
15:26 - I'm still thinking or we would make her
15:29 - still be thinking and I don't need an
15:32 - else here I can just do a simple if I'm
15:37 - improvising guys yeah I have a quick I
15:39 - have a question there's a lot of people
15:40 - are asking this in the chat so I thought
15:41 - it yeah we're clarifying yeah I'm seeing
15:43 - a lot of comments like oh this looks
15:45 - just like scratch or is this built off
15:46 - of scratch so can you can you explain
15:48 - and so can you explain the relationship
15:50 - between this and scratch and is this
15:53 - kind of like then if I was a scratch
15:55 - user I could bring this in as a library
15:57 - basically or how does that work
15:59 - yeah so scratch is waking right now on
16:04 - scratch 3.0 which is using nodejs and
16:09 - it's working on mobile any browser and
16:13 - the code is open source it's on github
16:15 - so we build on that code because a lot
16:19 - of the kids are very familiar with
16:20 - scratch blocks and they recognize it
16:23 - straightaway
16:23 - and they know how to play with it but
16:25 - then we build on top of it and created
16:27 - all of these different extensions
16:30 - unfortunately right now you cannot add
16:33 - this extensions on the scratch website
16:35 - you can only use them on the clock
16:36 - teammates website but hopefully in the
16:39 - future they will be added on the scratch
16:42 - like library of extensions as well if
16:46 - you are familiar with scratch and
16:48 - scratch extensions I actually published
16:49 - a few extensions on the previous version
16:52 - of scratch so if you go to scratch
16:54 - extort these are the old-school
16:57 - extensions and you can see in here some
17:00 - of the extensions we've done for a I
17:01 - like the clarify which does image
17:03 - recognition and then there was another
17:05 - one for a robot and micro bit and so on
17:08 - the tricky thing with this is that it
17:11 - requires flash so it only works on a
17:14 - desktop
17:15 - and with the new 3.0 scratch which I
17:17 - believe it's coming out in officially in
17:19 - January but it's in beta you can also
17:21 - try it online then you already have this
17:25 - new nodejs implementation and this new
17:28 - kind of library of blocks I don't need
17:31 - that was a simple enough answer but the
17:33 - short answer is we are building on top
17:36 - of scratch you can't import these
17:38 - extensions yet in scratch but you can
17:41 - use them in carbamates for now awesome
17:43 - thank you yeah
17:44 - so let's go back to our program and see
17:46 - if this works so let's start from the
17:50 - beginning click the green flag and we
17:54 - can say - nary anything so you if you
18:00 - want to give me a positive or negative
18:01 - or neutral all a boy and actually unmute
18:06 - my microphones they probably could hear
18:08 - me through your microphone but all the
18:09 - board is what I said okay
18:11 - so let's see how she reacts strike and I
18:23 - don't know what happened tell me
18:25 - something all aboard so she should be
18:38 - either happy or sad or neutral
18:45 - come on Mary work with us okay so let's
18:52 - try it here it's neutral oh I see
19:13 - oh yeah she does what we told her to do
19:16 - of course uh debugging by the way is the
19:19 - primary activity of f3 was on the coding
19:23 - tree yeah so we said if the feeling is
19:26 - neutral she's gonna be thinking and
19:28 - that's what she's doing
19:29 - so let's actually add something there so
19:31 - we know that this is neutral we could
19:35 - make her say something or we could make
19:38 - her play a sound let's make her play a
19:43 - pop if it's neutral so let's try again
19:47 - all aboard
19:52 - yep
19:54 - so that was neutral and now I want to
19:57 - try like something positive the coding
20:02 - train is fun let's see yeah and she's
20:13 - happy so with all of these things I just
20:17 - wanted to show like a very quick simple
20:19 - example but as you can see it's much
20:22 - more funny if we do it together so
20:23 - because I want you guys to give messages
20:27 - to nari what we're gonna do now and this
20:29 - is like where the majority of extensions
20:32 - and doing this inter platform like
20:36 - connecting everything makes a lot of
20:38 - sense and it allows us to play with many
20:40 - different parts of the web and the
20:42 - physical world so what we're gonna do
20:44 - now is we're gonna add another extension
20:46 - so instead of me giving Mary examples
20:50 - I'm gonna ask you guys to do that so for
20:52 - that we're gonna use on other extensions
20:54 - with wheatbelt which is the Twitter
20:56 - extension so instead of me typing here
20:59 - and doing typos I'm gonna let you do
21:02 - typos if you tweet to the coding train
21:08 - train we're going to analyze the
21:11 - feelings of your tweet and based on that
21:13 - McNary react so I'm just going to add it
21:18 - in here so instead of asking a question
21:22 - we're just going to
21:24 - [Music]
21:27 - put the tweets you guys are sending and
21:29 - actually because we want to see what the
21:32 - tweets are I'm also going to make her
21:35 - say the tweets so we see them on the
21:37 - school on the screen and let me find us
21:42 - a block alrighty so first she's gonna
21:54 - tell you to tell her something and then
21:56 - she's going to show what you guys are
21:57 - tweeting so I hope people are gonna
22:00 - start tweeting with the coding training
22:04 - yeah let's give it a try so to be clear
22:07 - they should tweet at the coding train or
22:10 - just a hashtag oh we could do both okay
22:13 - but for now I did it with the hat or
22:15 - with those like I'll do one first at
22:16 - least yeah I did one with at the coding
22:20 - train we can also do
22:22 - hashtag coffee mates afterwards or the
22:26 - coding drink okay I sent I sent one if
22:29 - people again like people won't yeah
22:31 - they'll be there about 30 seconds behind
22:33 - so stuff okay so that's right and I'm
22:38 - live-streaming come watch how is she
22:44 - reacting to that
22:49 - oh yeah it was neutral so she played a
22:51 - sound let me make her see that's so we
22:55 - should we can give her personality so if
22:57 - it's neutral she can say okay I like
23:02 - that
23:04 - and then if she's happy she can say
23:09 - that's awesome
23:13 - and if it's sad it's like oh no tell me
23:25 - something else all right
23:36 - so it's gonna be the same tweet I can
23:39 - also try to treat here hopefully someone
23:41 - else okay has tweeted okay I like that
23:47 - so this is the neutral one let me tweet
23:50 - from here oh there there are okay let's
23:58 - try it
24:02 - alright so let's see get the latest
24:07 - tweet from the coding training oh yeah
24:13 - I'm still getting I'm a live streaming
24:16 - maybe it's like a little bit of a lag is
24:20 - it getting the tweets that the from the
24:23 - coding train and not people at
24:24 - mentioning the coding train maybe yeah I
24:28 - think it should be people mentioning it
24:31 - but coding train because that's the
24:36 - that's the last tweet from the coding
24:38 - train which is I'm live-streaming okay
24:41 - we can test that very quickly at the
24:43 - coding train great go back here yeah I
24:56 - think it's only getting the ones from
24:58 - the coding training so let's do the
25:00 - hashtag that's my bad sorry guys if you
25:07 - can use the same tweet you had but use a
25:10 - hashtag instead of at so we're gonna try
25:14 - that instead and oh yeah this this works
25:18 - so actually if I just change the ad with
25:22 - a hashtag they should be seeing the
25:28 - tweets that you guys have sent so let's
25:30 - give it a try
25:33 - tell me something
25:35 - oh do you guys see what happened it was
25:39 - so fast that we couldn't see it so we
25:41 - need to add a wait time so we can
25:43 - actually read what you guys have tweeted
25:54 - [Music]
26:05 - laughs good it's hard I haven't done
26:07 - this in a while okay
26:15 - the coding train up oh wait we'll put
26:19 - more weight because one second is not
26:21 - enough to read it
26:22 - let's do two seconds it's good not to
26:25 - have it on for two yeah so far I'm
26:27 - watching everything is a-ok pretty nice
26:32 - audience in general tell me something
26:36 - TGIF think oh she likes that she's happy
26:40 - okay we are we getting a new one
26:44 - let's see it's the same one okay I'll
26:51 - try one last one let's try with a
26:53 - negative one just to see if it works so
27:01 - tasteful toasty tweeted I have very
27:03 - mixed feelings so hopefully that would
27:05 - be neutral oh yeah let's see if we get
27:07 - it that would actually be a very
27:08 - interesting example choo choo choo cocky
27:15 - meets rocks like that before are two
27:18 - nice examples thank you for playing
27:22 - along so this is kind of like how it
27:24 - works like you saw we started like with
27:27 - I don't know five blocks and then like
27:29 - initially just kind of give an example
27:33 - and make the character react to a
27:35 - specific phrase we we said like what
27:38 - would you like to eat and then we wanted
27:40 - to create a more natural like
27:42 - interaction like talk to nari the way
27:44 - you talk with a friend so for that we
27:46 - use the feelings extension so it can
27:49 - analyze the feelings of different
27:51 - messages that we would send and then we
27:53 - added the extension which makes it
27:55 - social like the Twitter extension
27:56 - allowing all of us to play this game
27:59 - together and you can imagine like doing
28:02 - this with kids is much more fun than
28:03 - trying to deal with the lag and all the
28:07 - other complications of life coding but
28:09 - the idea is that it opens up a world of
28:11 - possibilities and
28:14 - you so right now only a character on the
28:16 - screen reacting but when we have also
28:18 - like a lego robot reacting to what we're
28:20 - saying or cause more robot or things
28:25 - that are in the physical like a microbe
28:26 - it showing a heart you can imagine that
28:29 - the world becomes a playground and all
28:31 - of these things can be combined in many
28:33 - different ways now from our perspective
28:36 - or you know customization perspective if
28:40 - we play with this a little bit longer
28:41 - you're quickly going to see what are the
28:43 - limitations of these like feelings
28:44 - extension and then we're gonna start to
28:47 - think okay who trained this extension
28:49 - what kind of examples did they use why
28:52 - does it pick up why doesn't pick up
28:54 - sarcasm or why doesn't it pick up you
28:58 - know more like backhanded compliments
29:00 - and things like that so that comes like
29:03 - a natural transition and question for
29:06 - kids as they're playing along and poking
29:08 - with these things so we build like also
29:10 - on the clock we meet website you're
29:12 - gonna see these links or tji and if you
29:15 - click on it it's going to die oh wow
29:20 - that was so slow so so basically once
29:27 - they tried existing AI models it could
29:31 - be for vision or for text or for many
29:35 - other things then they can start to
29:37 - teach their own and maybe you know a
29:40 - child would one nary to laugh at his
29:42 - jokes or like get like a very specific
29:46 - insider Joe you know message that he's
29:49 - sending so he can go to the tji page
29:51 - over here and this is building on top of
29:54 - IBM Watson and it allows kids to create
29:58 - I did
30:02 - yes no problem
30:05 - so yeah the caca meet Studio built on
30:09 - top of IBM Watson and it allows kids to
30:12 - create their custom classifiers so if
30:15 - they don't want to use already pre
30:17 - trained model that exists online they
30:19 - can make their own with their own
30:21 - examples so in here we could do this
30:23 - make me happy project and start writing
30:26 - example is just like what kind of text I
30:29 - would like Mary to recognize as happy
30:31 - and what kind of text I would like Mary
30:34 - to recognize the sad or maybe I want to
30:36 - add another category where it's not
30:38 - neither happy or sad or neutral it's
30:41 - more like I don't know weird messages
30:45 - right I like weird stuff so we can kind
30:51 - of give much more nuance to instead of
30:54 - black and white and like cats and dogs
30:56 - or we can start to add our own examples
30:58 - and then once we have five examples for
31:01 - each of these categories click on the
31:04 - teach me button this will create a
31:06 - classifier then that we can use
31:08 - afterwards you know a copy mates game by
31:11 - adding this text extension so it's it's
31:15 - all like coming from like okay let's do
31:17 - the fastest thing that we could do so we
31:20 - can have a game or an interaction that
31:22 - it's fun and then like peel off the
31:24 - layers and start to understand what are
31:27 - some of the things like how can I
31:28 - influence how this works and how would I
31:30 - like to customize it and what would I
31:32 - like to create I had an example with
31:34 - vision as well but um I don't know how
31:36 - many more I'll try to show it quickly
31:38 - that one is using color tracking and we
31:43 - have one that is drawing and one that is
31:46 - playing a game I don't know which one I
31:47 - should show drawing or like right now
31:52 - that you mentioned you might have to
31:53 - show both okay okay if people will want
31:56 - to see the other one now that's true
31:58 - okay so save the falling again you guys
32:01 - try this at home there on the website
32:02 - and this one what it does is that it's
32:07 - using the color tracking extension which
32:10 - allows us to basically pick any color we
32:13 - want to track so what's happening here
32:16 - is that if I start the game you're gonna
32:18 - see like these guys are like falling we
32:22 - have it's from that expression of it's
32:24 - raining cats and dogs it's quite literal
32:27 - and I'm tracking the color red so
32:30 - technically when I'm showing red I can
32:33 - start saving them so it shouldn't be
32:36 - falling anymore before I was working so
32:43 - it's not saving them so that means I
32:46 - need to change my red that I'm tracking
32:50 - so it's probably a little bit darker and
32:54 - if I want to have like a precise color
32:58 - peeking we're going to make the video
33:01 - not be transparent so we can actually
33:03 - see the full color and then we can
33:07 - actually go in the video stream and pick
33:10 - the color that we want to track so if I
33:13 - click in here I have this color picker
33:16 - so I can say track this kind of red so
33:20 - normally hopefully I'm saving them so if
33:25 - I'm not showing that red they're falling
33:27 - and it's sad and then when I'm showing
33:30 - the color they're like so going back so
33:34 - yeah that's kind of like saved a falling
33:36 - how to save the following game works and
33:38 - then you could do it like also with ping
33:41 - pong or multiple colors like where
33:45 - multiple objects and maybe you want to
33:48 - do something like oh when I'm wearing
33:49 - this color I want music or things in my
33:53 - house to start in a specific way so we
33:56 - did a project I will show it to you here
34:00 - very quickly where I keep on talking
34:03 - about physical things which I couldn't
34:04 - bring with me today to show hopefully in
34:07 - future demos but this is what it looks
34:10 - like when instead of having only
34:14 - is happening on the screen you have
34:16 - things happening in the real world so
34:19 - this is a project where an entire room
34:23 - is reacting to how you describe your
34:27 - dreams
34:36 - I had a dream that I was in a magical
34:40 - forest we get the bubble machines and
34:48 - beautiful colors and like beautiful
34:51 - music so she is just describing what
34:55 - kind of dreams she had those get
34:57 - analyzed with feeling extension and then
35:02 - things start reacting to it but if we
35:05 - don't want to talk and we're just
35:07 - wearing a specific color things can't
35:08 - react to that as well yeah this is
35:11 - showing how we can program Alexa and let
35:14 - me quickly go back to the other one with
35:16 - the drawing let's see if I have it call
35:22 - our drawing many things are gonna change
35:26 - also like you see right now I'm like AB
35:29 - loading and downloading in the future
35:31 - we're gonna have a link where you just
35:33 - click on it and you would load the
35:34 - project automatically this is tracking
35:37 - green which is all behind me let's see
35:39 - if that works
35:40 - yeah so when the extension sees the
35:44 - color that we're tracking this little
35:46 - guy will start drawing so let's go back
35:49 - to our red over here and we're gonna try
35:57 - it and then start the project so he's
36:03 - just floating around that drawing and if
36:05 - I show him red he's gonna start drawing
36:07 - on the screen and we can make him play
36:12 - music as well or I don't know maybe just
36:15 - only draw with the color that he's
36:17 - sensing and things like that so I just
36:19 - wanted to show examples of like how we
36:22 - could play with vision and with text and
36:25 - create interactive projects because I
36:28 - think like the biggest thing like if we
36:30 - talk about what two kids - after scratch
36:34 - right we're after coding if you have an
36:37 - Alexa at home or if you use Yui or it's
36:42 - a very different paradigm I think for
36:44 - for everyone and especially for kids is
36:47 - you start to understand the
36:49 - it's coding is not just a set of
36:52 - instructions that you're sending to this
36:54 - devices you start to understand that
36:57 - especially with AI and machine learning
36:59 - in the in the loop you have more of a
37:01 - conversation so the more you talk to
37:03 - Alexa the better it should become
37:07 - recognizing what you're saying we're
37:10 - picking up your accent or personalizing
37:13 - the answers and I think in the future
37:16 - like the reason it is important to teach
37:18 - this to young people it's because they
37:22 - need to understand this fundamental
37:23 - paradigm shift of going from just
37:26 - sending a set of instructions like
37:28 - making a recipe for a pie to actually
37:32 - understanding how a feedback loop works
37:34 - what if like for nari to make nari happy
37:37 - we made this game right and I keep on
37:39 - giving her examples but then Dan starts
37:42 - giving other examples because what makes
37:44 - them happy and what makes me happy might
37:46 - be different how do we negotiate that
37:48 - right and how do we become more aware of
37:51 - what we share and where and how is that
37:55 - being used so I think these are all part
37:58 - of the underlying concepts and goals of
38:00 - trying to provide these playful tools
38:03 - that would allow kids to get a better
38:06 - understanding of how these technologies
38:08 - work and yeah and that's what we're
38:10 - trying to do with cocky mates and
38:12 - there's lots of resources I actually
38:15 - just published a blog post about the
38:17 - project as well and you can hear maybe
38:21 - well well I don't know if you have any
38:24 - questions but I wanted to quickly show
38:28 - how kids explain it because I think they
38:30 - do a much better job than I do so here's
38:34 - what a I looks like for seven-year-old
38:39 - let's see I'm gonna skip through the
38:42 - part of the video where I'm talking over
38:48 - here this is on YouTube it's called kids
38:50 - teach AI a little humanity would
38:52 - calculate and let's see what they have
38:54 - to say about it who decides how its
38:56 - applied to benefit society
38:59 - we show children how a robot sees the
39:01 - world how does it learn to recognize
39:04 - objects how does it know to recognize
39:06 - words for you a potato we also allow
39:09 - them to be able to teach a robot or a
39:11 - computer I'm gonna give you ten examples
39:13 - of images and then you're gonna learn
39:15 - what a gesture is so every interaction
39:18 - you have with it it's kind of like a
39:20 - conversation so you are having this
39:24 - learning companion discarding me that is
39:27 - learning with you and teaching you at
39:29 - the same time so we were programming
39:32 - robots
39:33 - you could play rock paper scissors you
39:38 - did rock paper scissors into the camera
39:41 - and on shoot you did one of the motions
39:44 - and the camera did one of the motions
39:46 - it's like rock paper scissors shoot the
39:52 - computer gets like better as you play
39:54 - the game cuz like that we might not know
39:57 - everything at first but if we keep
40:00 - trying we get better everyone has heard
40:03 - about like machine based learning or
40:04 - artificial intelligence and there was a
40:07 - certain no questions asked for a lot of
40:08 - the more tech-savvy parents as I could
40:10 - go for it technology is gonna be a huge
40:12 - part of their lives much more so than my
40:14 - life if it's scary for some people this
40:16 - AI technology I totally get it but as a
40:19 - parent and as a teacher I thought it was
40:21 - really important because these are
40:23 - skills that 21st century kids need to
40:24 - have when they understand this idea of a
40:27 - feedback loop that the more information
40:29 - you give to a machine or a robot the
40:31 - better it becomes Neela how smart are
40:35 - you it really allows them to understand
40:37 - how machine learning in AI is different
40:39 - than just coding so I think this is a
40:41 - very powerful paradigm for children so
40:43 - they understand that when they have an
40:45 - Alexa at home or smart assistant
40:46 - everything they do the way they talk to
40:49 - it gets fed into the algorithm so the
40:51 - machine is actually reacting to them
40:53 - right now
40:55 - we don't have basic AI literacy we don't
40:58 - know what k12 AI education should look
41:01 - like so we have the opportunity to
41:02 - really shape that at the Media Lab we
41:05 - believe that should be done in a
41:07 - hands-on way children should work as
41:09 - part of groups in community
41:10 - they should be able to share ideas and
41:13 - they should feel empowered by tools that
41:15 - allow them to build real projects that
41:17 - matter to them well my dad was young he
41:19 - bought a car and take apart let's see
41:23 - how it work so you teach people's that
41:26 - young how these things that grown-ups
41:29 - mostly program how it works yeah
41:34 - so basically AI for kids it's like the
41:37 - cars of their generation and if a
41:40 - seven-year-old can see that hopefully we
41:44 - can all to see that I won't stop here
41:47 - with it yeah I do have some questions so
41:49 - I can come slide around the other side
41:50 - of you actually so I'm curious that to
41:53 - me that quote is so kind of amazing and
41:56 - so wise of this seven-year-old sort of
41:58 - like think of that that just came right
42:00 - from that that boy just sort of thought
42:02 - of that so we asked them like why do you
42:08 - think so I should mention that that
42:10 - video was made a month after doing
42:12 - workshop school right so it wasn't like
42:15 - they just didn't yeah it was like
42:16 - actually what they remembered after one
42:19 - month right when we went back and the
42:22 - Jimmy who did the video with me from
42:25 - who's the videographer from Media Lab
42:27 - was like why do you think you're doing
42:29 - this like why did why does it matter and
42:32 - he came back to us with that quote about
42:34 - cars like how his dad took apart a car
42:37 - yeah and that it surprised him that you
42:41 - teach people so young how these
42:43 - technologies work right and from you
42:44 - know it's so profound because I think a
42:47 - lot of times we kind of like because we
42:49 - are product of a system of education
42:51 - yeah we kind of limit what a child could
42:54 - learn at a specific age right winning
42:56 - actuality we see it like you see it with
42:59 - your kids and I say kids that I'm
43:00 - working it's like they learn it's such
43:05 - an interesting problem too because with
43:07 - a car it's a physical thing taking it
43:09 - apart means physically manipulating the
43:11 - metal the wires the pieces and a
43:14 - computer you could say the same thing oh
43:15 - learn how an Arduino works or a micro
43:17 - troller learn to light up an LED is in a
43:19 - way that aspect but with a machine
43:21 - learning algorithm you know what is
43:24 - taking
43:24 - depart me you know ultimately if you
43:25 - look if you think about like a neural
43:27 - network and you look at taking that
43:30 - apart well it's just a whole bunch of
43:32 - numbers and how do you unpack you know
43:33 - well and I think in many ways maybe what
43:36 - it is is taking it apart is like looking
43:37 - at the data kind of understanding what
43:39 - the data is and and watching it break I
43:42 - think is the only way to understand lock
43:46 - how why how it works or why it works
43:48 - because when it when it just works then
43:50 - it feels like magic breaks you can
43:52 - understand why did it break now I
43:54 - understand how it works a little bit
43:56 - absolutely and too quickly and on that I
43:59 - think you know when I showed the
44:02 - teaching AI to Google engineers they
44:05 - were like this is not they're not doing
44:08 - the model they're just adding the data
44:09 - they're controlling the weights and how
44:11 - many right layers and I'm like this is
44:13 - and I'm like you're right that's the
44:16 - next and it's like it is like a very
44:19 - good question he's like what primitives
44:21 - and what we tinker with right and I
44:23 - would tell you that especially for kids
44:26 - like this idea of a cockney made it's
44:27 - much more profound that I have a
44:29 - character on screen or it's like you are
44:31 - we are creating embodiments and stories
44:34 - that kids can relate to and we saw that
44:36 - in the data because like I've been doing
44:39 - research with 450 kids long term like
44:42 - six weeks in schools and community
44:44 - centers and and when they talk about
44:46 - what they learn he's like yeah it's like
44:48 - that project with the robot when you
44:50 - teach it to be out like this and this is
44:51 - how it works but they are creating this
44:54 - embodiment of what does it mean to learn
44:56 - how to recognize what's in a picture
44:58 - right and I agree I think it's like a
45:01 - really it's a new question an
45:03 - interesting question you know if you'll
45:04 - if you try to look sort of like a Google
45:05 - AI education you know this was like
45:07 - seminal course might be like and Andrew
45:09 - Ames Coursera actually learning course
45:11 - where you're starting from you know
45:13 - linear regression and so what are other
45:16 - and no that's amazing and fundamental
45:18 - and really meaningful and important but
45:20 - is that the appropriate entry point for
45:23 - every context probably not and so what
45:26 - are the other context what are the kinds
45:28 - of reasons why and how and that people
45:30 - kids or adults might want to learn about
45:32 - machine learning and so one of the
45:33 - things that I love about this especially
45:35 - it really relates to like
45:36 - the program ITP where I teach is this
45:38 - kind of I think the core concept or
45:40 - values like learning through play and so
45:43 - you know how and you know and I think so
45:48 - like how what kind of toys can you build
45:49 - what kind of like games can kids play
45:51 - and I think that's like fundamental and
45:53 - really exciting about this work and the
45:55 - confusion part you know I was very cool
45:56 - so like I learned so much from doing
45:58 - business school it's like they always do
45:59 - things that I never expect so they would
46:02 - train a classifier with images and they
46:04 - were like okay we want to distinguish
46:07 - Kirby's of course that's very important
46:09 - from dogs it's like but now we want to
46:12 - confuse it can be fine like hooker be
46:14 - that looks like a dog or can we put a
46:17 - dog with sunglass and like them going
46:20 - through this process of like how can we
46:21 - confuse that AI and like having fun with
46:24 - it and at the same time like discovering
46:26 - like what are the boundary is right and
46:28 - what can this do and what can it not do
46:31 - or how do I teach it and I think that's
46:34 - amazing
46:36 - and I want to have provide more
46:38 - opportunities for kids to because when
46:39 - we start to go and tell them like have
46:41 - you guys heard about AI and self-driving
46:44 - cars and the kid would say like that's
46:46 - boring driving a car it's fun yeah we
46:50 - need to start from your interest and
46:51 - what they love cool so I do have a bunch
46:55 - of questions I might have missed by the
46:56 - way cuz I was listening intently might
46:58 - have missed some of your questions if
47:00 - anybody is in the slack Channel and
47:02 - there was an interesting question could
47:04 - also tag me and I'll catch that more
47:05 - easily but some of the questions I have
47:07 - is and let me let me actually ask this
47:10 - one because I think it's a sort of key
47:11 - one so is there a specific and this
47:14 - comes from George Dow um it's there and
47:17 - I'm rephrasing the question but is there
47:19 - a specific target age that your let that
47:22 - cognate is designed for and kind of like
47:25 - what are the sort of limits of that like
47:27 - I mean I can imagine like you know me I
47:29 - could play with it I would have fun I'm
47:30 - 45 but you know what it was your sort of
47:33 - target audience there and what has been
47:35 - successful with different ages that you
47:36 - found yeah so I
47:38 - say my tesis and all the research is
47:40 - online we could put links in the
47:42 - description descriptions and we
47:44 - published a lot of papers it is for kids
47:46 - of six and a half to fourteen but we are
47:50 - expanding that so creating a bit more
47:52 - advanced features for high schoolers and
47:55 - a bit more simplified features for
47:57 - younger kids but right now like the core
48:00 - of the research was with kids in that
48:01 - age group and their parents and teachers
48:04 - as well so we did a lot of teacher
48:06 - training and we did workshops where we
48:08 - would invite the parents as well because
48:10 - it's so important we realized I should I
48:14 - should mention this was like one of the
48:16 - things that surprised me the most like
48:18 - in this workshops oh yeah and I put some
48:20 - drawings of how very young kids describe
48:23 - like signing
48:24 - it's like Dora the Explorer and the dots
48:26 - connect what I think I like so record
48:31 - sound coded what happens but yeah we
48:34 - basically videotaped everything that
48:38 - kids were doing like we wanted to go
48:41 - past this novelty effect because if you
48:43 - go to a child with a construction kit or
48:45 - robot or of course you know they're
48:48 - amazed and everything is like the wow
48:50 - effect in the beginning but if we go to
48:53 - schools actually like three or four
48:55 - times per week for six weeks then we can
48:58 - really start to see what happens when
49:00 - the novelty of technology wears off how
49:03 - much can we engage these kids and how
49:05 - far they gonna go because the measure of
49:06 - success for me in terms of learning is
49:09 - not only that they know what model is or
49:14 - how you know sentiment analysis works or
49:17 - how computer vision works but it's also
49:20 - like a diversity of projects that they
49:22 - would create and how to use this like
49:25 - tools and concepts to actually build the
49:27 - world around them so we are like a
49:29 - measure of success it's not only like oh
49:31 - I have the definition of this it's more
49:34 - like are they building like very
49:36 - different projects are they tinkering
49:38 - with this are they playing with this are
49:40 - they you know breaking this so going to
49:44 - schools we videotaped everything that
49:47 - kids were doing
49:49 - then we coded we did like logistical
49:51 - regression we coded to see what were the
49:54 - factors that matter the most in them
49:56 - understanding these concepts and
49:58 - changing their perception right to
50:00 - become a bit more skeptical and more
50:03 - critical and the number one factor that
50:05 - mattered most was collaboration and it
50:08 - was significantly more impactful than at
50:13 - the time they would spend coding or the
50:16 - prior experience they had or it was like
50:18 - how much they would talk with their
50:20 - peers and like how they would like
50:23 - basically develop their ideas in like
50:26 - arguing or saying no I think it does
50:28 - this or like I actually think it's not
50:30 - like gonna remember you because so it
50:33 - was fascinating that and and I do think
50:36 - it's so important to design for
50:38 - collaboration and for jobs and in that
50:40 - context the conversations kids will have
50:42 - with their parents at home matter a lot
50:44 - yeah cool ok so if I ask that question
50:48 - Oh another question which I guess is
50:50 - sort of a quick one maybe in a way which
50:52 - is that does any of the stuff that
50:55 - you're working on with cognates is it
50:56 - just design for mobile devices smart
50:59 - phones or is it all needs to be done
51:01 - from like the browser desktop so it can
51:05 - be used its perspective so it's no js'
51:09 - it's in the browser right now we don't
51:11 - have specific apps when you say it's no
51:15 - Jess I'm just not I'm just curious does
51:17 - that mean so the servers and is is
51:20 - running node so as the client is doing
51:22 - stuff it's like sending the data to the
51:24 - server then it gives the results back so
51:26 - that sentiment analysis that it's doing
51:28 - is actually happening on the server
51:29 - which is interesting to think about the
51:32 - possibilities that you could also have
51:33 - it happen on the client now with the
51:35 - tensorflow Jas and some of the other
51:37 - stuff that working on here ITP with the
51:39 - ml 5 libraries one big limitation of the
51:44 - current implementation is that you need
51:45 - to have a Wi-Fi connection right and in
51:48 - a lot of schools right now face
51:50 - that's not always available so we want
51:53 - kids to train their models with text or
51:55 - images but then be able to download them
51:57 - and use them locally so that's something
52:00 - I'm working on right now is like how do
52:02 - we use these models with tensorflow
52:04 - light and other implementations locally
52:08 - and for the mobile part we're also
52:11 - talking to App Inventor to port some of
52:14 - these extensions in that inventor and if
52:17 - you have ideas like Oliver
52:18 - Cody's online yes actually somebody did
52:21 - ask like where is the github repo maybe
52:23 - the point people search coffee meets on
52:26 - github it's the first result it's all
52:29 - there I can also show it here do you
52:31 - have specific kinds of contributions
52:34 - that you're looking for like missing
52:35 - pieces are there like fix the bugs and
52:41 - build new extensions because like some
52:44 - of the cool stuff we've done more for
52:45 - art and creativity with style transfer
52:47 - so we made an extension for style
52:50 - transfer for images and for audio it's
52:52 - not published yet because it's very
52:54 - heavy in the background yes like it
52:57 - can't be done now in the browser so we
52:58 - have a meaning she who did it just
53:00 - recently a guest video all about that
53:03 - the training has to happen separately
53:06 - but once you have the model yeah you can
53:08 - use it yeah so new extensions like
53:13 - actually the simplest way if you are a
53:15 - developer and you want to contribute is
53:17 - to go to the coffee mates VM it's where
53:20 - all the meat is we have the GUI which is
53:21 - like the interface but the VM is like
53:23 - we're all but you might have to make
53:25 - that a little bigger for people yes so
53:28 - the link and I'm totally standing in
53:30 - front of it but yeah me too actually we
53:32 - can do whoops how do i yes there you go
53:38 - so if you go to github Media Lab
53:43 - carbamates VM and then in here all the
53:49 - extensions are in their own dedicated
53:52 - folder so if you start with the one that
53:55 - I showed you today like the sentiment
53:56 - it's basically one javascript file and
53:59 - each of the blocks is
54:02 - fine like we define like what the what
54:05 - type of block we're using is it a hat or
54:08 - is it a reporter and then each of those
54:11 - blocks is basically calling a JavaScript
54:14 - function that in this particular case
54:17 - I'm using this NPM this node library
54:19 - called sentiment here and it's like
54:24 - basically going to that librarian saying
54:27 - like look at this string if the feeling
54:31 - is positive return true and in the
54:33 - feeling it's like very very like very
54:35 - simple so even with this extension maybe
54:38 - you want to add another block or maybe
54:41 - you want to change the language or maybe
54:44 - you want to actually play with the
54:45 - scores that we're using here right and
54:47 - it's like oh you know that example you
54:50 - had oh yeah
54:51 - the one with the food would you like
54:53 - something to eat
54:54 - that wasn't neutral right it was
54:56 - positive like what can we do two more
55:00 - maybe we actually allow the kids to play
55:02 - with the score right so yeah and if this
55:05 - I'm just gonna put the video back
55:07 - because people always complete but it's
55:09 - gone for too long that complaint is the
55:11 - wrong word they'd like to see it's very
55:13 - nice this is super interesting
55:15 - I like seeing this now like peeling back
55:17 - the curtain I realized that how amazing
55:20 - this is in terms of repo just if for
55:24 - somebody who is working on some machine
55:28 - learning algorithm to be able to have
55:31 - that running in JavaScript to be able to
55:33 - just suddenly have this other front-end
55:35 - to it that a kid could access and you
55:37 - know one of the things I'm I don't know
55:39 - I'm not sure if this is that - the node
55:40 - package I'm thinking of but the one that
55:42 - I've looked at quickly but I think that
55:44 - it might be the same as using this like
55:45 - that a fin 111 list which is a familiar
55:48 - it's a big long list of words that a
55:51 - group of researchers decided gave
55:54 - weights to positive and negative scores
55:56 - and one of the things that I have done
55:57 - with my students here there's a build a
55:59 - little example where you could change
56:00 - all those weights and add your own words
56:02 - and so that would be like you know Jimmy
56:05 - and that could be a signature that could
56:06 - that you know you could imagine the same
56:07 - way of
56:08 - that you're showing kids that they can
56:10 - do the image train an image classifier
56:12 - does that I'm and so that I'm also
56:14 - wondering is the image classifier stuff
56:16 - is that also an example of what you're
56:18 - doing it's like transfer learning so
56:20 - it's already starting with a pre train
56:21 - model that transfer time yes when you're
56:29 - working with kids they're not going to
56:31 - have the patience to wait for an hour
56:33 - right well also you won't necessarily
56:35 - have a data set that's large enough
56:37 - toward it but it's still conceptually
56:39 - they're going to learn about all the
56:41 - vocabulary and the steps and it's very
56:44 - in line with like the teachable machines
56:46 - projects and Google and the stuff that
56:48 - we're doing with ml5 so I I didn't I
56:50 - knew there were connections here but
56:51 - there's even more one of the things that
56:57 - I'm thinking a lot about now is like
56:58 - what are the experiences and play
57:01 - patterns and you know what Katti batti
57:03 - is that kids could do it in mobile that
57:05 - they couldn't do it a lot and we were
57:07 - talking about this it's like your phone
57:08 - already has so many sensors it's crazy
57:11 - and where we have it with us in our
57:13 - pocket all the time so it's like what if
57:15 - I make a game where he's like tracking
57:17 - if I'm sitting too long in one place and
57:19 - he's gonna start like vibrating but like
57:20 - I build that with blocks right or if I'm
57:23 - teaching it like I want you to recognize
57:25 - that this is my pattern of what I do
57:28 - when I go to ITP right and tweet this
57:31 - and whatever or just with gestures kids
57:35 - love like with micro beta does it has an
57:37 - accelerometer and they love to again
57:40 - this Packard was describing this as body
57:42 - synchronicity and it's actually
57:45 - fascinating like how complex how much
57:48 - kids could solve complex problems if
57:50 - they can project it to their body so if
57:53 - I need to like code and algorithm where
57:56 - I tell a robot to draw square if I
57:59 - pretend I'm the robot and I think like
58:01 - what do I need to do to draw the square
58:03 - it's so logical and it's obvious so how
58:06 - do we bring that experience to other
58:09 - concepts right yeah that was a long no
58:12 - no no you're fine right this whole
58:14 - channel is me just talking too much so
58:15 - there's nobody else to say anything with
58:18 - us here so there is another question
58:20 - which I did grab
58:21 - which is a little bit off-topic but
58:22 - since you're here and I know the MIT
58:24 - Media Lab is its own thing and the MIT
58:26 - is a huge University but someone did ask
58:28 - I'm interested in attending MIT as a
58:31 - fresh freshman I was wondering if you
58:33 - could ask her about time there any tips
58:35 - for someone so you have any tips or
58:37 - thoughts about like the experience of
58:39 - going you know as a student from another
58:41 - country and coming to MIT what was your
58:43 - experience like in a minute or two maybe
58:47 - this is too big of a question to
58:57 - demystify what it means to go to a place
59:01 - like Media Lab or NYU or and I think a
59:05 - lot of the times I would look to the
59:07 - project that were coming from there and
59:08 - I was like oh my god like I would never
59:12 - you know be able to work on this or get
59:14 - there and seeing people's pathways and
59:18 - demystifying that it's been very helpful
59:20 - so whoops what we we made it to an hour
59:23 - we did it's so it's a long story I could
59:30 - explain to after because I talked about
59:32 - it incessant Leon someday I'm gonna fix
59:34 - it or get a different camera but at this
59:36 - point it's just like I'm so used to it
59:37 - being there it's like a ritual right so
59:41 - I wrote a blog post about this and I'll
59:44 - share it but I will I will tell you that
59:47 - I think in my case what really helped is
59:49 - that if you work on something that
59:52 - you're passionate about you are going to
59:55 - do your best work and then also be
59:58 - playful about it and be open about it
60:00 - like and it starts very early it
60:01 - actually starts extremely early the
60:03 - reason I'm doing this with kids is
60:05 - because I realized like when I grew up
60:07 - in my small village in Pennsylvania we
60:10 - didn't I didn't have access to all these
60:11 - things I had to learn it much later in
60:13 - life I'm 32 now and you know to get
60:17 - there like I had to go through so many
60:18 - filters like first generation to be able
60:22 - to study abroad and first gen'l'men get
60:24 - scholarship here work at night here like
60:26 - a lot of the things where it's like if
60:28 - you
60:29 - enjoy what you're doing and you're
60:31 - playing with it and you're having fun
60:34 - then you are going to do it for a long
60:36 - time and you will eventually get where
60:38 - you want to get and I think if there's
60:40 - one thing that defines MIT for me is
60:42 - that all the students and people I met
60:44 - there are extremely passionate about
60:46 - what they do and they are driven by
60:49 - learning because you never stop learning
60:51 - like that's the other thing that I think
60:53 - especially in this day and age we talk
60:55 - about kids but it's actually everyone
60:56 - like we never stop learning so I know
61:00 - this is very broad I'm happy to talk to
61:04 - you it's a good answer so well obviously
61:10 - we'll put this in the video description
61:12 - once later and anybody watching this
61:14 - later will see it but just cuz you
61:16 - mentioned the blog post a few times can
61:17 - you point people to that URL right now
61:19 - for watching and actually I can paste it
61:21 - into the chat so while you're pulling it
61:22 - up I will also pull it on yeah so this
61:25 - was just published so if you google kids
61:28 - teach AI a little humanity it's on
61:31 - medium and I should have made a short
61:34 - link it's no problem cuz I'm gonna paste
61:38 - it into the chat yeah so it's a medium
61:40 - we go great yep it's a bit long but um
61:44 - thank you 14 minutes to read I think you
61:47 - can read for 40 minutes and if you
61:49 - manage to watch this video for an hour
61:51 - it has stories of an astronaut in there
61:53 - so yeah certainly one thing I'm really
61:56 - curious about next time this was an
61:57 - interesting it not an experiment really
61:59 - but this was a little bit different than
62:00 - the usual content in that I don't have
62:03 - an audience that I know of there's a
62:05 - couple younger kids that I've heard from
62:06 - who do actually watch some of the
62:08 - tutorials I have but most of the
62:10 - audience I'm is you know adults or high
62:13 - school or college or or beyond so but
62:17 - I'm kind of curious are there any
62:19 - parents out there with kids are there
62:21 - any teachers out there who are thinking
62:23 - about how to integrate technology in the
62:25 - classroom and topics like AI and how to
62:27 - discuss those things and so definitely
62:29 - get in touch leave a comment or on
62:30 - Twitter if you're thinking about using
62:32 - cognates or if you're an open-source
62:34 - enthusiast for sure know a lot of you
62:36 - are and it
62:37 - did contributing could certainly leave a
62:39 - comment or get in touch and I think it
62:41 - will make sense well sort of like look
62:42 - at this after because I you know an hour
62:44 - is a nice round number for a video from
62:45 - we probably couldn't could like get all
62:47 - this material but we'll see if it makes
62:49 - sense to kind of also just break it out
62:52 - like some of this code examples you're
62:53 - sure day you showed us like a short
62:55 - tutorial that could be a standalone
62:57 - video as well so anybody's any feedback
62:59 - or suggestions about that I will hear
63:00 - from Matthew who does video editing for
63:02 - the coding trainees not able to watch
63:04 - live today but he'll he'll watch it
63:06 - later and I used to get really good
63:07 - feedback from him so I think you know
63:17 - for me it's like it's been quite a
63:20 - learning journey to let go and be like
63:23 - this is not perfect but we're building
63:24 - it together so I look forward to see
63:27 - what you're gonna be doing with cockney
63:28 - mates and yeah I also look forward to
63:33 - hear from your feedback and this is just
63:36 - the beginning it's it's fun I yeah
63:39 - awesome thank you so much for being here
63:41 - and let's see so I'm this stream it's
63:45 - going to shut off when I press this
63:46 - button over here that turns it off I
63:48 - actually have a little bit more time
63:49 - than maybe I thought I did so I might
63:50 - come back in a little bit for just like
63:52 - a short I'll do some short coding thing
63:54 - try to do that once a week and then I
63:56 - will be back again next week with your
63:59 - regularly scheduled program this is a
64:02 - very strange life that I have now that
64:04 - I'm always in a room talking by myself
64:05 - to a camera it's nice that you're here
64:07 - with me at least today okay so thank you
64:09 - for all of your questions I'm really
64:11 - sorry if I missed anyone's question in
64:12 - the chat still learning how to figure
64:14 - out how to make all this stuff work and
64:18 - I will see you all soon good bye and I
64:27 - said it wasn't the kids Channel wait I
64:28 - have to find the place this is the
64:29 - awkward thing this is no we're not this
64:31 - is actually live day we're still on
64:33 - until I hit this button and also after I
64:36 - hit this button it sometimes actually
64:37 - still streams like a it's about thirty
64:39 - seconds so happy now we're really
64:40 - leaving bye