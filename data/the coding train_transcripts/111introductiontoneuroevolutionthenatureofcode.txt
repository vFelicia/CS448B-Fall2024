00:00 - hello welcome to the first video in a
00:04 - new chapter of the book nature of code
00:06 - chapter 11 only strangely chapter 11
00:10 - does not exist so I'm doing something a
00:12 - little different here
00:13 - where all my previous other nature of
00:15 - code videos that go along with this
00:17 - nature of code book the book was written
00:18 - first came out in 2012
00:21 - and and this is the current version of
00:26 - its and then I made videos after the
00:27 - fact now what I'm going to do I want so
00:30 - chapter 9 is about genetic algorithms
00:32 - and chapter 10 is about neural networks
00:34 - and I have a set of video tutorials that
00:35 - go along with both of those chapters
00:37 - today I'm going to start talking about
00:39 - something that I want to be in the next
00:41 - edition of the nature of code in chapter
00:43 - 11
00:44 - called neuro evolutions so I want to
00:46 - take the idea of a genetic algorithm and
00:48 - a neural network and use them together
00:50 - in a magical way to make wonderful
00:53 - things happen on the screen or or
00:57 - doesn't have to even be on the screen
00:58 - and some other capacity that I can't
00:59 - even imagine right now so what is it
01:02 - that I am going to do so first of all ok
01:06 - so if you are on keyboard if you have
01:09 - watched some of my previous some of my
01:11 - other neural network tutorials you the
01:14 - most recent thing before the recording
01:16 - of this video that I made was a doodle
01:18 - classifier it's kind of the classic
01:21 - machine learning classification example
01:24 - I have some images maybe they're
01:26 - handwritten digits maybe they're doodles
01:28 - of cats and rainbows and unicorns and
01:29 - all that sort of stuff and I want to
01:31 - feed those things into a neural network
01:33 - and I want the neural network to
01:35 - classify them and if you've watched
01:37 - those videos you might have noticed that
01:40 - there's this whole elaborate training
01:42 - process the training process involves
01:46 - making that guess having some labeled
01:49 - correct data and then feeding that and
01:53 - then looking at the error like what is
01:54 - it supposed to be versus what a guest
01:56 - and feeding that error back through the
01:58 - neural network looking at the guests
02:00 - output versus the correct label
02:04 - calculating an error and setting that
02:06 - error backwards through the network
02:07 - through a process known as back
02:09 - propagation where all of the weights are
02:12 - tuned in
02:13 - so while this is the most well known and
02:16 - probably most common and sort of
02:18 - standard technique for training a neural
02:20 - network back propagation with gradient
02:23 - descent very fancy sounding there are
02:25 - many other ways I mean there there's
02:27 - other ways that you can train a neural
02:29 - network one of which is using a genetic
02:32 - algorithm so what if we just threw away
02:34 - all of that calculus math at all this
02:37 - sort of like error this error that and
02:39 - back propagation this and we just said
02:42 - hey I've got an idea why don't I make
02:45 - it's never having one neural network why
02:47 - do I make a thousand of them and I'll
02:48 - try them all maybe some of them will
02:51 - classify image maybe one will classify
02:52 - images better than another one does
02:54 - maybe I'll keep that one and one just
02:57 - really gets everything wrong maybe I
02:59 - won't keep that one at all and maybe
03:01 - I'll pick from the ones that kind of do
03:04 - well and take those and duplicate them
03:06 - or mix them up to make a new population
03:08 - of neural networks and see how those do
03:10 - and this is the central idea of a
03:13 - genetic algorithm now I might suggest if
03:16 - you want to if you if netic albums are
03:19 - totally new to you you might want to
03:20 - pause this video right now and go watch
03:22 - a genetic algorithm tutorials if the
03:24 - concept of a neural network is totally
03:26 - new to you you could pause and go watch
03:28 - those tutorials but you could probably
03:29 - also just keep going good I'm gonna I'm
03:32 - gonna cover almost all of this stuff
03:33 - anyway and if as I try to sort this out
03:36 - so I'm gonna take a break for a minute
03:37 - I'm gonna erase this whiteboard here
03:39 - what's there right now left over from
03:40 - the doodle classification and then I'm
03:42 - gonna diagram out how a neural network
03:45 - can be trained using a genetic algorithm
03:48 - and then through that diagram I will
03:50 - discover things I need to add to my
03:52 - neural network code base and at some
03:55 - point if all goes according to plan you
03:59 - know I have this particular this was the
04:02 - doodle classifier example which you see
04:05 - it's classifying my rainbow but what I
04:08 - want to do is take this version of the
04:11 - game flappy coding train it's not very
04:15 - flappy I guess and see if I can use a
04:18 - neural network that is that evolved to
04:21 - play this particular game so that's
04:23 - going to be the goal of this series and
04:25 - then I have
04:26 - sorts of other ideas for other types of
04:27 - neuro evolution tutorials I believe this
04:30 - is often also referred to as neat neat
04:34 - algorithm because it's neat neuro
04:37 - evolution of it see here's the thing I
04:39 - was just saying gyro evolution and all
04:42 - the while that could sound so much
04:43 - smarter by saying neuro evolution of
04:45 - augmenting topologies that's totally
04:47 - neat alright be back in a minute
04:50 - now that I have a blank whiteboard let
04:53 - me review the steps of a genetic
04:55 - algorithm and think of them in the
04:57 - context of a neural network so the first
04:59 - thing in a genetic algorithm that I need
05:01 - to do is create a population and the
05:08 - population is going to be a whole lot of
05:11 - neural networks neural networks are the
05:15 - individual elements so maybe that
05:16 - population is 100 neural networks - I
05:21 - need to evaluate fitness of neural
05:30 - networks okay so this is kind of like
05:33 - again this is kind of like the setup I
05:35 - know that's kind of getting close to the
05:36 - top there it's the thing that I'm going
05:38 - to do once at the beginning of the
05:39 - program I sort of initialization state
05:42 - then this is this thing that I'm going
05:44 - to do for a loop you know generation
05:46 - after generation in you know in p5 this
05:49 - might be called the draw loop I mean to
05:52 - evaluate the fitness of all the neural
05:53 - networks and then create a new
05:59 - population and the way I will do that is
06:04 - by pick quote-unquote parents based on
06:14 - my handwriting is getting worse and
06:16 - worse over time
06:17 - based on pick parents based on fitness
06:22 - scores maps of probability it's so much
06:29 - room in this direction probability and
06:32 - then I want to apply crossover which is
06:36 - a way if I pick two parents for example
06:38 - I can
06:39 - half of their so-called digital DNA of
06:42 - one and half of the other or some random
06:44 - amount of one random and another and
06:46 - combine them into a new entity and then
06:49 - I can apply mutation which would be
06:53 - which is the step of saying hey let me
06:55 - look at the D let me I have this child
06:57 - DNA that is made from two parents let me
07:00 - randomly just change some of it up as if
07:02 - it's spontaneously mutating to continue
07:04 - to have variation in the system so again
07:06 - you could go watch my genetic algorithm
07:08 - tutorials where I describe all this
07:10 - stuff in much greater detail of
07:12 - different techniques and why and how but
07:14 - this is the basic idea but you might
07:16 - remember if you did watch those
07:18 - tutorials that this is kind of like the
07:20 - algorithm and it you know obviously you
07:22 - could change it and be creative with it
07:24 - but it's kind of somewhat of a standard
07:26 - the really tricky thing when you're
07:30 - making your own genetic algorithm and
07:31 - applying it to your own project is as
07:34 - follows number one is this idea of
07:37 - genotype versus phenotype what is that
07:44 - so-called digital DNA the genotype what
07:48 - is the data of that DNA and what is that
07:51 - data do how does it express itself into
07:53 - a system so this is really key in
07:55 - thinking okay well the neural network is
07:57 - somehow the genotype what could be the
08:00 - data so in fact thinking back to my
08:03 - simplest neural network which is just
08:05 - has a to two layers really a hidden
08:07 - layer and output layer the inputs come
08:10 - in to the hidden layer they get
08:11 - processed from the hidden to the output
08:13 - they get processed and then we have a
08:15 - final result so the core elements of
08:19 - those layers are weights and biases so
08:25 - all the weight matrices and the bias
08:29 - vectors those things which I described a
08:32 - detail of my neural network tutorials
08:34 - make up the genotype of the normal
08:37 - neural network the core aspect of it now
08:39 - the phenotype is the expression it's
08:41 - really really what am I using the neural
08:43 - network for so for example the
08:45 - expression of the neural network might
08:47 - be in the game flappy / bird the
08:49 - decision whether to jump or not jump
08:51 - that's the expression that's how
08:53 - it's going to be used applied in the
08:55 - given scenario in a classification
08:56 - example it could be its classifying an
08:59 - image that's how the data from the
09:00 - neural networks going to be used to make
09:02 - a guess based on this image and and and
09:04 - turn it into a string so that's aspect
09:07 - number ones we've got that so what that
09:08 - means is when I write the code I need to
09:11 - somehow figure out how to do crossover
09:13 - and mutation with weights and biases I I
09:17 - think I can create probably a population
09:19 - of random neural networks that's just
09:21 - gonna be like the new neural network new
09:22 - neural network new neural network
09:23 - evaluating the fitness I've got to get
09:25 - to I can pick two random ones but I need
09:28 - to apply crossover mutation and to be
09:29 - honest what I might do it first in my
09:31 - first implementation is not even
09:33 - bothering with crossover and not even
09:35 - bother with picking more than one parent
09:36 - so one technique to simplify the genetic
09:38 - algorithm is just to make copies so I
09:41 - can pick the good ones and make copies
09:43 - of them mutate a little bit and keep
09:45 - going it may not work as effectively as
09:46 - if I use crossover but it'll certainly
09:48 - be easier to code so the other thing
09:51 - that's tricky with with when you're
09:55 - making your own genetic algorithm
09:57 - applying it to your own project is the
10:00 - fitness function question mark when
10:05 - you're smart question mark so this is
10:06 - crucial if you don't have a good fitness
10:08 - function this whole selection process
10:11 - this quote-unquote natural so it's not
10:12 - very natural here it's like digital
10:14 - selection this I'm not gonna be able to
10:16 - distinguish between members of the
10:19 - population that do really well that
10:21 - should be that their digital DNA should
10:22 - be passed down the next generation
10:24 - versus ones that don't so I want a good
10:26 - fitness function that gives me a good
10:28 - range of probabilities and so in this
10:30 - case we could think about the
10:32 - classification it could be okay well
10:33 - this neural network give it 100 images
10:35 - its Fitness is how many of those it
10:37 - classified correctly and we could even
10:40 - go into it deeper and somehow score the
10:42 - fitness in court according to its
10:43 - confidence level without classifying
10:45 - them correctly but that might that might
10:47 - be flawed in some ways also so that's
10:49 - one thing with the flappy bird scenario
10:51 - if we think about the flappy bird game
10:56 - what is the fitness here well the
10:59 - fitness could would simply be the score
11:00 - so I am a neural network
11:02 - I am a neural network playing floppy
11:05 - coding
11:06 - now peepee poo-poo input-output P books
11:09 - that my soul like cordial so it could
11:14 - just be like how long am I able to go
11:17 - through this world without running into
11:19 - a pipe so that could be the fitness so I
11:22 - could say hey why don't you thousand of
11:24 - you try playing this game a thousand of
11:25 - you electronic neural network magic
11:27 - machines try playing his game and and
11:31 - your fitness is how long you last before
11:34 - you run into a pipe and so that is the
11:38 - fitness function so we have all the
11:40 - pieces so what do I have already like if
11:43 - I'm going for this flappy bird example I
11:45 - already have the flappy bird game so I
11:48 - have the flappy bird code I have my
11:51 - genetic algorithm examples but
11:53 - ultimately there's not really I don't
11:55 - really have a genetic algorithm library
11:57 - per se so I'm probably gonna have to
11:59 - build the genetic algorithm stuff in the
12:00 - code but I do have a neural network
12:03 - library so I don't have to write I don't
12:08 - have to write the flappy bird game I
12:10 - don't have to write the neural network
12:11 - library however it might make sense for
12:14 - my neural network objects to know about
12:17 - crossover and mutation that might be
12:20 - something that probably should go into
12:21 - the neural network library so that any
12:23 - moment I could say like hey you neural
12:25 - network a new neural network get
12:26 - together make another one or hey you
12:28 - neural network mutate yourself so I
12:30 - probably should that's something so
12:32 - that's the first thing I think I'm gonna
12:33 - do in the next video is add crossover
12:36 - and mutations or maybe to start more
12:38 - simply I'm just gonna start with like a
12:41 - copy function just to kind of get going
12:42 - here a copy function and mutation um so
12:46 - those things need to go into the neural
12:48 - network library and then the third thing
12:49 - is I just need to apply the GA so this I
12:53 - really need to do a lot of work to write
12:55 - the genetic algorithm code so I'm gonna
12:57 - start with my flappy bird code import
12:59 - the neural network library add crossover
13:02 - slash copy mutation and then start to
13:05 - implement the idea of a genetic
13:07 - algorithm in this particular program
13:09 - that started with the flappy bird code
13:10 - that imported internal dialog library
13:12 - that my father bought for two zeusie
13:15 - anyway nevermind random reference ok
13:18 - because it's like the flap
13:19 - bird that imported the neural network
13:21 - library that that added the genetic
13:23 - algorithm that there's that there's a
13:25 - song going on there that somebody else
13:27 - will finish for me all right
13:28 - um Passover is coming up okay
13:32 - so that's that okay so you've made it to
13:36 - the end of this first video for chapter
13:38 - 11 of the nature of code which doesn't
13:40 - even exist yet but maybe by the time
13:41 - you're watching it oh I'll be so happy
13:43 - if it exists by the time you're watching
13:44 - this and so in the next video I'm going
13:47 - to revisit the neural network library
13:48 - and add functions for copy and mutation
13:51 - I'll see you there
13:56 - [Music]
13:59 - you