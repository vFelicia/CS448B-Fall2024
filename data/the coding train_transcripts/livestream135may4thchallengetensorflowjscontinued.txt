00:05 - okay I'm here I'm just checking I have a
00:08 - new system I press a button over here to
00:10 - start streaming rather than press a
00:11 - button over there and apparently I think
00:13 - it worked because I'm here with you live
00:15 - on the coding train hello I think he's a
00:23 - little quietly it's finals week here at
00:25 - NYU I think maybe they'll get out of
00:32 - class a little bit or I might just sort
00:34 - of forget about it start to ramp up the
00:37 - energy volume but hello in fact I'm just
00:43 - going to get started with the fact that
00:47 - it is May 4th and I'm just gonna I'm
00:50 - looking around good morning and let's
00:53 - begin with a coding challenge Oh first
00:56 - hello to the computer science class at a
01:03 - why Jackson SS in Ottawa Ontario
01:07 - hello maybe you're actually watching
01:08 - this I hear you're having a computer
01:10 - science class and maybe you'll do this
01:13 - coding challenge with me so I'm gonna
01:15 - open up processing how's this we're just
01:18 - getting started right here could it be
01:21 - the coffee I was I was trying to get
01:25 - started at 10:30 this morning but I had
01:27 - a visitor and it was lovely to have a
01:30 - visitor and I got a common conversation
01:31 - I was talking I was talking I was like I
01:33 - would spend 25 to go upstairs so I
01:36 - didn't even get a chance to eat my melon
01:38 - so I'm really gonna one-up gibreel this
01:40 - here gibreel is if you're watching this
01:43 - is for you you know both people say they
01:47 - don't like melon
01:47 - it's not anybody's favorite fruit and
01:49 - I'll admit when I get a fruit salad
01:51 - really you know I'm like picking around
01:54 - to go for the blueberries or the mango I
01:56 - have to say a really good honeydew melon
02:02 - throat low pH which is good for me I've
02:09 - got
02:11 - acid related anxiety has lost a piece of
02:17 - fruit the heck okay
02:19 - the sound is low oh whoa wait a second
02:25 - oh my goodness just like look just so
02:36 - you guys all know that I'm not
02:37 - completely insane this is this a piece
02:39 - of honeydew melon on a fork this is a
02:46 - new mystery cloaking device melon that's
02:48 - totally as well mm-hmm so today's a
03:02 - return return of the ten-minute coding
03:06 - challenge can I I really shouldn't do
03:16 - this every once in a while people are
03:19 - like how come you never use the timer
03:20 - anymore oh no I don't want to full
03:22 - screen ah I just want a little okay I
03:26 - want to be able to pop this out no it's
03:30 - fine it's fine
03:39 - there's a way I used to do the 10 minute
03:41 - timer with OB yet with a wire cast I
03:44 - could do this here's where I things are
03:46 - gonna go wrong today on the coding train
03:48 - I was like I'm gonna start immediately
03:50 - with coding talent I thought let me try
03:52 - to put a 10-minute time and then 45
03:55 - minutes later I'm trying to debug the
03:57 - timer you could turn up the overall
03:59 - volume level a little bit let's see if I
04:01 - can manage that
04:02 - oh it's quite low actually on the
04:08 - microphone there we go
04:10 - how's that I just turned up my volume a
04:13 - little bit so hopefully that's better
04:14 - for everybody now there's a browser
04:18 - source in OBS there's also a plug-in for
04:21 - timers all right I'm giving myself ten
04:24 - minutes to try to make a ten minute
04:27 - timer this is like okay ready so this
04:30 - now we're gonna have the timer - if only
04:33 - I knew how to program my own timer oh
04:36 - okay this timer now represents by ten
04:40 - minutes to get an open broadcast studio
04:42 - timer going okay so if I go here and let
04:48 - me open we try just using a different
04:50 - browser than the other browser I've
04:52 - opened just ten minute timer and then if
04:57 - I do this and then if I add a source
05:04 - display source image source scene video
05:09 - capture color source browser source
05:13 - create a new browser source ooh oh look
05:18 - at this
05:18 - oh and then I put the oh look at this
05:21 - I'm gonna I put the URL for this this is
05:28 - crazy how do I get the URL for this
05:40 - leave Paige
05:46 - oh my goodness oh my goodness oh my
05:52 - goodness here we go I better get myself
05:56 - 15 minutes for this coding challenge
05:58 - like 10 minute timer
06:01 - I really oh here we go
06:05 - copy now if I put this here paste okay
06:16 - okay whoa oh can I not feel can I
06:22 - interact with it
06:23 - I can't interact with it this is kind of
06:26 - wacky this is so weak I like a crop it
06:31 - what I can't interact can i refresh it I
06:39 - can't interact with it interact mode for
06:43 - others an interact mode I want the
06:45 - interact mode okay hold on properties
06:48 - local file shutdown refresh cache reload
06:54 - this page yeah okay but how do i how do
06:58 - I interact I don't see it interact will
07:05 - preview lock preview preview scaling
07:07 - full screen copy filters interact whoo
07:13 - look at that oh and I have now I can
07:15 - interact with it this is great I love
07:17 - learning open broadcast studio live well
07:20 - live streaming hello good morning
07:23 - maybe we'll get the tensor fluff chance
07:25 - today it's quite possible okay so now
07:28 - what I want to do is I want to know know
07:30 - I want to crop it how do i crop in I
07:34 - forgot how I crop in OBS this is
07:39 - changing the size I've done this before
07:42 - or but what if I just do this with
07:45 - interact whoa
07:54 - how do I crop
08:01 - holding alt oh my goodness okay you guys
08:04 - don't realize this is like a game of
08:06 - Twister so the computer for open
08:08 - broadcast studios monitor over here the
08:11 - mouse is right here and the keyboard is
08:13 - over here so what's the equivalent of
08:15 - alt on a Mac ctrl option there we go
08:24 - twister here there we go all right we're
08:31 - back and how do I I can't start it now
08:39 - okay hold on
08:40 - I have to unfold screen it I have to I
08:44 - have to refresh it refresh cache of
08:47 - current page okay we've got to start
08:49 - over here this is gonna be fine now
08:52 - though because stop oh I know I have to
08:56 - do option again option no option option
09:14 - option
09:16 - [Music]
09:18 - reset ten minutes can i key I'm out who
09:24 - cares that's fine okay did it everybody
09:27 - we did it and I still have I still have
09:31 - five minutes ago at this time okay oh
09:34 - yeah now let's make it 15 minutes let's
09:42 - make it a 15-minute timer is when was
09:45 - there ever a coding challenge completed
09:47 - oh the keyboard doesn't work in
09:52 - interacting with it oh my goodness are
09:54 - you serious this is crazy
09:57 - keyboard doesn't mean to work with
09:59 - interacting oh boy oh boy okay hold on
10:05 - hold on we can make this 15 minutes add
10:09 - it at interact no no no no not interact
10:12 - okay
10:12 - interact browser source where do I
10:17 - change the URL properties ten-minute
10:23 - just changes to 15 refresh cache of
10:28 - current page and no how about refresh
10:35 - the whole page there we go alright
10:43 - oh and interact alright now we're
10:49 - talking now we're talking
10:51 - just use the OBS timer plugin
10:54 - oh that would but I wanted to learn
10:56 - about how to have a browser thing in
10:59 - open broadcast studio so that's I'm glad
11:00 - that I learned that now alright so
11:31 - [Music]
11:49 - okay I can't see the I can't see the
11:53 - YouTube chat too easily I don't have any
11:55 - like good space sound effects I meant to
11:57 - get some space sound effects we won't
12:00 - have that for today next time Oh in fact
12:03 - I even have this great Darth Vader mask
12:05 - that like changes your voice and the
12:07 - Darth Vader but if I make it cousin the
12:10 - whole coding challenge wearing that
12:12 - which I'm sure would have been very
12:14 - entertaining for everybody another time
12:17 - one of these days I'm gonna have a lot
12:18 - more time to buy costumes and do more
12:21 - stuff whew it's getting warm in here
12:23 - let's get started
12:35 - hello wait okay I'm recording hello
12:41 - happy May 4th I'm gonna do Cody
12:44 - challenge for May 4th on the coding
12:48 - spaceship miss Cody challenge I'm going
12:52 - to make some scrolling text that looks
12:54 - as if it is scrolling off into the
12:56 - distance and it is the return of the
12:59 - 15-minute timer with yeah
13:01 - when has that ever gone wrong I mean
13:04 - it's always been so great to have the
13:05 - time for nothing if it goes wrong with
13:07 - the timer so um why am i doing this
13:09 - challenge today it's I don't know it's
13:11 - the 4th of May and I thought it might be
13:12 - appropriate and maybe someday I'll get a
13:14 - sponsorship and then I'll be able to you
13:17 - know have all these logos and music
13:19 - happening at the same time ok here we go
13:23 - let's start the timer and let's begin
13:26 - all right so I'm gonna do this in
13:29 - processing processing is a Java based
13:31 - programming environment if you were
13:32 - anybody else or if you were born after
13:34 - 1990 you would probably do some kind of
13:36 - like CSS transforms and have some crazy
13:38 - cool 3d text scrolling thing in the
13:40 - browser I'm old and I like to draw my
13:43 - pixels one at a time so here we go let's
13:47 - make a window that is let's just start
13:51 - with like 800 by 600 and let's let's it
13:54 - just admit the fact that we're going to
13:56 - be doing this in 3d and I'm going to add
13:58 - the p 3d renderer then in draw I'm gonna
14:01 - say background zero oh and I need some
14:03 - text hmm
14:05 - so let's make a text file but first let
14:07 - me save this and I'm gonna call this I'm
14:10 - gonna just say this is the desktop under
14:11 - May 4th challenge and I'm just checking
14:21 - the chat because I'm gonna need help
14:22 - definitely gonna help them at 14 minutes
14:24 - okay and don't get distracted don't get
14:27 - distracted okay text edit on the e key
14:30 - still doesn't work on this computer so
14:32 - many things going wrong format plain
14:34 - text so let's get some text I am using
14:36 - in this coding challenge processing org
14:39 - and so I don't know this looks like some
14:42 - good text oh yeah this is great let's
14:45 - look at this let's use this
14:47 - [Music]
14:49 - okay so I'm gonna save this as I'm gonna
14:53 - go to the desktop and I'm gonna go to
14:55 - May 4th challenge and I'm going to go to
15:00 - space dot txt you know II on fingers
15:04 - okay there we go so now in back in my
15:07 - sketch here I want to access that text
15:10 - so I'm going to create actually I'm
15:15 - gonna create a variable I'm gonna call
15:17 - it a txt I don't want to call it text
15:19 - because there's a function called texted
15:21 - processing and just so I don't confuse
15:23 - myself and once I'm going to use the
15:25 - load strings function and I'm gonna load
15:30 - what could I call that file space space
15:35 - dot txt but the thing is you might be
15:37 - wondering here I really don't have time
15:39 - to explain I'm going to anyway why do I
15:41 - have this array of strings called lines
15:43 - well it so happens that the load strings
15:45 - function loads a text file and takes
15:48 - every line from that text file it makes
15:50 - it a separate element in an array and
15:52 - this is actually very convenient in most
15:54 - cases but not so much right now so I am
15:56 - then going to instead say actually this
16:00 - might actually be really useful because
16:01 - I might I might want to make use of that
16:03 - array but right now I'm just gonna say T
16:05 - XT equals join lines lines
16:10 - join and then I will join them with the
16:13 - line break character and join good I'm
16:17 - going to join them with the line breaker
16:18 - lines not join hmm maybe I need to give
16:21 - it double quotes because it's not a
16:22 - character it's a string no oh let's
16:27 - check our errors cannot invoke join
16:30 - string on the type of string array oh oh
16:33 - right let's do this this is a processing
16:38 - function that exists called lines
16:40 - that's called join that's written into
16:43 - processing
16:43 - there's no join function for an array in
16:47 - Java I guess
16:49 - and the join function is part of the
16:51 - processing API where I can take an array
16:53 - and join them with a line break okay now
16:55 - we are going to say a fill 255 because I
17:00 - want my text to be white on a black
17:01 - background then I'm going to say text
17:05 - txt and I'm gonna say I'm gonna give it
17:08 - a bounding box of the full window and
17:11 - let's just run this and see what we got
17:13 - okay there we go there's our text it is
17:16 - in this window there it is
17:18 - alright let's do some stuff I really
17:20 - should think about the font oh I didn't
17:22 - even think about this do I have time to
17:24 - go look for the appropriate font for
17:26 - this particular simulation that I then
17:29 - I'm attempting to code without buzz
17:31 - marketing for free a particular
17:33 - commercial product
17:37 - oh it's a single anyway text font Oh
17:42 - text size let's just try text size
17:45 - sixty-four okay I also want to use it
17:49 - that's pretty good I also want to use
17:51 - text align and I want to full justify
17:55 - that's not gonna work
17:57 - let's try Center just out of curiosity
17:58 - what does that do uh it centers it okay
18:03 - centers it within that box well let's
18:05 - reuse that for right now okay we're
18:06 - doing well look at this I got ten
18:08 - minutes I have time to eat some melon
18:10 - there's gonna be really weird I I'm so
18:13 - confident about this code challenge this
18:16 - piece of melon which you're wondering
18:17 - what is the deal with this piece of
18:19 - melon it's purple it's blue this is the
18:22 - magical space melon that they eat on the
18:26 - planet ma Phooey
18:29 - that's the only planet I know
18:41 - I have delicious very good very low pH
18:46 - soothing of the throat okay
18:54 - sponsored by alien melon okay now what I
18:59 - want to do is I need a variable I'm
19:01 - gonna say I was about to say let but I'm
19:04 - in processing I need to specify the type
19:05 - float y equals zero lets you let's set
19:09 - the text at zero comma Y and let's say Y
19:12 - - - so Y is just going to change by one
19:16 - every frame and now we have scrolling
19:22 - text where'd it go oh look at this I
19:26 - gave it a bounding box which was the
19:28 - high OH
19:29 - this was gonna be a no edit this is
19:32 - gonna be a no edit coding challenge
19:34 - can't edit that out the camera went off
19:36 - it's fine it fixed it so I need to can I
19:40 - possibly make this bounding box without
19:42 - I mean I could just do this and here's
19:50 - the thing I want it to start right I
19:52 - want it to Y to start at height okay I'm
19:59 - getting some so now here we go
20:05 - processing is a flexible software
20:08 - sketchbook and a language for learning
20:10 - how to code okay this is great we're
20:15 - wasting time here
20:17 - all right I'm told there is a specific
20:18 - color that I'm supposed to use so let's
20:22 - change that r75 2 1 3 2 3 8 all right
20:33 - across the thing is a flexible software
20:37 - sketchbook I there must be a specific
20:39 - font it also needs to be full justified
20:41 - I'm gonna see if I can manage that but
20:44 - here's the thing
20:44 - it's so this is just scrolling up but I
20:46 - I have made this do not forget AP 3d
20:52 - sketch we
20:53 - means what I can do right now is I want
20:55 - to rotate the scene this way now if this
20:59 - is if this train whistle is representing
21:02 - my axis of rotation this is the z axis
21:05 - that would be something spinning around
21:06 - so if I were to just say for example
21:09 - whoops let me zoom back out here and say
21:11 - something like oh let me rotate by you
21:14 - know 45 degrees which is radians of 45
21:18 - or I'm gonna say PI pi divided by 8
21:21 - no pi divided by 2 is 90 so pi divided
21:24 - by 4 is 45 degrees we should see the
21:28 - text it's completely gone
21:32 - why I need to look I need to rotate
21:35 - around the center I need to rotate
21:37 - around the center of this oh look at
21:39 - that there it goes here comes it's kind
21:43 - of like this
21:50 - that should be the sound effect that
21:52 - goes along with this all right so I what
21:53 - I want to do is rotate by X but let's I
21:55 - think actually what's going to make more
21:56 - sense is for the world of this universe
21:59 - that I'm building to be have its origin
22:03 - point in the center so really what I
22:05 - want is for I'm going to take out the
22:07 - rotate really what I want is to
22:10 - transport or agender oh so now I want
22:14 - that origin point to be in the middle
22:16 - and you're going to see it now
22:17 - why am I not seeing anything I will
22:20 - eventually it's very slow the scrolling
22:22 - text high-wage too overconfident about
22:26 - this but so now what I want is for the
22:29 - text actually to not be at 0 comma Y but
22:33 - to be at negative width divided by 2 so
22:36 - offset it and then Y can start at height
22:40 - divided by 2 and now we should see back
22:46 - to what I had before and now hopefully I
22:51 - can now rotate right this was this will
22:56 - now rotate my text along the z axis so
22:59 - it's doing that but what I really want
23:01 - to do is I want to rotate it along the x
23:04 - axis I wanted to like sort of fold down
23:06 - so I want to say rotate X and processing
23:15 - is a flexible software is it too slow or
23:20 - is that actually the appropriate speed I
23:21 - also can't see it at all so let's make
23:25 - it much wider Oh wrong color I'm told
23:31 - 238 to 1375 I did it backwards ok
23:41 - processing is a flexible software
23:44 - sketchbook and a language for learning
23:49 - how to code within the context of the
23:54 - visual arts I don't know that's going
23:56 - kind of slow let's uh let's have this go
23:58 - a little bit faster what else does this
24:01 - need this is done
24:03 - done four minutes ago yeah there we go
24:12 - what else should I do that is
24:16 - approximately the right speed yeah so
24:18 - the one thing is I pretty sure that if I
24:20 - were being true to this particular
24:22 - design it really should be full
24:25 - justified I'm trying to think of how to
24:27 - do that
24:28 - make it like 80% of the width yeah so I
24:31 - guess what I should do also the bounding
24:34 - box I guess I can adjust the bounding
24:40 - box ya know but that's not doing me any
24:45 - good because why doesn't that Oh No okay
24:55 - so negative width so hold on so I need
24:58 - to let me just make this so this should
25:03 - be negative W device so I want the
25:05 - bounding box and the text to be centered
25:08 - based on the bounding box so I've got a
25:10 - and I want that bounding box don't have
25:11 - to be the full width so I'm shrinking it
25:13 - by like eighty percent and I probably
25:15 - should have the font the text size be
25:17 - related to the width as well so it was
25:20 - like 1200 divided by 64 mph it was 60
25:23 - point that would be a hundred two
25:26 - hundred so I could say width divided by
25:29 - 200 right oh no I meant to say not 220
25:35 - so let's do this and so that's right I
25:43 - guess the size is too big actually so
25:46 - let's make the text size width divided
25:47 - with times 0.15 and now whoa I meant oh
26:00 - one five know what I'm doing anymore
26:09 - don't just make up numbers so no point
26:12 - force can be really thick
26:15 - oh five 5% oh yeah 5% I prefer good
26:20 - let's make it a little smaller let's
26:22 - make it like 3% this is really the way
26:25 - this is the way to program just try
26:27 - different numbers
26:28 - oh the width is still too wide ah this
26:32 - is the problem I liked my size I wanted
26:38 - to enter there we go thank you
26:43 - that only took me so I have a minute 42
26:45 - seconds left processing is a flexible
26:47 - software sketchbook and a language for
26:50 - learning how to code within the context
26:51 - of the visual arts okay what else do I
26:53 - need to do in my minute and a half that
26:54 - I have left text mode is model or shape
26:57 - yeah yes so there is a textbook do the
27:00 - full justified no I have a challenge to
27:02 - you try to oh and I did the reason why I
27:07 - was doing this is because I wanted to
27:08 - demonstrate Processing's wonderful
27:10 - fullscreen function and whoa that's
27:23 - weird why did that happen when I went
27:27 - full screen huh do I just need to rotate
27:34 - much more what what did I do to deserve
27:39 - this
27:41 - that's so weird what if I do this how am
27:47 - i doing on time
27:59 - yeah that's so weird why would I went
28:03 - full scope from p.3d thank you
28:05 - I feel under I'm a so of course size is
28:11 - where you specify the width and height
28:13 - manually and a particular renderer if I
28:17 - say full screen I still need to specify
28:18 - the renderer so it was working but it
28:20 - just defaulted to a 2d renderer and
28:22 - rotate X didn't work Oh time run off
28:28 - I finished here we go we're done oh I
28:39 - can't do the gibreel slag I can't talk
28:43 - while I'm eating how does he do it
28:45 - somebody's gotta tell me we don't know
28:48 - what I'm talking about
28:49 - check out de brillz YouTube channel I
28:51 - have now made a sideways scrolling
28:54 - yellow text thing with no theme music or
28:56 - branding whatsoever with some processing
29:00 - text in the amount of time that I was
29:03 - given it really should have it really
29:07 - should be full justified I will leave
29:09 - that to you I hope you make a version of
29:11 - this please make some but that timer do
29:13 - you hear the timer or you just hear it
29:17 - cuz I really want to hit okay okay make
29:22 - your own version of this add stuff to it
29:25 - to make it more fun or different or with
29:27 - your own style I'll try to make a
29:29 - JavaScript version of this with p5 and
29:31 - the WebGL renderer p5 we could make a 3
29:33 - J s1 and then of course all of you who
29:37 - know more than I do
29:38 - prop many of you could probably make a
29:40 - CSS one with transforms and all that
29:44 - fancy new stuff I know Sarah Dresner who
29:47 - is like my CSS probably knows a way to
29:52 - do this ok put a star-filled behind it
29:54 - yes you can do that goodbye I'm gonna
29:56 - finish this I'm just like I'm just gonna
29:57 - be done with this cozy down goodbye ok
30:03 - there that was the coding challenge for
30:06 - this morning start tensorflow okay yeah
30:12 - yeah all right people want me to start
30:14 - tensorflow okay it's very warm in here
30:17 - I should probably tweet that I'm going
30:22 - to start the tensor flow stuff now so
30:24 - let me close this out come up and save
30:30 - this oh wait I have to do something I
30:32 - have to remember I have to stop I just
30:40 - have to do a little housekeeping here to
30:42 - upload this because I I'm gonna release
30:44 - that today as a standalone coding
30:46 - challenge so I need to upload this to
30:49 - Google Drive Oh No so I've been using
30:58 - this old Google Drive software on this
31:00 - computer and every time I come up here
31:02 - it tells me this software you using
31:04 - we're not gonna we're not supporting it
31:05 - anymore you should really like update to
31:07 - blah blah blah new Google Drive thing I
31:09 - just never bothered to do it it looks
31:12 - like it actually finally but it's no
31:14 - problem because what I'm going to do is
31:17 - I'm just going to you're just gonna have
31:19 - to bear with me here I'm gonna do this
31:24 - manually I have to log in through the
31:27 - browser at account oh no no I'm actually
31:30 - logged in right I want to be in oh no I
31:34 - want to go to this one so sorry I need
31:37 - to upload the video file for that it'll
31:39 - just take me a second and I have to oh
31:43 - my god I have to put in my net ID and
31:50 - then I have to oh wrong password
31:54 - seriously and then I need to send myself
32:01 - a push for two-factor authentication
32:04 - this is really good and I'm gonna say
32:09 - approve yep okay now I'm in Google Drive
32:15 - I'm gonna go to the coding rainbow
32:17 - folder that's what it's called did that
32:19 - that's right I said it
32:20 - I'm gonna make a new folder I'm gonna
32:23 - call
32:23 - may 4 and I'm gonna create that folder I
32:27 - know you can't see what I'm doing
32:28 - someday I will share my open broadcast
32:32 - studio machine screen then I need to go
32:35 - to the browser I need to go to the
32:37 - desktop I need to grab this file which
32:39 - is 1.25 gigabytes and upload it and it
32:44 - is uploading less than a minute left
32:46 - hopefully this isn't messing with the
32:48 - streaming and then I'm going to come
32:50 - back here and hit start recording again
32:52 - then we can get rid of the I can close
32:56 - this browser source thing unless I need
33:00 - a timer again and I can close this and I
33:06 - can come back to the chat and there we
33:10 - are okay so I don't know
33:12 - so it's 11:15 I have about two hours
33:16 - which is pretty good actually I am going
33:21 - to try to recall does it bother you if I
33:27 - have this up higher it's just that you
33:30 - could see the keyboard of the other solo
33:32 - for some reason maybe what I usually do
33:34 - actually is laptop unhook no green
33:41 - screen unhook move this down a little
33:44 - bit so I'm a little bit lower but now I
33:47 - can move this up a little bit yeah
33:49 - that's better
33:50 - okay and then lock all right sorry for
33:54 - all this configuring stuff no audio no
33:59 - the audio must be working you line up
34:04 - the timer with the end and the rest just
34:06 - plays I don't know what's taught but
34:08 - what you got I don't know what
34:09 - everybody's talking about in the chat
34:11 - okay so I now I'm going to open up
34:17 - terminal I'm gonna go to the desktop and
34:25 - I'm gonna go to p5 tensorflow
34:28 - and I'm going to open up atom text
34:31 - editor so I've got this is where I last
34:35 - left off
34:37 - and I'm going to run a server I am going
34:47 - to type in my password then I'm going to
34:57 - open up the browser localhost it and hit
35:09 - refresh this is where I last left off
35:12 - like this little wider oh I have plenty
35:18 - more room here I'll move this over okay
35:22 - and then we need to get to the API
35:28 - reference and okay so here let me make a
35:35 - list of the things that I want to talk
35:38 - about reshape where are the oh is it in
35:47 - here TF tensor flatten a scalar as 1d as
35:50 - 3d as 40 as tight buffer data disposed
35:53 - to end perma shape reshape expand
35:56 - squeezed clone where are the math
36:00 - operations for tensors
36:12 - can categorise model with layers so I'm
36:22 - just looking here Oh operations this is
36:24 - what it's down here okay so what I need
36:27 - to let me make a list here this camera
36:29 - is off I think that I don't need any of
36:38 - this anymore so I need to get myself
36:40 - organized where do I have some paper
36:44 - towels here to erase this whiteboard Oh
36:50 - might have a slight problem I'm missing
36:54 - a key supply where would it have gone I
36:57 - wouldn't have used it all up
37:00 - somebody we have another mystery I would
37:03 - play the serial podcast
37:04 - theme music again but the copyright
37:06 - violation for that last time it's like
37:08 - can't do that again uh-huh well I have
37:14 - this remnant of a paper towel maybe I'll
37:19 - use that how far will this get me pretty
37:26 - far
37:32 - so I want to make a list of the other
37:35 - tensorflow J s kind of just general
37:41 - topics that I want to discuss for
37:43 - example I want to talk about memory
37:45 - management I want to talk about if we
37:48 - need a bigger paper towel then this
37:50 - piece these are some tissues oh there
37:53 - they are
37:54 - they're the paper towels found them okay
38:07 - not very much this paper towel roll save
38:11 - the earth everybody I probably should
38:15 - get a reusable I mean I try to use the
38:18 - eraser whenever I can but when I'm this
38:21 - is tends to work better just a little
38:22 - water and a paper towel but at least I'm
38:25 - being only using one little tiny slice
38:30 - here so I want to make a list and I
38:33 - don't think that I'm going to make a
38:35 - completely comprehensive set of
38:37 - tutorials of every single piece of
38:40 - what's inside tensorflow das but the
38:48 - things the things that I've done so far
38:50 - if I make this list let me do it over
38:53 - here so so far what have I done so far I
38:56 - did kind of like an intro check I also
39:02 - made a video where I talked about
39:06 - tensors check so the other things that I
39:12 - need to do are I think this could be in
39:14 - one variables and memory management then
39:25 - I want to talk about operations and then
39:31 - I want to look at so if we look at the
39:34 - operations in the API like what might be
39:37 - a small list
39:44 - down here like add subtract multiply
39:47 - square difference math so I don't know I
39:50 - I don't think I'm gonna I don't think I
39:52 - need to go over all of these
39:54 - oh but matrix multiplication definitely
39:56 - then there's some of these convolutions
39:58 - so I you know there's a lot of stuff
40:00 - here so I'm gonna go over the basics to
40:03 - lay a foundation and as I go and make
40:05 - other examples we might return to some
40:07 - of these but so I do I want to talk
40:11 - about operations and then I want to talk
40:14 - about the layers API and then I want to
40:19 - do X or color predictor and a doodle
40:26 - classifier this is my and then after
40:34 - that I'm going to move on to ml five so
40:38 - this is kind of I mean in theory I had
40:42 - hoped to get all the way through X or
40:44 - today I don't know if that's
40:46 - particularly realistic but this is what
40:49 - I'm going this is my plan for I'm going
40:51 - to cover you know between now and the
40:53 - beginning of June I would say I think I
40:55 - can get through all of this between now
40:56 - the beginning of June and then in June
40:58 - I'm gonna focus on this new machine
41:00 - learning library that's built on top of
41:02 - all this stuff called ml five so that's
41:04 - my plan let me just take a moment to
41:06 - look at the chat the Select channel for
41:08 - patrons and see if there's any questions
41:10 - or comments or anything that I'm kind of
41:12 - missing that's key here of course you
41:20 - know I can't win I come back and look at
41:26 - the chat know what's being discussed is
41:28 - whether I should use Visual Studio code
41:30 - or Adam haven't you all learned anything
41:33 - the code editor is not the point it's
41:37 - theme ideas the way of being together as
41:40 - human beings in the world yes I mean you
41:43 - might like Visual Studio code yes I
41:45 - might like Adam yes I probably would
41:46 - like Visual Studio code more if I just
41:49 - used it you know I could I could put
41:51 - some firmware on this camera so it would
41:53 - stop shutting every time
41:55 - minutes why let's just enjoy ourselves
41:58 - all right I'm gonna check the chat again
42:00 - so I got some thumbs up from Caitlin
42:04 - thank you very much
42:05 - I mean okay um yeah butBut vim I know a
42:16 - good point
42:17 - you would think me being you know kind
42:20 - of of a earlier generation of programmer
42:24 - that I might be using something like vim
42:26 - the problem is I didn't actually start
42:28 - learning to program until I was 20 this
42:31 - is not entirely true because I always
42:32 - have to qualify this but I I like to say
42:34 - that it didn't start programming till I
42:36 - was 28 which is true because I never did
42:39 - it other than like a little thing and
42:42 - basic on an Apple 2 plus when I was in
42:44 - like maybe fourth grade I think I took
42:47 - one class in middle school where we
42:48 - actually did some assembly language and
42:50 - I took one course about programming and
42:52 - C++ as like an evening course after a
42:55 - question from college but none of those
42:57 - really ever took with me so so I didn't
43:00 - actually grow up with vim for example
43:05 - all right
43:07 - why don't you use NPM server that's also
43:11 - a very good question there's no reason
43:12 - there's absolutely no reason because my
43:16 - fingers remember how to type Python - em
43:19 - and I I think actually with the kinds of
43:22 - tools that I use using like a live
43:25 - reload Sewer server so many things could
43:27 - make more sense all right
43:29 - okay so let's let me look at variables
43:34 - for a second actually know this I made
43:37 - this list and it's like I don't really
43:39 - know any of this I'm trying to learn it
43:42 - as I make these videos which I should
43:44 - probably say when I start the next one
43:46 - variable so variable oh you can make a
43:51 - variable out of a tensor oh so that you
43:56 - can like train it I see so the thing is
44:00 - this is not I'm gonna go and use the
44:02 - layers API so I'm less likely to end up
44:06 - being but I think it's good too
44:09 - Inchon this stuff so ot have zeros I
44:11 - like that I'm getting notifications on
44:14 - my yes tidy yes yes yes yes tidy dispose
44:19 - these are good points thank you Eric
44:26 - people are guessing that I'm 50 usually
44:30 - people guess them let's not talk about
44:33 - my age it's not the point of this these
44:35 - videos alright so let us begin I think
44:47 - I'm going to turn the notifications off
44:48 - on my wash but it doesn't it doesn't
44:51 - actually help okay
45:00 - all right oh this needs a little work
45:08 - better better
45:13 - okay No hold on I need a little more
45:19 - tape here bear with me
45:35 - I fix the problem I think I did okay
45:47 - great
46:02 - all right this is my third tensorflow
46:05 - chance video and I actually just a
46:07 - moment ago I made this list so what have
46:09 - I done so far I have made an
46:11 - introduction to where tensorflow J is
46:13 - sort of fits into the kinds of stuff
46:15 - that I'm working on and thinking about I
46:18 - made an intro video to the idea of what
46:21 - a tensor is and how to make a tensor a
46:23 - variable that stores a tensor in your
46:25 - JavaScript code and now you really what
46:29 - I want to do is I want to get down to my
46:31 - goal is to get to the point where I'm
46:32 - remaking earlier machine learning coding
46:35 - challenges I did but instead but using
46:37 - tensor flow j s as the basis for them
46:40 - the foundation for them so the things
46:42 - that I think that I need to mention and
46:44 - talked about before I get to that is I
46:46 - need to talk about variables and memory
46:48 - management there's something difference
46:50 - between a variable and a tensor there's
46:52 - they're kind of a similar thing but it
46:54 - has to do with memory management I would
46:56 - talk about operations so mathematical
46:57 - operations that you can do on these
46:59 - tensors the layers API that's a really
47:02 - that's like the topic I'm the most
47:03 - excited about on this list and so once I
47:05 - can do three more a little quick general
47:08 - tensor flow dot J's videos which are by
47:10 - no means comprehensive as to everything
47:12 - that's in tensor flow that is to much
47:14 - larger API than what I'm going to cover
47:17 - and also I don't actually know any of
47:19 - this stuff I'm just kind of figuring it
47:21 - out as I go so I'm trying to talk you
47:23 - through me learning it so just in case
47:24 - you're thinking you're watching a video
47:25 - by an expert and then and then I'm gonna
47:30 - get to these coding challenges and then
47:31 - I've teased this before but there's a
47:34 - new library called ml five which is
47:36 - built on top of tensor flow Jas which
47:38 - I'm going to eventually do a lot of
47:39 - tutorials and videos and hopefully bring
47:41 - some guests in also to do stuff with ml
47:43 - 5 ok so back to the computer you could
47:49 - like edit this and I could just reappear
47:51 - over there no point in doing this all
47:53 - right so I'm back so the where I left
47:55 - this off I think if we look at this code
47:57 - that I had is I created a tensor I use
48:01 - tensor 3d because I knew the shape was
48:04 - going to be of rank 3 having three
48:06 - dimensions yes and this is the shape I'm
48:10 - putting integers in it
48:11 - I'm console logging it and in
48:14 - and we can see the results here now
48:16 - incidentally I think I should also note
48:18 - that if I actually want to look at the
48:21 - data not just seeing it the string of it
48:25 - like printed out there then what I want
48:27 - to use is actually the data function oh
48:30 - wow I probably shouldn't have called
48:32 - mine data so let's call it a tensor
48:34 - price shouldn't call it that either
48:36 - let's call it tense a very tense tense
48:39 - data now this is gonna be a problem I
48:42 - think let's see what happens here and
48:43 - this is this is gonna relate I don't get
48:45 - to the point here you'll see you'll see
48:48 - look at this a promise oh that's so nice
48:52 - of tensorflow not gesture promise me
48:54 - something what are you promising so
48:55 - here's the thing there's something weird
48:57 - going on here and this is actually
48:59 - really the topic of this with variables
49:01 - and memory management in that there
49:03 - something is happening here something is
49:05 - happening right here these values are
49:08 - stored in a plain old array that's in
49:11 - the computer's memory and when we make
49:13 - this tensor out of them that data gets
49:17 - copied onto the computers graphics
49:20 - processing unit the GPU that takes some
49:23 - time and we want to minimize the amount
49:25 - of times we have to copy memory back and
49:28 - forth so this is the thing we have to
49:29 - think about as we build more examples in
49:31 - code and in fact this
49:41 - this here is doing this asynchronous
49:44 - this this here is doing this a secretly
49:47 - now I wonder if I could give it a call
49:48 - back I'm just gonna experiment here I
49:53 - think they're only using this thing
49:55 - called promises which I made a video
49:57 - tutorial about this yeah there really
49:58 - need to so what happens if I give it a
50:02 - call back to see like oh can I can I
50:04 - give it a call back there oh wait so
50:06 - let's let's do this and see like oh
50:10 - let's give it a call back and then see
50:11 - if we can look at the stuff that comes
50:13 - out of the call back let's see what
50:15 - happens there no because I have too many
50:18 - parentheses yes
50:19 - too many parentheses no nothing happens
50:22 - there so it's not using and and I'll cos
50:26 - told me I could use a wait but I owe
50:28 - this there's so much es6 and beyond
50:31 - JavaScript going on here
50:32 - so actually what I want to do is if I
50:36 - say tense dot data I can save then and
50:39 - then is this special function that's
50:42 - part of a promise where it's saying like
50:44 - once the promise has been resolved
50:46 - you've made a promise to me you're going
50:48 - to keep that promise and when that
50:49 - promise comes to roost cockadoodledoo
50:53 - then I can can I just write code in
51:00 - there no I have to make a function I can
51:03 - say console dot log stuff so how it
51:10 - works yeah look at that so there we go
51:12 - we can see this is one way but I
51:14 - actually don't want to deal with any of
51:16 - this so because I want to just so this
51:19 - is something that's going to come up
51:20 - let's try to avoid this and there's also
51:23 - a keyword called await that I could
51:25 - potentially use but luckily there is
51:29 - also a function called data sync so if I
51:33 - use the function data sync you can see
51:38 - this here what this will do is actually
51:40 - give me all the data back but without
51:46 - without the but-but-but-but block but
51:49 - wait wait for it to be done so now
51:51 - we should be able to say boy really very
51:55 - tense so you see here it is and then
51:56 - here's I notice it all came back as a
51:59 - one-dimensional array hmm
52:02 - so oh yeah I have I have used timeout
52:07 - for a second
52:08 - think about this I should probably go
52:11 - back I'm trying to think I waded into
52:21 - this territory of promises that I didn't
52:23 - mean to almost want to like start this
52:25 - over because I do need to come so like
52:30 - like I do need to it is gonna be
52:35 - something there's no way around it
52:37 - this is why ml5 exists because what I've
52:40 - been working on this stuff for ml5 have
52:42 - been kind of like hiding all of the
52:45 - await async stuff and just using
52:47 - callbacks but promises are the way of
52:49 - the world aren't they I'm in a couple
52:51 - years am I just gonna all these if I've
52:53 - still using callbacks in the older-style
52:55 - am I just going to be I don't know I
52:57 - don't know the answers to these
52:58 - questions but what's interesting here is
53:04 - all the data comes back in a
53:05 - one-dimensional array which I guess is
53:07 - kind of normal because I'm asking for it
53:09 - as just the raw data again there's also
53:12 - the get function right just curious
53:15 - about this like if I say get does that
53:20 - works I think that's how I can get one
53:25 - yeah so night that gives me 94 can I do
53:28 - something like this
53:30 - 46 uh yeah but wait oh no was it just
53:36 - giving me whoops undefined so shouldn't
53:40 - I be able to get if it's three
53:41 - dimensions I don't know but I can do
53:44 - this get 28 and that should be 10
53:49 - because this is 29 and this is 10 so
53:52 - there's also get and get happy I guess
53:54 - cuz get you're only looking at one at a
53:55 - time that doesn't need a callback or
53:58 - promise call
54:02 - blacks are dead long live promise got it
54:07 - got it dude - trills okay it would never
54:19 - be 2d or 3d its doors they have things
54:21 - that's right it's always the 2d the
54:24 - shape is really a concept for us
54:26 - ultimately the data is just a list of
54:28 - numbers okay so
54:46 - okay back to recap this is what the
54:49 - tensor is and this is this is the way
54:51 - that we're thinking about the tensor and
54:53 - how the data is stored and the print
54:55 - function allows us to see that they're
54:56 - easily in the console if I want access
54:58 - to the data the data sync function will
55:01 - just give me all of that stuff
55:02 - ultimately just as a list of numbers
55:04 - because this idea of the different the
55:06 - shapes and the dimensions is really for
55:08 - you know us as human beings to think
55:10 - about it and store it but ultimately
55:11 - it's just a bunch of numbers so I should
55:13 - also mention that in addition to data
55:15 - sync there is also a get function so if
55:18 - I were to say tense dot get and I were
55:23 - to say zero we would see I've got the
55:28 - number 80 which is right there and if I
55:30 - were to say one I've got the number
55:32 - forty one and if I were to say you know
55:35 - a twenty nine which would be the last
55:37 - one I've got the number forty-seven
55:40 - so get is another way I can start to
55:42 - pull that stuff out data sync data and I
55:45 - need to come back and I probably should
55:47 - add something about like what we need to
55:51 - support some of this stuff that I
55:53 - haven't really talked about is a video
55:54 - on promises promises and also one on a
56:00 - weight and async and promises are oh I
56:08 - went to I went to high again I let's
56:12 - don't worry everybody
56:17 - we're just Matt to to the rescue I
56:23 - really should add an addendum here which
56:26 - is that in order to support this
56:28 - material that I'm covering at some point
56:30 - I need to come back and make a video on
56:33 - promises and how the arrow syntax is
56:37 - often typically used with promises and
56:38 - this then function so these are
56:41 - something I need to come back and do
56:42 - some additional content on as well as a
56:45 - weight and a sink because if you want to
56:48 - work with this
56:50 - particular library how these new ways of
56:54 - handling synchronous and asynchronous
56:56 - things in JavaScript are kind of key
56:58 - foundational elements I've got to come
57:00 - back and talk about this I would suspect
57:02 - that funfun function has some nice
57:04 - videos on these topics but I don't know
57:06 - so maybe I'll link to those in this
57:08 - video's description ok but the point of
57:11 - what I was saying is what if what I
57:13 - wanted to do right now is I wanted to
57:16 - change some of the numbers for example I
57:19 - wanted to do the equivalent of saying
57:20 - something like 10 set 0 to 10 in other
57:27 - words I'm sure this doesn't exist but
57:28 - what if what I wanted to do is say like
57:30 - oh whatever number is in the first spot
57:32 - in the tensor I want to change it to
57:35 - something else well I actually can't do
57:37 - that these tensors once you've created
57:40 - them are immutable and that means the
57:43 - values can never ever be changed this is
57:47 - different than this like Const
57:49 - declaration which just means you can't
57:50 - like reassign a variable name but you
57:53 - can might be able to like change the
57:54 - internal data of an object that's
57:56 - different these tensors absolutely
57:58 - cannot be changed so if you need to
58:02 - change the values and you might in a
58:04 - kind of learning system you're building
58:06 - right what if you're storing all the
58:07 - weights of a matrix in a tensor and you
58:10 - want to adjust those weights rather than
58:12 - copying into new tensor to new tensor
58:14 - this is where the concept of a TF dot
58:17 - variable comes in so I can say Const bar
58:23 - oh I shouldn't Const V tense oh boy this
58:28 - is getting really weird TF variable
58:31 - tense I can take a tensor and make it
58:35 - into a variable by passing it through TF
58:38 - dot variable so let's just look at this
58:42 - and sort of see what's there and we
58:47 - whoops us we don't want this set thing
58:51 - and you can see now this looks very
58:54 - similar it has a shape it has a data
58:57 - type but it's now stored differently
58:59 - this is because tensorflow has a kind of
59:02 - low-level library
59:03 - managing web the data using the graphics
59:08 - card intensively really needs to do
59:11 - different things it has to manage the
59:13 - memory differently if the stuff is never
59:14 - going to change versus if it's going to
59:15 - change and so if I go now to tension
59:18 - flow Jas and I look here at TF variable
59:21 - we can see this is now something that
59:26 - has a new parameter called trainable so
59:29 - in fact you can add this thing called an
59:30 - optimizer to it and adjust it so that's
59:32 - an important thing I wanted to mention
59:33 - and I'm just going to leave it at that
59:36 - for right now if I need to use a TF
59:38 - variable later we'll come back and look
59:39 - at when when I might want to use a TF
59:41 - variable versus just a TF tensor okay so
59:56 - I'm just taking a pause here for another
59:59 - little and I feel like I could do as
60:02 - many positive edits as I want now
60:04 - because I did that coding challenge in
60:06 - 15 minutes
60:08 - hmm I also I need to have one more piece
60:12 - of melon don't worry this is the last
60:13 - piece of melon
60:24 - memory management okay
60:39 - all right let's talk about the next
60:42 - piece of this which is memory management
60:44 - so let's say I'm going to now all of a
60:47 - sudden take I'm going to get rid of this
60:50 - variable thing and I'm gonna take all of
60:53 - this code and I'm gonna put it in draw
60:59 - what does that mean this means I am
61:06 - making a new tensor 30 or 60 frames per
61:10 - second this could have 30 pictures I can
61:12 - every time through draw so let's let's
61:15 - go and do that
61:16 - ooh oh and I don't
61:19 - where's the veto I don't need this in
61:22 - fact I can get rid of all this stuff
61:24 - right now so again this this code isn't
61:27 - doing anything but it's gonna I'm gonna
61:28 - make new tensors every time through draw
61:31 - so here it it's chugging along so how do
61:35 - i somebody somebody must know there's
61:38 - probably a way right can I go to like
61:40 - for memory a heap snapshot sure take
61:44 - snap take snapshot yeah all right
61:51 - somebody else somebody help me out here
61:53 - kites I use the task manager whoops task
61:59 - manager
62:04 - I want to see the fact that I have like
62:11 - a memory leak here just gonna show it
62:17 - yeah so let's make this more extreme so
62:28 - this code is running running running and
62:30 - what I want to do is check how much
62:32 - memory it's using now there is this
62:34 - there are different like memory and
62:36 - performance evaluation tools so they can
62:40 - use in the developer console I'm gonna
62:41 - do something a little simpler right now
62:43 - I'm just going to go here to the task
62:44 - manager in Chrome and in task manager
62:47 - I'm going to is I'm gonna wait them it's
62:49 - gonna take a minute to wake up here but
62:51 - what we can see is the memory footprint
62:54 - so the browser as a whole I have a tense
62:56 - I have the tension flow Jeff's website
62:58 - and then this is the tab for my code and
63:00 - also there's like a GPU process running
63:02 - so what I want to do is look at this
63:04 - seventy five point eight point nine
63:07 - seventy six point three point four so
63:15 - this is actually just going up kind of
63:16 - slowly but it's going up it's never
63:18 - going back down if you are writing
63:20 - software where the usage of memory just
63:23 - keeps increasing over time and never
63:26 - stops this is what can be known as a
63:28 - memory leak I have to pause for a second
63:31 - I don't know if Nikhil I don't think the
63:33 - keel is watching today I forgot to tweet
63:35 - that I started this
63:37 - Nikhil is one of the creators of
63:38 - tensorflow digest is this memory
63:40 - actually the right thing to look at
63:45 - because what I want to show is how the
63:52 - like would that actually show up here if
63:55 - it's using like the GPU memory like this
63:59 - which is different like is it actually
64:02 - this that I should be looking at GPU
64:04 - process that's going well let's see what
64:07 - I'm going to do is let's change this to
64:09 - B so this is 2 by 5 by 3 so it's 15 by 2
64:15 - if we do it 15
64:18 - by like by a hundred let's just do a lot
64:20 - more and let's let's be really extreme
64:22 - about it got to come back and do this
64:38 - I suspect I mean certainly going up a
64:44 - lot faster so maybe it is the GPU
64:52 - process is staying stable and this is
64:55 - going like way up way faster right I
65:01 - would have thought it would be on listed
65:03 - under the GPU process
65:13 - yeah but look at that but you can show
65:19 - GPU member by right-clicking on the
65:20 - header of the chrome task manager and
65:22 - choosing GPU memory I'm trying to right
65:31 - click on the header of the task manager
65:37 - I'm not seeing how to do that whoops oh
65:44 - and the keel is in the chat no that's a
65:47 - different Nikhil that's a different
65:49 - Nikhil
65:50 - well hello Nikhil Siviglia different
65:53 - Nikhil then Nikhil Thor at unless
65:54 - Nichole Paredes in the chat table header
65:57 - row oh there we go
66:01 - memory footprint GPU memory
66:20 - it's interesting because the memory leak
66:22 - is clearly here looked all over couldn't
66:29 - fine right that's clearly the memory
66:31 - leak but the GPU memory is tiny and this
66:45 - is stable I mean let's hold on let's I
66:51 - mean let's be a bit more thoughtful here
66:54 - let me do this because it's just not
66:58 - garbage collecting whoops sorry that I
67:02 - have to take this break here like does
67:06 - this stay stable now I'm not making
67:08 - anything yeah so this is a bit of a
67:12 - mystery to me why the memory leak would
67:16 - show up here under memory footprint is
67:19 - it possible that I don't have GPU
67:21 - enabled how would I test that
67:35 - override software overrides the building
67:39 - software and enables jeep an unsupported
67:43 - that's enabled I think I have GPU
67:49 - enabled Oh GPU only gets involved once
67:53 - you train you can't fill up the CPU
68:05 - memory either it's just a gate you won't
68:10 - see the GPU process the other GPU is
68:12 - enabled I think that K we c'mon right
68:15 - I think the GPU only gets involved once
68:17 - you train the tensors are only moved to
68:19 - GPU memory when you start doing
68:21 - calculations why else would it be moved
68:24 - to GPU memory it does make sense that is
68:29 - a very very good point got it got it the
68:34 - GPU is just for computing okay so like
68:38 - if I were to do something like yeah but
68:43 - this still is a memory leak like watch
68:45 - now so maybe I don't need to get into
68:56 - like right now I fixed the memory leak
69:01 - with by calling dispose this is what I
69:07 - wanted to demonstrate so I think I'm
69:09 - actually demonstrating this quite well
69:13 - which there was a key command to get the
69:41 - this is the one that should be going up
69:49 - before it was like crazily going up and
69:52 - now it's not anymore
70:04 - interesting
70:21 - okay I keep this
70:27 - there we go there we go okay alright
70:32 - alright come back that's you I'm gonna
70:41 - be this is gonna rewind all the way back
70:46 - [Music]
70:54 - okay so there are a lot of tools here in
71:01 - the in the chrome developer tools where
71:04 - I can evaluate performance and memory in
71:06 - a very detailed way what I'm actually
71:07 - just going to do is go to this task
71:09 - manager and what you'll see here with
71:11 - the tax task manager is it's shoving me
71:13 - I have the developer tools open
71:15 - I have tensorflow J the the page the
71:18 - webpage retention flow digest and I have
71:20 - my my sketch open in this particular tab
71:23 - here so what I want to do here let me
71:25 - just save this code and I move this over
71:28 - here and hit refresh so we can look and
71:32 - we can see like okay well what is the
71:33 - memory footprint this is the memory
71:35 - footprint right now of that with my
71:38 - sketch how much memory it's using now
71:40 - there's a question of is the memory CPU
71:42 - GPU and that's an interesting piece of
71:45 - complexity and it just sort of went down
71:46 - the truth of the matter is I'm like not
71:48 - doing very much let me go back and
71:51 - change this to like this was to 5 by 3
71:54 - matrices so what if I made 10,000 of
71:56 - them and so that would be 15 10,000
72:01 - times 15 numbers that I need and let's
72:06 - go back and let me move this over here
72:08 - and hit refresh and now if I take a look
72:13 - at the tab
72:21 - it's you can see it's starting to go up
72:30 - hold on why why is this misbehaving with
72:37 - me and not demonstrating what I wanted
72:39 - it to demonstrate I have to kill the
72:47 - task manager and reopen it I'm gonna try
72:50 - this again
73:06 - shift escape so weird sometimes it
73:13 - memory leaks them sometimes it doesn't
73:17 - well there we go oh there we go it just
73:22 - took a little while
73:40 - okay I'm gonna refresh this page I'm
73:42 - gonna pull up the task manager shift
73:44 - escape does not work for me I thought it
73:45 - might and let's take a look at the
73:50 - memory footprint for the p5 tensorflow
73:55 - sketch I'm running and let's see what
73:58 - happens to it
74:02 - not much give it a minute
74:06 - give it a minute it's definitely doing a
74:13 - lot of work
74:23 - it'll take a while where it triggers the
74:25 - jazz garbage collector until it can't
74:27 - anymore yeah
74:34 - yeah maybe this was a sort of pointless
74:37 - demonstration yeah there we go
74:47 - it kicks in now does it kick in if I
74:52 - don't yeah so maybe did it run out of
74:54 - memory somewhere else and then started
74:56 - to fill up somewhere else wow that's
74:58 - crazy so I wonder let me try doing an
75:05 - operation so what if I create I'm gonna
75:09 - have to what if I create two tensors
75:26 - two tensors and then let's look at let's
75:31 - do the matrix multiplication so I'm
75:35 - coming out of the tutorial you know
75:37 - we're in this is this must be element
75:44 - wise yeah this element wise a dot
75:52 - multiply B so let's just try that so let
76:03 - me call these a and B a equals a dot
76:08 - multiply B so let's take a look at this
76:18 - well it's actually just just curious
76:25 - here all right it's doing something
76:31 - it's doing that like if I do an
76:33 - operation maybe I needed to talk about
76:35 - operations before I talked about memory
76:37 - management there we go look at this
76:48 - there we go
76:49 - that's so I think whoever was explaining
76:54 - in the chat that it doesn't actually
76:56 - start to use the GPUs memory unless it
76:59 - you're doing an operation was right and
77:01 - now if I change these to
77:14 - yeah there we go this is the
77:16 - demonstration that I'm looking for
77:18 - by the way I meet someone named I meet
77:21 - in the chat asked how come you don't
77:22 - practice this stuff beforehand I you
77:24 - know it actually so I have different
77:26 - ways of doing things but for many of my
77:30 - videos and tutorials I the practice was
77:32 - really like teaching a course about it
77:34 - for years and years and years and this
77:35 - is not something I've taught before so
77:37 - I'm actually just figuring it out
77:38 - unfortunately as I go here but yes I
77:42 - could see why that might make sense you
77:43 - might prefer to just come back and watch
77:44 - the edited videos which a lot of this
77:46 - debugging gets taken out ok so now I'm
77:51 - rethinking this whole thing where maybe
77:57 - what I wanted to do was talk about
77:59 - operations first so I could leave my
78:10 - weird so when this gets published I
78:13 - could leave the amount of time I spent I
78:16 - could actually just we could just cut
78:22 - all of that I could just cut all of that
78:26 - and I could do I could start with
78:31 - looking at operations what makes the
78:33 - most sense I'm looking for your feedback
78:34 - here so I could just cut all of that
78:37 - that was an interesting exploration I'm
78:39 - just gonna move on video 3 is gonna be
78:41 - operations boy I hear the fan going nuts
78:46 - on this so let me just say no loop here
78:50 - real quick so that's option 1 what time
78:55 - is it this is new already oh crap
78:57 - option number 2 is leave all of my
79:01 - talking about variables and this kind of
79:05 - weirdness and then cut right to me
79:09 - saying actually I'm gonna talk about
79:10 - operations before memory management
79:12 - switch those talk about operations and
79:16 - then I mean I could do all these in one
79:18 - video to be honest now that I'm thinking
79:20 - about it
79:20 - variables operations and maths where I'm
79:22 - going to do so I'm going to make this
79:24 - all because I'm not really doing a
79:26 - comprehensive
79:26 - a tutorial here I'm just going to talk
79:28 - about in one video variables operations
79:32 - and memory management and I'm just gonna
79:36 - talk about operations first that's what
79:39 - I'm gonna do I think that makes sense
79:50 - [Music]
79:52 - okay yeah I'm gonna talk about TF tidy
79:56 - in I was going to choke dispose first
79:58 - and then all right got it
80:12 - so me I am so me is right this makes a
80:14 - lot of sense whoops I'm in the wrong
80:15 - camera that the library keeps references
80:18 - to every tensor so that they can't be
80:20 - garbage collected right so the tensors
80:23 - can't be garbage collected because what
80:25 - if you want them to copy them onto the
80:27 - GPU but they don't actually go onto the
80:28 - GPU until until you do until you
80:32 - actually do an operation okay okay
80:40 - Lappe 2 3 4 says should there be a video
80:42 - on matrix maths
80:44 - I already made all those videos so this
80:45 - is really picking up on that so ok so
80:49 - Matthew if you're watching I don't know
80:51 - if this is gonna work and I can always
80:52 - just come back and do all this over
80:53 - again which I'm happy to the way that
80:55 - I'm gonna have this work right now is
80:58 - everything up until basically I came
81:01 - over here and did this can stay in the
81:04 - video and then we're gonna cut to me
81:07 - saying I'm gonna change how I'm teaching
81:11 - this and then I'm going to go straight
81:12 - to operations so in the code I need to
81:17 - back myself all the way back out to
81:20 - where I had variable and how the stuffin
81:24 - set up
81:30 - yeah okay
81:36 - okay Simon rights make through video
81:40 - three just variables and video for
81:42 - operation I could make video three just
81:44 - variables but wasn't that just like four
81:46 - minutes I guess people are happy to
81:47 - watch a four-minute video but I sort of
81:49 - feel like for me my the way that I'm
81:51 - kind of doing things the videos need to
81:52 - be like 15 to 20 minutes that's kind of
81:54 - like the chunk maybe that was like 20
81:56 - minutes I don't know what I'm talking
81:57 - about oh I was feeling so confident well
82:04 - who knows I'm just doing my best okay
82:20 - where's the eraser
82:27 - hi so I'm back actually with a weird
82:30 - edit point because I just went down a
82:31 - rabbit hole of trying to figure
82:33 - something out about memory management
82:34 - and I discovered that actually the
82:36 - memory management stuff makes a lot more
82:38 - sense to talk about after I've already
82:42 - looked at operations
82:44 - so let's actually I'm gonna switch this
82:46 - order here and right now in this video
82:49 - that you are watching I'm gonna talk
82:52 - about operations next and then maybe
82:54 - I'll move maybe I'll take a break and
82:55 - move on to memory management in the next
82:57 - video something like that okay so let me
82:58 - come back and talk about operations so
83:01 - what do I need when I'm saying
83:02 - operations not the kind of operation
83:04 - like I had here on my elbow recently not
83:07 - that recently a year ago so now it's too
83:17 - late I already alright so let's talk
83:21 - about operations okay what do I mean by
83:25 - operations so if I come back to whoops
83:36 - if I come back to the tension flow
83:40 - digest webpage there's actually a part
83:43 - of the sidebar here part of the API
83:46 - which is all about operations and when I
83:48 - to get my bad phrase that's what I mean
83:50 - mathematical operations that I want to
83:53 - perform on the tensor itself what if I
83:55 - want to double every number in the
83:57 - tensor or I want to take two tensors and
84:00 - element wise multiply every number by
84:03 - every other number what if I want to do
84:05 - matrix multiplication between those two
84:07 - tensors now this would probably merit a
84:09 - whole video series about linear algebra
84:12 - and matrix math luckily or unluckily for
84:15 - you I made a whole series about that
84:17 - already so you could pause here and go
84:20 - and watch that I would also refer you to
84:21 - the three blue one brown video series on
84:24 - linear algebra which is excellent so
84:26 - rather than get into the weeds of all of
84:28 - the mathematical pieces themselves I
84:30 - just want to kind of like look at a few
84:32 - and see how you would use these okay
84:35 - so let's for example say I want to use
84:36 - TF add
84:37 - so if I click on that I can see uh add
84:39 - two tensors element-wise a plus B what
84:43 - does element-wise mean well what that
84:46 - means just to sort of recap is if I have
84:49 - two matrices a b c d and i have another
84:56 - one
84:56 - e f g h and i want to add them together
85:01 - and i want to see the results
85:03 - element-wise means a plus e b plus F
85:09 - right I just take them ones that are in
85:12 - the same spot and add them together so
85:14 - we could create we could do that right
85:16 - now in our code and I could say I'm
85:19 - gonna call this tensor a and I'm gonna
85:22 - this is a little bit silly but I'm just
85:24 - gonna make a second one that's with the
85:27 - same numbers in it obviously I'm more
85:29 - likely would have two tensors with two
85:31 - different values and then what I want to
85:34 - do is say TF wait how do I let me look
85:37 - at this Oh a add B sorry
85:40 - so what I want to do is I'm going to say
85:41 - Const C equals a add B which by the way
85:45 - would be exactly the same as saying B
85:47 - add a in this case with other operations
85:51 - the order of the matrix the matrix the
85:53 - tensor so I shouldn't say matrice matrix
85:55 - matrices so that really could play a
85:58 - role so if I say a dot B and I were to
86:02 - say a print B print C print and I come
86:09 - back here and go and hit refresh we're
86:12 - going to see you know here's a here's B
86:15 - they're the same and then every number
86:16 - is doubled basically because I took a
86:18 - plus B so really obvious I should make
86:20 - two different random sets of numbers but
86:22 - this is this is how an operation works
86:25 - and depending on what you're doing you
86:27 - need different mathematical operations
86:30 - let's see if there's any other ones we
86:32 - want to look at maximum minimum modulus
86:38 - per what would be a good one to look at
86:40 - squared difference is a good one
86:46 - do I wanna know the basic math stuff I'm
86:49 - not gonna look at right now I think I
86:52 - should look at matrix multiplication
86:54 - probably our transpose reduction minimum
87:07 - of so much stuff here okay I'm not gonna
87:09 - go through all this let's look at all
87:11 - right so as you can see there are a lot
87:18 - of things we could subtract multiply
87:20 - divide there's maximum minimum modulus
87:22 - power squared difference all need to be
87:23 - interesting to pursue and I might come
87:25 - back and do more videos about particular
87:27 - mathematical op operations but really I
87:29 - think just showing you ad hopefully now
87:31 - you could kind of look at the
87:32 - documentation and see what each one does
87:34 - I think it's worth at least doing
87:36 - there's a lots of other math
87:37 - functionality but I think it's worth
87:39 - looking at matrix multiplication TF NAT
87:41 - mall because this is a really key
87:44 - concept in building a neural network how
87:49 - to do this weighted sum of all of the
87:52 - inputs and all of the weights passed
87:53 - through you really need matrix
87:55 - multiplication if you go back and watch
87:56 - my other videos so let's look at this
87:58 - one so here we can see a dot mat mole so
88:03 - really it's just another function but
88:05 - we're gonna run this an interesting
88:07 - thing here what if I were to try and I
88:11 - don't need to print I'm not gonna bother
88:13 - printing a and B let's just try this
88:15 - right now so I'm going to write this
88:16 - would work a dot multiply and ul B
88:20 - because that's doing element wise a time
88:22 - you know in this case a times B times FC
88:26 - times G let's go back and I'm gonna hit
88:30 - refresh oh it worked so I guess the way
88:38 - okay of course it works I forgot I was
88:41 - doing L then what of course of course it
88:42 - worked I'm doing element wise
88:43 - multiplication I'm trying to demonstrate
88:45 - here that if I actually want to do
88:47 - matrix multiplication which is a totally
88:49 - different thing mat mole is that what
88:52 - was called now there we go oh I love
88:57 - this is like my favorite error
88:58 - this is very simple these are like kinds
89:01 - of areas are gonna run to all the time
89:02 - themselves before era matmo inputs must
89:05 - be ranked 2 got ranks 3 and 3 the reason
89:09 - why this is is when you do sorry I'm
89:15 - seeing a super chat thank you to Daniel
89:17 - hello to Brazil this is gonna make a
89:22 - editing point for I also I also wanted
89:26 - to oh you can get the amount of tensors
89:32 - in memory by saying TF dot memory ah
89:34 - Thank You me that's gonna be really
89:36 - useful me I am to me thank you
89:38 - matrix multiplication hold on I the
89:44 - columns and rows that the number of
89:50 - columns and the first one equals the
89:52 - number of rows in the second one yeah
90:00 - when you do matrix multiplication the
90:04 - number of columns in the first matrix a
90:08 - has to match the number of rows in the
90:12 - second one and by the way you can't even
90:17 - have like a this is fully you can't have
90:20 - a rank three you get your majors month
90:21 - so this by the way this whole thing is
90:23 - flawed because this was only gonna work
90:26 - so let's if I have a rank two mate
90:29 - tensor or basically a matrix a two
90:31 - dimensional array so now let's get a
90:35 - different error message now error in
90:39 - math so first of all matrix
90:41 - multiplication is only for matrices in
90:44 - two dimensions tensors in two dimensions
90:46 - and then the error here is the inner
90:48 - shapes three and five of the tensors
90:51 - with shapes five three and five three
90:52 - are in transpose so what's this error
90:55 - message about to do matrix
90:59 - multiplication the number of columns in
91:03 - the first one must match the number of
91:07 - rows in the second Matrix
91:11 - in here this would work this would
91:13 - actually work because these are two by
91:15 - two and so the columns here matches the
91:17 - matches the rows here and again if you
91:21 - go back to my video on matrix
91:23 - multiplication you'll see why in more
91:24 - detail about this so but just to follow
91:26 - up here what I must do now in order to
91:30 - do Mitra's multiplication as I probably
91:32 - would have shape for a I could transpose
91:35 - one of them but let's do this first so
91:37 - I'm gonna do shape a and then I'm gonna
91:39 - do shape B this is a good time to cover
91:41 - transpose and shape B and now this
91:46 - should give me something there we go
91:48 - there's my new matrix and out of matrix
91:51 - multiplication if I am doing excuse me a
91:54 - five by three multiplied with the three
91:56 - by five I end up getting a five by five
91:59 - matrix which is correct
92:00 - now another way I could have done this
92:03 - by the way is if I used the same shape
92:06 - for both of them if I backed in here I
92:10 - should be able let's do this okay I
92:12 - should be able to say B now let's just
92:15 - see what happens if I say B transpose no
92:20 - so here's the thing remember these
92:22 - things are immutable
92:23 - so even transposing it I probably have
92:26 - to say consul's be transposed and then I
92:31 - can do a dot mat mall BB and there we go
92:36 - so what does transpose do with the
92:38 - matrix transpose if I have a two by
92:46 - three matrix we'll take that matrix and
92:49 - transpose the numbers into a three by
92:52 - two matrix so again why do I I'm not
92:55 - doing anything of any value or meaning
92:56 - here if you go back you could probably
92:58 - go back as an exercise if you want an
93:00 - exercise right now go to my toy neural
93:03 - network look at nnj s go through all of
93:07 - the matrix maths that in that and see if
93:09 - you can rewrite that with the tensor
93:12 - flow the TF operations I don't know why
93:14 - you'd want to do that but if you want to
93:16 - just do everything you could possibly do
93:17 - in this world that's something you could
93:19 - try
93:19 - and maybe I'll try to publish something
93:21 - which is like an answer key to that I
93:22 - don't know you could ask me in the
93:23 - comments or somebody could make one I
93:25 - could post it alright so I think this is
93:27 - about where I want to stop right now
93:29 - again this is not meant to be
93:31 - comprehensive I just want to talk
93:33 - through what are the pieces here we know
93:36 - that there are tensors tensors are n
93:39 - dimensional groups of numbers with we
93:43 - can also those are immutable they can
93:45 - never change if we need them to change
93:48 - we could use this thing called a
93:49 - variable maybe we need to see an actual
93:51 - scenario where we need that variable
93:53 - hopefully that'll come up in one of my
93:54 - videos in the future
93:55 - but you could try it yourself and then
93:57 - we can also perform operations we can
94:00 - perform operations like take these
94:02 - tensors that take this tensor and add
94:04 - this one or double this or find the
94:06 - maximum number and this one and there's
94:07 - plenty plenty more matrix multiplication
94:09 - so I encourage you to explore all of
94:11 - those and maybe I'll come back and go
94:13 - through some of them as we need them but
94:15 - I just want to give you an overview of
94:16 - what's there in the tensor flow jsapi
94:19 - itself so in the next video I'm gonna
94:21 - talk about something very important
94:23 - because I have not been paying attention
94:25 - at all to how whenever I create a tensor
94:28 - I'm using memory in of the computer and
94:31 - sometimes I'm using maybe I'm using
94:32 - memory that's all you know in the RAM
94:34 - sometimes using the GPU memory what's
94:36 - going on with all that so I want to in
94:38 - the next video specifically talk about
94:40 - memory management and how to make sure
94:42 - if I'm making all these tensors and
94:44 - doing all these operations how I how to
94:46 - make sure I avoid having a memory leak
94:49 - okay I'll see you in that video ok so ok
94:59 - so I think where are we now 12:20 I'm
95:06 - about an hour ok so I think that you
95:13 - know that wasn't my best finest work but
95:15 - I think we're good I'm gonna keep it and
95:17 - I can always come back so I have to
95:19 - reconsider whether I want to kind of
95:22 - read
95:23 - do a discussion of variables and
95:25 - operations but I think something can be
95:26 - pieced together from that Matt Matt you
95:28 - can do some magical work so now I'm
95:30 - going to start with memory manager
95:48 - all right it's time oh boy it's time you
95:53 - know hold on I think I hear tissue I
95:56 - just had a little pizza snot gurgle up
95:59 - there
96:00 - here's one yes hold on I'll be right
96:03 - back I should meet my microphone
96:04 - apologies for the noise
96:20 - okay I'm back I just saw a question in
96:23 - the live chat that's going on right now
96:24 - saying what's the memory leak guess what
96:27 - you're gonna find out what a memory leak
96:28 - is in this video in particular how to
96:31 - manage memory if you using tensorflow no
96:34 - chance now here's the thing I live in a
96:35 - world where I generally program either
96:38 - in processing which is built on top of
96:40 - Java or I program in Java and be fought
96:43 - with the p5 library in the language
96:45 - JavaScript and I don't have to worry
96:49 - about memory management I mean often do
96:51 - but most of the time I don't there's
96:52 - something my friend my friend Liv lives
96:57 - in the computer their name is garbage
96:59 - collector and the garbage collector just
97:01 - kind of is always there checking to see
97:03 - if I'm using any of my variables anymore
97:05 - and if I'm not collects that memory and
97:07 - reallocates it for somebody else a
97:09 - memory leak is something in your program
97:12 - which continues to allocate memory over
97:15 - and over again and yet where you don't
97:18 - need to you'll need to remember that
97:20 - stuff and so you're filling up the
97:21 - computer's memory and it's just to
97:24 - infinity and eventually the memory will
97:26 - be full and your program will crash your
97:28 - computer will crash I mean maybe it's
97:30 - not a leak technically if you keep if
97:32 - you need to save all that stuff but most
97:34 - the time like if you're creating a
97:35 - variable that's just keeping track of
97:37 - the computers like a score in a game and
97:40 - your reallocating new memory for that
97:43 - score over and over and over again and
97:45 - you don't need the old score you should
97:47 - deallocate that memory and if you're
97:49 - programming in like a low-level language
97:50 - like C or C++ you sometimes have to
97:52 - manage this memory yourself higher-level
97:54 - languages that are more apps that have a
97:56 - layer of abstraction the browser is
97:58 - there to protect us I think as a java
98:01 - virtual machine they have a garbage
98:03 - collector that handles some of this
98:04 - memory mandrin tests are dope flow
98:07 - duchesses in this sort of funny
98:08 - in-between place and we're programming
98:10 - in JavaScript but tensorflow digest is
98:12 - doing some highly manual management of
98:15 - the memory of your GPU to do all this
98:17 - fast math operation so we have to make
98:19 - sure we carefully think about how our
98:22 - allocating memory and explicitly
98:24 - deallocate memory so that's what I want
98:26 - to look at so let's take a look we're
98:27 - gonna
98:28 - this is gonna be exciting we're gonna
98:29 - make a memory leak happen and then we're
98:31 - gonna fix it
98:32 - yay all right so what so this is the car
98:36 - that I had before let's actually keep
98:38 - this this is kind of interesting but
98:41 - what I'm gonna do instead is I'm gonna
98:44 - take all of this code and I'm going to
98:49 - put it in draw what's draw you might ask
98:55 - Oh again there's no reason for me
98:56 - there's no particular reason why I need
98:58 - to be using p5 the p5 library with
99:01 - tension Fletch s right now but one of
99:04 - the things that p5 library has it has
99:05 - this animation loop if you write the
99:07 - function draw it's going to execute that
99:09 - function 30 times per second 60 frames
99:11 - per second depending on the situation so
99:13 - I just want to hit save and now I'm just
99:16 - gonna hit refresh so in theory this is
99:18 - chugging along right now so the question
99:21 - is how do I look at how much I mean
99:24 - there's I don't see anything like I
99:25 - could like maybe what I want to do is do
99:27 - like console dot log hello just to make
99:30 - sure it's like running and we could see
99:33 - the hairs I'm seeing hello over and over
99:35 - again over here over and over again in
99:37 - the console so it looks like if the
99:38 - programs are running fine it's running
99:40 - fast no problem let's look and see what
99:41 - memory it's actually using so there's a
99:44 - lot of tools up here whoops no here that
99:47 - I don't really know how to use for
99:49 - evaluating the performance of your
99:52 - webpage in the developer tools I'm gonna
99:54 - go and you up here under window and go
99:56 - to task manager one of the nice things
99:58 - about tattle oh my goodness we
100:00 - definitely have a memory leak okay I
100:03 - think and I think I filled it up I think
100:06 - probably the GP so the memory footprint
100:08 - so let me scroll this over here so we
100:11 - can see these are the various things
100:12 - that browser is this is the browser as a
100:14 - whole so this is the regular computer's
100:16 - memory the tensorflow documentation tab
100:18 - is using 94 megabytes
100:20 - FIFA but the GPU which is just filled
100:23 - its way up to 2 gigabytes really fast
100:25 - let's try let's try setting the frame
100:30 - rate 2 to 1 and refresh the page and let
100:37 - me go back to the task manager and maybe
100:39 - now we can see
100:41 - Wow it's already at two gigabytes am I
100:45 - gonna go down this rabbit hole again
100:48 - let's so let's just be clear about stuff
100:51 - let me comment all of this out let me
100:55 - comment out all of the tensorflow Jas
100:58 - stuff and let me hit refresh again let
101:02 - me go back to the task manager I think I
101:05 - might have to click the task manager
101:06 - might not refresh its values ah you know
101:09 - what if I don't reopen the No Wow why do
101:19 - I have to look let me hold on just bear
101:21 - with me for a second let me quit Chrome
101:24 - it's crazy how I want to use the TF
101:27 - memory thing but I wanted to just look
101:29 - at it in I wanted to look at it in
101:45 - here we go
101:50 - okay so something was going on with the
101:52 - browser probably I had filled up the
101:55 - memory somewhere else so I just actually
101:57 - quit Chrome and restarted it so now you
102:00 - can see the GPU is using thirty two
102:03 - point eight megabytes of memory which
102:04 - isn't that much and maybe over time it's
102:07 - gonna like to go up because I make it oh
102:09 - oh actually no it's not because I also
102:11 - in testing things I commented out sorry
102:13 - I comments without all the tensor stuff
102:15 - so let me put the tensor stuff back in
102:18 - right and now let's take a look at the
102:21 - GPU memory so I'm gonna close the task
102:24 - manager I'm gonna hit refresh now I'm
102:27 - gonna go to the task manager again and
102:30 - I'm gonna look here that's it I'm gonna
102:32 - look here at this number so we can see
102:35 - I'm using some memory maybe it's gonna
102:38 - go up maybe not but the thing is I've
102:40 - got very I'm using like a very small
102:43 - amount of numbers so really what
102:45 - tensorflow digest is designed to work
102:47 - with the reason one is to work with
102:48 - large amounts of numbers so let me go
102:50 - back to my code and let me just say what
102:52 - if instead of having 15 numbers I'm
102:55 - gonna have 15,000 which would be 500 by
103:01 - 300 so I'm gonna have a 5 to 500 by 300
103:05 - matrices transpose one of them and do
103:07 - matrix multiplication so let's do that
103:10 - let me now let me hit refresh one weird
103:13 - it's very hard to demonstrate whoops oh
103:15 - not 50 150 thousand 15 that whoops oh
103:19 - that should actually be a hundred fifty
103:22 - thousand let's do that one hundred fifty
103:23 - thousand that's what I meant
103:24 - let me hit refresh let me go back to the
103:29 - task manager and now let's look at that
103:33 - memory it's going up little by little
103:36 - it's going up now let's say I was trying
103:39 - to do that 30 frames per second let's
103:42 - get rid of this frame rate 1 hit save
103:45 - close the task manager the task manager
103:47 - I feel like needs to be and I'm gonna go
103:49 - back and open up the task manager my
103:51 - last time demonstrating this and now I
103:54 - really want to see this memory leak I
103:55 - want to see this number go up 63 66 68
104:00 - so you can see the memory is leaking
104:03 - right I don't
104:04 - need just keep storing all the to keep
104:06 - track of all these tensors that I've
104:08 - been making every time through draw and
104:09 - maybe there might be some kind of oops I
104:14 - want to sort by memory man whoops where
104:17 - where am I here GPU yeah so you can see
104:21 - this number it's going up and up and up
104:22 - so and actually wasting a lot of memory
104:25 - regular memory also ooh oh boy up and up
104:31 - when up we go ah sorry watch it maybe
104:34 - edit out like the last 5 10 seconds of
104:36 - what I've been saying don't have to just
104:42 - slide to the left of the page so it
104:43 - sticks out and click back and forth to
104:45 - give it focus okay yeah probably need to
104:48 - restart chrome yeah so I'm gonna just do
104:52 - like an edit point and like I'm gonna
104:58 - let this go real high
105:07 - but you can kind of go back as much as
105:09 - you can to like get rid of all my
105:11 - awkwardness and now I think we're in
105:14 - good shape okay so I let this run for a
105:17 - little bit we could really see the
105:18 - memory leak is happening you know this
105:20 - is only gonna go up it's never gonna go
105:21 - down so one of the things now there's i
105:25 - I'm using the task manager the truth of
105:27 - the matter is and I'm just gonna I'm
105:29 - gonna type in here no loop just to shut
105:31 - this off for a second the truth of the
105:34 - matter is tensorflow digest provides us
105:36 - with a mechanism to check this as well
105:38 - so I can also say TF dot memory let's
105:42 - actually go to the API API reference
105:47 - memory TF memory and I can look at the
105:55 - number of bytes allocated the number of
105:57 - tensors this tight kind of thing so
105:59 - let's actually look at let's let's look
106:00 - at number of tensors so I can say I
106:02 - think TF memory dot num tensors I can do
106:07 - what's maybe it's just is it a function
106:09 - or is it a property let's try this
106:10 - console.log this oh let me get rid of
106:18 - the hello so you can see here these are
106:23 - all the tensors being stored and they're
106:26 - going up and up and up the good news is
106:28 - there is a way to get rid of tensors
106:32 - that you don't need anymore and I'm
106:33 - gonna write that down there are two
106:35 - functions you want to know about for
106:37 - memory management one is called dispose
106:40 - and there might be more
106:42 - and I just written off the edge we try
106:49 - that again
106:51 - there are two functions okay probably
106:53 - there might be more than this but
106:54 - there's two functions that I want to
106:55 - talk about as they relate to memory
106:57 - management there is the function called
107:00 - dispose and there's the function called
107:02 - tidy and there they do the same thing
107:05 - they clean up memory that's not used but
107:08 - they do it in a different way so let's
107:09 - look at how that works
107:11 - so coming back over here if I go into my
107:15 - code and I say like these are all my
107:17 - tensors a B
107:19 - a B and C I'm gonna call this B
107:21 - underscore T because that's actually
107:24 - like sometimes I feel like a naming
107:25 - convention like transposed to B this is
107:28 - my own naming convention and I'm gonna
107:29 - say a dot dispose B dot dispose C dot
107:35 - dispose and B underscore t dot dispose
107:39 - so this is me manually despo after you
107:44 - know this is like do something
107:47 - meaningful here like I want to do
107:49 - something meaningful with these tensors
107:51 - and then I'm done with them I want to
107:53 - dispose them so now let's run this again
107:57 - I'm gonna hit refresh and look zero zero
108:01 - zero zero the Argo tensor stored in
108:03 - memory and in fact if I go to the task
108:06 - manager we should see load up please
108:12 - that the GPU process is not growing it's
108:16 - at 229 megabytes and it's not getting
108:19 - any higher there is no longer a memory
108:21 - leak we have correct fixed the memory
108:23 - leak the thing is so that's good that's
108:26 - step one we we've talked about dispose
108:36 - the thing is you might be writing a
108:38 - program using tension flow to ask more
108:40 - you're just making tensors like crazy
108:43 - you're just tense or happy and so really
108:46 - having to manually keep track of
108:48 - everything and call dispose on
108:49 - everything can become rather unwieldy
108:51 - and that's where TF tidy comes in so TF
108:56 - tidy is a function that you don't call
108:59 - on a particular tensor but it allows you
109:02 - to wrap a bunch of code in that will get
109:05 - cleaned up when it ends what I mean by
109:07 - that is I can say TF tidy my stuff and
109:12 - then I can write a function called my
109:15 - stuff where I do all of this so what
109:20 - this is doing is saying execute this
109:22 - function my stuff but make sure you tidy
109:27 - it up after you're done so let me run
109:29 - this and see what happens
109:32 - and you can see I still have zeros and
109:35 - just to be sure that this function is
109:37 - running let's put hello inside that
109:41 - function look and now we could see that
109:49 - function is running here's the thing
109:51 - you're not gonna see anywhere in any
109:54 - tension flow digest examples it written
109:56 - this way so you noticed yeah I'm just
109:58 - going to do a couple quick steps here I
109:59 - wrote a named function and past it into
110:03 - TF tidy I could more likely you're gonna
110:06 - see an anonymous function that doesn't
110:08 - have a name passed into TF tidy like
110:11 - this and even more likely than that
110:13 - you're going to see that arrow syntax so
110:15 - I encourage you to check my video on
110:17 - arrow syntax but this is what you're
110:19 - typically gonna see this is ah
110:21 - inside of the draw loop every time I
110:24 - want to do some stuff some meaningful
110:27 - stuff with my tensors but whatever I do
110:30 - I want that to be cleaned up and I don't
110:33 - think it will clean up variables I don't
110:37 - know if somebody in fact check me on
110:38 - this but I think the variable is
110:40 - something that gets held in memory does
110:43 - TF tidy clean I don't know why I
110:44 - bothered to say that
110:45 - so maybe cut that part out alright let's
110:52 - test this one last time we've got TF
110:55 - tidy and hit refresh and once again zero
110:59 - tensors let's put one constant test
111:06 - equals TF oh no whoa look at this this
111:11 - should be tensors to D by the way I'm
111:13 - surprised it didn't pick up it didn't
111:15 - give me an error there oh I think that's
111:17 - the same error that I filed a bug report
111:19 - at and that's been fixed maybe I maybe
111:22 - I'm not using the most recent version of
111:24 - tensorflow jjs is there a point xi no
111:30 - but when there is one that will be fixed
111:34 - its ignore me so now I'm going to go in
111:37 - here and I'm gonna say TF tensor to D
111:40 - values shape and I'm gonna run this
111:45 - oops to lowercase D and now we can see
111:49 - ah I'm creating all these tensors I have
111:52 - a memory leak these are getting cleaned
111:54 - up but I could you know manually dispose
111:58 - of this one I everything's been cleaned
112:01 - up or last piece this one could go
112:04 - inside of Tidy and then there we go
112:08 - alright and by the way I'm the chat is
112:11 - reminding me that there is a function
112:13 - called TF keep so I probably
112:16 - if inside of TF tidy I could use TF keep
112:19 - if I have all this stuff happening but I
112:21 - want to make sure to keep this one so
112:22 - this could get very complex very fast
112:24 - and I'm really trying to just give you a
112:26 - cursory overview here and hopefully as I
112:29 - start to build some examples where I'm
112:31 - trying to do stuff with tensor flow
112:32 - digest it'll make a bit more sense as
112:34 - we're using this stuff in the world okay
112:37 - thanks for watching see you in a what's
112:40 - next on my list
112:41 - oh the layers API alright so I'm gonna
112:44 - talk about the layers API next okay
112:57 - all right what time is it 12:30 6:00 I'm
113:02 - definitely not getting to X fourth this
113:04 - morning if I could come back last but
113:06 - the Citiz less we're gonna didn't come
113:08 - back small chance I could come do a
113:10 - little more this afternoon
113:11 - so laters API that's a big topic I
113:17 - almost would rather just do like I
113:20 - wonder I wonder if I should come back to
113:22 - that another day think I'm gonna come
113:25 - back to that another day because that's
113:28 - a big topic and that's really paired
113:30 - with the X or things 1236 I'm looking at
113:38 - the chat
113:39 - hello Hong Kong so what's gonna be what
113:47 - about what have I done let's come back
113:49 - over here and check so I did this now we
113:56 - talked about variables we talked about
113:58 - operations we talked about memory
114:00 - management ok the layers API so much to
114:09 - discuss I guess I could do a video about
114:13 - the layers API I just do I feel tired
114:16 - the other thing I could do is I could go
114:18 - do that water ripple coding challenge
114:23 - let's put it to let's I'm gonna do let's
114:25 - put it to a straw poll or I could go now
114:31 - it should increase my chances of coming
114:33 - back this afternoon I might feel a
114:34 - little bit more refreshed but let's see
114:38 - here I want to get some water anyway so
114:42 - look layers API this is not the boat
114:48 - which layers API water ripples coding
114:56 - challenge so just to be clear the layers
115:03 - API means just like another one of
115:05 - videos in this similar style where I'm
115:07 - like this is the layers API this
115:09 - what the things are named this is what
115:11 - they do here's a quick little like try
115:13 - something out but not really using it
115:15 - like I will eventually use it doing any
115:17 - of these particular examples like X or
115:20 - color predictor or doodle classifier and
115:23 - the water ripples coding challenge is
115:29 - the water ripples coding challenge is
115:35 - [Music]
115:40 - trying to follow this old article from
115:45 - days of yore to make a little like water
115:51 - ripples simulation know if you can see
115:53 - this but I don't you can't really see
115:58 - this very well but so that's those are
116:02 - your choices so I will give this a
116:05 - little bit of time
116:19 - and moving its I want to get some water
116:21 - so I'm gonna be back in I'm going to oh
116:50 - [Music]
116:53 - well I'm not gonna take 15 minutes to
116:56 - get water forget it you don't need a
116:58 - timer oh well I could also just put it
117:01 - here I'm gonna be back I'm gonna try to
117:04 - get some water
117:04 - I don't think I have a cup up here so
117:07 - this microphone is about to get muted
117:11 - while I go get some water and I'll be
117:14 - back in about five minutes and I'll do
117:16 - just one more thing this morning
117:22 - I mean the music goes on for four
117:26 - minutes hope I'll be back before the
117:27 - music shuts off
117:48 - [Music]
118:09 - [Music]
118:15 - [Music]
118:45 - [Music]
118:55 - [Music]
119:15 - [Music]
119:46 - [Music]
120:19 - [Music]
120:34 - [Music]
120:57 - you know what must have happened what
121:01 - must have happened is when I went so far
121:03 - away lost the connection so I don't know
121:10 - what that would have been but it was
121:12 - definitely muted the whole time
121:13 - so it must have like lost the can I went
121:17 - pretty far away went like all around the
121:19 - opposite side of the building and it's
121:21 - connected wirelessly so huh okay look I
121:26 - found though paper towels so sorry if
121:33 - there was like a horrible sound thing
121:36 - that happened there I guess I should
121:37 - know that now shouldn't it should know
121:39 - that by now
121:40 - all right let's take a look
121:49 - water ripple coating showers hey only 67
121:53 - people voted all right this is probably
122:04 - a terrible idea for a variety of reasons
122:06 - but we're gonna attempt this water
122:08 - ripples coding challenge so next time I
122:17 - do this I should software muna in
122:19 - Wirecast and OBS like this wait yeah you
122:27 - did I'm not you did i'm not muted okay
122:31 - [Music]
122:33 - all right
122:34 - they're also gonna just been no so I'm
122:40 - definitely gonna need me the whiteboard
122:47 - for this but I want to keep my list
122:53 - [Applause]
123:14 - Oh finally can I take a minute I would
123:17 - like to take a minute of your time to
123:20 - just mention one of my favorite
123:24 - youtubers simone geertz i don't know if
123:28 - i'm pronouncing her name correctly let's
123:31 - find her channel Simone it makes the
123:35 - lots of I don't like to swear on my
123:37 - channel Alec at all she has a lot of
123:39 - subscribers she makes the most amazing
123:41 - robots she's awesome check out her
123:46 - channel subscribe to it go back watch
123:48 - all of her videos if you haven't seen it
123:49 - I wanted to just plug her patreon for a
123:52 - minute she recently published a video
123:55 - about a brain tumor that she has and she
123:59 - has amazing which is no surprise really
124:01 - a completely amazing attitude about it
124:04 - and sense of humor in what is obviously
124:08 - an incredibly serious and difficult
124:10 - thing to go through
124:11 - I you know watch her video if you want
124:14 - to hear the medical explanation about it
124:16 - I'm not qualified to speak for her or
124:19 - speak about it but I do want to mention
124:21 - that I did support I did subscribe to
124:24 - her patreon it in or that she had one or
124:25 - it just occurred to me and I know that
124:29 - you know she's gonna be on high you know
124:30 - I was on hiatus for a couple months when
124:32 - I broke my elbow but really having
124:34 - surgery on my elbow to fix some pones is
124:36 - nothing compared to what she's going
124:38 - through with the so I would encourage
124:40 - you if you can to subscribe to her
124:44 - patreon I mean I have one too but I
124:47 - think that if if you can have a lot of
124:49 - supporters through her patreon that'll
124:50 - hopefully help her get through this
124:52 - amount of time or I imagine she can't
124:53 - make videos for her channel and if
124:55 - anybody else is a youtuber who has them
124:58 - or anybody else in the world has some
124:59 - ideas of ways of supporting Simone I
125:01 - know she has large larger following than
125:04 - I do certainly and so there's a lot of
125:07 - people supporting her already I'm sure
125:09 - but if there's
125:10 - as any ideas or things we can do to
125:12 - support her I think that would be a nice
125:13 - thing to do
125:15 - okay now I am ready for this coding
125:24 - challenge so this I go this is so let me
125:27 - I'm gonna do this in processing I'm
125:33 - going to call this water ripples why am
125:53 - i why in a million years am i starting
125:55 - this right now I have no idea but I am
126:07 - hello and welcome to a coding challenge
126:10 - in this coding challenge I am going to
126:11 - attempt to make a 2d water simulation
126:14 - now you might be asking how are you
126:16 - going to do so so this is actually I
126:18 - wrote this code not I didn't invent this
126:20 - algorithm but I wrote this code it's got
126:22 - to be at least 10 years ago this is one
126:24 - of the first things this essay on how to
126:27 - create this algorithm for creating 2d
126:29 - water ripples has been on the internet
126:31 - for a really long time in fact it's not
126:33 - on the internet anymore
126:34 - this was the URL and this URL hugo dot
126:39 - elias it doesn't go anywhere but
126:42 - thankfully the Internet Archive and I
126:45 - don't know who this person is who wrote
126:46 - this essay thank you hello if you're out
126:48 - there let's get in touch write in the
126:51 - comments but this is a really fun
126:53 - algorithm and it works it's very if you
126:56 - if you're looking for some background
126:57 - for it you want to know a little bit
126:59 - about how pixels work two-dimensional
127:01 - arrays may be cellular automata this
127:03 - idea of a grid of cells with States I've
127:06 - had a bunch of videos that I made
127:08 - related to how this algorithm works that
127:09 - I will link to in this video's
127:10 - description
127:10 - excuse me but what I'm going to attempt
127:13 - to do in this video is just read this
127:15 - web page and write the code that falls
127:18 - along exactly what
127:19 - doing and see if we can get the result
127:21 - that is on that it's described here to
127:24 - create 2d water ripples so let's just
127:26 - get started
127:27 - I'm apologize for having to have to read
127:29 - this out loud okay
127:30 - bah-bah-bah narrative narrative
127:31 - narrative narrative so firstly you'll
127:33 - need two arrays of words well integers
127:36 - okay so let's do that so let me go open
127:40 - up processing processing I always feel I
127:43 - have to say this is a programming
127:45 - environment built on top of Java more
127:47 - information at processing org download
127:50 - this if you want to follow along and I
127:51 - will create a JavaScript version of this
127:54 - that runs in the browser as well when I
127:55 - polish the code all right so let's set
128:00 - void setup void draw these are the sort
128:03 - of basic functions to control the flow
128:05 - of the program in processing and I'm
128:06 - going to say I'm going to make two
128:11 - 2-dimensional I'm just gonna say like
128:13 - 100 by 100 just arbitrarily right now
128:16 - let's actually do a 200 by 200 and I'm
128:20 - gonna say I'm gonna say water one water
128:22 - 2 because I don't know what those are
128:24 - could be useful yet look at this and
128:26 - like I'm gonna say size 200 200 okay so
128:30 - I have a window that is 200 by 200
128:33 - pixels and I have this these two
128:36 - missionaries and I bet you couldn't
128:37 - write like a super fast crazy version of
128:39 - this with shaders or something so maybe
128:41 - you're watching this you're gonna want
128:43 - to do that later but let's try to do
128:44 - this basically just follow along okay
128:45 - back to here that's right these arrays
128:49 - will hold the state of the water one
128:50 - hold the current state the other holds
128:52 - the state from the previous frame so
128:53 - let's actually call this current and
128:56 - previous oh why can't those have the
128:59 - same number of letters in them no
129:01 - preview play view so this is gonna be
129:04 - current and play view whatever now that
129:06 - bothers me more previous okay it's
129:10 - important you have to erase this you
129:11 - need to know how the water has changed
129:12 - since the last frame buffer too but for
129:14 - one buffer - I could call them buffer
129:15 - one buffer - anyway data from the
129:17 - previous frame blah damping some integer
129:20 - between 0 & 1 so we need some sum so we
129:22 - need to have a damping let's try 0.9 so
129:27 - the beginning loop what I need to do
129:29 - well first I need to I
129:31 - I need to fill those arrays with some
129:33 - values strengthen matters I think
129:35 - they're going to get filled by default
129:37 - with with zeros and I also want to I
129:42 - think I want to keep track of the
129:43 - columns and rows in a variable oh that
129:50 - didn't work the way I wanted it to I
129:53 - lost my ability to type
129:55 - oh that's right all right there we go
130:01 - for every knot so let's this is begin
130:04 - loop so this is the it boy this
130:05 - background is making hard for you to see
130:06 - the algorithm but for every non edge
130:08 - element so let's do that for every non
130:10 - edge element what does that mean for int
130:13 - X x equals 1 let's actually use I and J
130:19 - I equals 1 I is less than columns minus
130:26 - 1 I plus plus that is a way of looping
130:29 - through every non edge element and I'm
130:31 - gonna do the same thing with j j is less
130:34 - than rows minus 1 and a j plus plus
130:40 - alright and now what do I do
130:45 - let's just copy paste this and say all
130:52 - right so what this really means here is
130:54 - this is saying current the current X Y
131:00 - which is really current I J is equal to
131:05 - the sum I mean you can see these are a
131:07 - bunch of neighbors X minus 1 X plus 1 y
131:09 - plus 1 Y minus 1 what this is really
131:11 - doing if I come over here to the
131:13 - whiteboard you'll have to excuse this
131:14 - I'm doing some tutorials about
131:15 - tensorflow yes I didn't want to race
131:17 - that so that's still here in this coding
131:19 - challenge basically if this is my
131:26 - current IJ I want the new value that
131:29 - goes in this IJ to be a function of its
131:32 - value as well as its neighbors to the
131:34 - right to the top to the left and the
131:36 - bottom so that's what's happening here
131:38 - so I'm gonna go and I'm going to say
131:41 - equals previous
131:45 - X minus 1 y plus previous oh and it's
131:51 - not X I'm using I and J which now I
131:53 - regret making that decision oh this is a
131:56 - good timer going up hold on sorry
131:58 - everybody
131:59 - that was a timer for when I had to go
132:00 - get the drink I got that hold on I don't
132:06 - like to interact alright
132:13 - that timer wasn't there visible was it
132:15 - okay okay
132:20 - Matt gene you can edit a little bit of
132:23 - this out if you can all right i J it's
132:30 - all plus right now let me go back here
132:33 - wait these are being or these being
132:37 - multiplied by each other this is weird
132:40 - where are the pluses I sort of assumed
132:43 - this was all being added together right
132:46 - it doesn't actually say let me see does
132:51 - it describe this yeah I'm pretty sure
132:54 - this is addition well let's try it it
132:57 - would make sense to add everything
132:59 - together so I minus 1 J boy I plus 1 J
133:06 - then plus I J minus 1 plus I J plus 1
133:23 - rule come on
133:25 - indent this the way that I like plus and
133:30 - then so that this whole thing divided by
133:35 - 2 minus previous I J so I think I got
133:44 - that right so basically and let's
133:48 - actually let's just do this
133:54 - so this should be all of it I mean I
133:56 - don't love the way this is Auto
133:58 - formatted but we'll live with it I can
134:00 - actually put this on the next line might
134:01 - make me happier so this is all of these
134:05 - added together previous I minus I minus
134:08 - 1 I plus 1 J minus 1 J plus 1 all added
134:11 - together divided by 2 minus what the
134:14 - current value is so this is kind of like
134:16 - an image processing algorithm you're
134:18 - saying like add up all the things around
134:20 - me and then subtract my value ok now
134:26 - display buffer 2 and swap the buffers
134:29 - wow this is really coding jobs gonna be
134:31 - over soon
134:32 - so what do I what's one way I could
134:34 - display it hmm well let's first set a
134:37 - background and then while I'm doing this
134:41 - I could say load pixels and I could say
134:46 - update pixels right because what I could
134:48 - do is I could use the value of current
134:51 - IJ to be the pixel color yes so I'm
134:58 - gonna say pixels so let me first get an
135:02 - index value index equals I plus J times
135:06 - columns this is an algorithm that I've
135:09 - talked about many many times this has to
135:12 - be inside of the loop this particularly
135:19 - my talked about many times and what this
135:22 - algorithm is doing is it saying like the
135:24 - pixels are actually stored in a one
135:26 - dimensional array but I'm looping
135:27 - through this two-dimensional array so
135:29 - find the right location in the one
135:30 - dimensional array and then give me a
135:32 - color equal to the current I J value ok
135:39 - and update pixels so let's just run this
135:45 - and see if anything happens
135:47 - it's all black that's good because it's
135:49 - all zeros right what if I were to just
135:52 - initialize let me just go through I
135:55 - didn't actually do the swapping part but
135:57 - just just for the sake of argument let
136:00 - me go through and actually write
136:03 - something to initialize that whole array
136:07 - two dimensional array and just say
136:09 - current I equals 100 previous let's just
136:15 - bij J equals this is a little bit silly
136:17 - what I'm doing but I just want to see
136:19 - that this is working run this again we
136:23 - should see a gray value
136:25 - whoops run this again right we see a
136:28 - gray vow if I do 255 for both of those
136:31 - I'm gonna see white okay so it actually
136:33 - is rendering what's in there and then I
136:36 - forgot something really important which
136:38 - is written in the algorithm swap the
136:39 - buffers because what is now current
136:42 - should be previous for the next frame
136:44 - and then we have a new current which
136:46 - would then become previous for the next
136:47 - frame and so there's a nice swapping
136:49 - algorithm that I can use to do that I
136:51 - can create a two dimension of referenced
136:54 - called I'm gonna call temporary which
136:56 - should equal current then I'm gonna say
137:00 - previous equals oh no no I miss 8 which
137:04 - equals actually yeah previous 10 so I
137:11 - missed a previous is now the current
137:12 - right the current is now previous and
137:15 - then I can just reuse that other the
137:18 - previous one for current instead of
137:19 - making it new two-dimensional array this
137:21 - is a swapping algorithm I have to store
137:23 - a reference to previous because I'm
137:25 - gonna overwrite what previous is
137:27 - pointing to but then I'm gonna set
137:28 - current equal that so this should now
137:30 - still work but I'm not gonna see
137:32 - anything so now hopefully we're gonna
137:35 - see something now here's the thing I
137:37 - kind of I kind of want these to be
137:38 - floats I don't know why they're integers
137:40 - sort of feel like they should be floats
137:43 - so I'm gonna do all this like math to
137:45 - them and so this should also be a float
137:53 - and now what if what I'm going to do is
137:58 - I'm going to whenever I click the mouse
138:02 - so let's just see if this works to be
138:05 - lets say previous previous like 100 100
138:14 - equals 255
138:17 - [Music]
138:18 - and um let's see if this is gonna do
138:23 - what I think it's gonna do I'm just
138:24 - thinking thinking I'm thinking I'm
138:26 - thinking like a crazy person while I'm
138:28 - live-streaming
138:29 - does this make sense what I'm doing of
138:32 - whatever let's just run it yeah there we
138:34 - go
138:34 - ooh something happened it's like spread
138:36 - it spread out from the center there mmm
138:39 - what did I get wrong that was
138:42 - interesting
138:48 - both times look at this algorithm
138:51 - Oh if did I forgot about the dampening I
138:54 - forgot about the dampening very
138:56 - important there so where do I do that so
138:59 - now I also need to say current I J I
139:03 - need to dampen it equals current IJ
139:07 - times damping - I call it damping or
139:09 - dampening I guess I should call it
139:11 - dampening right dampening
139:34 - hmmm this didn't work the way I'd hoped
139:42 - so let's see here let's look at this
139:45 - this all of this all of this divided by
139:53 - two is this multiply is this these
139:55 - should be multiplied together what's the
139:57 - chance these should be multiplied but
140:00 - also it does say there it should be
140:02 - integers so I don't mean but what
140:07 - numbers should I be putting in these oh
140:10 - wait yeah this is adding okay let me
140:21 - look at this yeah
140:30 - whoops
140:42 - but oh the camera went off thank you
140:48 - this deal is little debugging sessions
140:50 - gonna have to get edited eret line 37
141:10 - right so is my swapping wrong swapping
141:15 - should be right
141:25 - the swapping should be fine breathe
141:38 - I think the swampthing is okay but what
141:47 - I'm interested in here is this the same
141:49 - thing destination oh that's interesting
141:57 - oh but that's the same it shouldn't
142:03 - matter more damping or hey hold on
142:09 - let's try throw it let me try let me be
142:13 - 0.9 just isn't enough
142:15 - let me try 0.5 whoops no I don't think
142:20 - the dampening is happening all right I
142:25 - guess it is
142:33 - weird some weird stuff is going on here
142:37 - it does should these be normalized
142:40 - values between zero and one and maybe I
142:45 - should just be like scaling up by 255
142:49 - that's where the same thing what's the
142:53 - difference they're right mmm it's
142:58 - current not previous yeah but why would
143:00 - that make a difference
143:05 - wouldn't that not make a difference
143:19 - whoa-oh-oh-oh it does make a difference
143:33 - it definitely makes a difference why
143:39 - does that make a difference yeah that's
143:41 - no dampening yeah it's very different
143:47 - but how could my brain is not cool
143:49 - that's not clicking into my brain right
143:50 - now it's very different because so I
144:01 - start with all these previous values and
144:03 - then the current value is equal to oh
144:07 - because it's been swapped of course it's
144:12 - different because it's been swapped okay
144:15 - so let me because it's different data
144:22 - right thank you it's been cuz of the
144:25 - swap we didn't we didn't start from a
144:27 - blank thing okay yeah I didn't notice
144:35 - that here thank you okay whoops so I
144:41 - didn't actually I wasn't being very
144:42 - careful here this I should actually be
144:45 - taking whoops sorry hold on there's uh
145:01 - I'm back that was edited out like a me
145:04 - just like spinning my head around for a
145:06 - while there because I really was not
145:08 - being very careful it this is says
145:10 - buffer 2 here this says buffer 1 here
145:14 - and in my code I have previous I'm
145:17 - adding up all the previous dividing that
145:19 - by 2 and then subtracting out previous
145:21 - but that's not what I want right because
145:24 - we have current and we have previous and
145:33 - so it's different data so I'm taking the
145:38 - neighbors from previous and then
145:41 - subtracting out what's current so let me
145:43 - fix that let me fix that change that
145:48 - here the dampening is there I added that
145:52 - in while I was debugging maybe you've
145:54 - just saw me do that I'm not sure
145:56 - and now aha
146:00 - there we go that looked like a water
146:01 - ripple alright let's let's be a little
146:04 - bit more explicit of all let's um let's
146:06 - just make the dampening zero like really
146:09 - high I'm just curious yeah you can see
146:11 - that ripple kind of going out whoa and
146:13 - bouncing around the edges cool I'm gonna
146:16 - leave it at 0.9 now this is really what
146:18 - I want to do let me make this like 600
146:20 - by 400 let me add mousepressed and by
146:29 - the way the let me put let me I'm gonna
146:32 - take the columns should equal the width
146:35 - I'm gonna put all this the rows should
146:40 - equal the height and I want to
146:45 - initialize I got to do this all after I
146:46 - set the size and now these I can set the
146:54 - the two arrays oh so I want to do all
147:01 - that and setup so that whenever I change
147:03 - the size of the window to the number of
147:05 - columns rows and the kind the two
147:07 - dimensional arrays all change so let's
147:09 - run this and see just see
147:11 - whoops what happened to my oh I
147:13 - commented it out that out so now what I
147:15 - want to do is when I click the mouse I
147:19 - want to find the right spot in the array
147:23 - and I want to say index equals Mouse X
147:27 - plus Mouse Y times rose and me clicking
147:32 - the mouse is like dropping a pebble into
147:34 - the water and so I can say I think I
147:36 - should I put it in previous I don't know
147:37 - it doesn't might not matter previous
147:39 - index oh no no no I forgot these are two
147:42 - dimensional arrays already so I can
147:43 - actually just say previous mouse X now
147:45 - it's y equals 255 so as I click and I'm
147:52 - just curious I think it'll actually work
147:53 - the same way if I put current yeah so
147:57 - let's let's use current kind of makes a
147:59 - little more sense to me let's D let's
148:01 - increase the dampening a bit I mean
148:03 - there's actually decreasing it so the
148:05 - ripples go out a little further I want
148:06 - to see them interact with each other
148:07 - that's pretty cool and so there we go
148:11 - water ripples in processing pixel-based
148:14 - water ripples and now would be so what
148:17 - Oh
148:17 - ooh what am I even doing what am I even
148:19 - doing Mouse dragged there we go how
148:25 - lovely look at this wonderful water
148:27 - ripples all rippling around good so yeah
148:30 - I think now I've made something that you
148:33 - the viewer could do much more with for
148:36 - example what if you thought about color
148:38 - what if you actually started with an
148:41 - image and then you made the sort of
148:43 - pixels of the image the initial values
148:46 - ah and you could like ripple over those
148:48 - oh I still want to do that I'm not gonna
148:50 - do that I'm gonna let you do that make
148:53 - something with this now this is
148:55 - eventually gonna get really slow and
148:57 - it's probably gonna be really slow into
148:59 - more the big larger the higher the
149:00 - resolution I make and if I'm gonna try
149:02 - to make a JavaScript version of it it's
149:04 - probably going to be really slow due to
149:06 - how slow pixel operations are in html5
149:08 - canvas but I don't think about all this
149:10 - stuff I just want you to be aware of
149:12 - that I'm sure that some of you will
149:15 - write in the comments and have some
149:16 - clever ideas how to make this into like
149:18 - a shader or something that's
149:20 - optimize but I'm happy where this is
149:21 - this is two-dimensional water ripples
149:23 - thanks to the Hugo Elias page from many
149:29 - years ago about how to do this algorithm
149:31 - in two dimensions okay thanks for
149:34 - watching goodbye
149:36 - [Music]
149:41 - alright line 37 is still wrong or is
149:46 - that just from before no I think I did
149:51 - not get her what's wrong with this
150:04 - bring director lingo back have the
150:06 - canvas adjust color with a rainbow
150:08 - effect yeah so many things alright it's
150:10 - 1:15 I'm gonna go I think I did a lot of
150:13 - stuff today I feel pleased yeah this
150:21 - would be a good for me to actually learn
150:23 - about shaders and come back to that
150:25 - I'm just looking here looking through my
150:29 - emails to there's anything really
150:31 - important there's more comments on my
150:37 - tensorflow
150:38 - example I'm whoops not here
150:48 - sorry a tensorflow where let me go to
150:51 - Schiffman repositories yeah here's I'm
150:58 - looking for tensor flow jet so this by
151:00 - the way is where I am creating some of
151:02 - these examples that I hope to make and
151:04 - kind of build from scratch in a video
151:05 - tutorial and I wrote some questions
151:08 - about this and I can XOR one and I think
151:12 - that and Nikhil Thor out is one of the
151:14 - creators attention flow digest responded
151:17 - here so so I'm gonna read this very
151:24 - carefully after I go off and I'm glad
151:26 - this is here because you know so when I
151:29 - this is going to be helpful information
151:30 - for when I come back and actually get to
151:33 - these parts here alright so thanks for
151:37 - tuning in today I can take a few minutes
151:40 - to answer some questions anybody in the
151:44 - chat have any questions you want to ask
151:46 - I'm looking at the patron chat I'm
151:48 - looking at the YouTube chat right now
151:54 - David Smith says there's a fantastic
151:56 - WebGL version of this in 3d with shader
151:59 - shaders made by Evan made by Evan WebGL
152:08 - water whoa
152:15 - that's cool that's better than mine
152:30 - how would webcam video input training
152:34 - neural network to play the chrome
152:35 - dinosaur game I would love to do that
152:38 - can you play chess I'm not very good I
152:40 - mean I know how to play chess
152:41 - I can play chess I'm also very good at
152:43 - losing a chess it's divided by two minus
152:46 - current I know I fixed that though that
152:48 - was the problem
152:49 - oh I think people are what I think
152:50 - people are like in the chat like thirty
152:53 - minutes or 45 minutes behind Oh pick up
152:56 - the ball how do I pick up the ball
152:59 - interactions press the spacebar drag the
153:01 - background drawing the water
153:03 - press drag the sphere to move it around
153:05 - wow wow this is crazy
153:12 - this is more than I could ever do all
153:17 - right
153:22 - how is AI useful for a startup well I
153:25 - think the first thing anyone should do
153:28 - when they're considering using an AI
153:30 - algorithm is ask themselves if they
153:32 - should be doing what they're doing
153:34 - and if what they're doing is kind of
153:35 - helping the world in some way so that's
153:39 - what I would say so I don't know that AI
153:40 - is useful for a startup I should still
153:44 - you should still do an introduction to
153:45 - firebase I have done an introduction to
153:47 - firebase alright so I think I'm gonna go
153:58 - let me play my goodbye song
154:01 - thanks everybody for tuning in now
154:03 - here's the Pearson I got good news bad
154:05 - news it's mostly just bad news I will
154:07 - not be live-streaming next week however
154:13 - oh yeah I don't know what do people
154:20 - think hold on what should I call that
154:30 - coding challenge my name a the fourth
154:32 - coding challenge star shy use the word
154:36 - the War of the Stars coding challenge so
154:42 - I think probably just may the fourth
154:45 - coding challenge is good I know that
154:49 - like may may the fourth be a part of
154:53 - your soul is a copyrighted phrase so I
154:57 - TV thesis week as next week may 8th to
155:00 - 11th I will be watching all of these
155:02 - thesis presentations there are many of
155:05 - them these will all be live-streamed so
155:08 - instead of watching me next week you
155:10 - should tune in to the live stream not on
155:12 - the coding train you have to go to this
155:13 - webpage ITP that NYU dot edu slash show
155:16 - slash thesis 2018 mark your calendars if
155:20 - possible I'm gonna try to be in the
155:22 - slack for those of you who are patrons
155:24 - and are in the slack Channel we can have
155:27 - a little like chat going in the live
155:29 - channel for these lot this live stream I
155:31 - mean I'd like to give my full attention
155:32 - to the students so I don't want to be
155:34 - just there in the audience like typing
155:35 - on my laptop but to the extent that we
155:37 - can have a discussion about them and
155:38 - answer to talk about them and answer
155:39 - questions during the live stream I'm
155:41 - available for that and yeah
155:44 - so that's what's coming next so that's
155:47 - next week so I won't have my regular
155:49 - coding trained live stream also if you
155:55 - are in the New York City area you should
155:57 - come to ITP
155:59 - Tuesday May 15th Wednesday May 16th
156:03 - I am tentatively planning to do my
156:05 - coding train livestream from the show
156:08 - Wednesday May 16th probably around 2:00
156:11 - or 3:00 p.m. so usually like to do that
156:13 - before the official
156:14 - the show I think this year I'm gonna ask
156:17 - somebody to like hold the camera for me
156:19 - I would try I like the idea of you know
156:24 - kind of just holding the camera myself
156:26 - and being like a one-person operation
156:27 - but I'm currently horrible at it and so
156:31 - I might try to psych get a slightly
156:33 - better system with that so I'm more
156:44 - making a joke about how I can't say may
156:46 - the the number four be with you somebody
156:54 - said to me earlier today because
156:55 - otherwise revenge of the fifth will come
156:57 - next I don't know all right where am i
157:03 - under live I think I'm going now
157:10 - celestial body conflicts I like that
157:13 - okay oh I'm going to see infinity war
157:17 - this weekend very excited about it with
157:19 - my nine year old son we're very excited
157:22 - about it I don't know should I be
157:24 - excited about now people are gonna spoil
157:26 - me in the chat just totally annoying so
157:28 - now would you have the YouTube chat
157:29 - anymore goodbye everybody I will see you
157:33 - not next week but the week after next
157:36 - stay tuned follow me on Twitter or it's
157:39 - subscribed the alarm bell I'm trying to
157:41 - schedule these now as events so that
157:44 - usually like the upcoming live streams
157:46 - are scheduled actually on YouTube in
157:48 - more in advance so hopefully I'll be
157:50 - able to keep doing that and that's it
157:52 - for today goodbye oh this is what I do
157:55 - now I play my trailer as the outro so
157:58 - I'll do that play the trailer as the
158:00 - outro
158:07 - [Music]
158:11 - to make
158:56 - [Music]
159:02 - [Music]
159:05 - you