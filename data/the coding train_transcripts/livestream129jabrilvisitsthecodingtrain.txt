00:00 - yes my event is starting oh wait maybe I
00:06 - shouldn't be showing this yet that's
00:07 - fine
00:07 - it could be back here right hello I
00:10 - think I've started screaming
00:12 - welcome to the code big train live on a
00:19 - Friday so this is a special Friday
00:22 - coding train episode I have a very
00:23 - special guest and this is my special
00:26 - guests project that this about
00:28 - approximately one hour livestream will
00:30 - be about you should know audio is low
00:33 - this is good so I have a to mic sit set
00:36 - up going and so when we debug that a
00:39 - little bit here before I get started I'm
00:41 - opening up the slack channel which is
00:44 - for patrons so make it louder so hold on
00:49 - special guests I don't know why I'm
00:51 - making this like some sort of like
00:52 - surprise reveal but special guests just
00:56 - say like a couple sentences and let's
00:57 - test your audio hello testing testing
01:00 - key do a cut to me well in testing audio
01:02 - I can actually hello what's a special
01:06 - hello testing deep thinning thinning
01:10 - there all right so is it just my mic
01:15 - that's low I can hear him but I can't
01:17 - see him know that you know is it is my
01:21 - mic lower than my special guests bike
01:24 - because you don't know who it is it's
01:31 - gonna take a minute the one H one issue
01:33 - with live streaming is the chat is about
01:36 - 20 seconds behind us in real time so
01:39 - that question they won't actually hear
01:40 - it for about 20 seconds I love it I'll
01:42 - make is fine high minus low Mike is
01:47 - low only is my mic low is my my ten
01:50 - years was fine and I can actually turn
01:52 - so first of all I'm kind of ok with my
01:54 - mic being low
01:56 - first of all is it actually registering
01:57 - my mic if I'm happing on here you
02:01 - hearing like a tapping both mics are
02:03 - fine I'm gonna mine I'm tapping mine now
02:05 - cuz it could be on low just cuz they're
02:08 - only hearing it through your mic
02:10 - no no it's mine turn mine up a little
02:13 - bit okay I hear tapping on both I can
02:18 - hear you both fine okay
02:19 - hello welcome I have a very special
02:25 - guest here in the coding trade studio
02:27 - I'm gonna cut to special guest welcome
02:30 - to gibreel
02:31 - if you're not familiar with - Brielle's
02:33 - youtube channel i probably just google j
02:38 - ABR ILS on YouTube it's also I learned
02:42 - how to say it now
02:43 - f stuff stuff stuff you're wrong no
02:47 - joking yes that's the FD stuff on
02:51 - YouTube gibreel has been teaching
02:53 - himself machine learning for the last
02:56 - around nine months and has discovered
03:00 - they made all sorts of exciting and
03:01 - interesting projects has made a bunch of
03:03 - videos about those projects happen to be
03:06 - in New York this week is actually doing
03:08 - a short-term residency at ITP which is a
03:10 - program where I teach and as taught a
03:12 - workshop here this week and gave a
03:13 - presentation out his work so it's Friday
03:15 - afternoon coding trade time and so I
03:20 - thought it would bring him here to talk
03:23 - about a new project that he's making so
03:25 - before I get to that let me just do some
03:27 - housekeeping today it's going to be a
03:30 - shorter livestream than usual there
03:32 - won't be any coding challenges or
03:34 - tutorials from me I hope to make that up
03:36 - with a bonus livestream next week or the
03:38 - week after but happy whatever holidays
03:43 - that are happening today and this
03:44 - weekend you might be celebrating I have
03:46 - to catch a train
03:47 - in a couple hours so what look it's
03:50 - funny I have to catch an actual
03:52 - real-life train in a couple hours the
03:54 - head out of town so this is just going
03:58 - to be a guest live a guest session I
04:02 - will say though that if you don't
04:04 - subscribe I don't know why I'm like
04:05 - pretending I don't have a computer here
04:07 - YouTube let's search for stuff stuff so
04:15 - this is hey you have but you have to
04:17 - YouTube I have a million a billion to me
04:20 - I kind of knew that but I forgot about
04:23 - that is are you are you do you work on
04:25 - all of them no so this is the one you're
04:27 - activists to bros okay so this is
04:30 - Jibril's youtube channel and you can see
04:34 - just memorize this channel ID I'll read
04:36 - it to you
04:36 - capital u capital C getting this town
04:40 - capital q you're cheating when your
04:42 - numbers book today oh yeah I've we're
04:44 - gonna have you read some random numbers
04:47 - so what was I saying so you should
04:50 - definitely subscribe you should click
04:52 - look I'm gonna subscribe so this the
04:54 - reason why I'm not subscribed is not
04:56 - because I'm not subscribed it's because
04:58 - this is a fake account that I set up
05:01 - just that I bought YouTube red with so
05:03 - if I look at stuff on YouTube on my
05:05 - livestream that ads don't show up it's
05:07 - also a a YouTube channel an account that
05:13 - my kids use when they watch YouTube
05:15 - because I don't want them to watch have
05:19 - to watch the ads either so you can see
05:21 - what kind of videos they like to watch
05:23 - look gibreel visits the coding train
05:27 - okay now let me go back and I'm gonna
05:29 - give you a clue here you're gonna what
05:31 - you're gonna want to do is you want to
05:32 - go to his channel you're gonna want to
05:33 - click Subscribe then you're going to
05:36 - click this alarm bell I learned about
05:38 - this today I actually already knew about
05:40 - this but the alarm bells gonna if you
05:42 - could do this with my channel too if you
05:43 - want I guess you probably already
05:44 - subscribed if you're watching do it but
05:45 - it'll give you a it will give you a
05:49 - notification as soon as there's a new
05:51 - video and the reason why you might want
05:53 - to do this is there's gibreel gibreel
05:56 - will be publishing a new video on Sunday
05:58 - mm-hmm I think you're gonna want to
05:59 - watch
06:00 - okay so if you want to get that
06:03 - notification it's gonna be on his
06:04 - channel so you're gonna have to
06:05 - subscribe there okay I'm looking at the
06:09 - chat so I think that oh these are look
06:14 - at this these are some great let's look
06:15 - at these oh look at your friends oh that
06:18 - okay so also by the way this I learned
06:20 - about recently to gibreel is doing live
06:22 - streams I guess I could let you talk
06:24 - about your own stuff I don't know why I
06:25 - can't stop talking my this is my channel
06:27 - I guess I'm in charge here
06:29 - this channel is where gibreel does his
06:33 - stream archives get published here right
06:35 - your live streams are actually on Twitch
06:36 - rictus okay
06:37 - and then also some nice the physics girl
06:40 - is an awesome channel coding trainers
06:42 - it's kind of okay and I don't know some
06:44 - of these other channels but I'm
06:45 - definitely gonna have to check them out
06:46 - they look cool all right
06:48 - so and here you can see here you can see
06:52 - YouTube - real real life - real - okay
06:57 - if you're reading this you've been hacks
07:00 - okay alright he's like a real live a
07:05 - real life youtuber in person I don't
07:07 - think of myself as that because I'm like
07:09 - an old person but useful energy okay I
07:15 - have alright so I think okay let me
07:18 - mention two other things number one is
07:20 - there's a lot of live streams going on
07:21 - right now I saw that just normally I
07:25 - would tell you to watch something else
07:26 - if it's just me but since this job
07:28 - really should stay here but there is no
07:32 - there's the glitch channel this is
07:33 - totally giving me the wrong stuff Oh
07:36 - glitch code editor YouTube I don't know
07:41 - why I saw that they were live-streaming
07:43 - I can't find it
07:44 - nevermind glitch glitch I don't know why
07:48 - I'm plugging glitch but I love glitch
07:49 - it's a code editor not an official
07:51 - sponsor or anything but they they're
07:54 - they have a live stream going on today
07:55 - and then there's also the tensorflow
07:57 - dev summit this in particular I wanted
08:00 - to mention let's see if we can tune in
08:01 - to the live stream really briefly what
08:05 - are we learning about
08:08 - all right you see it now you don't hear
08:14 - the audio from this except through my
08:16 - mic so maybe I should just do a
08:18 - voiceover saying these workers servers
08:25 - and there's very little going on same to
08:27 - estimate I can't do it anyway
08:29 - so you the tensorflow dev summit is
08:31 - going on live right now I don't know
08:33 - what this is about but and I think
08:35 - earlier already today there was a very
08:37 - exciting announcement if I go to Jas
08:40 - tensorflow dot is at work I think yes so
08:45 - you might have heard me talk about a
08:48 - project called deep learn Jas on this
08:52 - channel what happens if I go too deep
08:54 - learn Jas org
08:55 - it's still there but it now says exactly
08:58 - what I wanted to tell you is that deep
08:59 - learned digest has become tensorflow Jas
09:03 - so that's pretty exciting like it
09:07 - graduated it grew up it graduated it's a
09:09 - teenager now maybe in whatever computing
09:12 - years open-source ears and how that
09:14 - translates a dog ear but member ask them
09:19 - the chat can we get to the point very
09:20 - unlikely it's gonna happen and so that's
09:27 - really exciting that how this project is
09:29 - growing to be able to unlock and make
09:31 - possible more types of machine learning
09:34 - algorithms and possibilities in the
09:36 - browser and I have been working on a
09:38 - project at ITP with a bunch of
09:41 - researchers I know Jabril has been
09:43 - experimenting with it for maybe an
09:44 - upcoming project if I go to github.com
09:50 - /ml 5j s and i'm gonna go here so this
09:53 - is a machine learning library kind of
09:55 - like a higher-level simple basic library
09:58 - to do some machine learning stuff that
10:03 - was built that is built on top of deep
10:05 - learning is wherever that
10:09 - and now that deep learned dodgy ass has
10:11 - become tensorflow digest this means
10:13 - we're going to do a lot more work on
10:15 - this to support all the new
10:17 - possibilities that are unlocked from
10:19 - tensorflow jazz in particular most of
10:22 - our examples in this library involve
10:24 - using pre-trained models and if you want
10:27 - to train your own model you've got to go
10:28 - and like set up your Python environment
10:30 - we have some tutorials for that but now
10:33 - we're gonna start to be able to make
10:34 - some examples and things where you can
10:35 - actually do the training in the browser
10:37 - so I'm slowly getting to it but this is
10:40 - I hope gonna be a big focus of my
10:42 - channel April May June however long I
10:46 - have that energy to do the service so
10:49 - that's that's coming let me see if there
10:51 - are any questions in the chat is it
10:54 - efficient to learn in the web and I have
10:58 - a question it does not it it's what what
11:01 - the researchers at Google have done in
11:03 - making tensorflow
11:04 - jazz is nothing short of heroic in
11:07 - getting all of the matrix operations
11:09 - that need to happen to happen in with
11:12 - WebGL using the GPU of the computer in
11:14 - the browser but its performance is still
11:17 - not going to be as fast as kind of
11:19 - native C++ tensorflow
11:21 - but it's remarkable how fast it is and
11:23 - the ease of not having to set up an
11:25 - environment just go to a webpage to
11:27 - execute a task to program something to
11:29 - make an animation I think there's a lot
11:30 - of exciting possibilities there okay so
11:36 - let's let's transition now to our guest
11:42 - and so I'm gonna let me see so I don't
11:45 - remember
11:45 - trying to remember you could step into
11:49 - the frame
11:50 - welcome to brill so i'm looking over
11:54 - here cuz i have a monitor of here so one
11:56 - thing by the way is that I have to
11:58 - practice is that the people we are
12:00 - speaking to are there but you'll notice
12:02 - I do this a lot like blah blah blah blah
12:05 - because I'm staring at the monitor I was
12:06 - observing very Pro okay so I'm trying to
12:10 - think when I first discovered to Brill's
12:14 - channel and I wish I had a good memory
12:17 - of this or story of this but I
12:18 - definitely remember when I first saw
12:21 - his video on the run forest project so
12:25 - I'll let Jabril introduce himself and
12:28 - say more about his background and how he
12:29 - got into this machine learning stuff if
12:31 - you like rather than try to do it myself
12:33 - but what I loved about that I have a
12:35 - book that some of you might be familiar
12:36 - with called nature of code where I have
12:38 - a kind of a chapter on neural networks
12:40 - and a chapter on genetic algorithm and
12:42 - they're kind of old and out-of-date and
12:44 - I've kind of been wanting to expand that
12:46 - and do more with it this is now you know
12:49 - you're experiencing this live and so
12:53 - when I saw that project a run forest
12:56 - project which she hasn't have if you
12:58 - haven't seen it's a unity based
12:59 - simulation that trains a simulation
13:02 - forest gump amazingly character to run
13:05 - around to me is using both neural
13:06 - networks and genetic algorithms and it
13:08 - was really like I looked at like oh this
13:09 - is the perfect kind of demonstration
13:11 - example in the kind of creative coding
13:13 - or game making or art making context of
13:16 - how to apply machine learning to as
13:18 - simple it's not that simple but to a
13:22 - graphics motion based simulation so I
13:24 - was super excited to see that inspired
13:26 - me to think about some new stuff and
13:28 - where I wanted to take some of my
13:29 - tutorials to JavaScript I don't know the
13:31 - Internet's put the internet puts people
13:33 - in touch huh I've been watching his
13:34 - videos I think he's watching sometimes
13:37 - and so so welcome to the coding train so
13:43 - what I'm gonna do awkwardly is I'm going
13:46 - to take my coffee and my laptop and I'm
13:49 - gonna slide out of the way and go sit
13:51 - there's a chair over there and then I'm
13:53 - just gonna turn over to you we might
13:55 - mute my microphone and you can talk
13:57 - about your project and code and I'll
14:00 - watch the chat to see if there are
14:03 - questions so after a like a little bit
14:05 - of time I'll come back and ask you some
14:07 - of the questions people have asked sweet
14:09 - make sense very cool okay I'm shuffle
14:12 - awkward shuffle awkward okay all right
14:15 - howdy everyone how is it going so yeah
14:18 - I'm gonna give a little brief overview
14:20 - about Who I am for those of you that do
14:22 - not know what
14:23 - I'm sure as all of you so my name is
14:26 - Jibril I run a little YouTube channel
14:28 - called Jibril's here on YouTube and
14:30 - recently I converted my channel to focus
14:33 - on computer science that happened in
14:34 - September and that was probably one of
14:36 - the best things I've ever done because I
14:38 - learned that you know I had a great
14:40 - passion for writing code and write and
14:42 - making products and projects that were
14:45 - based on computer science and so yeah I
14:49 - mean obviously if I had a passion for
14:50 - that it was easy to show that in video
14:54 - projects as well and fast forward so one
14:58 - of the the biggest projects that I
15:00 - produced to date is the run forest
15:01 - project that got a lot of I is really
15:04 - grateful for and that really harnessed
15:07 - the power of machine learning which is a
15:09 - really big buzzword these days and yeah
15:13 - that's that's pretty much overview I
15:15 - spent nine months learning on how to
15:16 - write you know narrow networks from
15:18 - scratch or iPhone so I'm gonna pause you
15:19 - for a second people tell me the audio is
15:21 - low oh okay
15:23 - so let's let's do a little I'm sorry to
15:24 - interrupt you in the middle it's not no
15:26 - worries is my replacing good you know
15:29 - it's because it's going through it's
15:31 - fine you're good you're good okay I got
15:32 - it I have an idea let me just check a
15:34 - couple things okay I got a feel time so
15:36 - I'll dance
15:37 - - I actually muted myself okay all right
15:52 - just let us know if this mic is still
15:54 - too low but yeah that's pretty much the
15:56 - overview I spend about nine months
15:58 - learning how to write machine learning
15:59 - algorithms from scratch because it was
16:03 - something AI is really cool to me I
16:05 - think and so yeah
16:08 - the run forest was released and today
16:10 - today what we're gonna do is we're going
16:12 - to examine this really simple JavaScript
16:16 - machine learning application kind of how
16:19 - it was done it's another machine
16:22 - learning application written wrote from
16:25 - scratch so we're gonna take a look at
16:26 - the code and all that good stuff
16:28 - um so let's let's get into this so here
16:32 - we have this example it's what I call a
16:35 - color predictor
16:36 - network to demo and it asked you a
16:39 - simple question does white or black look
16:42 - better over this color and so the color
16:45 - is within the circle and it's randomly
16:48 - generated
16:48 - so what so there we use a what kind of
16:54 - the do is press two two that's it okay
17:01 - okay and I just walk that's it no ok so
17:11 - what's important for us to start before
17:13 - we can get into the application let's
17:16 - understand the the main computational
17:19 - part of this application so we have a
17:21 - color and as you know colors are they're
17:24 - represented as a vector of three or
17:27 - sometimes four if you include the Alpha
17:30 - but we're not including the Alpha we're
17:31 - only going to use the RGB values so we
17:35 - have our inputs which is three is that
17:40 - own frame yes all right
17:41 - so we have red green and blue and these
17:46 - are values between 0 and 255 for each
17:51 - input so we need to build a neural
17:56 - network that will be able to take these
17:57 - inputs and then do a computation on them
18:00 - and then pass into an outputs to predict
18:02 - if it looks better over black or white
18:05 - so let's first draw our outputs just
18:08 - make sure it's all in the frame yes
18:10 - that's good and this is gonna be it
18:13 - predicts black and this predicts white
18:16 - so now we need a hidden layer is what we
18:19 - call hidden layer with artificial neural
18:22 - networks in the middle that does the
18:23 - computation part and this is our guess
18:26 - and so we are just going to arbitrarily
18:29 - just duplicate the same size of our
18:32 - inputs for our hidden layer nodes we're
18:34 - just gonna say three it's a good place
18:37 - to start if we're really serious about
18:39 - this we could expand it try five try
18:41 - seven and just log the results for all
18:44 - of them and see which one works the best
18:46 - but we're going to say three for this
18:47 - example
18:48 - make it nice and simple and so we have
18:52 - our RGB and if we go back to our example
18:56 - what's happening here is there's a
19:01 - computation that happens within our
19:06 - network to three one two three one two
19:12 - three and Dan feel free to interrupt if
19:16 - you think that I'm little off-base with
19:17 - anything uh-huh uh-huh uh-huh
19:24 - okay so this what did I just do it looks
19:27 - really confusing but it's actually
19:29 - really simple so we we need to somehow
19:32 - get our inputs computation and into our
19:36 - outputs and the way that we do that is
19:38 - we use what I'm using bubbles to
19:40 - represent what are called weights within
19:42 - our known network and so every single
19:45 - node within our hidden layer has the
19:48 - same amount of weights as there are
19:50 - inputs so what that means is there's one
19:55 - weight for this input there's one way
19:57 - for this input and there's one way for
19:59 - this input and the same for the rest of
20:01 - them one weight for this input one way
20:04 - for this input one weight for that input
20:06 - and repeat I didn't do that right boom
20:11 - boom and so what that happens is that we
20:14 - pass this through we do our input times
20:18 - the weight and then plus our bias and we
20:21 - can repeat the process this will give us
20:23 - a value let's say that we after we
20:24 - compute all these sum them up add a bias
20:27 - it will give us let's just say 0.5 and
20:30 - then we'll pass that to our outputs
20:32 - which is three huh huh passes to our
20:44 - output and then that will give us a
20:46 - value for each of these so let's say
20:47 - this is 0.3 and then this is 0.7 and
20:50 - then it's just as simple as we'll just
20:52 - say that this is higher 0.7 so it's
20:54 - guessing white so that's a quick
20:57 - overview on what's going on here with
21:00 - we're
21:01 - Daniel's gonna post a more in-depth
21:02 - tutorial on this or you already have or
21:05 - well so I have tutorials yes this is you
21:13 - know the same kind of structure that
21:14 - I've used in my network library correct
21:17 - yes and I'm I was thinking at some point
21:19 - maybe next week hopefully I might try to
21:21 - recreate your project as like a coding
21:23 - challenge okay so we can put a link to
21:27 - yours okay so we'll put a link to Daniel
21:29 - Shipman series and what she goes
21:30 - in-depth with this so if you want to
21:32 - learn more about what's going on here
21:33 - but that's a quick overview on the math
21:35 - on the computation so our inputs it gets
21:38 - times about weighting biases then we get
21:40 - a value and when we pass that to our
21:41 - output same computation and then gives
21:43 - us a prediction so yeah let's do it
21:49 - all right so people are asking we're
21:51 - using libraries give you a bunch of
21:53 - questions just because the Chad's gonna
21:55 - scroll too fast okay actually no it's
21:57 - fine I stopped it from scrolling so what
21:59 - for question umber one are you using any
22:00 - libraries or are you building this from
22:02 - scratch okay so yeah so this is a from
22:05 - scratch computation we're doing this
22:06 - completely from scratch and it's not
22:11 - necessarily important that you do from
22:15 - scratch no networks but if you want to
22:17 - get a good understanding on how to debug
22:19 - networks this is a really good it's a
22:22 - really good a way to go about ensuring
22:24 - that you can do that yep okay next
22:29 - question is is does the input have to be
22:31 - from 0 to 255
22:33 - okay sure the inputs have to be
22:34 - normalized what's the from 0 to 1 yes
22:38 - great question great question so again I
22:40 - just glossed over this but so
22:43 - normalizing inputs for colors is
22:45 - actually really simple and it is always
22:47 - best to normalize your your input data
22:51 - so because we know that the the domain
22:54 - for a color value is always going to be
22:57 - 1 the 256 or in computer language we
23:00 - shift that by 1 0 255 we can simply just
23:03 - divide whatever this value is over 255
23:05 - and that will remap this between 0 and 1
23:08 - and so essentially when you're writing
23:10 - your program you would just pass the
23:12 - input through
23:13 - a function that would just divide about
23:16 - 255 so yes great question hmm
23:20 - so I'm curious about this too I sort of
23:22 - think it's probably okay the question
23:24 - for you asked it but is there a benefit
23:28 - to having two output nodes yes so
23:38 - there's a lot of debate on this and I I
23:41 - and I agree with the side that it's
23:44 - easier when you have like classifiers
23:47 - versus like if you have just one output
23:50 - node that is map between negative one
23:52 - and one and right and then if it's if
23:55 - it's above one zero then it's going to
23:57 - be white if it's below zero then it's
24:00 - going to be black yeah based on the
24:05 - research that I've read it's always best
24:07 - to go on a classifier yeah maybe this
24:11 - would be fine in the case of there's
24:13 - only two right the correct correct
24:26 - correct and the whole reason for that is
24:32 - because what what happens when you
24:34 - separate them is you get probabilities
24:36 - versus like you get a map of between
24:38 - zero and one which again if it's one
24:40 - output you can get away with that but if
24:41 - you try and encode your outputs using
24:44 - this for like 30 different the neural
24:48 - network might not make good sense of
24:49 - that oh cool so let's let's continue on
24:52 - because we need to get into the code
24:55 - part so let's look at some of the code
25:01 - as to how we went about writing that
25:04 - parts of our neural network and write
25:09 - down is up I keep forgetting I'm new to
25:11 - Mac so please forgive me here alright so
25:16 - and you beautified my coat no fries no
25:23 - worries
25:25 - beautified and zoomed okay so we first
25:30 - need to define all of our variables at
25:32 - the top so RGB is our input and then we
25:38 - have the amount of choices which is a
25:41 - variable that we use for our output just
25:50 - getting one second to skim this make
25:52 - sure I don't give you the wrong
25:53 - information here sweet so we set up our
26:02 - variables are jeebies our input data and
26:05 - then so one thing that's really
26:08 - important that I should go over just the
26:11 - just to make sense of what's going on
26:13 - here is two wrong computer on this one
26:18 - like that so so it's really important in
26:21 - order for you to write your algorithm
26:23 - you need to you need to know how to
26:25 - compute this compute both of these so
26:28 - this is really just an array of values
26:33 - so we can call this array G of I right
26:37 - so this is G of zero and this is G of 1
26:41 - and G just stands for a guess I put 0 0
26:43 - 1 right and so we want to know what does
26:48 - G of I or what does G of 0 or what does
26:50 - G of 1 equal how can we get that
26:53 - equation well if we look at our diagram
26:55 - for our neural network it's actually
26:57 - quite simple
26:57 - so this is in frame right here so we can
27:01 - do G oh my goodness can I write okay so
27:10 - let's do it over here so G of I which
27:12 - again is this array this output layer G
27:16 - of I equals the summation of hidden
27:23 - layer this is going to be a hidden layer
27:25 - of I and this is going to be inputs of I
27:29 - that's how we define each of these
27:31 - vectors so G of I equals a summation of
27:35 - H
27:37 - hidden layer and then we have to go into
27:40 - another loop because we can't use the
27:43 - same indicee of I and J because it yeah
27:47 - it won't return the right value so
27:49 - hidden layer of J which is just gonna be
27:52 - 0 1 2 times the weight of G of I right
28:03 - and then we simply just add our bias of
28:06 - G of I and so this is the equation that
28:11 - we can use to compute each of our output
28:14 - nodes and so just to clarify what's
28:17 - going on here this is summation symbol
28:19 - which simply means to add up all within
28:23 - the the array so hidden layer J times
28:27 - the weight this is a function which
28:29 - simply just grabs the weight of whatever
28:32 - output node you're on so if you pass G
28:36 - of 0 for example to through this weight
28:39 - function it will just grab whatever bias
28:41 - or I'm sorry whatever weight of G of I
28:44 - is there so that's actually G of I of J
28:49 - actually hereby up J huh so now we have
28:56 - this equation that tells us exactly what
28:58 - these values equal so now we don't know
29:02 - what HL j equals so we also have to
29:04 - define HL of J and we go about doing
29:07 - that by doing the same exact process
29:10 - after this will be L of I for indices
29:13 - same exact process summation of our
29:16 - inputs right inputs what I use I NP and
29:23 - puts J times weight of HL of I so the
29:32 - same exact input we need H ll by mm-hmm
29:37 - and then we simply just pass our bias
29:39 - and again this this right here is a
29:41 - function all it does is it grabs the
29:44 - bias for whatever node that we passed
29:46 - through it so bias of HL y
29:51 - mm-hmm and there we have it we have our
29:53 - entire equation because we know exactly
29:54 - what inputs input of J equals it's going
29:57 - to be simply the random value of our
29:59 - color and so this is what we need to
30:04 - write in our software how we on time dad
30:10 - cool
30:11 - I keep forgetting up is down that's okay
30:15 - so same exact thing that you see on the
30:18 - board is what we write here in our code
30:20 - so first before we can get the what the
30:24 - guess no Zico we have to first forget
30:26 - what the hidden layer nodes equals so
30:28 - simply put as we did on the white board
30:32 - hidden layer zero equals we'll get to
30:35 - what Rayleigh was in a second but hidden
30:37 - there zero equals we did our input
30:40 - encoder which was a question that was
30:42 - asked earlier about normalizing our
30:45 - input data so this function simply just
30:48 - divides our input divided by Oh 255 and
30:50 - then we'll times that by the weight of
30:55 - our of our hidden layer so this this is
31:01 - an array function that I will go over
31:05 - really quickly that we instantiate to
31:10 - hold all of our weights so color
31:17 - predictor 0 0 0 I'll go over this I
31:21 - think it's important so so the function
31:26 - color can you see this I think so okay
31:32 - there's a lot of data that you have to
31:34 - remember this is interesting color
31:37 - predictor variable uh-huh so there's all
31:42 - these different dimensions to it and I
31:47 - think it's interesting or it's important
31:48 - to go over what the dimensions mean so
31:51 - let's just get to and then let's just do
31:53 - I don't know one so what does this mean
31:56 - if you have color predictor isay row two
32:00 - what does that mean well well so we want
32:06 - to store these arrays into our color
32:10 - predictive variable and we can go about
32:11 - doing that by defining the location of
32:15 - all of these so if the hidden layer is
32:16 - going to be 0 and then the guess is
32:19 - going to be 1 right and so all the notes
32:24 - are then going to have their own
32:25 - assignments so 0 1 and then 2 same here
32:31 - this is going to be 0 and 1 and then the
32:36 - weights are also gonna have their own
32:37 - assignment as well so 0 1 2 3 and the
32:41 - same day 0 1 2 3 and we repeat that for
32:45 - every single weight inside of the nodes
32:48 - right and so how this works is our color
32:51 - predictor is if we want to get grab
32:53 - reference to 0 that is going to be
32:55 - hidden layer and then 2 is going to be
32:58 - the last node and then 1 is going to be
33:01 - the the second way because start 0 1
33:04 - second way so this variable is grabbing
33:07 - a reference to this way that's exactly
33:10 - what color predictor is 0 to 1 is doing
33:13 - and so you see this eye
33:14 - that's an extra dimension that you might
33:16 - be confused about so let's talk about
33:18 - that real briefly so a lot of
33:21 - information there's a lot of information
33:23 - but bear with me here
33:25 - Oh switch camera' okay all right I need
33:28 - that all right so this so you see this
33:31 - extra eye and what does that mean so
33:34 - traditionally - traditionally with such
33:36 - an example you would use back
33:40 - propagation to train this no network
33:42 - however time was a factor and as well as
33:46 - that we wanted to go over lesson of both
33:49 - neural networks and genetic algorithms
33:52 - so why not combine them together so what
33:54 - we did for this example so that eye is
33:57 - actually just grabbing a reference to
33:59 - what predictor we are currently using so
34:04 - genetic algorithms real quick you have
34:07 - to have a population you have to assign
34:09 - Fitness scores to every single
34:13 - what's sorting for the creature within
34:16 - the population and then you have to
34:18 - mutate them and breed them in X Y & Z so
34:21 - we have a population of 800 predictors
34:23 - at four at start and then they all have
34:28 - randomly initialized weights and biases
34:30 - which again just to make sure it clear
34:31 - are all of these values wait-wait-wait
34:34 - by swim away bias these are all randomly
34:36 - initialized the function that we use for
34:39 - this program is randomized between zero
34:43 - and one and then they all based on their
34:47 - randomly initialized weights we'll make
34:48 - a guess on which one they think is
34:50 - correct and so the most of them said
34:54 - that black is the correct color that
34:57 - looks best over this randomized color
35:00 - and then we simply just use a genetic
35:08 - algorithm to train this this predictor
35:12 - to converge on the best possible
35:14 - predictor and yet that's it that's a
35:19 - general overview on this the code is
35:23 - available on github and I left a lot of
35:28 - comets however that it will require a
35:33 - bit more in depth if you if you really
35:35 - want to like get a full grasp on this
35:38 - from learning have fun knowing
35:39 - absolutely nothing if you already know
35:41 - some stuff about no numbers between
35:42 - learning I'm pretty sure this example is
35:44 - pretty straightforward from you but the
35:46 - benefit of doing of writing neural
35:49 - networks from scratch is that you really
35:50 - have a good grasp on what's going on
35:52 - behind the scenes versus using libraries
35:55 - and you're able to debug you know
35:59 - different problems that might arise when
36:01 - you are writing your neural networks
36:04 - would be it from scratch or using
36:05 - libraries yeah and that is pretty much
36:13 - it we we do have plans to update it with
36:15 - the actual back propagation algorithm in
36:18 - there so that you can learn from that as
36:22 - well
36:23 - and
36:28 - okay where did that my hat go
36:31 - oh the cap the KY I picked it up I held
36:35 - it in my hand I put it in my pocket
36:36 - oh very cool so let me come over here a
36:40 - few more questions okay let's see what I
36:44 - can find here okay
36:48 - four so first people had asked to is the
36:51 - code already at github or you're gonna
36:53 - on github are you gonna update it
36:54 - yeah I I slept a little bit so stay
36:58 - tuned whenever whenever it's on github I
37:00 - will come back and edit the description
37:03 - for this livestream and put a link to
37:05 - but they can currently go to Steph's of
37:07 - the comic slash color
37:10 - oh that link that I use right yes so you
37:12 - can go to let's let me zoom in here and
37:15 - show you so this one yes if you want to
37:21 - grab the code right now I don't know why
37:24 - whenever I paste links into the YouTube
37:27 - chat they don't seem to work for that
37:28 - answer so but anyway so I would paste
37:30 - this into the chat but that wouldn't
37:31 - even work so you can see it yeah up
37:34 - there that you can grab the code now but
37:37 - I will also include a link to github
37:40 - repository or whatever that and it is my
37:43 - intention I think one of the reasons why
37:45 - I love this demo and people are kind of
37:47 - asking this a bit in the chat was like
37:49 - oh like do you really need a neural
37:50 - network for this right and I don't I
37:52 - think to me that I mean that's a
37:53 - perfectly valid and interesting question
37:55 - and probably the answer is no you don't
37:57 - need a neural network for this but when
37:59 - learning about neural networks when
38:01 - trying to build your own machine
38:02 - learning project if you can start with a
38:04 - well-defined small and scoped problem
38:07 - then you can really figure out and
38:09 - because you in some ways I do this
38:12 - similarly with the Juniper so my genetic
38:14 - algorithm prom projects I take a example
38:18 - where I know the answer right so I can
38:21 - see if the genetic algorithm worked
38:22 - because ultimately what I want to do is
38:24 - use a neural network or a genetic
38:25 - algorithm in some domain where maybe I
38:27 - don't know the answer I couldn't solve
38:29 - right so easily but to figure out how
38:31 - those things work I've got to come up
38:32 - with and so this is a really nice
38:34 - problem for that because it's simple
38:36 - small
38:36 - and for people who want to do creative
38:39 - coding graphics and design stuff it's
38:40 - got color and then and not to mention
38:43 - once you learn how to do this stuff from
38:45 - scratch this is easily scalable for the
38:48 - most part you still have to worry about
38:50 - some other stuff like vanishing
38:51 - gradients and stuff like that but for
38:53 - the most part you can take this and
38:54 - scale this up and it'll work just about
38:56 - the same so there's also that benefit as
38:58 - well so there were a couple of questions
39:01 - that came in on Twitter asked Jabril
39:05 - hash tag hash tag people there were a
39:08 - lot of questions like how are you
39:09 - speaking with your mouth there was a lot
39:11 - of moving I am a BOTS how can I become
39:14 - like you I don't know if that's an
39:16 - answerable question but that was the
39:18 - question that came in from id AXI so on
39:21 - Twitter I'm so here's a question from I
39:23 - am rashon on Twitter this is a big
39:26 - question ok let's do it I don't know I
39:28 - think this is a question I've certainly
39:29 - touched on and but how is AI let me read
39:34 - the question how it actually is written
39:36 - how is AI different from a neural
39:38 - network or deep learning or machine
39:40 - learning they often seem to be used
39:41 - interchangeably and cause confusion so
39:43 - first of all I want to say like question
39:46 - and I struggle with this question all
39:47 - the time because there's all these
39:48 - different terms so we so let me list
39:50 - those terms artificial intelligence deep
39:53 - learning machine learning and then I
39:55 - might put neural network in a like
39:56 - different category but that's another
39:58 - term as well I don't know if you have a
40:00 - kind of like way that you describe these
40:03 - the terminology of people when they ask
40:05 - those kind of yeah I'd like to start
40:06 - with English is difficult I like to
40:09 - start there but for the most part AI is
40:12 - it's like a grab all for everything a I
40:14 - like you can hard code AI you don't have
40:17 - to use machine learning so that's kind
40:19 - of like the grab all for at all and then
40:22 - what was the other the code words would
40:23 - so oh boy all these things are coming in
40:25 - AI machine learning deep learning yeah
40:29 - and so machine learning I think it's
40:31 - like the next level down so you don't
40:34 - need to use a neural network to do
40:36 - machine learning there are different
40:37 - ways you can go about teaching the
40:40 - machine how to learn one really good
40:41 - example is decision trees people haven't
40:44 - developed really complex decision trees
40:46 - and
40:46 - the machine just kind of explores the
40:48 - space and learns the best way to use
40:50 - this this is injury so that's another
40:52 - way of applying machine learning and
40:54 - then would you say neural network and
40:56 - debugging yes yeah so neural networks is
40:59 - essentially what we showed and even
41:03 - that's kind of to the bay because like
41:05 - recurrent neural networks are no
41:07 - networks but they're not really you know
41:11 - neural networks you know that make sense
41:14 - so I don't know it's it's if you say no
41:17 - network people will know what you're
41:19 - talking with most part I'm gonna try to
41:21 - give my take on this let's do it let's
41:24 - do it well I think I would put neural
41:28 - network in a different category than
41:30 - those other terms because to me neural
41:32 - network need oh look at the cat I don't
41:33 - know I'm so bad I don't have a good I
41:35 - wanted to get like between the ferns
41:38 - like set up in here where I could get
41:40 - like a camera and some like chairs a
41:41 - little coffee table and can have like a
41:43 - conversation but it's no just the
41:44 - awkward standing thing somebody in the
41:46 - chat told me to put a mirror behind the
41:49 - cow and then we're like talking to each
41:50 - other but looking at the view I like
41:52 - that that might be weird though there's
41:53 - nobody else here I'm kind of egotistical
41:55 - all this I used to have a screen over
41:58 - there and I would always stare at that
41:59 - but anyway I limit so so the reason so
42:01 - neural network to me is a particular
42:06 - algorithm that involves connected nodes
42:09 - that and data flows from one node to the
42:13 - other and there could be different
42:13 - architectures and styles and so that
42:16 - neural network data structure or
42:18 - algorithm can be applied in the field of
42:22 - artificial intelligence machine learning
42:23 - at deep learning but neural network is
42:25 - an example of a particular algorithm I
42:28 - would say you could sort of think of it
42:29 - also as a data structure but there's an
42:31 - algorithm there in terms of how the data
42:33 - flows through the structure so that's
42:36 - what that's what I think and then I
42:37 - think that artifice to me artificial
42:40 - intelligence is this umbrella term
42:42 - mm-hmm that is really just like hey or
42:45 - can computers and candy have
42:49 - intelligence like humans do and what
42:51 - does that
42:52 - and apparently my technology is not
42:57 - intelligent enough to record video for
42:59 - more than 30 minutes at a time
43:01 - oh so I think that is a very broad
43:04 - umbrella term for just the big field of
43:06 - like simulated intelligence rather is
43:08 - that is it real intelligence is that the
43:09 - illusion of intelligence is that the
43:11 - same things like I'm a deep
43:12 - philosophical question and then I
43:15 - machine learning to me as a subfield of
43:18 - artificial intelligence involving making
43:20 - sense of data mm-hmm so you have data
43:22 - and that's input to a system and you
43:25 - have some output which might be making
43:26 - sense of that data whether it's a
43:28 - prediction for something it's gonna
43:29 - happen in the future or a classification
43:31 - of something and then then I think of
43:34 - deep learning as a kind of almost like a
43:38 - modern rebranding of neural networks
43:41 - it's like hey we have bigger datasets
43:43 - now and faster computers now all of a
43:45 - sudden the things that people researched
43:47 - many years ago called neural networks
43:48 - that nobody thought could really do
43:50 - anything or they thought good but
43:51 - couldn't now all of a sudden we can do
43:53 - more of them with and so it's really
43:55 - just like I mean it's not meant to be
43:57 - marketing but it's kind of like
43:58 - marketing this idea of big data a neural
44:01 - networks and yeah I agree I think it's a
44:04 - lot of the marketing side of things
44:06 - because you'll reach so many different
44:08 - posts like they're deeply needed machine
44:10 - learning yeah it has two hidden layers
44:12 - that's it yeah
44:14 - like literally I think it's more the
44:15 - marketing side my personal opinion but
44:17 - that's awesome cool let me see if we
44:20 - have any other oh yeah neural network I
44:23 - like this definition neural network is a
44:25 - universal function approximator
44:27 - oh really this is actually like a really
44:31 - this is Robin I'm gonna hello let's try
44:33 - this oh this is crazy talk now now I'm
44:35 - coming over here I actually think this
44:37 - is really kind of a good way to think
44:38 - about it I was thinking about this the
44:39 - other day because what if we made like
44:42 - function color predictor and we just had
44:48 - like an if statement in there like and
44:50 - you give it a color so if the brightness
44:53 - blah blah blah that color is greater
44:56 - than some value then you should put
44:58 - black on that color or white on that
45:00 - color
45:01 - so this is like a hard-coded function
45:04 - that takes inputs and returns an output
45:06 - right and so we could we could write a
45:09 - lot of if statements where you get
45:10 - really crazy complicated about this we
45:12 - could come up with a whole set of rules
45:13 - and a neural network in a way as a thing
45:15 - that you could put in here to kind of
45:17 - learn to return the value according to
45:19 - in a more mysterious way in a way like
45:22 - in a sense it can learn it acts so in a
45:25 - way like does do neural networks in
45:27 - machine learning replace coding right I
45:30 - don't think of them as we're plate maybe
45:31 - someday they will in some weird way but
45:33 - I think of it as like they don't replace
45:34 - coding but they can replace our act as a
45:37 - function in your code so that function
45:39 - that you might have hard-coded a lot of
45:40 - if statements can have a machine
45:42 - learning system in it take some inputs
45:44 - and generate an output yeah I agree I
45:46 - mean when it's all said and done
45:48 - algorithms are input instructions output
45:51 - yeah and you're just replacing the
45:53 - engine bird you know totally
45:55 - I believe Suraj I already did a video on
45:58 - that I think
45:58 - Suraj haven't already done a video on
46:00 - that it's probably the answer for
46:01 - everything we might ever talk about in
46:03 - this cuz he definitely has a video a new
46:06 - Simpsons coding train are you gonna show
46:09 - us the working code or is it just a
46:10 - discussion so I think we're wrapping up
46:11 - here this is really just a discussion
46:13 - the code is here something I'd asked us
46:15 - to scroll the top ok tendency was at the
46:18 - top but I don't know if that really
46:20 - matters but I'm standing in front the
46:22 - code anyway but this code is available
46:24 - at that URL there'll be a link in this
46:25 - video's description and I think I mean I
46:28 - I don't know like I mean I feel
46:30 - committed to doing this I just don't
46:31 - know when exactly it'll happen but
46:33 - hopefully sometime next week I'd like to
46:35 - make my own version of this project
46:37 - which I'll do like in a coding challenge
46:39 - from scratch so we can and then we can
46:41 - kind of compare and contrast that and I
46:42 - have a feeling that you'll probably
46:44 - gonna have some other video content
46:45 - about this project at some point yes did
46:47 - I mention that you should subscribe
46:48 - there's gonna be a special guest did I
46:51 - mention that you should subscribe me a
46:55 - special guest I don't know
46:56 - I have no idea who wait how do I YouTube
46:59 - you need what do you know you can get
47:02 - one of these vanity URL things now so
47:04 - you can get like this ah I don't know
47:07 - because I have one now any alone I don't
47:09 - know maybe you have to be like very
47:10 - special and YouTube to get that unlocked
47:12 - for you I think you're special thank you
47:15 - but so I'm just gonna search for you
47:17 - again if you just do Jabril as it comes
47:19 - up oh well then you that I don't think
47:22 - URL though oh you have to search it and
47:25 - they come captain is shipped yes okay so
47:32 - here once again subscribe yeah so I'm
47:36 - gonna I'm gonna just show you them an
47:37 - unsubscribe this is terrible unsubscribe
47:40 - now I'm gonna show you how you do this
47:41 - you go search to brill's and the search
47:45 - bar then you click Subscribe
47:46 - then you click the alarm bell because if
47:50 - you want this special surprise video
47:53 - that might come out very soon you'll get
47:54 - a notification okay you need a hundred
47:58 - subscribers to get the vanity URL so I
48:01 - got some work to do yeah all right so
48:05 - I'm let me just check to see if there's
48:07 - oh yes
48:08 - people are asking your twitch so let's
48:11 - see if we can let me say if I do this
48:13 - what do you think the chance that I'll
48:14 - come up it's just a real CPU yeah oh
48:18 - well so if you go to twitch.tv gibreel
48:22 - CPU that's drills twitch and actually so
48:26 - I was gonna say in this free but whoa
48:28 - whoa all right they can't hear this
48:30 - bunch I mean they can if it comes
48:33 - through our mics but the audio from this
48:34 - laptop does it seem us freaking out but
48:38 - actually I'm curious so tell me about
48:40 - your because I'm always I always feel
48:44 - like I have no idea if I'm doing I don't
48:46 - think there is an answer to this like my
48:48 - process of this weird process like I do
48:49 - live streams are in YouTube uh-huh then
48:51 - I cut up an oedipal I streams of
48:52 - separate videos also on YouTube it's a
48:54 - nice I think oh I should be live
48:55 - streaming on Twitch should I not be
48:57 - posting we're done - so what's your how
48:59 - do you separate those you have the
49:00 - YouTube channel you have Twitch and then
49:02 - you have a second YouTube chat right Jim
49:03 - real CPU alright what are those pieces
49:05 - yeah so I'm keeping my focus on the
49:07 - dubrow's channel like
49:08 - yeah so I'm literally live-streaming and
49:10 - then whatever comes out of that isn't
49:12 - being straight uploaded to YouTube and
49:14 - YouTube but it's a separate YouTube
49:16 - channel like the lyric the live streams
49:18 - on Twitch don't show up in the Charles
49:20 - correct gibreel a YouTube channel they
49:22 - show up in the gibreel CPU you'd correct
49:24 - unless I do like really special live
49:26 - stream yeah so do you have three things
49:30 - to subscribe we live stream YouTube live
49:33 - stream archive and and the main jet oh
49:36 - well thank you I know at least subscribe
49:39 - to the main channel definitely a main
49:40 - channel yes Bruno clarifies you don't
49:43 - need a hundred K subscribers only 100
49:45 - and then you can do the channel main
49:46 - thing so you could get youtube.com slash
49:50 - come I can't say that
49:53 - alright so let me see let me just check
49:57 - the ask tube real hashtag on Twitter
50:00 - maybe that's do you think if there's
50:02 - anything No okay anything else
50:04 - there actually somebody used this
50:06 - earlier in 2012 or some weird going
50:08 - through I should have made this ask
50:10 - let's see tube reals with the S let's
50:13 - see if that shows up oh yeah so next
50:15 - time you're not seeing this but next
50:16 - time we'll do different hashtag anyway
50:19 - cool um so what time is it it is 4
50:21 - o'clock that means I have to leave and
50:23 - go catch my eye hand coding train so I
50:28 - will be back for sure next Friday I hope
50:32 - that we'll be able to do more
50:33 - collaborations like this to Brill is
50:35 - based in San Diego right so we do not
50:38 - even know San Diego sounds dreamy to me
50:40 - so that you have to go to trip there but
50:43 - awake me asks when is the next coding
50:45 - challenge so I'll probably do coding
50:47 - challenges again next Friday if I can
50:50 - get it together I'd like to try to at
50:52 - least tackle this caller predictor idea
50:54 - before next Friday already show one
50:56 - thing ok you can I don't know where you
50:58 - want you could stand here because I
51:00 - wanted to mention people most recently I
51:03 - did a coding challenge about quadtrees
51:05 - hmm okay so github.com slash coding
51:10 - training slash quadtree and so if you
51:16 - remember the
51:19 - code demo this this was what I did in my
51:25 - tutorial so I just made a whole bunch of
51:29 - random points in space 2d space then I
51:32 - registered them in this quadtree data
51:34 - structure which you'd have to go back
51:35 - and watch the videos to find out what
51:36 - that is and then I had an algorithm that
51:38 - in a hopefully faster way that iterating
51:41 - over all the points pulls out selection
51:44 - of points within a certain radius and
51:46 - actually I didn't do the circular region
51:48 - in the tutorials somebody sent a pull
51:51 - request in after I uploaded the code for
51:53 - the circular region so then what I did
51:56 - not and I want to do this as a coding
51:58 - challenge but I did it in class my NYU
52:01 - class earlier this week I did a
52:04 - collision detection test so let's look
52:06 - at this so this is just a simple example
52:10 - that has I believe there are one oh yeah
52:12 - it's down here there are 1000 particles
52:15 - I think if such a nice smiley face 1000
52:19 - particles and I'm testing if they are
52:22 - intersecting and when they're
52:23 - intersecting they're highlighted white
52:24 - when they're not intersecting they're
52:26 - just gray and you can see I'm getting a
52:28 - pretty reasonable framerate I bet you
52:31 - I'm getting kind of a lower I was
52:33 - getting 60 frames per second no problem
52:35 - when I tried this so maybe it's just
52:37 - this computer or because it's hooked up
52:40 - to the streaming system or there's other
52:42 - things in the browser like the twitch
52:44 - channel going but anyway the point is
52:47 - I'm gonna uncheck this using quadtree so
52:49 - as soon as I uncheck this using quadtree
52:51 - it's going to it for every dot iterate
52:55 - over all the dots instead of using the
52:56 - quadtree
52:57 - and you can see now I'm at 4 or 5 frames
52:59 - per second so we can see how the
53:01 - quadtree at least even though you know I
53:03 - did get a lot of comments along the
53:05 - lines of you're doing your quadtree
53:07 - incorrectly if there's ways of making it
53:08 - better and more efficient and to is like
53:11 - why are you doing a quadtree in
53:12 - JavaScript that's sort of silly like
53:14 - it's not going to be very fast and so
53:16 - while all of those points are valid and
53:17 - true I would say you can see that even
53:20 - with all of my failings as a programmer
53:22 - and using javascript I'm still getting
53:25 - like an incredible speed performance
53:27 - and look if I go down to like if I you
53:30 - know I can see even with like three
53:31 - thousand particles I'm still getting
53:34 - like 15 frames per second and if I
53:36 - uncheck this I mean just forget about it
53:37 - I don't even you know oops didn't even
53:41 - couldn't even like like oh you can't see
53:44 - what just happening like some checked it
53:45 - no it's okay oh so you can see like the
53:48 - framerate is officially zero right now
53:49 - so if I if I can manage to check that
53:52 - again we'll see so there is certainly
53:53 - I'm sure like more optimizations that I
53:55 - could do but there is a benefit so I
54:00 - have a challenge for everybody watching
54:02 - if anybody right now everything is in
54:05 - this github repo coding train slash
54:08 - quadtree and you can see links to the
54:11 - video tutorials the pseudocode Wikipedia
54:14 - page and then these are the two examples
54:16 - you're fine you're fine there's some
54:18 - other quadtree libraries and javascript
54:20 - that are down here but i have a
54:23 - challenge for anyone which is that i
54:26 - would love to have another example here
54:28 - that is flocking with quadtree so i will
54:31 - be accepting pull requests if you want
54:32 - to make a flocking demo with this
54:35 - quadtree of code you know i mean i'll
54:36 - make this myself at some point but i
54:38 - love to have people contribute so that's
54:40 - one thing to see like can I get a
54:42 - flocking simulation in JavaScript with
54:45 - like 600 agents that's gonna run
54:47 - reasonably well okay whoops I'm getting
54:51 - a notification here Oh
54:54 - jump thank you 66 e and the chat says
54:57 - don't forget you have to do this before
55:00 - you leave this means we're wrapping up
55:03 - oh you have to read some random okay
55:05 - alright unfortunately I don't have the
55:07 - sound board from any lullaby music you
55:09 - can pick a page read whatever you like
55:11 - I'll take your time enjoy
55:13 - I'll check the chat for any last
55:15 - important questions yeah you know what
55:20 - this is silly to have the quadtrees
55:22 - thing behind you so let's so I guess
55:25 - what probably makes options are your own
55:27 - website or just like the full let's just
55:29 - give you the full do I get the
55:30 - soundtrack I don't have it hooked on
55:33 - dang it I can't
55:35 - it we can do if we can edit an overlay
55:38 - oblate okay that's why people can now
55:39 - the other thing I could do is this is
55:42 - fun sometimes people want to make their
55:44 - own nice remixes mm-hmm and then they
55:50 - can overlay music and whatever they're
55:53 - gonna step out mmm seven nine five zero
56:00 - point three three one one point seven
56:05 - one four one point eight eight nine -
56:10 - point eight five eight - point four zero
56:17 - one one point two one five one point
56:23 - five two six point six nine two - point
56:30 - five six seven point four one zero
56:44 - beautiful that was beautiful my tears to
56:46 - my eyes people are telling me that that
56:49 - it's very dangerous to stand in front of
56:51 - a greenside all the time and nobody ever
56:54 - I made a hole like I like dance the for
56:56 - the reason for like I like 45 minutes
56:58 - straight nobody ever did okay there's
57:01 - some applause all right so quadtree neon
57:04 - so I think we can wrap up thank you so
57:08 - much - Brielle's for being here and ITP
57:10 - this whole week thank you thank you for
57:12 - coming and being a guest on the coding
57:14 - train thank you to many more future
57:19 - collaborations and things yes I got a
57:22 - free spring there I was just glad I
57:26 - didn't like messed up you can't do like
57:27 - this or like that get my face back or
57:30 - something cuz that's all right so I'll
57:33 - just say goodbye Thank You internet for
57:35 - watching now go it's a if glitch project
57:37 - is still live streaming or tensorflow
57:39 - dev summit still live streaming or I
57:41 - don't know go watch somebody play some
57:43 - beautiful music or something
57:44 - something noncoding related all right
57:46 - turn off YouTube go outside be with
57:49 - friends and family
57:50 - I feel anyway anyway you do you choose
57:52 - what to do don't listen to me we're
57:54 - gonna leave I'm gonna I don't have a
57:56 - good system for this I just have to only
57:57 - take me dude I use this mouse and you go
57:59 - over here to click this stop stream and
58:01 - then we disappear okay so I need like a
58:03 - little outro video or something I do
58:05 - have like I do have an intro video right
58:08 - I can actually just go straight to the
58:09 - infra ok here we go goodbye cookie