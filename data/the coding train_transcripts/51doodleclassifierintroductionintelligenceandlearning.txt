00:00 - hello welcome to a new video series in
00:03 - this video series I'm going to build
00:05 - something that thing is going to be a
00:08 - doodle classifier in other words you
00:11 - might be familiar with something called
00:12 - M nest you might have heard of M nest
00:15 - it's the m-miss database of handwritten
00:17 - digits this is a very famous classic
00:20 - hello world if you will a data set for
00:23 - machine learning to test an algorithm to
00:26 - see how it works even to teach about
00:28 - machine learning it is it is divided
00:31 - into training and test data I will talk
00:33 - about that during the course of these
00:35 - videos but it is a database of
00:37 - handwritten digits here is a and you can
00:41 - see it if I if I say no loop here in the
00:44 - console really quickly you can see there
00:46 - is a zero it is labeled in the database
00:49 - as a zero now what I have over here is
00:52 - my beautiful drawing of a wonderful
00:55 - kitty cat which by the way my example of
01:00 - trying to guess what digit that kitty
01:01 - cat is it guessed it as a two so what I
01:05 - want to do in this series you could find
01:07 - my emne stemple it's not in a video
01:10 - series but it's there in the github
01:11 - repository is I want to build from the
01:13 - very beginning a inist style classifier
01:18 - but instead of classifying digits i want
01:20 - to classify doodles so i want to know is
01:23 - that a cat you drew or a puppy or a
01:25 - rainbow or something else and how am I
01:28 - going to do this I am going to do this
01:30 - with the Google quick-draw data set up
01:34 - so quick draw is a project I believe
01:37 - from Google creative labs and let's just
01:40 - play it for a second let's draw draw an
01:42 - octagon in under 20 seconds oh my god 1
01:46 - 2 3 4 5 ok and this is way too stressful
01:56 - for me and it started talking to me I
01:58 - know if you could hear that I don't got
02:00 - it I don't got it so this is a game that
02:02 - you can play
02:03 - as you play it a machine learning system
02:05 - tries to guess what you're drawing and
02:07 - it just so happens that let me find
02:13 - quick draw data set I don't know what
02:15 - I'm looking for here well that I already
02:19 - have that sorry ah quick draw did it
02:21 - just so happens that people playing this
02:24 - game
02:25 - Google collected 50 million drawings
02:28 - across 345 different categories and all
02:30 - of that data is available to you and in
02:33 - fact this is what I'm looking for I
02:35 - could go to you could and I could browse
02:37 - the drawings here so I could say like
02:39 - let me look at all of the cellos and you
02:42 - can see these are millions and millions
02:45 - of different cellos that people have
02:47 - drawn and I have access to all this data
02:49 - now what's really interesting is that in
02:51 - addition to just having the image itself
02:54 - you're like oh look I can see it on my
02:55 - screen the system saved the vector path
02:59 - of the drawing itself so there's a lot
03:02 - that you could do with it in thinking
03:03 - about this sequence of how it's drawn
03:05 - and that's something I hope to get to at
03:07 - some point in a future video but in this
03:12 - example I am going to treat these as
03:14 - little bit mapped images I'm just gonna
03:16 - use a little snapshot of each drawing
03:18 - that's going to be the data associated
03:21 - with a given classification also known
03:24 - as label or class this is a 28 by 28
03:28 - pixel cello now this is not my own
03:32 - genius idea because I don't have any of
03:34 - those definitely not M NIST Google
03:37 - quick-draw this idea came from this blog
03:41 - post by Rajiv Shah using Google's
03:44 - quick-draw to create an amnesty dataset
03:47 - you can follow along and there's
03:48 - information about how to do this all of
03:50 - this is looking at how to do this in
03:53 - Python I believe I don't know if it then
03:56 - goes on to use tensorflow or what or if
03:59 - it's just actually showing you how to
04:00 - get the data but I'm going to sort of do
04:02 - this on my own and I'm gonna use
04:03 - processing and - to parse and work with
04:06 - the data and p5.js to then do the neural
04:09 - network magic stuff okay are you with me
04:12 - are you gonna watch this so the first
04:15 - video this is like my introduction to
04:17 - the ID
04:17 - and in the next video I'm going to start
04:19 - working with the data but let's do let's
04:20 - ghost go a little further by way of
04:22 - introduction so how is this going to
04:26 - work and so one thing I want to mention
04:28 - is that I already have the I'm going to
04:33 - be able to do this because I have built
04:35 - something and there's a whole video
04:36 - series that you can watch where I build
04:39 - it's about 10 or so like 18 videos long
04:41 - toy neural network this is a JavaScript
04:46 - implementation of a simple neural
04:48 - network now eventually if in the great
04:51 - future beyond when you're watching this
04:53 - in the year 7,500 from your gelatinous
04:57 - tube I will hopefully have also
05:01 - completed this same demonstration or
05:04 - similar demonstrations using something
05:07 - called ml 5 which is built on top of
05:10 - something called deep learn is so deep
05:14 - learning is is a project also from a
05:17 - Google research group which is an
05:18 - implementation of deep learning in the
05:21 - browser hardware accelerated with the
05:23 - GPU doesn't that sound fancy so
05:26 - basically it's a highly optimized way of
05:29 - doing a lot of stuff where we have
05:30 - really big data sets and you need to do
05:32 - stuff faster in a more robust fashion
05:34 - for me right now I want to demonstrate
05:36 - the core concepts and using this sort of
05:38 - like simple toy library is not gonna
05:41 - produce them quote unquote best results
05:43 - but I'm hoping it reduces the best
05:45 - results for learning at this point and
05:47 - we can I'm gonna get to this stuff after
05:48 - that ok that's number one
05:52 - so assuming I have that that means I
05:55 - don't have to in the course of these
05:58 - videos write the code for the so-called
06:00 - neural network the neural network is
06:02 - going to be the thing that sits in the
06:03 - middle something has to go into it some
06:08 - set of input something has to come out
06:10 - of it some set of output I should say
06:13 - that to do machine learning in the sense
06:16 - of like here's some data please
06:18 - do something with this analyze this data
06:20 - for me do some math with it and then
06:22 - give me some information about it back a
06:24 - neural network is not the only thing
06:27 - that can sit in between
06:28 - input and output and you might have seen
06:30 - other videos that I've done about you
06:32 - know K nearest neighbor there's things
06:35 - like support vector machines decision
06:38 - trees there are lots of other machine
06:40 - learning algorithms through this for
06:43 - this case for this learning process and
06:45 - for some of the other examples where
06:46 - neural networks perform really well that
06:48 - I hope to get to that's what's sitting
06:50 - in here so what I need if I have that
06:52 - already from my library what I need is
06:55 - to figure out what are my inputs and
06:58 - what are my outputs in this case my
07:01 - input is going to be I am going to use a
07:06 - 28 by 28 pixel image maybe it is said
07:12 - doodle of a cat right and that is going
07:17 - to be my input into the system now if
07:20 - you've watched my previous videos what
07:22 - you'll typically see and this will
07:25 - change as we get to more sophisticated
07:29 - machine learning architectures in
07:31 - particular I just want to like
07:32 - foreshadow this something called a
07:34 - convolutional network which is really
07:36 - designed to work with images I'm not
07:38 - doing that yet this needs to be
07:40 - flattened and it needs to be flattened
07:43 - into what's often referred to as a
07:45 - vector or a one column matrix so I need
07:49 - to take this data it's an image and
07:51 - convert it to a list of numbers this is
07:54 - this is the what this is probably in
07:56 - many ways the most important thing that
07:58 - you need to do when you're working with
08:00 - machine learning is like what is my data
08:02 - how do I format it and and there's lots
08:05 - of other questions about it as well so
08:06 - well I'm gonna come to that but let's
08:07 - just thinking about this this is a
08:09 - pretty this there's a way that I can do
08:10 - this I'm not saying it's the
08:11 - quote/unquote best way but there's it
08:13 - certainly a simple way each one of these
08:15 - pixels has a brightness value that
08:18 - brightness value is somewhere between 0
08:20 - and 255
08:21 - I can normalize it because it helps to
08:23 - have your inputs have kind of a smaller
08:26 - range of lobe numbers I could normalize
08:28 - that by dividing by 255 to range from 0
08:31 - to 1 and then now 28 by 28 is 786 a 784
08:37 - pixels
08:38 - I now have you know
08:41 - one you know point seven point six so
08:44 - this will become my inputs I need to
08:46 - look at the images I need to convert it
08:48 - into an array of floating point numbers
08:50 - normalized between zero and one and that
08:52 - becomes the input to the neural network
08:54 - system and if you look at the neural
08:55 - network library it's actually that's
08:57 - what it's asking you to pass into a
08:58 - train function or a predict function
09:00 - give me an array of numbers
09:02 - alright so wouldn't just take a pause
09:04 - here for a second
09:06 - and I want to get to the outputs but
09:08 - before I do that something really there
09:10 - something really important here so while
09:11 - the purpose of these video tutorials
09:13 - that you're watching that I'm making is
09:15 - probably primarily the learning process
09:17 - what I mean by that is your learning
09:18 - process and I'm just creating a kind of
09:21 - arbitrary scenario that's somewhat
09:23 - interesting to see if how this stuff
09:24 - works really if you really if you're
09:28 - working with machine learning these
09:29 - systems it's really important for you to
09:31 - ask yourself should I be doing what I'm
09:33 - doing is what I'm doing ethical am i
09:36 - hurting someone did I what is this data
09:38 - set that I'm using what's missing in the
09:41 - data set so we think about it this we
09:43 - could say okay well I'm just building a
09:45 - doodle classifier you know what's the
09:47 - worst thing that's gonna happen but I
09:48 - think as a useful exercise to yourself
09:50 - you might think about who is not rep
09:53 - what is not represented in that doodle
09:55 - data set so I would love to come back to
09:57 - this as a topic about how to collect
09:59 - data and think about data and bias and
10:01 - algorithms in a more substantive way I
10:03 - will just take a moment to point you to
10:05 - the research of Mimi on ooh aw oh ha who
10:09 - runs a project called missing data sets
10:11 - and I encourage you to check out her
10:14 - website and a lot of her work around
10:16 - missing data and ways and people are
10:18 - abstracted represented and classified so
10:19 - that said let me come back now to the
10:25 - next piece output so if our input is
10:29 - pixels and we've taken all of those
10:31 - brightness values and normalize them to
10:34 - zero through one we now need an output
10:36 - now here's the thing what am i trying to
10:40 - do in the case of the handwritten digits
10:42 - I'm trying to say is it a zero is it a 1
10:44 - is it a - is it a 3
10:46 - blah-blah-blah-blah-blah
10:47 - in this case I'm trying to say the kitty
10:49 - cat this is a rainbow is it to you
10:54 - or is it a cupcake all these wonderful
10:57 - things is it a heart baby it'll be some
10:59 - hearts on it so let's just say I'm going
11:02 - we have to make a decision here let's
11:04 - just say I'm only going to use three
11:06 - kinds of doodles in that case my outputs
11:11 - what I want is also a vector a one
11:14 - column matrix a list of numbers and I
11:18 - want those numbers to represent the
11:21 - probability that this particular image
11:25 - is any one of those given categories for
11:28 - example if it's if it's a kitty cat
11:31 - instead of a rainbow or a cupcake maybe
11:36 - I want it to give me that output if it
11:38 - is a rainbow maybe I want it to give me
11:42 - this output if it is a cupcake maybe I
11:46 - want it to give me that output in
11:49 - reality we're probably going to see
11:51 - something that looks when the when the
11:54 - neural network itself is guessing we're
11:56 - gonna see something that looks more like
11:57 - you know a point eight point one point
12:00 - one and in theory we want all of these
12:03 - to add up to 100% now the first time I
12:07 - do this as I begin it's probably not
12:09 - going to do that but at some point
12:11 - towards the very end of this playlist
12:14 - I'm gonna get to something called
12:15 - softmax which is an algorithm for
12:18 - guaranteeing that the output of a neural
12:19 - network everything adds up to 100%
12:21 - probability so we'll come back to that
12:23 - at some point okay this is the main idea
12:28 - and so what we have going on here is a
12:32 - supervised learning process and by that
12:36 - I mean we have this data set it is
12:39 - labeled I have the data from Google I
12:43 - have all those drawings so I'm going to
12:46 - give the neural network I'm gonna say
12:48 - here's a drawing of a kitty cat I expect
12:51 - you to say to me 1 0 0 if you give me an
12:55 - incorrect answer I am going to ask you
12:58 - to adjust all your little parameters
13:00 - inside of you little parameters weights
13:04 - and things
13:05 - inside of your neural network and try
13:08 - again we're gonna do this over and over
13:10 - and over again that's supervised
13:11 - learning
13:12 - here's known data here's known data
13:14 - here's known data we've got to do that
13:15 - for quite a while before we are ready to
13:18 - then say now I'm gonna draw my own kitty
13:21 - cat for you what do you think neural
13:24 - network do you like it so that's the
13:27 - idea but there's an important piece of
13:29 - this when I go to get the data one thing
13:32 - that I want to do is that I want to make
13:34 - sure that in addition to training data
13:37 - let's say I take 1,000 kitty cat
13:40 - drawings I want to save some amount of
13:42 - it you know maybe a typical amount it
13:45 - might save is 20% so I might save 200 of
13:48 - those drawings and only use 800 in the
13:52 - training process and save 200 of them
13:56 - for testing
13:57 - meaning how can I know whether my
13:59 - machine learning algorithm is working
14:01 - well well if I just test it to see if
14:03 - it's getting the right answers for the
14:05 - drawings I've trained it with I might be
14:07 - stuck with something called overfitting
14:10 - overfitting refers to when almost like
14:12 - the neural networks is doing such a good
14:14 - job
14:14 - it's trained itself so well that it's so
14:18 - highly optimized in tune to the stuff
14:19 - that you're trained it with that it
14:21 - can't really deal with stuff that it's
14:22 - not trained with and that's thing we
14:24 - have to watch out for now there are
14:25 - techniques to fight against that I'm
14:28 - something I'm going to come back to in
14:30 - another videos like something called
14:31 - dropout and there's more and more things
14:33 - but one way we can at least sort of test
14:35 - ourselves that we're hopefully not
14:37 - overfitting is by running data that it
14:40 - wasn't trained on and seeing how will it
14:42 - perform how many do I get correct out of
14:45 - those 200 after I've trained it so this
14:48 - is what why I need to do so that's by
14:51 - way of introduction then the next video
14:53 - what I'm going to do is download a bunch
14:56 - of drawings prepare them and get them
14:58 - ready because it's work by the way
15:00 - preparing cleaning normalizing thinking
15:03 - about your data is just as a big is a
15:08 - project unto itself right machine
15:10 - learning isn't just some magic that you
15:11 - do and you just say sprinkle the data on
15:14 - it and now I'm done you've really got to
15:15 - be thoughtful about that data and so
15:17 - I mean hopefully hopefully I will be
15:19 - somewhat thoughtful about the data in
15:21 - the next video
15:22 - okay see you soon
15:27 - [Music]
15:30 - you