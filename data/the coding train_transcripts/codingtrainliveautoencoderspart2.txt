00:15 - [Music]
00:24 - do
00:31 - [Music]
00:37 - do
00:39 - [Music]
01:01 - do
01:10 - [Music]
01:18 - [Music]
01:26 - [Music]
01:38 - [Music]
01:53 - [Music]
02:01 - do
02:03 - [Music]
02:21 - [Music]
02:30 - hello test one two i hope my audio is
02:34 - coming through please let me know in the
02:36 - chat
02:37 - uh in discord
02:40 - in youtube
02:42 - by carrier pigeon smoke signal however
02:45 - you could possibly reach me
02:47 - please
02:48 - let me know apologies for all the stops
02:52 - and starts today i will be beginning
02:55 - in just a few minutes assuming my audio
02:58 - is coming through loud and clear okay
03:00 - see you in a moment
03:11 - [Music]
03:25 - [Music]
03:30 - momentum
03:33 - [Music]
03:45 - [Music]
03:57 - [Music]
04:11 - [Music]
04:21 - [Music]
04:59 - [Music]
05:38 - [Music]
06:11 - [Music]
06:29 - hello
06:30 - happy saturday
06:34 - to the coding train with me miner
06:37 - internet personality dan shipman
06:41 - i am the host of the coding train i'm
06:42 - coding train i am coming to you live
06:46 - i know it's some kind of miracle that
06:48 - i'm here right now uh i don't know how
06:51 - this is gonna last
06:53 - i better just very quickly say thank you
06:55 - to
06:56 - curiositystream for sponsoring today's
06:59 - live stream you can get access to all of
07:01 - the documentaries amazing documentaries
07:03 - on curiosity stream as well as the
07:05 - nebula
07:07 - everything that's on nebula can i tell
07:09 - you about something that's on nebula
07:10 - right now let me tell you something
07:12 - that's on nebula right now hold on a sec
07:15 - on nebula right now is let's go to my
07:18 - library right here look at this
07:20 - this particular video which is going to
07:23 - come out probably hopefully by tomorrow
07:25 - on youtube still finishing up but if you
07:27 - want to get some early access to this
07:29 - particular video along with all sorts of
07:31 - other amazing stuff you could get you
07:33 - can sign up the whole year of curiosity
07:36 - stream and nebula
07:39 - um at that link
07:41 - 26 off i think that's
07:43 - 14.79 for the whole year
07:46 - amazing amazing you should totally check
07:48 - out all the documentaries and all the
07:50 - youtube creators that are on uh nebula
07:52 - okay
07:53 - uh
07:56 - the stream's still working so at least i
07:58 - got that out
07:59 - um and what am i here to do today well
08:02 - if you might remember
08:03 - a week or so ago and i'm look just
08:05 - checking the chat here to see if people
08:07 - are watching
08:09 - i'm not seeing any messages which is a
08:11 - little bit weird
08:12 - if i'm being perfectly honest so
08:14 - hopefully i'm not just speaking into a
08:16 - vacuum
08:17 - but um
08:19 - i've been working on a project
08:21 - to create an auto encoder using
08:23 - javascript with the tensorflow.js
08:26 - library library in node.js and i would
08:29 - like to finish that today
08:31 - so this is part two um if you were
08:34 - looking for part one
08:35 - if i come back to here i really don't
08:38 - see any chat messages this is very
08:40 - strange
08:42 - okay
08:43 - codementlike says hi i'm cars waves okay
08:46 - people are there you're there oh thank
08:48 - goodness
08:50 - not very many of you probably because
08:51 - i've totally botched this in the sense
08:53 - that i was supposed to stream this
08:55 - morning at 10 a.m
08:57 - and i had scheduled it i'm using discord
08:59 - events now so you should sign up for the
09:01 - coding train discord somebody post that
09:03 - link into the chat
09:05 - and then i make an event and you know
09:06 - what time and you can like register your
09:08 - interest you'll get a reminder all the
09:10 - things i've always been wanting for
09:11 - wanting to have
09:13 - and then i was like no i can't stream
09:15 - because my internet wasn't working
09:18 - i'm in a garage which is a detached
09:20 - garage from my main house which is where
09:22 - my new studio is and i'm going to be
09:24 - here all the time every day all day
09:26 - starting in january 2022 lots of plans
09:29 - um so i'm working on getting this place
09:31 - wired
09:32 - and uh powered by solar energy
09:36 - so
09:37 - uh
09:38 - uh i disconnected uh i'm gonna say i uh
09:41 - obviously hired people to do a lot of
09:43 - this work
09:44 - but the uh electro electrics was
09:46 - disconnected to this building and then a
09:48 - trend we dug a trench
09:51 - to wire electrics of the house so they
09:52 - could put solar panels here to power the
09:54 - house and the garage ran coax and cat5
09:58 - underground uh put it in a splitter so i
10:00 - can have internet in both and for
10:02 - whatever reason i can't get internet
10:03 - both to work
10:05 - and i discovered
10:06 - that if i just turn off
10:09 - the internet to the house right now it
10:12 - seems to work here in the garage so
10:13 - that's my temporary solution at least
10:15 - for today to get this live stream in on
10:18 - saturday november 20th and finish off
10:21 - this project ah i was trying to figure
10:22 - find where i was i was here to show you
10:25 - uh part one so this doesn't say part one
10:28 - but you can see oh and look at this
10:31 - so this is also by the way available
10:33 - here i just haven't released it yet it
10:34 - should be out
10:36 - tomorrow i'm just got a lot of slowness
10:38 - here but i'm logged into my account
10:39 - which is why i see it
10:42 - i'm very excited about this video can
10:44 - you please post the discord in the chat
10:46 - i'm gonna go ahead and do that
10:48 - um since uh no one else got around to it
10:50 - just yet and i believe
10:53 - that should be oh my god i posted the
10:56 - wrong link
10:57 - uh discord
11:01 - [Music]
11:04 - okay um it's discord dot gg slash coding
11:07 - train okay
11:09 - so um what was i looking for oh so
11:12 - that's part one if you watch part one
11:14 - great you're in the right place if you
11:16 - didn't watch part one well i'll recap it
11:18 - a little bit
11:19 - as i get into um
11:22 - working on the project so
11:24 - i need to find my way back to where i
11:26 - was before let me open up processing
11:31 - because i was using processing to
11:32 - generate the images that i want to um
11:36 - use to
11:38 - train
11:39 - the model
11:42 - and i need to
11:44 - i don't need this
11:46 - and i need to get all right let me just
11:49 - switch myself back over here
11:52 - while i'm getting various windows set up
11:55 - so um
12:00 - let's see um talk amongst yourselves for
12:02 - a minute please
12:04 - you know normally you would think i
12:05 - would have this all set up before i
12:07 - begin streaming i don't know why i'm
12:08 - hiding this from you i'm just opening up
12:12 - so
12:14 - my item and i think the project
12:18 - is in the auto encoder tf demo
12:21 - let's open this up in
12:29 - in visual studio code all right okay
12:32 - let's go back to
12:36 - the auto
12:38 - encoder keras page
12:42 - which is sort of my a model my tutorial
12:45 - that i am following
12:46 - and
12:48 - uh
12:50 - hi bruno hi adrian hi embark hi sorel
12:54 - i'm seeing some nice messages in the
12:56 - chat welcome a bunch of people are
12:57 - joining in that's great
12:59 - um
13:01 - so what do i how am i going to get
13:03 - started here so first let's see if my
13:04 - whiteboard is still working oh looks
13:06 - like i need to work on the focus there
13:08 - and wow it's so i think it's brighter in
13:10 - here today the sun is out
13:13 - so i do get some sunlight in this room
13:14 - so first thing i need to do is focus
13:16 - this camera i think that's better right
13:19 - i think i just focused it
13:21 - let me go back and look
13:23 - here
13:24 - looks better yeah that looks like it's
13:25 - in focus now oh and i need to ah uh okay
13:29 - hold on everyone i'm going back to here
13:32 - i also want to record this session to
13:34 - disc
13:35 - just in case
13:37 - the thought experiment is you know do
13:40 - you really later
13:42 - if you're not here live with me right
13:43 - now part of the process of figuring it
13:46 - out together would you really want to
13:48 - come back and watch four hours of live
13:50 - streaming about building an auto encoder
13:52 - project
13:53 - maybe
13:55 - but my thought is if i can get
13:56 - everything recorded to disk
13:58 - then perhaps i can succinctly package
14:01 - this in like a 30 to 45 minute video
14:03 - which skips a lot of the rambling and
14:05 - all that kind of stuff so let me
14:08 - uh i need to
14:09 - i'm kind of like shocked that i'm doing
14:11 - this because as of this morning i was
14:12 - like i'm just gonna reschedule this to
14:14 - like november 30th so i just need to
14:17 - check
14:18 - my settings here
14:20 - um output
14:22 - streaming recording indistinguishable
14:24 - quality large file size well no wonder
14:27 - high quality medium file size
14:29 - i forgot that i done this start
14:31 - recording so i recorded last session
14:34 - to disk
14:37 - and i looked at the file afterwards and
14:39 - it was 57 gigabytes
14:42 - because i'm recording a 4k uh video to
14:45 - disc which has all of the different it
14:48 - has
14:48 - um just the laptop feed it has me
14:52 - actually me just with the green screen
14:55 - um and it has the whiteboard if i had
14:57 - the ipad here i have a ipad a hookup but
15:00 - it's not hooked up right now
15:02 - so this is my new setup i'm obviously
15:04 - still trying to build up momentum thank
15:06 - you to everybody's patience
15:09 - kindness and consideration as i try to
15:12 - figure out i feel like the coding train
15:13 - is going to be born anew in 2022.
15:19 - that rhymes which is quite lovely okay
15:21 - i've got a little bit of coffee left
15:26 - um i've got to get back to my children
15:29 - but i'm giving myself till 3 30. it's 90
15:32 - minutes i'm recording to disc
15:34 - um
15:35 - and thank you to all of your thank you
15:38 - sorel you are here with me i appreciate
15:40 - it all right
15:41 - little straw poll here i'm gonna put a
15:43 - little straw poll into the chat
15:45 - um
15:46 - did you watch
15:48 - part one
15:51 - just to give me a sense
15:53 - of who watched part one i can't see by
15:55 - the way who's answering so you know it's
15:57 - not like you know did you study for the
15:59 - test and you don't want to admit it like
16:01 - i would like to know the real
16:02 - information here
16:03 - so uh in the chat now should be a poll
16:08 - asking whether you watched part one or
16:10 - not
16:11 - and as i
16:16 - kind of get um
16:18 - let's just see if things are still
16:20 - working here it looks good um
16:23 - i'm just sort of checking out my code
16:25 - from before
16:26 - still seems to be running
16:29 - um
16:30 - that's fine there but
16:32 - this i term needs to be a little bit
16:36 - more over ah come on i term
16:39 - why do you do me like that okay i think
16:41 - that should be good
16:43 - and then processing i don't actually
16:45 - know that i'm even going to need
16:47 - i actually will want this for sure i
16:50 - just realized okay
16:51 - um i also remember um k weekman
16:56 - how would you like to be referred to
16:58 - like i do it all sorts of different ways
17:02 - but i remember you saying that
17:05 - um i should reconsider maybe the
17:08 - optimizer or the loss function i'm using
17:11 - um so again the my my sort of working
17:16 - sort of uh the working philosophy here
17:18 - right now is just to get all the pieces
17:20 - plugged in and then i want to add more
17:23 - layers and sort of think more
17:25 - thoughtfully about the various hyper
17:27 - parameters of the system that i'm
17:29 - building and then also hook it up to p5
17:31 - so i can see the results in the browser
17:34 - oh by 3 30 today no problem there's
17:35 - probably gonna be a part three i'm being
17:37 - perfectly honest um
17:39 - but um i seem to recall you had left
17:43 - some comments in the discord um so i let
17:46 - me make sure i come back and revisit
17:47 - that although maybe i'm not going to
17:49 - right now i am seeing the poll results
17:52 - that
17:53 - uh 60 of you 73 people have voted 61
17:57 - percent of you have did not watch part
17:59 - one and 39 of you did watch part one so
18:03 - i think this means uh this swings the
18:05 - pendulum for me i'm gonna give you a
18:06 - quick recap of kind of everything i did
18:09 - in part one
18:12 - and let's um let's put a timer on here
18:14 - let's time box this
18:16 - uh
18:17 - 10 minute timer
18:20 - so i don't want to allow myself
18:26 - more than 10 minutes
18:31 - where oh what's i'm using up so much of
18:33 - my time just to put this
18:38 - in the page here okay
18:41 - okay so there's my 10 minute timer i
18:43 - don't want to i want to be starting on
18:45 - the new stuff by the time that hits zero
18:48 - okay um so
18:52 - quickly
18:54 - i am very interested in machine learning
18:57 - generative machine learning models
18:59 - models that generate synthetic images
19:03 - text perhaps sound other kinds of media
19:06 - uh if you have been following the world
19:09 - of deep learning today the what you
19:10 - probably have heard of is something like
19:12 - oh again or stylegan or stylegand2 or
19:15 - stylegand3 and then there's this like
19:18 - latent space oh all these images are in
19:20 - the latent space and i can walk through
19:21 - the latent space and look at this ai is
19:23 - dreaming about cats in a style gantu
19:26 - layton space of all cats cats and many
19:28 - more cats
19:31 - if you have no idea what any of that
19:33 - means
19:34 - how could you possibly get started to
19:36 - learn some of the vocabulary feel
19:38 - comfortable with working with these
19:39 - systems even if you're ultimately just
19:42 - an end user of pre-trained models
19:45 - you're not designing and training the
19:46 - models yourself for me the process of me
19:49 - trying to
19:50 - sort out how all this stuff works and
19:52 - understand be able to read the style
19:54 - gand paper and maybe understand a bit
19:56 - more about it begins with auto encoders
19:59 - an auto encoder is
20:01 - a very simple um well i don't shouldn't
20:05 - say very simple because none of this is
20:07 - particularly simple but it is a good
20:09 - starting point to think about how
20:11 - generative models work and uh the last
20:14 - live stream i went through building this
20:15 - whole diagram to talk about how we could
20:19 - build something called a copying machine
20:22 - out of a neural network
20:23 - so if an image is sent into the neural
20:26 - network if we could just get that same
20:28 - image back out then somehow
20:31 - the neural network would have learned
20:34 - some type of like
20:36 - represent internal representation of
20:39 - that image in a way that it can
20:41 - reproduce it so obviously to copy an
20:44 - image is a simple well this is a simple
20:47 - process with an algorithm i can just say
20:50 - for every pixel make a new image take an
20:53 - existing image for every pixel put the
20:56 - new pixel in the new image
20:58 - so
20:59 - the auto encoder is not an efficient
21:01 - copying machine but it does give us this
21:04 - ability to
21:05 - copy the image while also compressing
21:08 - the data because the idea is if we start
21:10 - if i have a 28 by 28 image with 784
21:14 - pixels as the data moves through these
21:16 - layers
21:17 - of the neural network we have fewer like
21:20 - i have 784 inputs the first layer might
21:23 - only have
21:25 - half of that in neurons and then another
21:27 - layer might have half of that and then
21:29 - so these numbers have to somehow be
21:32 - compressed into a smaller amount of
21:33 - numbers that then get expanded back out
21:36 - to the original image so this is like a
21:38 - copying machine and an image compression
21:40 - engine it is not an efficient image
21:43 - compression engine
21:45 - because if we really want to do image
21:47 - compression to save high resolution
21:48 - image with less file space on a on our
21:51 - hard drive we could just use jpeg or
21:54 - other kind of known tried and true image
21:55 - compression algorithms but if we are
21:58 - able to take the these images compress
22:01 - them down and have the neural network
22:02 - the auto code to learn how to uh decode
22:05 - them right we have an encoder and a
22:06 - decoder then at some point and hopefully
22:09 - i'll get to this part today i can take
22:12 - off after i've trained it i can take out
22:15 - the encoder and just start with the
22:16 - decoder feed in noise and generate new
22:19 - images in the style of the original
22:22 - training data set or i could do certain
22:24 - kinds of operations like image denoising
22:27 - for example what if i sent a noisy image
22:29 - in right if these are all the the
22:32 - example i'm using is i'm just using
22:33 - geometric shapes so if the auto encoder
22:36 - learns the internal and internal
22:37 - representation of what it means to
22:39 - render a square if i send in a noisy
22:42 - square it will then take that and in
22:45 - theory re-render it back out without the
22:47 - noise that's the idea so this is what
22:50 - i'm working with i went through this
22:51 - diagram i probably in a much longer
22:53 - period of time
22:55 - and then um
22:57 - looked at if i come back over here
23:00 - um
23:01 - and
23:03 - i see some comments so hold on come back
23:05 - over here now and i've still got five
23:07 - minutes left in my recap of before
23:11 - and if i come back here
23:14 - what was i trying to say francois
23:16 - yes okay so this is an article from 2016
23:20 - so quite a while ago where i first
23:22 - encountered the idea of an autoencoder
23:24 - this encoder and decoder this original
23:27 - input compressed representation
23:29 - reconstructed input the output is the
23:31 - reconstructed input
23:33 - and there is sort of a guide here
23:35 - explanation as well as a guide for how
23:37 - to
23:38 - build these layers using a library
23:41 - called keras which was a sort of higher
23:44 - level which is some i should know this
23:47 - maybe somebody in the chat could could
23:49 - kind of explain but like does keras
23:51 - still exist or is it really just now
23:54 - fully integrated into tensorflow and not
23:56 - called keras anymore but when keras was
23:59 - first developed it was a kind of higher
24:02 - level layer if you will
24:04 - above lower level machine learning
24:06 - libraries so you could say things like
24:08 - create a neural network with this kind
24:10 - of architecture in keras in a sort of
24:12 - higher level way and you could plug
24:14 - tensorflow into it to do the actual
24:16 - lower level institution or pi torch or
24:19 - other ones so the way i
24:21 - know and work with keras
24:23 - is
24:24 - by working in tensorflow js
24:31 - which i want to look at the um
24:35 - this is i want to i think it's just like
24:37 - js.tensorflow
24:42 - um let's see if this yeah um and i want
24:44 - to go to the api um
24:46 - in the tensorflow.js api there is a
24:50 - particular
24:52 - set of functions
24:53 - objects
24:55 - that are part of the
24:57 - layers that are called layers tf.layers
24:59 - layers model sequential
25:02 - layers here we go
25:03 - and this is a net this is essentially
25:07 - the uh original
25:09 - modeled after or directly ported from
25:11 - the keras
25:12 - python library
25:14 - oh i hear somebody
25:16 - hello
25:19 - take a short intermission i've got uh
25:21 - i've got a visitor help me right be
25:23 - right back i'm just putting on
25:25 - intermission and i'll be right back
25:28 - music
25:39 - [Music]
25:47 - [Music]
25:55 - [Music]
26:01 - [Music]
26:09 - okay i'm back
26:10 - [Music]
26:14 - okay i'm back
26:16 - um
26:19 - oh oh i need to stretch all right um
26:22 - i disconnected the internet in the house
26:24 - which is causing some some problems but
26:27 - we're gonna we're all we're all gonna
26:28 - get through this together
26:32 - uh
26:34 - okay
26:35 - um i forgot where i was well i was
26:38 - talking about uh
26:39 - tensorflow.js so oh and you don't see
26:42 - that now let me come back here
26:44 - so the code that i began to write
26:47 - is as follows so obviously i went
26:49 - through this in greater detail in the
26:51 - previous stream
26:52 - but i've got a node i'm eventually going
26:55 - to turn this into a web server but this
26:56 - is just a node script ultimately right
26:58 - now a little node project where i'm
27:00 - creating a sequential model that is
27:02 - exactly i'm trying to recreate this
27:04 - exact model in code now
27:07 - i'm calling it an autoencoder because
27:09 - that's the application that i'm doing
27:11 - it starts with an encoder which is a
27:14 - dense layer that receives 784 inputs
27:18 - because my images are going to be 28 by
27:19 - 28 i'm arbitrarily having it be 32
27:23 - units then it decodes back to 784
27:27 - it's just those it's this is like it's
27:29 - just two layers just uh one layer for
27:31 - the encoder and one layer for the
27:33 - decoder and then i've set up an
27:36 - optimizer a loss function these are
27:38 - things i also talked about in the
27:39 - previous
27:41 - i've only got a minute left here in my
27:42 - recap so you know i can touch on those
27:44 - as we go
27:46 - and then i just fed it with random noise
27:50 - so where i left off is i now would like
27:53 - to and i have this processing sketch
27:56 - which generates a variety of square
27:59 - images of squares
28:01 - i have those
28:03 - hopefully if i could
28:05 - find them here in a folder called data
28:09 - so now i would like to feed the auto
28:11 - encoder these actual images
28:14 - expand
28:16 - the number of layers
28:19 - um
28:21 - and um
28:23 - i'm reading the chat yeah so my uh
28:27 - things are complicated these days for me
28:28 - as they are for everybody my kids are
28:30 - home i disconnected their internet my
28:32 - wife is out of town
28:34 - so
28:35 - um they're having a couple hours of free
28:37 - time um but um
28:40 - and i wanted to get this out of the way
28:41 - because oh oh my god what is beeping at
28:44 - me oh it's the timer
28:45 - do you hear that i'm like what's
28:47 - happening there's a paper going on uh
28:49 - okay okay okay i got you we're gonna get
28:51 - started with the code uh whoops um
28:55 - but i know i've lost track of what i'm
28:57 - saying but i i've got lots of things to
28:59 - do with them tomorrow next week through
29:01 - thanksgiving and so i was just if i
29:03 - could just do this stream today
29:06 - then i can kind of figure everything out
29:08 - next week so here i
29:10 - am um hi computational mama in the chat
29:14 - so um
29:17 - um let's see okay how are we all feeling
29:20 - about that any questions about uh what
29:22 - i've covered so far
29:30 - before i get started here
29:32 - and i'm thinking i'm going to need to
29:34 - read in the images
29:40 - how do i want to read in the images
29:46 - um anybody got a suggestion for a node
29:48 - package that i should use i mean i could
29:50 - use just the file system package to read
29:53 - the files then i need to unpack them
29:56 - into
29:56 - their pixels and turn those into tensors
30:02 - oh gloria pickle oh you know what now
30:05 - i'm feeling kind of guilty but she was
30:08 - out all day
30:09 - uh earlier today with me as i was going
30:12 - around and we had a nice walk she's in
30:14 - her sleeping in her crate she's she's
30:16 - crate trained she loves her great she
30:17 - feels very safe in there if there's ever
30:19 - a try about my dog by the way not my
30:21 - daughter who gets your confused
30:24 - my children are free range right now in
30:26 - the house the dog i often have her with
30:28 - me but she's sleeping in her crate um i
30:31 - was about to say like um
30:33 - that's her favorite spot like if there's
30:34 - a thunderstorm she's terrified she just
30:36 - wants to be in her crate so she sleeps
30:38 - in her crate at night very comfortable
30:40 - there but i don't want to leave her
30:41 - there for more than a couple hours then
30:44 - i need to let her out after her nap to
30:46 - roam free outside and be here
30:48 - okay i want to make me some coffee after
30:51 - watching but don't want to leave the
30:52 - stream l.a noob
30:55 - um i really think l.a noob
30:58 - you should uh make yourself some coffee
31:00 - you're not going to miss anything trust
31:02 - me
31:03 - got a couple minutes to make some coffee
31:04 - i really doubt you're going to miss
31:06 - anything critical
31:08 - all right
31:11 - can you restate what you need to do with
31:12 - the files okay
31:14 - i need i have all these images i want to
31:18 - load them so i want to write let's write
31:19 - some pseudo code
31:21 - i'm going to do it right here i'm going
31:22 - to write a function
31:24 - i will call it load images
31:28 - i am going to
31:30 - load all image files in the data
31:34 - folder
31:36 - read the pixels
31:38 - convert
31:40 - the pixels to
31:42 - tensors for tfjs
31:45 - so this is what i need to do
31:47 - i know how to do the last stop because
31:49 - i'm familiar with tensorflow.js it's
31:51 - stuff that i've done i know how to load
31:53 - image files in general i would use the
31:55 - node file system package
31:58 - okay the door open you got your phone
32:01 - you're good does it it'll connect
32:02 - automatically right
32:04 - okay
32:05 - okay
32:06 - um
32:07 - it's a little chilly in there because i
32:09 - didn't turn the heat on but you can turn
32:10 - the heat on if you
32:11 - want um the thermostat on the wall it's
32:16 - a little thing you just go
32:18 - there
32:19 - you're closing the door okay
32:23 - um
32:25 - okay so i could use the file system
32:28 - package
32:29 - and the file system package allows me to
32:32 - load files let's just
32:35 - what no no just turn it to like 70 where
32:37 - it says 70. i think it's a good number
32:40 - um
32:43 - so
32:44 - let's see so let's see load
32:47 - read image pixels node.js
32:52 - get an array of pixels from an image
32:54 - using node.js image pixels
32:57 - get pixels i just feel like
33:00 - um
33:01 - [Music]
33:02 - jimp i could use the jimp
33:08 - package and this seems promising
33:12 - javascript image manipulation program an
33:14 - image processing live preferred node
33:15 - written entirely javascript with zero
33:17 - dependencies this is good
33:19 - does it support promises
33:22 - doesn't look like using promises yes
33:25 - okay
33:26 - this looks good
33:28 - there's no
33:29 - no so helmer yeah i gotta talk about
33:31 - this no internet no heat this is a
33:33 - detached garage and it is um i'm trying
33:38 - to get all the stuff in here to make it
33:41 - more
33:42 - livable i mean we don't live in the
33:44 - garage but to have some more
33:47 - loungy relaxing space we have a ping
33:50 - pong table
33:51 - to have enough like power and internet
33:53 - to power my coding train stuff
33:56 - but you know i don't run the heat in
33:58 - here all day because we're not in here
34:00 - and that would be very wasteful anyway
34:03 - how do you all feel about this jimp
34:05 - library i think this is looking good for
34:07 - me
34:08 - so i am going to
34:10 - give it a try until someone tells me not
34:12 - to do it
34:13 - npm install jimp
34:17 - uh yep
34:21 - so let's run that
34:24 - so i'm now
34:26 - loading this package
34:31 - okay great
34:32 - by the way i'm always curious it always
34:34 - says though some of the packages are
34:35 - looking for funding
34:37 - so
34:38 - i'm always good to support open source
34:40 - projects so see there's some of the open
34:42 - source projects that i'm using somehow
34:43 - through these dependencies
34:45 - um maybe i will come back to that later
34:48 - um now up there goes to see the heats on
34:51 - so now that's the boiler going
34:54 - so hopefully that doesn't mess my audio
34:56 - up too much
34:58 - ammon in the chat on pixel data in
35:01 - oh i could just use tensorflow.js to
35:03 - load the pixel data oh tf image
35:07 - that's a great point
35:09 - okay i should probably use that
35:13 - great point
35:14 - okay so this was interesting to explore
35:16 - but let's um
35:18 - let's look at i forgot about that thank
35:20 - you for that that is a great note
35:22 - so let's go to tf.image
35:27 - yeah look at this
35:40 - extra but does it look will it load an
35:43 - image for me
35:44 - so these are all operations if
35:50 - hold on
35:52 - what does it expect
35:59 - like it expects an image does it expect
36:02 - like
36:04 - like an image html image element
36:19 - all right let's see
36:28 - uh from pixels uh this is all stuff
36:31 - happening in the
36:33 - from pixels
36:35 - yeah ah okay
36:42 - there is the from pixels function
36:46 - oh but this is all only in the browser
36:49 - so i'm not in the browser right now i
36:51 - mean i could be doing all this in the
36:52 - browser
37:00 - tf image decode okay
37:03 - image.decode how come i didn't see that
37:10 - tf image
37:12 - decode
37:14 - i don't see that as a function
37:21 - tf io decode image
37:25 - interesting
37:26 - oh but this is tensorflow not tf
37:34 - yeah so it doesn't look like
37:36 - some of those
37:39 - that like decoding an image file is
37:42 - present here
37:43 - um
37:45 - it probably wants to work with images
37:48 - from
37:49 - the browser check this out what i just
37:51 - sent should work says cirelli
37:55 - so the thing is like of course we could
37:57 - improve this later
37:58 - um
38:00 - image data right
38:02 - so the parameters are image data
38:05 - so uh pixel data image data
38:10 - image data can i use this in
38:13 - yeah this is all canvas stuff so i'm
38:16 - kind of in headless mode right now
38:21 - so i sort of feel like node.js canvas
38:23 - image data
38:33 - so i could use the node canvas module
38:39 - so i could use node canvas
38:42 - and then
38:44 - load an image
38:50 - what's the load image function oh okay
38:53 - ah all right maybe i should do that
38:55 - maybe that makes sense
38:58 - uh so all right this is interesting
39:01 - let's try this because the other reason
39:03 - to do this is it'll translate nicely to
39:06 - working in p5 but i'm a little bit
39:09 - skeptical of this working in node but
39:12 - i'll give myself a little bit of time
39:14 - let's try installing canvas
39:20 - so
39:22 - um
39:26 - let's comment all this stuff out right
39:28 - now
39:31 - come back to it
39:35 - so and let's say
39:36 - [Music]
39:41 - import
39:43 - how do i do an import with this
39:52 - can i do this
39:54 - import
40:14 - how do i do this is it like this
40:17 - could that possibly be right
40:20 - uh
40:26 - um all right so let's see
40:32 - um import create let's just see okay so
40:36 - now let's try
40:39 - load image
40:48 - let's make this an async function
40:56 - data
40:59 - square 0 0 0.
41:10 - yeah and then
41:15 - see what happens
41:20 - so i'm just testing this canvas load
41:22 - image function
41:24 - to see if it will load the file
41:26 - um
41:28 - import from
41:32 - and see what happens
41:35 - okay
41:37 - is it really called canvas it's not
41:38 - called node canvas but okay
41:44 - create canvas not found
41:54 - import oh i see
42:10 - let's try this
42:14 - okay look at this
42:16 - image 28 by 28 data square complete
42:20 - huh okay
42:21 - this is interesting
42:23 - import star as canvas
42:26 - i don't think my
42:28 - my uh
42:31 - import is right so hold on
42:46 - is this
42:54 - this work now
42:58 - i don't know how to use these es6
43:00 - imports
43:08 - so for whatever reason
43:12 - this works but this is not the correct
43:14 - way to do it i'll have to revisit that
43:16 - later
43:19 - i'm so used to using require okay
43:21 - so
43:22 - um first of all let's
43:25 - just for a minute here um
43:27 - i just want to no i guess i want to
43:29 - leave tf.js
43:31 - loaded for right now it
43:33 - is that what is its console logging
43:35 - there yeah okay
43:38 - so now if i want to load all the images
43:44 - um
43:46 - i mean i could use file system to like
43:48 - figure that out but i'm just going to
43:50 - hard code this
43:52 - um i have how many i have a hundred
44:04 - um and then let's make this a template
44:06 - literal
44:09 - and
44:15 - so
44:15 - [Music]
44:19 - how do i do number formatting in node
44:23 - is that native
44:26 - oh there's numeral
44:31 - all right let's try numeral this looks
44:32 - cool
44:34 - and this might be over overkill for what
44:36 - i need to do
44:38 - but
44:44 - import load image from canvas
44:55 - what if i want to import more than one
44:57 - thing
45:06 - um okay
45:09 - so now let's see uh
45:11 - how do i use numeral
45:14 - uh
45:15 - import
45:26 - if i want to like call it uh nl for
45:29 - numeral i don't know uh and then
45:34 - nl
45:39 - this this might not actually be
45:41 - format okay
45:46 - uh
45:47 - nli
45:49 - format
45:52 - um
45:58 - this is like the format i want is ah so
46:01 - it's
46:03 - that's the format i want
46:05 - so now this
46:08 - i think this should give me
46:10 - all of the file names i to string pad
46:14 - start okay okay import abc from x yeah
46:19 - um thank you for all these helpful tips
46:21 - in the chat
46:23 - uh okay i'm i'm running out of space
46:25 - here let's see if i can get myself some
46:26 - more room
46:28 - okay so then let's just do console.log
46:32 - image
46:33 - let's just do 10 images to start
46:37 - see if this works
46:39 - no no no so numeral i didn't need
46:42 - because i could just do it with
46:44 - string
46:55 - let's try did i did i install numeral i
46:58 - did
46:59 - so how come this didn't work
47:03 - import
47:07 - numeral from numeral maybe it's that
47:19 - load image is not a function
47:24 - didn't like this pour it
47:36 - i don't know what how did i get it
47:38 - working
47:54 - okay
47:56 - so
47:59 - i'm doing things in some awkward
48:01 - unnecessary ways like first of all i
48:03 - don't need this numeral package
48:05 - because i could just use like number to
48:07 - string or something but it works nicely
48:10 - for me
48:11 - and i
48:12 - don't understand why i'm doing it this
48:14 - way uh import
48:18 - mode image
48:23 - that no
48:25 - i don't i still don't understand how es
48:27 - i should read up on how these uh import
48:30 - statements work but this works
48:32 - um
48:35 - yeah i tried that
48:36 - import load image from canvas
48:43 - all right look
48:44 - watch i don't want to get stuck on this
48:46 - stuff but
48:51 - right i believe this should work
48:56 - and it's not
48:58 - so you got me
49:01 - as to why
49:03 - that doesn't work
49:05 - but this is working
49:09 - okay so now the question is can i then
49:13 - uh the point of this was to convert them
49:15 - to tensors
49:16 - um now
49:19 - from pixels
49:21 - image
49:24 - uh t no not
49:33 - wait
49:36 - so i've loaded them
49:41 - the problem is
49:43 - with browser
49:46 - so i don't have a
49:49 - browser
49:52 - i should just have done it the way i was
49:54 - starting to do it
49:56 - uh
49:59 - uh
50:04 - yeah
50:05 - yes that's a good
50:07 - um so just out of curiosity i'm gonna
50:09 - take sorel's i'm probably mispronouncing
50:12 - your name
50:14 - import
50:18 - and then i could say
50:24 - it's a little bit
50:25 - more verbose
50:29 - yeah i i'm lost
50:32 - but also
50:41 - how do i convert it now
50:45 - to
50:45 - a
50:47 - tensor
50:48 - can i just say
51:14 - see this is what i want to do
51:18 - but i don't think it's going to let me
51:21 - it's not a function
51:31 - can i get this to work from node
51:45 - just added support to tf from pixels in
51:48 - node
51:50 - it's from 2018.
52:03 - this supposedly
52:17 - this should work according to this
52:26 - am i in the wrong version of tf.js
52:29 - somehow
52:34 - do i need core
52:59 - fixed tf from pixels
53:08 - you know why
53:12 - supposedly
53:26 - tf from pixels is not a function
53:30 - must have changed
53:34 - so let me just see which version am i
53:36 - using
53:40 - three
53:41 - is this somehow like different if it's
53:43 - like
53:44 - should be fine
53:46 - no this is the node version
53:48 - so did that go away
54:04 - oh tf image no
54:10 - i mean
54:13 - can i just put the browser in there and
54:15 - it'll figure it out is it as simple as
54:16 - that did i forget just
54:28 - pixels passed to tf browser must other
54:30 - be
54:32 - image data in brower
54:39 - hmm
54:41 - i should go back to my original solution
54:43 - oh tf from pixels was deprecated
54:47 - [Laughter]
54:48 - i should just go back to my original
54:50 - solution i'm going to go back to my
54:51 - original solution i'm using gym
54:54 - because i really don't i can make a
54:56 - tensor very easily with this small
54:58 - amount of data we could come back if
55:00 - there's like a more efficient way of
55:01 - doing this let's just go back to jimp
55:09 - or i could probably read the pixels just
55:10 - with node canvas
55:13 - but um
55:17 - which might be useful because then
55:21 - if i want to ever just do this in the
55:22 - browser but
55:36 - so let's not do it this way
55:45 - well actually what if i just can i just
55:46 - read the pixels here
56:00 - this is what comes up first in my search
56:05 - image data
56:08 - imagedata.data
56:10 - is it there
56:12 - is it there
56:19 - do i have the pixels
56:23 - no
56:27 - it's such a weird thing for it to
56:29 - console log
56:33 - yeah sean this is such a good question i
56:35 - don't really know why i started doing
56:38 - i was kind of imagining that at some
56:40 - point
56:41 - i wanted to like process huge amounts of
56:43 - data
56:44 - and like
56:46 - i don't know there's not really a good
56:47 - reason it's just kind of where i started
56:49 - because it was easier for me to sort of
56:50 - like work it out
56:52 - um and i could just use the file system
56:54 - like i said this is sort of silly i
56:56 - could come back to
57:04 - get image data
57:11 - i said i have to draw it as i go okay
57:13 - all right all right
57:20 - i've gone far enough with this
57:22 - silly way
57:30 - okay get array of pixels from an image
57:32 - file
57:34 - um image pixel color okay
57:37 - right this is where i started okay great
57:40 - so we're going to use promises and we're
57:42 - going to read
57:44 - so import jimp
58:03 - i don't know
58:05 - maybe that's right
58:10 - um
58:10 - and then
58:13 - um now we should be able to say
58:21 - let's just try this just real quick
58:26 - and
58:36 - oh no
58:48 - let's see what happens here
58:54 - jim dot read is not a function
59:04 - i don't know how to import anything
59:07 - okay
59:08 - we got something
59:11 - decoders
59:16 - how do i okay
59:18 - uh
59:26 - oh okay
59:28 - instead of using require ah there we go
59:30 - oh just as simple as that okay
59:33 - i over complicated it
59:41 - okay
59:45 - oh and look it drew the
59:46 - it redrew the image great
59:48 - okay so this is working
59:51 - uh let's go back boy
59:53 - boy this stuff takes forever okay so
59:56 - just to just to figure out where we are
59:57 - for a moment and um
60:00 - i'm gonna take a short break in a second
60:02 - um to check on my daughter
60:05 - and talk about curiosity stream
60:07 - but um this is where we are let's see um
60:11 - i am
60:13 - currently
60:15 - just trying to load the image to read
60:17 - the pixels to put it into a tensor
60:19 - and i'm going to say
60:22 - this now
60:27 - and the question is
60:33 - how do i where is the jimp documentation
60:40 - contain scale auto crop crop blit
60:42 - composite mask convolute flip
60:46 - pixelate displace clone resize
60:50 - align looking for
60:52 - like pixels
60:59 - okay
61:01 - no
61:04 - there's got to be a way to just read the
61:06 - pixels directly
61:09 - to get the pixels as an array
61:22 - some neighbor pixels
61:28 - boy i'm making this so hard
61:32 - let's see if this gives us anything can
61:35 - use
61:36 - data all right that's promising
61:42 - there's get base64 get buffer
61:46 - get pixel color
61:48 - well that's kind of useful but i don't
61:49 - want to go through and get the pixel
61:50 - colors one at a time
61:59 - undefined wasn't there something called
62:01 - data
62:05 - oh bitmap bitmap okay
62:17 - there's the raw
62:18 - data
62:20 - of the image
62:28 - get buffer
62:35 - let's see what this looks like
62:42 - mine must be a string i got some weird
62:45 - error there that didn't work
62:48 - i can't believe how much trouble i have
62:50 - in getting the pixels am i really gonna
62:52 - get the pixels one at a time all right
62:53 - let's just do it
63:26 - this is so crazy what i'm doing
63:39 - get pixel color
63:42 - j comma k
63:56 - what oh pixel's i doesn't even mean
63:59 - anything okay
64:01 - sorry um
64:16 - this is me reconstructing the pixel
64:18 - array
64:19 - oh what
64:22 - what are you doing
64:26 - automating things for me that i don't
64:28 - want you to do
64:34 - this actually makes kind of sense
64:41 - this bit image scan
64:44 - hey wait armor is giving me something
64:47 - scan
64:49 - is that from jimp
65:00 - uh here's a good reference your your url
65:03 - probably won't work sorrell
65:07 - so this is giving me the probably like
65:10 - the integer
65:12 - um this bitmap data
65:16 - this is in the gymp documentation oh
65:18 - image.scan thank you okay
65:27 - um
65:31 - a scan
65:33 - ah scan a region
65:35 - image bitmap data
65:38 - got it
65:41 - got it got it got it okay okay
65:44 - let's see
65:46 - scan
65:48 - jimp enables low volume of images and
65:50 - memory through the bitmap property of
65:51 - each jimp object
65:57 - why is this
66:02 - this is so weird
66:21 - our
66:25 - jeez
66:27 - this is so
66:30 - this is so insane how much this is like
66:34 - driving me crazy
66:38 - like
66:39 - how much i'm getting stuck in this
66:45 - this makes you want to go back to the
66:47 - browser
66:51 - all right let's let's go for this this
66:53 - is really weird but
66:56 - scans a region of the bitmap and calls
66:58 - the function f on every pixel
67:02 - um
67:05 - but couldn't i just do this myself it's
67:08 - the
67:08 - is the date hold on a second
67:12 - bitmap data okay
67:19 - so let me just try something
67:23 - let r equal
67:25 - image bitmap data
67:31 - zero
67:42 - is it just
67:44 - can i operate the bitmap like an array
67:48 - ah there we go
67:50 - this was so easy
67:54 - oh i'm such a dummy okay okay
67:57 - there we go so now i can do
68:04 - um
68:07 - but uh
68:08 - index equals zero
68:13 - index
68:14 - i'm just gonna i know it's everything's
68:16 - 28 by 28 so i'm just hard coding it in
68:35 - you just use n
68:37 - and then the actual pixel
68:40 - the actual index is n times four
68:45 - the r is
68:46 - is n plus zero
68:49 - n plus one n plus 2 but
68:53 - i'm not doing an rgb image so i can just
68:56 - use the r
68:59 - and now if i console log r
69:03 - i could oh i could just use the map
69:05 - function but i'll
69:08 - raw date i'm just gonna make an array so
69:11 - i could do some kind of higher order
69:13 - array function to just like do and i've
69:16 - got i could basically turn the bitmap
69:17 - into a tensor directly but
69:22 - since i've got grayscale images
69:24 - that's probably what i should do
69:25 - actually but
69:27 - i'm just going to say raw data
69:29 - just for now raw data
69:32 - n
69:33 - equals r
69:37 - and then console log
69:40 - raw data
69:44 - okay great so this is all of the raw
69:47 - grayscale values there we go
69:51 - we're getting somewhere
69:53 - so now
69:55 - uh remember when i was doing this before
69:58 - i
69:59 - uh
70:00 - though these are the x inputs
70:04 - so this generate image
70:07 - we returned a function
70:11 - so
70:12 - um
70:14 - train model x train i'm just sorry i'm a
70:17 - little lost here oh okay so x inputs
70:24 - so loading all the images
70:29 - we have
70:30 - x inputs
70:34 - and then
70:37 - x inputs
70:43 - index i is
70:46 - that raw data
70:47 - so basically i'm loading every single
70:49 - image
70:51 - into an array and then putting it in my
70:53 - x inputs array because
70:58 - and i can take all this other stuff out
71:00 - because and let's get rid of the random
71:02 - one
71:04 - because when it's time to train the get
71:07 - the training data
71:15 - so this i need a
71:17 - curly bracket there to close this out
71:20 - then
71:21 - the training data is a tensor out of all
71:24 - of these images and then i'm not going
71:26 - to call train model just yet but let's
71:28 - sort of see
71:32 - i is not found why is i not found oh
71:34 - right because this
71:36 - does need to be in here there we go
71:41 - okay so now that's one image as a tensor
71:45 - so now i can actually go ahead and load
71:48 - all 100 images
71:52 - okay i loaded 100 images into those
71:55 - tensors by the way the reason why you're
71:56 - seeing 255 everywhere is those images
71:59 - are all white around the edges and all
72:01 - of the the data that wouldn't be 255
72:04 - should be dot dot yeah i need to
72:06 - refactor this stuff chris is saying
72:08 - should make getting the raw data into a
72:10 - separate function absolutely so i will
72:13 - refactor this later
72:15 - but now i should be able to say await
72:18 - train model
72:20 - and let's see what happens here
72:24 - oh uh oh x train is not defined
72:29 - oh because i made that
72:31 - those global okay
72:33 - well here
72:35 - i'm going to just be very silly about i
72:36 - need to rethink how all these functions
72:38 - are organized
72:45 - remember this is something i talked
72:46 - about last last time this is very weird
72:49 - why
72:50 - are my inputs and my outputs the
72:52 - training data this is unique to this
72:54 - auto encoder problem where instead of
72:57 - like an image classification problem
72:58 - where i would have a whole bunch of
72:59 - images paired with their target labels
73:02 - those images
73:03 - the the training the correct output for
73:06 - each image is that image itself
73:11 - okay let me come over here
73:15 - and
73:23 - so something happened
73:25 - i don't get what this loss is
73:30 - it's a negative number i'm a little
73:31 - confused by that
73:33 - um but this is also so few images
73:36 - so i think i'm at a good place
73:39 - where now i can just take a short break
73:41 - i'm gonna turn the heat on for a little
73:42 - bit to warm it up in here
73:47 - and so the things that i need to do
73:48 - after i take this short break are
73:52 - let me make more images
73:55 - let me think about
73:59 - the hyper parameters and configuration
74:02 - of this network
74:04 - like if i just like right now if i just
74:06 - change this to the encoder having 784
74:09 - units
74:14 - interesting i wonder i need to think
74:16 - about the learning rate
74:18 - the loss i don't know what's going on
74:19 - here exactly i need to rethink the hyper
74:22 - parameters normalize the data
74:24 - thank you aman
74:26 - ah why did i forget
74:28 - why did i forget that thank you
74:31 - all right let me do that quickly
74:34 - so important
74:38 - i forgot to normalize the data no wonder
74:41 - it's like exploding
74:44 - there we go okay
74:47 - we're getting somewhere
74:48 - the loss is like a number that makes
74:50 - sense now it started with 0.683 went all
74:53 - the way down
74:54 - to 0.1 i could try more epochs but i'm
74:56 - going to get more data
74:58 - i'm going to um
75:01 - you know
75:02 - just uh i should be able to get a loss
75:04 - of zero essentially if
75:06 - i have 700
75:09 - yeah look at this look at that oh the
75:11 - loss that's going on i mean of course
75:12 - they've defeated the purpose by not
75:14 - actually compressing the data but okay
75:17 - warming up then that's what i'm about to
75:18 - do all right
75:20 - okay okay thank you thank you i forgot
75:22 - to normalize the data okay everybody
75:25 - i'm i'm really close now
75:27 - this was a lot a lot of time that i
75:29 - spent like trying to just figure out how
75:31 - to load the images sorry for all of
75:34 - those
75:34 - um kind of strange tangents and
75:37 - different libraries this is still kind
75:39 - of awkward and weird
75:41 - but the fact that the data can be read
75:44 - from the file with jimp and then the
75:46 - actual pixel information is just in this
75:48 - bitmap.data property this this could
75:51 - definitely be improved but it's getting
75:52 - me all the way there now okay so um
75:57 - um i want to uh
75:59 - take a break for a minute uh before i
76:01 - take my break let me thank today's
76:04 - sponsor
76:05 - oh the sponsor
76:07 - um this is uh uh this a sponsor is
76:10 - curiosity stream and i i some of you
76:13 - probably weren't here at the beginning
76:14 - of the live stream where i showed this
76:16 - to you so curiosity stream i'm just
76:18 - gonna quickly play this brief ad for you
76:20 - from curiosity stream directly so you
76:22 - can learn all about what curiosity's
76:24 - stream is but don't go away because
76:26 - after i play this i'm going to talk to
76:28 - you about why you should sign up through
76:30 - my
76:31 - link coding train to get access to some
76:33 - extra cool stuff from another thing
76:34 - called nebula so just hold your horses
76:36 - here we go
76:37 - from the founder of discovery channel
76:40 - comes a new independent streaming
76:42 - service
76:43 - curiosity stream
76:47 - home of groundbreaking documentaries
76:51 - and award-winning original series
76:58 - follow your curiosity
77:03 - this is curiosity stream
77:54 - oh i'm really
77:56 - i'm so getting fired
77:59 - i know okay okay so i'm talking to you
78:02 - so at least that
78:05 - start over start over i'm exit exit
78:08 - stage right i'm coming back
78:10 - don't make don't make don't don't
78:12 - everybody sign up so don't get fired
78:13 - okay hello everyone uh you just saw that
78:16 - wonderful 30 second promo about
78:18 - curiosity stream which is one of my
78:20 - favorite streaming services because it
78:22 - is chock full of so many wonderful
78:25 - educational documentaries the things
78:27 - that i like to watch the most is all the
78:28 - nature stuff um so we can see here just
78:31 - realm of the volga whoa
78:34 - the volga flows 2 000 miles oh i've got
78:37 - to check this one out um i was just
78:39 - saying that um one of the ones that i
78:41 - have watched with my kids that i really
78:43 - love which was under here under kids is
78:45 - ancient earth which is uh all about life
78:49 - that existed in the permian triassic and
78:52 - cretaceous periods so
78:55 - right and hudu says even without the
78:57 - sound i want to watch that sea lion show
78:59 - so just curiosity stream if you sign up
79:02 - through my link and i believe
79:04 - if i go slash coding train
79:09 - it'll sort of show us that
79:12 - because i'm already logged in so if i
79:14 - wasn't logged in it would have a nice
79:15 - little banner at the top that says you
79:17 - get 26 off of the annual
79:20 - subscription that comes to
79:23 - 14.79 it's barely over a dolla uh barely
79:26 - over a dollar per month
79:28 - at 14.79 for the entire year but i think
79:32 - the thing that i really want to tell you
79:34 - that i'm really excited about is this is
79:36 - a bundle so if you sign up for curiosity
79:40 - stream
79:41 - bundle through the link you will also
79:42 - get access to nebula so nebula is a
79:44 - streaming service built by youtube
79:47 - creators
79:49 - many of my favorites here if i go to my
79:51 - library there's some that i'm following
79:53 - um renee ritchie um if you like ai and
79:56 - want uh machine learning want to learn
79:58 - more about machine learning you should
79:59 - definitely be checking out jordan
80:01 - harrid's videos there's some other ones
80:03 - that are here
80:04 - um in my and look at this all of these
80:07 - uh daniel shiffman coding train videos
80:10 - and in particular one of the things that
80:11 - you get with nebula is early access and
80:15 - so this is a video that isn't yet out on
80:17 - the channel will be hopefully tomorrow
80:19 - if you want early access to it the full
80:21 - um
80:23 - um
80:25 - the full um
80:28 - if you want early access to it you'll
80:30 - you'll get that through the nebula
80:31 - bundle so so many wonderful creators um
80:34 - the other thing that you know a lot of
80:35 - this stuff is also on youtube but it's
80:37 - without ads on nebula
80:39 - um and
80:41 - um there are all these wonderful nebula
80:43 - originals so um this is a really awesome
80:45 - um
80:46 - uh like compilation of different
80:49 - creators i i wonder if i could make one
80:51 - of these i don't know but each uh
80:53 - different creators on youtube they're
80:55 - all making videos about the opening
80:57 - title sequences of different um
81:00 - television shows so um you can see renee
81:03 - ritchie did one about buffy the vampire
81:05 - slayer we've got soap's notes one about
81:08 - pokemon oh i've got to check this out so
81:10 - all these these originals are really
81:13 - just wonderful i'm just like poking
81:15 - through to look for some other ones um
81:18 - a big fan of legal eagle so you got this
81:20 - all of this bad law words good so uh
81:26 - so mikhail is asking did he say built by
81:28 - youtube creators or youtube's creators
81:30 - no built by creators so everyone that
81:34 - you see here on nebula participated in
81:37 - the making of nebula itself um
81:40 - and um
81:42 - um it you know this isn't really true
81:44 - for me but i know that one of the
81:46 - benefits for many youtube creators of
81:48 - nebula is certain kinds of content a lot
81:51 - of the um like historical
81:54 - um
81:56 - videos um
81:58 - that um certain kinds of content can't
82:00 - be on youtube it will get demonetized or
82:03 - it will get sort of
82:04 - um
82:06 - uh just if it's about a kind of a kind
82:08 - of topic like about you know world war
82:10 - ii for example so um i'm not saying this
82:13 - very eloquently but creators are free
82:16 - basically on to publish certain kinds of
82:18 - videos on nebula that would might cost
82:20 - them issues on youtube itself so that's
82:22 - one of the motivations as well as all
82:23 - these originals about being able to have
82:26 - no ads so you can get this for free
82:29 - not for free well you get it for free if
82:31 - you sign up for the oh oh i'm so be
82:34 - gonna get fired
82:38 - i'm really basically like i i i'm just
82:40 - i just got a cop to it today has been
82:42 - such a mess for me i had this all
82:44 - planned out this morning and everything
82:46 - i knew i wanted to say and do in this
82:48 - live stream i really do love this
82:50 - service nebula
82:51 - i participated it i'm i'm it's it's
82:54 - meaningful to me and it's like as i get
82:55 - to become uh spend more and more time on
82:58 - coding train i'm really hoping that come
83:00 - this january i'm gonna be able to dive
83:03 - more into
83:04 - nebula and make some maybe make a nebula
83:06 - original myself so if you want to get
83:08 - involved learn more about it also
83:10 - support the coding train itself get
83:13 - access to this incredible library of
83:15 - documentaries you can go right now
83:18 - to um curiositystream.com
83:21 - codingtrain that's the link right there
83:23 - keradostream.com
83:25 - codingtrain um thank you everybody for
83:27 - uh tolerating this like really terrible
83:30 - sponsor read i'm gonna do better next
83:32 - time i'm to take a like a two or three
83:34 - minute break
83:35 - you can sign up now if you have nothing
83:37 - to do in this two or three minutes i'll
83:38 - be right back to finish off this auto
83:41 - encoder project
83:44 - i'm gonna go feel bad about myself over
83:46 - there now be right back
83:48 - [Music]
83:58 - [Music]
84:07 - [Music]
84:14 - [Music]
84:19 - so
84:20 - [Music]
84:53 - [Music]
85:02 - [Music]
85:09 - [Music]
85:21 - [Music]
85:34 - all right i have returned
85:39 - i took some deep breaths did a very
85:41 - short 20-second meditation
85:46 - and
85:49 - john says well you got me to sign up so
85:51 - you didn't do too badly
85:56 - all right um
85:58 - those are those pity sign ups i
86:00 - appreciate it um all right let me get
86:02 - back into what we're all here for which
86:05 - is my
86:06 - building of an auto encoder
86:09 - all right
86:11 - so i think we're really close here
86:14 - to actually seeing some images
86:18 - generated from the auto encoder now if i
86:20 - wanted to go all the way through with
86:22 - this
86:23 - i would i want to eventually
86:27 - reconnect this back to the browser
86:29 - itself i mean maybe i should just have
86:31 - the model in the browser i don't really
86:33 - need a node server so
86:35 - um maybe run the training i'm not really
86:38 - sure where i want to go with this
86:39 - ultimately it so turns out but i do want
86:42 - to see the results of the auto encoder
86:45 - in the browser and start to understand
86:47 - how to manipulate the latent space but
86:52 - my goal for today given that i would
86:54 - like to wrap this up in about
86:56 - 20 to 30 minutes
86:58 - is to simply see an image generated from
87:02 - the auto encoder even just one
87:06 - so
87:07 - i'm trying to decide i think it would be
87:09 - worth me putting in a few more layers
87:15 - um
87:17 - so
87:20 - i mean i suppose like
87:22 - maybe i don't need to worry about
87:23 - improving this so much and let's just
87:25 - work with what i've got
87:27 - which is a hundred images
87:30 - um let's see what happens if i give it a
87:32 - 100 epochs
87:34 - and i'm just going to go down i'm going
87:35 - to compress the 784 pixels
87:39 - down to 64.
87:42 - oh and mikhail is asking a great great
87:45 - question
87:46 - in his image loading he's normalizing
87:48 - the pixels to between zero and one but
87:50 - all the tf tutorials i've seen use
87:52 - negative one to one is there any
87:53 - practical difference or just personal
87:55 - preference i would love to know the
87:56 - answer to that question um i think at
87:58 - the moment because i'm using this
88:01 - output i'm using the sigmoid function as
88:04 - the output activation function it's got
88:06 - to be between zero and one because the
88:08 - um the outputs are only going to be
88:10 - between zero and one with sigmoid but if
88:12 - i were using tan h
88:14 - then i could have outputs between
88:15 - negative one and one has to do with the
88:17 - um
88:19 - so
88:19 - but again i'm kind of flying blind i'm
88:22 - just sort of like
88:24 - throwing all the spaghetti at the
88:26 - wall to see what sticks just trying to
88:29 - get something working that i can go back
88:30 - and kind of fine-tune more thoughtfully
88:34 - um i don't need to print this out
88:35 - anymore let's just try uh training this
88:38 - let's see what happens with the loss
88:44 - so the loss seems to settle at um with a
88:48 - probably settled around 100 epochs at
88:50 - 0.07 that's great
88:54 - so
88:55 - could i now
88:58 - if i wanted to generate an image from
89:01 - this let's go back to the original so i
89:03 - i'm done with sort of like
89:06 - part two and a half of three parts this
89:09 - is in three parts part one was just
89:12 - building the auto encoder giving it
89:14 - noisy data
89:15 - part two a was
89:18 - getting actual data into the auto
89:20 - encoder part two b
89:22 - is
89:22 - looking at the results of the
89:24 - autoencoder after it's been trained
89:27 - so if i'm coming back to this what did
89:30 - uh what did this tutorial do
89:33 - and i'm not having any test data yeah
89:35 - right this is also by the way
89:36 - normalizing between zero and one
89:40 - decoded images oh using predict okay
89:45 - so if i can use predict
89:50 - to see okay great so let's do this let's
89:53 - follow this so i want to use predict
89:56 - let's refactor this a little bit to make
89:58 - it less weird okay
90:00 - so
90:02 - also known as the scientific method yeah
90:04 - um so let's let's get a little bit
90:07 - better here
90:09 - so basically i want to have a fun i'm
90:11 - going to write a function called like
90:13 - main
90:17 - which is a little bit silly
90:19 - fungshom function
90:22 - function
90:24 - and it's going to be an async function
90:28 - and the things that i'm going to do in
90:30 - it are
90:32 - load all image data
90:35 - convert image data
90:37 - to a tensor
90:40 - train the model
90:42 - uh
90:43 - uh
90:46 - test the model
90:49 - so i've done everything but this last
90:50 - step of test the model
90:53 - so this async function load images
90:59 - i can just say return x inputs so let's
91:03 - just call this
91:08 - all images
91:12 - and
91:14 - return all images
91:17 - so first thing i'm going to say is
91:23 - const images equals await
91:27 - load images
91:29 - okay then
91:34 - and there was a question about why this
91:35 - is a 2d tensor i'll talk about that if
91:38 - the data is flattened into one dimension
91:40 - i will talk about that in a moment
91:43 - so let's do this
91:51 - does this need an await no it doesn't
91:55 - so that's the trading data i should save
91:58 - some to be testing data but i'll just
92:01 - worry about that later i'm just going to
92:02 - reuse this is very bad idea very bad
92:05 - idea but i'm going to reuse some of the
92:07 - training data for my testing of the
92:09 - model we could separate out we can get
92:10 - new data later i promise
92:14 - [Music]
92:16 - and then training the model is as
92:18 - follows
92:23 - let's write a
92:24 - function called async
92:28 - train model
92:31 - and we're going to get
92:34 - data in
92:36 - so i'm going to say await async function
92:40 - a weight train model
92:42 - with x train
92:47 - and then
92:49 - is auto encoder still just a global
92:51 - variable yeah so you know it would make
92:53 - sense for me also
92:55 - to
93:03 - have a
93:05 - function
93:06 - that is build model
93:18 - so basically
93:20 - well
93:22 - auto encoder is a sequential model
93:25 - the build model function
93:27 - puts all the stuff into it
93:29 - why i'm i'm
93:33 - so i should be calling build model first
93:44 - the model
93:46 - what did i do wrong here
93:52 - there we go
94:01 - so let's bring this up here
94:12 - build model auto encoder
94:16 - again i'm not so sure this really makes
94:19 - a lot of sense the way i'm doing this
94:27 - um
94:28 - so now i need
94:32 - to pass this business arguments um this
94:34 - is pretty arbitrary what i'm doing
94:40 - but
94:40 - i'm trying to get rid of sort of global
94:42 - variables
94:44 - and so now i've created the sequential
94:47 - model
94:53 - i think actually i'd like to do this
95:09 - and then return it
95:14 - so what am i doing i am
95:19 - build the model
95:24 - load the image data
95:26 - convert the image data to a tensor so
95:29 - that i can train the model with that
95:31 - data
95:32 - then and let's just make sure this all
95:33 - still runs
95:38 - oh
95:39 - i think i have to call this function
95:46 - all right so
95:48 - everything still works
95:50 - everything still works training the
95:52 - model
95:53 - then
95:55 - i would like to test the model so i need
95:58 - one image
96:01 - so
96:04 - all the images are here
96:09 - so what i could do let's do the
96:11 - following let's be a little more
96:13 - rigorous about this
96:15 - i'm going to re-run
96:17 - my
96:18 - uh
96:20 - training data creation and make 500
96:23 - images 550 images
96:30 - oh
96:31 - let me let me make i'm going to make
96:33 - 550 images okay they're all squares
96:40 - okay we're almost there
96:42 - making 550 squares
96:45 - all done
96:47 - i'm going to get this data
96:50 - i'm going to bring it into
96:53 - um
96:56 - the autoencoder project
96:59 - going to replace it
97:03 - then i'm going to rerun this sketch it's
97:05 - not a sketch we run this code
97:11 - uh
97:15 - with uh
97:19 - i'm going to put an argument in here
97:22 - with for 500 images
97:35 - let's just see how this goes
97:37 - loss is getting better when i've got 500
97:39 - images i'm able to get the loss much
97:41 - further down
97:43 - although it seems to have settled by the
97:45 - time i'm at like 100 epochs
97:49 - so
97:50 - certainly
97:51 - there's not a huge reason for me to
97:53 - train it
97:55 - for
97:56 - long for that long let's just say 75 to
97:58 - make things run faster
98:00 - um and
98:03 - i think actually what i want to do is
98:04 - load all 550
98:07 - but i want to take out
98:12 - just a slice of them right so how do you
98:15 - do a slice
98:17 - javascript array
98:21 - slice returns a shallow copy of a
98:23 - portion array into a new array object
98:26 - so if i wanted just 500
98:30 - i would do this
98:33 - and then
98:34 - if i want to do
98:36 - test
98:37 - x test
98:39 - i could create a tensor
98:43 - out of those same images but slice
98:46 - from 500 to 550 right
98:52 - um
98:55 - let's skip um
99:00 - let's skip training the model for a
99:01 - second
99:06 - okay all right right so this makes sense
99:09 - i've got 500 training images 50 test
99:13 - images
99:16 - so now
99:23 - i should be able to say
99:29 - uh
99:30 - auto encoder
99:33 - predict
99:36 - x test
99:40 - let's see
99:43 - after it's trained is that
99:45 - all i need to do
99:49 - predict
99:52 - encoded images
99:55 - oh it's got the encoder and the decoder
99:59 - as separate things
100:05 - oh we made two separate i made encoder
100:07 - model
100:09 - anyway i'm going to do this my own way
100:12 - because eventually i want to like chop
100:14 - off the
100:16 - encoder and just feed in noise from the
100:18 - middle layer but let's just sort of see
100:21 - what happens here
100:26 - so i'm training and then ah look look
100:29 - look
100:30 - we're getting images out yes now we just
100:32 - need to turn those
100:34 - into um now we just need to turn those
100:37 - into images i bet you jim will do that
100:39 - for us
100:44 - so how do i uh
100:47 - write a new image by the way it's
100:49 - freezing in here
100:52 - create an image and write it in a text
100:55 - uh can i make a new image
101:00 - okay can i can i set the pixels
101:05 - and we're about to find out
101:10 - this this frozen mountain behind me is
101:12 - no joke
101:13 - i should really just turn the heat on in
101:15 - here but normally what i do is i warm it
101:17 - up before before i stream
101:19 - but i thought i wasn't going to i can't
101:21 - believe this is working
101:22 - okay
101:23 - so
101:24 - um i need to
101:26 - get the data so back to tensorflow.js
101:32 - uh where are we back to tensorflow.js tf
101:36 - data array
101:38 - no how do i get the tensor
101:43 - tf
101:44 - tensor uh
101:47 - tf image
101:49 - ones
101:50 - can't isn't there like how do i get the
101:54 - data data this is what i want
101:56 - gives me the data oh but i can actually
101:58 - just get it as an array
102:00 - returns the tensor data as a nested
102:02 - array
102:03 - okay
102:05 - so
102:06 - const
102:08 - uh
102:10 - did i already use the word images yeah
102:12 - like new images
102:14 - equals output
102:18 - uh array
102:20 - await
102:23 - let me just do console log new images
102:26 - index zero
102:32 - it's a little silly that i'm training
102:33 - the model every single time
102:36 - but okay great so now i got an array of
102:39 - 784 pixel values
102:42 - so i should be able to say
102:53 - you know i could use base64 encoding
102:55 - probably as a way as writing the images
102:57 - but this is fine
102:59 - [Music]
103:01 - and let's just do it with just one
103:09 - so now what i'm doing is i want to say
103:14 - image equals jimp
103:18 - quiz it creates
103:25 - really help if i really knew jimp
103:44 - writing text
103:46 - how do i create an image
103:57 - oh man
104:04 - new gym oh maybe just this oh okay
104:07 - creating new images here we go
104:19 - okay
104:21 - you can call the gym constructor can i
104:23 - do this with
104:25 - buffer data buffer
104:28 - raw image buffer
104:33 - four channel rgba image data okay
104:48 - just now can i do a weight
105:06 - so i'm making it what if i just make the
105:08 - buffer
105:23 - how do i do that thing where i like fill
105:25 - an array
105:26 - yeah all right so um
105:30 - all right let's just go ahead and do
105:31 - this
105:32 - buffer is an array
105:35 - and then for
105:38 - n equals zero n
105:41 - is less than new images index i
105:45 - dot length
105:47 - n plus plus
105:50 - buffer index n
105:59 - n times four plus zero
106:03 - right is
106:07 - is new images in okay so
106:12 - current
106:13 - is new images index i
106:21 - so
106:22 - if
106:24 - basically i want to take all of those
106:25 - values
106:30 - and expand them back out by 255. the
106:33 - reason why i'm multiplying by 4 is i i
106:37 - i took my grayscale image of rgba and
106:40 - made it just like one value
106:42 - so now i'm paying for that because i've
106:44 - got to expand it back out
106:46 - to four values and
106:49 - this one should always just be 255 so
106:51 - there's no alpha transparency
106:54 - and these are
106:56 - this is just putting whatever that value
106:59 - is in the rgb channels
107:01 - and then i should be able to
107:05 - make a new
107:07 - image and then how do i write the file
107:10 - right image right
107:12 - um
107:14 - right should be able to say
107:16 - image dot write
107:18 - test
107:19 - dot png now that's gonna let's just do
107:22 - it with one i'm just doing it with one
107:23 - image so it's fine obviously i need to
107:26 - number these i'll get to that
107:29 - and let's just see if uh output
107:32 - okay
107:33 - let's just see what's happened i'm sure
107:35 - i mes
107:36 - missed something important
107:39 - okay uh
107:41 - the first argument must be of type
107:43 - string or instance of buffer array
107:44 - buffer array array like object receive
107:46 - null
107:48 - where
107:58 - so close to having this working what did
108:00 - i miss
108:02 - uh
108:03 - log
108:05 - buffer
108:20 - let's
108:22 - just take a look at it let's also
108:24 - i'm just going to train the model for
108:28 - um and let's let's put the number of
108:29 - epochs in here
108:32 - just do 10 epochs
108:35 - so i can like test this
108:37 - more quickly
108:48 - okay so now
108:51 - i should be able to see the buffer after
108:53 - 10 epochs
108:55 - almost done
108:57 - i'm almost done okay this is the buffer
109:01 - that looks right
109:08 - oh maybe i can't use a weight here
109:15 - no matching so maybe maybe a weight
109:17 - doesn't work i need to follow
109:22 - um follow it's
109:28 - um
109:30 - call back methodology
109:47 - let's see what happens here what is it
109:50 - that last argument is error image
110:02 - is the function
110:05 - i'm a little lost now
110:07 - a little lost in my syntax
110:10 - new jimp
110:12 - and the arguments are
110:15 - oh this is first
110:17 - oh this is a separate argument it
110:19 - doesn't go in there okay
110:21 - so it does not go in this object there
110:23 - we go
110:24 - okay image
110:27 - and what if i actually just did it just
110:29 - as a test
110:35 - well okay let's try it with the data
110:36 - buffer
110:38 - data buffer error image
110:41 - and then if i said image write
110:49 - let's see if this works
110:53 - okay here we go
110:59 - cannot read properties of undefined
111:14 - we're gonna get there folks
111:23 - no matching constructor overloading was
111:25 - found
111:28 - do i need to round my output values to
111:30 - integers i don't think that should
111:31 - matter
111:37 - but yeah i could see how that's an issue
112:02 - the floor is not defined yeah yeah yeah
112:17 - all right let's just
112:20 - try um
112:25 - this for a second
112:28 - see if i can get a red image
112:45 - oh by the way there's something here oh
112:47 - nothing is there
112:58 - just now i'm i'm not trying to use my
113:00 - actual data from the neural network i
113:02 - just
113:03 - literally
113:05 - put the jimp code to draw a red image
113:08 - that's
113:09 - 256x256 there just to know that this
113:11 - works
113:14 - okay
113:15 - now do we have a red image
113:18 - yes or pink okay so image writing out
113:21 - does work
113:22 - now the question is
113:24 - what if i
113:26 - how do i fill create the buffer
113:28 - correctly
113:30 - so
113:31 - if i wanted to follow
113:36 - so why does this not work
113:41 - and this does
113:44 - um
113:46 - data
113:48 - i mean i must not have made
113:50 - the buffer correctly
113:55 - buffer
113:56 - buffer is expected to be a four channel
113:58 - rgba image data yeah which is
114:02 - not just a plain array
114:17 - let's see we can find an example
114:27 - yeah look here's the error
114:33 - huh other people are finding this error
114:38 - cannot create new jim buffer okay that's
114:41 - unfortunate
115:09 - yeah it doesn't seem to work
115:13 - buffer from array okay ah chris manning
115:16 - says buffer from array
115:30 - okay fingers crossed emoji
115:39 - what
115:40 - oh
115:41 - well i think that worked
115:45 - i mean oh but i didn't write the image i
115:47 - think that worked
115:50 - oh i think that worked
115:54 - oh this is very exciting
115:56 - i think that might have worked
116:04 - yes
116:04 - yes
116:05 - i've never been so excited to see a
116:07 - total like noise nonsense image
116:10 - [Laughter]
116:12 - oh my god that's amazing
116:14 - um
116:16 - okay
116:16 - wait wait wait
116:18 - all right so now hold on hold on first
116:20 - of all i need to train the model better
116:24 - and then
116:25 - okay so what do i need to do
116:27 - this i can get rid of
116:30 - i need to train the model
116:37 - with more epochs
116:40 - let's do 100 epochs
116:43 - then
116:44 - where was my crazy numeral thing i did
116:47 - um to
116:50 - let's find that yeah
116:52 - then i need to save it
116:57 - um
117:01 - so what am i am i an n am i in i i don't
117:03 - even remember i mean i still
117:07 - i
117:08 - output
117:11 - square
117:16 - num
117:19 - dot png okay so this should do
117:22 - so now basically i am
117:26 - and i should do all of them
117:28 - so new images.length
117:33 - and i've got a lot of like these prints
117:35 - here that i don't need
117:39 - okay so what this should be doing now
117:45 - and
117:46 - um
117:48 - and i should call i
117:51 - i have this main function let's take
117:52 - this out let's do oh and this should say
117:55 - a weight
117:58 - oh no it doesn't need in a weight it
118:00 - only needs in a weight
118:02 - if i'm converting it
118:04 - to
118:05 - data that i can actually use that's
118:07 - interesting so hold on
118:09 - so this is the train data
118:18 - this is loading all then i'm taking 500
118:21 - images to train it with
118:24 - then testing the model
118:26 - i'm going to say await
118:28 - generate
118:31 - generate tests
118:33 - and i want to give it the auto encoder
118:36 - and the test data
118:39 - so this should all be
118:41 - in its own function
118:43 - which is an async function
118:46 - generate tests
118:48 - which
118:49 - gets the autoencoder
118:52 - and the test data
118:57 - then writes it out
118:59 - okay
119:02 - so there we go these are the steps now
119:04 - right build the model load all of the
119:07 - images train the model test the model so
119:10 - train the model with 500 images test the
119:13 - model with 50 images
119:16 - okay ready everybody
119:19 - this definitely merits a
119:25 - here we go
119:27 - oh by the way it's funny how this poll
119:28 - is still up i'm gonna hit end pull
119:32 - yes thank you to chris ray
119:34 - train whistle
119:36 - for chris ray here we go
119:44 - huh
119:45 - i mean did it write all those images out
119:46 - that fast
119:48 - i found that hard to believe it looks
119:50 - like it no that's
119:51 - what
119:54 - oops
119:55 - i couldn't
119:57 - output oh yeah it did
120:01 - but something is wacky
120:07 - my images don't look anything like
120:10 - what was fed into them
120:14 - oh shoot
120:20 - what could i have done wrong
120:26 - oh
120:27 - we got everything to work
120:30 - just looking at this so i'm getting the
120:31 - output
120:34 - i mean
120:35 - to be fair
120:36 - this model is kind of ridiculous
120:42 - what if i go back to my just like let it
120:44 - like literally copy everything
120:52 - oops
121:11 - i can't tell if it re
121:14 - did it regenerate the output
121:17 - i mean maybe i need to rethink my model
121:31 - yeah no what is going on
121:38 - i mean there's images there
121:42 - it's outputting a zoomed in square
121:44 - you've set it to 28 pixels width in
121:46 - height i think yeah
121:48 - did you write the pixels out in the same
121:50 - order you read them in not necessarily
122:01 - so let's think about this
122:04 - this is me reading the images the data
122:07 - in
122:26 - right and then
122:40 - should be 784
122:47 - this is very silly i have to run through
122:49 - a hundred epochs of training this model
122:50 - just yeah yeah okay just to see that
122:52 - that number was 784.
122:55 - i am not reading the discord shot chat
122:59 - um simon is saying
123:02 - uh maybe you should add more layers i
123:04 - don't think you did anything wrong i
123:05 - think the my model is just bad
123:07 - more layers okay
123:09 - i believe in i believe that could be
123:11 - that that is the case
123:13 - okay let's let's
123:14 - let's add more layers
123:23 - um so
123:26 - let's do it let's do it by half so 784
123:31 - divided by 2 is 392.
123:35 - now let's just let's just use powers of
123:37 - twos so let's start with
123:40 - should i be using relu
123:42 - for all the encoder activation functions
123:46 - so let's just do encoder one
123:53 - encoder two is i don't need the input
123:57 - shape anymore
123:59 - uh is 128
124:03 - and then decoder 1
124:06 - would be 256.
124:12 - and
124:16 - again this is a little bit silly now i
124:18 - don't need to name all of them
124:19 - i could just do
124:22 - decoder two
124:25 - is 784
124:30 - okay
124:31 - so and let me be a little bit more
124:35 - i think it'll be nicer actually i don't
124:37 - need to i'm just going to add them in
124:39 - directly
124:40 - so let's add in
124:48 - add in this layer
124:52 - then add in another layer
125:01 - and then
125:03 - i wonder if there's a nicer way to write
125:04 - this but i'm just going to do this like
125:06 - this
125:08 - another layer
125:13 - and
125:14 - another layer
125:16 - back to 784
125:18 - okay
125:19 - so we're putting in
125:21 - um
125:26 - you should take one of your input images
125:28 - create the buffer the exact same way you
125:29 - are with the output yeah that's a very
125:31 - good idea chris manning i will do that
125:34 - i'm also going to do that so here are my
125:37 - layers the first layer gets 784 down to
125:41 - 256
125:42 - then down to 128
125:44 - then back up to 256 then back up to 784
125:49 - and out
125:51 - and i don't need this anymore
125:55 - so let's see how this does
126:06 - um
126:06 - [Music]
126:15 - 351 yeah
126:18 - still okay so let me do i let's do um
126:22 - let's do some jimp tests
126:25 - so i'm gonna do test.js
126:28 - so i've got too much stuff going on here
126:30 - to really know what's happening
126:32 - so
126:33 - let me do the following i'm going to
126:35 - take i'm in my in this test
126:37 - i'm going to just get rid of um
126:40 - everything but jimp
126:43 - and get rid of all the tensorflow stuff
126:45 - just for a second
126:47 - so i want to
126:52 - oh i lost some stuff
126:54 - so i want to
126:57 - uh
126:58 - test images
127:06 - so let's test images one
127:09 - so i'm going to read the image i'm going
127:12 - to
127:13 - get the raw data
127:21 - then let's try writing the image back
127:23 - out
127:24 - um
127:26 - to make sure that actually
127:29 - works
127:31 - the way i expected it to
127:44 - so now that i have the raw data
127:54 - this is this is the equivalent of raw
127:56 - data
127:57 - to expand it back out
128:00 - and write the image out
128:02 - so let us
128:05 - get rid of output
128:07 - so this should just be a nice little
128:09 - test
128:10 - to read one image in
128:12 - and write it back out just to make sure
128:14 - that that actually works probably takes
128:16 - longer to train says k weekman yeah
128:20 - so let's just do node test
128:24 - image right
128:33 - oh
128:36 - what's going on here
128:46 - oh
128:48 - there's a mistake here
128:52 - there's a mistake here
128:55 - n times four
128:57 - i'm using n
128:59 - to pull the colors
129:02 - that should be index
129:04 - whoa
129:07 - whoa
129:08 - that's a huge mistake
129:11 - that i've just caught right now
129:18 - any idea what the batch size should be
129:20 - also this is so arbitrary let's just say
129:21 - 32.
129:22 - i'm gonna make that lower cause i don't
129:24 - have that much data
129:25 - look at this
129:28 - this is a huge error huge error
129:33 - huge error huge error
129:36 - [Laughter]
129:37 - i think that might actually be
129:41 - i might have just found the issue
129:46 - clearly i need more time to train
129:48 - but we could actually look at what just
129:49 - came out
129:51 - yeah
129:52 - i did it i did it
129:55 - it worked
129:58 - look what comes out
130:00 - look at that that is beautiful
130:02 - beautiful
130:05 - auto encoder
130:08 - worked oh okay okay okay this is way too
130:11 - exciting hold on hold on everybody just
130:14 - everybody relax
130:17 - okay this is really exciting okay
130:20 - um now i i have to wrap up i'm way over
130:22 - time there's so much more that could be
130:24 - done to this part three i maybe will
130:26 - come at some point maybe this will all
130:28 - get edited into some video and i'll
130:30 - narrate it who knows i have no idea
130:33 - but
130:37 - what i
130:38 - want to do
130:40 - is a couple things
130:43 - one
130:45 - let's
130:49 - train it for much longer
130:52 - where's the training
130:55 - oh yeah
130:56 - i just want to see let's give it 200
130:58 - epochs
131:01 - i just want to see like when does the
131:03 - loss stop going down
131:08 - still going down
131:15 - i mean eventually i need to just save
131:17 - the model and not do this every time
131:20 - but i just want to see
131:25 - i want to see if i can denoise some
131:26 - images
131:33 - so where are we
131:35 - yeah i mean so
131:39 - 250
131:42 - we'll do 250 epochs
131:44 - so what i would like to do actually now
131:49 - just as an experiment
131:51 - is let me make
131:55 - a bunch of images with a lot of noise in
131:58 - them
132:01 - so
132:03 - let's do this
132:26 - a point
132:34 - so i'm just adding a lot of noise into
132:36 - the image
132:42 - maybe i need to add more let's add a lot
132:44 - more
132:50 - okay so i'm gonna make a whole bunch
132:51 - with
132:53 - uh
132:55 - that are very noisy
132:57 - i'm just gonna take the last 50.
133:04 - i'm just going to take the last 50.
133:12 - um where's the processing sketch that's
133:13 - not right
133:15 - here it is
133:17 - so i just need 500 to 549 right
133:24 - do these look even noisy hold on let's
133:27 - look at some of these
133:33 - oh you know what in the sampling down of
133:35 - it
133:36 - the noise is really gone
133:38 - so let's do um
133:42 - this
133:48 - this will be better i think
133:52 - this is so
133:54 - silly what i'm doing
133:56 - but it's fine
134:00 - uh this might be too noisy but let's uh
134:03 - let's give it a whirl
134:05 - okay so i'm gonna take these just these
134:07 - last 49 images
134:13 - and i'll put them in here
134:16 - apply to all
134:17 - replace
134:19 - so just so we're clear the first 499
134:23 - images
134:28 - right if we're looking at these
134:31 - right
134:32 - these are just plain squares but then my
134:34 - test images look like this
134:36 - can i denoise these images with my auto
134:40 - encoder we're about to find out
134:46 - so i'm now training the model off the
134:47 - first 499 images
134:53 - letting it kind of loss get down as low
134:55 - as i can get it
134:56 - and then
134:58 - we're going to look at what came out
135:04 - um
135:09 - so the output is
135:12 - the output has the noise in it is it we
135:14 - should we need to compare it one to one
135:18 - so that's
135:31 - it's a little less noisy wouldn't you
135:33 - say
135:35 - right these are the two
135:46 - it's slightly denoised
135:50 - [Laughter]
135:52 - interesting
135:54 - um
135:58 - so
136:00 - this is not the application that i'm
136:03 - looking to do
136:04 - what i would like to do and i think i'll
136:06 - have to wait for part three is i want to
136:09 - first of all bump up the resolution a
136:10 - little bit perhaps
136:12 - um
136:14 - then it looks like it smoothed the noise
136:16 - yeah um
136:20 - no i didn't train with the mini
136:22 - mini jimmy says the output has the noise
136:24 - because the noisy pictures were trained
136:26 - at the end i shouldn't have got those
136:28 - shouldn't have been part of the training
136:29 - the way i've written the code is
136:32 - i'm only training it with the first 500
136:34 - images
136:35 - so it shouldn't have any of the and i
136:37 - just put in the last 50. so if i
136:40 - manipulated my files correctly
136:44 - in terms of the input images
136:46 - there should be no noise
136:49 - all the way just all the way until 4.99
136:54 - and then they should be noisy
136:55 - so these are the training images
136:58 - and then these are the test images
137:02 - um something happened with the loss and
137:04 - acceleration yeah so let's
137:09 - let me post this code
137:13 - um
137:17 - um
137:18 - let's see i don't want this
137:20 - jpeg
137:25 - i'm gonna do a couple things one is
137:28 - no jpegs
137:30 - let me also
137:33 - get the training data generator into
137:41 - um
137:43 - here
137:49 - so this should be
137:53 - so i'm adding
137:55 - now that test file i don't need anymore
137:57 - because i just wasn't sure about i mean
138:00 - but i'll leave that in there so get
138:01 - ignore index package
138:04 - could it be pulling in image 500 that
138:06 - might be an issue i don't think so
138:07 - though
138:10 - oh they should be part of the training
138:12 - versus no noise in the target yeah
138:14 - that's interesting right that makes more
138:16 - sense
138:17 - um so uh yes and so now
138:21 - um
138:24 - code after part two
138:34 - now i'm pushing it i gotta go to the
138:35 - grocery stores it's not it's not five
138:37 - o'clock yet is it it's four o'clock okay
138:38 - i'm way over time here
138:40 - um
138:43 - i'm sorry looking at my oh
138:49 - text messages okay more epochs i don't
138:51 - think
138:52 - it's going to get down below but so so
138:55 - there's so much that could be done to
138:56 - improve this this is just a start
138:59 - here are some suggestions if anybody
139:01 - wants to pick up and continue this i'll
139:03 - try to come back and do this part three
139:05 - number one is
139:07 - you know i kind of haven't been too
139:10 - thoughtful
139:11 - about the layers i'm putting in here
139:14 - in terms of the number of units what
139:15 - activation functions i'm doing
139:18 - and
139:19 - this kind of stuff
139:21 - so i would love for any of you who's
139:23 - interested to sort of play around with
139:24 - this see what kind of results you get
139:26 - ultimately what i would like to do
139:29 - is take this model
139:32 - and be able to start feeding in data
139:35 - just from here
139:37 - um so i want to take random data
139:42 - and um
139:45 - i i basically want to start looking at
139:47 - this as a way to
139:49 - browse the
139:51 - latent space to as and the other thing
139:53 - is like this is just a plain vanilla
139:55 - auto encoder
139:56 - um
139:57 - and
139:58 - there is something called a variational
140:00 - auto encoder so what would i need to do
140:02 - to this to make it from a just this sort
140:04 - of like beginner starting point auto
140:06 - encoder and make a variational
140:08 - autoencoder i would like to know
140:11 - um
140:13 - right and simon is saying you didn't get
140:14 - to generating new images with the
140:16 - decoder only so that's got to be in part
140:19 - three
140:20 - so if you would like to pick this up and
140:23 - run with it on your own you can go to
140:25 - github.com codingtrain you
140:28 - can uh come here and check out the auto
140:32 - encoder demo i would take i probably
140:35 - wouldn't i'm not looking right now for
140:37 - pull requests that improve this
140:40 - um because i want to build keep
140:42 - improving it on my own but i a hundred
140:45 - percent would accept a pull request that
140:47 - adds a readme file that documents all
140:50 - this links to the live streams etc
140:53 - um and i would accept uh issues that
140:56 - propose improvements or document and you
141:00 - know link to your own version of it so
141:02 - i'll try to come back at some point
141:04 - it's probably going to be december this
141:06 - is probably the last live stream for
141:08 - november
141:09 - uh you know as i said if you wanted to
141:11 - watch my newest video
141:14 - all right if you want to watch my newest
141:16 - video all you need to do is go sign up
141:18 - for the curiosity stream and nebula
141:20 - bundle curiositystream.com codingtrain
141:23 - 26 off yeah adversarial autoencoder says
141:26 - andrea that's what i should be doing but
141:28 - i'm doing this very slowly
141:31 - so one step at a time um so uh if but
141:35 - this new video also should be out on
141:37 - youtube itself tomorrow or hopefully at
141:39 - least by monday sometime very very soon
141:42 - huge shout out to tim rodenbroker who
141:45 - donated to the crossing foundation
141:47 - fundraiser
141:48 - which uh inspired this video thank you
141:50 - to the sponsor curiosity stream
141:54 - curiositystream.com
141:55 - codingtrain tons of wonderful
141:57 - documentaries um as well as access full
142:00 - access to uh the nebula streaming
142:01 - service all right so this wraps up my uh
142:05 - demonstration explanation attempts at
142:08 - auto encoder we've got auto encoder part
142:10 - two done
142:12 - i'm gonna put on a sweater i'm gonna
142:14 - turn on the heat i'm gonna plug the
142:16 - internet back into the house
142:18 - i'm gonna go work on uh answering my
142:21 - students emails make some dinner for my
142:24 - children
142:25 - and i really appreciate
142:27 - everybody here
142:29 - uh participating in this
142:31 - cheering me on i'm very excited that
142:33 - this actually works
142:34 - um so more soon all right goodbye
142:37 - everybody see you next time on the
142:38 - coding train
142:40 - uh i can't find my music
142:43 - uh here we go
142:44 - as always i always forget that this
142:46 - stock this stock is
142:57 - [Music]
143:26 - [Music]
143:29 - this
143:30 - [Music]
143:45 - i'm going to do this this dot this dot
143:48 - this dot this dot song never forget this
143:50 - dot
143:51 - somebody composed that song for me
143:58 - [Music]
144:06 - i'm going to say once again
144:07 - here we go
144:13 - coordinate song
144:15 - [Music]
144:18 - it's the forward to cartesian coordinate
144:21 - song
144:23 - [Music]
144:30 - [Music]
144:37 - autotune and the internet will fix that
144:39 - for me
144:48 - [Music]
144:54 - it's
145:05 - cartesian coordinates
145:07 - [Music]
146:38 - unicorns and rainbows and cupcakes what
146:41 - else is there
146:44 - yes kittens thank you very much kittens
146:46 - and rainbows and cupcakes notice that
146:49 - look what i get
146:50 - i'm really losing my mind
146:52 - okay let's do it
146:55 - [Music]
147:08 - [Music]
147:09 - the kids
147:12 - [Music]
147:20 - the kittens
147:23 - kittens the kittens
147:27 - [Music]
147:32 - the kittens
147:35 - [Music]
147:42 - [Music]
147:53 - [Music]
148:01 - [Music]
148:08 - i feel just sort of like a nice
148:11 - feeling of relaxation
148:13 - everything's gonna be okay today
148:15 - dream is not broken it has not frozen
148:17 - this is a this is a wonderful thing
148:20 - okay we're gonna do it i'm really
148:22 - getting to something i need my sound
148:23 - effects
148:26 - [Music]
148:35 - [Music]
148:37 - what else is there
148:39 - [Music]
148:53 - all sorts of text generation analysis
148:56 - things
148:57 - that i will use continuously over and
148:59 - over again
149:01 - first thing i need to do is yes
149:04 - [Music]
149:18 - [Music]
149:20 - kittens the kittens that doesn't
149:59 - you