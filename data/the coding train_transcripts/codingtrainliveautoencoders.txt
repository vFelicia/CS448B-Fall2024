00:00 - [Music]
00:21 - so
00:25 - [Music]
00:32 - do
00:36 - [Music]
00:41 - [Music]
01:44 - do
01:46 - [Music]
01:59 - do
02:01 - [Music]
02:07 - [Applause]
02:09 - [Music]
02:29 - do
02:36 - [Music]
03:52 - do
03:57 - [Music]
04:01 - check one two here is my microphone
04:06 - please
04:09 - [Music]
04:14 - i think i might be quiet you're gonna
04:15 - all tell me i'm quiet
04:22 - [Music]
05:25 - [Music]
05:27 - all right
05:28 - i have pumped up my volume a little bit
05:30 - so i have a feeling now
05:32 - you can hear me and i will be
05:35 - showing you my face
05:36 - in just a moment
05:39 - not exactly prepared for this but what
05:41 - are you gonna do
05:42 - here we are
05:44 - [Music]
06:04 - bye
06:05 - [Music]
06:08 - the train is pulling into the station
06:12 - it is me dan welcome
06:15 - coding train time
06:17 - i see my image over there i see chat
06:20 - messages scrolling by i see
06:22 - way better works for me
06:24 - uh from colby james says much better
06:26 - voice maybe still slightly low i don't
06:29 - know it is what it is there is a dial
06:31 - over here that i can turn to make myself
06:33 - louder
06:34 - but i'm a little bit hesitant to do it
06:36 - just at the moment uh welcome happy
06:38 - monday i don't have a watch on i keep
06:40 - looking at my watch to know what time it
06:41 - is monday
06:43 - 405 p.m eastern this is quite possibly
06:47 - the worst time energy-wise for me
06:51 - to stream um but it is the time that
06:54 - happens to work for me this week today
06:56 - although good news
06:58 - second stream coming this coming friday
07:00 - so this will likely be part one in part
07:03 - two and
07:04 - i just have to say so um
07:07 - long story but there is uh another dog
07:09 - who is staying with us who is not gloria
07:11 - who's behind a door over there and i
07:13 - hear whimpering crying her name is
07:15 - bailey i might have to let her out in a
07:17 - minute um but i'll see about that um
07:20 - maybe especially if i go over to the
07:22 - whiteboard so i've been working on
07:24 - my setup hopefully
07:26 - you can see the fruits of my labor some
07:29 - nice bright lights a really excellent
07:31 - keying of my green screen background
07:34 - i believe i can show you what it
07:36 - actually looks like without the key
07:39 - i had a little button for that but i
07:42 - don't see where it went anymore me green
07:44 - there we go
07:46 - so looking at this you would think like
07:48 - actually that's not so great
07:50 - it's a curtain i kind of kind of got to
07:51 - tighten it and some shadowing but good
07:54 - enough
07:55 - someday i'll have some machine learning
07:56 - model that will in real time just
07:58 - segment me out but until then uh green
08:02 - screen i also have been working on my
08:04 - whiteboard shot
08:06 - so let me attempt to switch over to
08:08 - there
08:09 - i think it looks much better
08:11 - i got a new tripod so the actual uh
08:15 - camera is a little bit higher um my my
08:18 - pants actually showing in the shot
08:19 - almost
08:21 - um and i've been working on focus
08:23 - focusing the lens
08:27 - so i definitely plan to draw some
08:29 - diagrams today let me know how this
08:31 - looks
08:32 - um
08:32 - could still work on the lighting it's
08:34 - probably very echoey over here because i
08:36 - have no sound blankets here
08:39 - and i still need to put up some sound
08:40 - foam on the ceiling but i'm
08:42 - there's a lot of work going on right now
08:44 - uh to get this studio going where i will
08:46 - be spending a lot of time uh starting
08:49 - this coming january um currently oh i
08:52 - didn't mean to show you that just yet
08:53 - but that's fine um i am hoping that by
08:56 - this spring the coding train will be
08:58 - entirely solar powered so wait and see
09:02 - we'll see if i can get there currently i
09:04 - am running off of the
09:06 - grid
09:06 - whatever power is coming to me from uh
09:09 - central hudson because i'm upstate in
09:10 - new york and hudson valley but i uh am
09:13 - working well i'm not doing this because
09:15 - i'm completely incapable i would love to
09:18 - do more but working on replacing the
09:20 - roof
09:21 - which is over my head in order to have
09:22 - something a little bit more a little
09:24 - more heft
09:25 - so that solar panels can then be
09:27 - installed and then i can power
09:29 - everything coding train wise this whole
09:32 - live stream
09:33 - uh and i suppose the internet connection
09:35 - that i'll be getting is
09:36 - sort of powered from some other location
09:39 - coming in through here but i'm getting
09:42 - way off too off topic i've got to get
09:43 - started on what i have for you today
09:45 - so
09:46 - um
09:48 - colby says i like this whiteboard setup
09:50 - personally works better than you might
09:52 - think says zero control
09:54 - and martin says i just decided to give
09:56 - up my tensorflow exam revision and watch
10:00 - this live stream terrible terrible
10:02 - decision
10:04 - no
10:06 - if you have real work to do
10:08 - with real
10:11 - uh studying of actual educational
10:14 - content i highly suggest you switch over
10:17 - to that i don't want anyone's test or
10:20 - grade or homework to be displaced by my
10:23 - shenanigans i'm hoping that whatever i
10:25 - do today will eventually turn into
10:29 - an edited tutorial video
10:31 - or a um
10:33 - something more than whatever it is i do
10:35 - today so let me get a couple of things i
10:37 - just got to jump right into the code
10:38 - stuff um
10:40 - unless um
10:41 - i don't i won't be doing community
10:43 - contributions or some of my other more
10:46 - wackier segments today
10:49 - francello asks is this a permanent
10:51 - studio well
10:53 - i have changed my studio
10:56 - so many times in the last bunch of years
10:58 - i'm trying to figure out there must be
10:59 - some like coding train anniversary
11:01 - coming up soon because i'm doing this
11:02 - for a while
11:04 - um
11:05 - but um this is what i hope will be a
11:07 - quite permanent studio and certainly
11:10 - uh
11:11 - you know i'm going to be my plan is to
11:13 - be incredibly active in working in here
11:15 - somewhat full-time-ish starting in
11:17 - january i have a little sabbatical from
11:19 - my job at nyu so get get used to it
11:22 - people you hope we're going to see more
11:24 - of me
11:25 - coming in january
11:27 - now um
11:28 - [Music]
11:29 - ah yes uh before i um
11:32 - get get going let me just thank today's
11:34 - sponsor of the coding train and are my
11:36 - friends over at brilliant do you like
11:39 - learning i like learning do you like
11:41 - watching me on youtube guess what if the
11:43 - answer is no
11:45 - if it's yes or no i have something for
11:46 - you uh brilliant um and the reason why
11:50 - is maybe the way you like to learn is
11:52 - through
11:53 - interactive lessons
11:56 - and interactivity and trying things out
11:58 - on your own so it's one thing to listen
12:00 - to me blah blah blah blah blah blah auto
12:02 - encoder neural network
12:05 - it's another thing to actually get in
12:06 - there and try it yourself i'm sure you
12:08 - know this from
12:09 - how it is to learn to code but brilliant
12:12 - is a website there is an app a wide
12:15 - range of courses all through the
12:16 - sciences uh computer science and physics
12:19 - and they have this brand new updated
12:21 - version of their logic course so i'm
12:23 - gonna come back in the middle
12:25 - of
12:26 - uh today's live stream and start the new
12:29 - logic course and see how it is you can
12:31 - sign up for free at brilliant.org
12:32 - codingtrain that lets them know you
12:34 - found it for me and they and that's a
12:36 - good thing all around win-win for
12:38 - everybody uh is free but you can also
12:40 - unlock to unlock all of the premium
12:42 - content all the courses if you use that
12:44 - link that's right above me right here
12:46 - you will uh the first 200 people to do
12:47 - so will get a 20
12:49 - off of the annual subscription finally
12:51 - to monitor system is giving its best
12:53 - conceived video and chat file at the
12:55 - same time ah
12:57 - lee shala says what is sabbatical yes i
12:59 - have uh worked
13:01 - my hardest over many years teaching my
13:03 - classes seven uh years to be exact
13:06 - and as part of my teaching contract i
13:08 - get a semester uh without teaching any
13:10 - classes
13:11 - and to work on some research projects
13:13 - although i will say
13:14 - guess what my primary goal if i'm being
13:16 - perfectly frank
13:19 - is not the coding train now you might be
13:21 - like what
13:22 - you have a sabbatical and your goal is
13:24 - either first of all it's my own like
13:26 - mental health insanity it's probably my
13:28 - primary goal as it should be for you
13:30 - but um i have got to um
13:34 - get this nature of code book off by the
13:36 - way i'm just looking at my tripod and
13:39 - even though the camera is level
13:41 - the tripod is like so askew and then the
13:44 - top is like it's like is that not going
13:46 - to fall over like who puts this studio
13:48 - together this is insane okay i have to
13:50 - deal with that later that's really
13:52 - really looks like it's gonna fall over
13:54 - you can't see it
13:56 - everything seems fine to you i think
13:57 - it's gonna be fine nature of code book
14:00 - i have got to get that second edition of
14:02 - the nature code book out published new
14:04 - website new print edition new examples
14:07 - more machine learning i don't know maybe
14:08 - there'll be an auto encoder in there
14:10 - probably not not really part of that
14:11 - book but that's my number one goal is to
14:14 - i've said i'm going to do that
14:16 - the nature of code book actually came
14:18 - out
14:20 - i think 10 years 2012. so it'll be 10
14:23 - years do you know when i started talking
14:24 - about doing a second edition of that
14:26 - book
14:28 - i don't even want to know 2015 at least
14:32 - so
14:33 - um so here we go
14:35 - all right so um i i don't i've lost my
14:39 - rhythm in terms of what it is i actually
14:40 - do on these live streams
14:42 - i'm trying to return to my roots which
14:44 - is essentially if i have something that
14:46 - i'm trying to learn or teach and i have
14:48 - not had a chance to explore that
14:51 - uh doing it while live streaming is the
14:53 - perfect
14:56 - thing for me to do so that's what i am
14:57 - going to do today and the topic that i
14:59 - am going to explore
15:02 - is an autoencoder now look at this
15:05 - building auto encoders in catas keras
15:08 - saturday
15:09 - may 14th 2016 what was i doing
15:13 - in may 2016
15:16 - huh
15:17 - trying to think
15:19 - i don't remember let's see may
15:21 - 2016 a coding train can we find any
15:25 - videos that i was producing then
15:27 - may 30th
15:29 - object oriented fractal trees oh guess
15:31 - what i was probably doing then working
15:33 - on updating picture code booking p5.js
15:37 - oh that's so sad uh yeah look at this
15:40 - reaction diffusion ah those are the days
15:42 - when i used to do all these coding
15:43 - challenges
15:44 - it was another time back then uh anyway
15:47 - um
15:48 - i think i i don't know if i encount
15:50 - actually probably did not encounter this
15:52 - article around then i probably
15:54 - encountered it a couple years later a
15:56 - year later um
15:58 - this building auto encoders in keras is
16:01 - a guide that i'm going to use and you
16:03 - might today and you might be wondering
16:04 - like wait what
16:06 - what like what year is it on a meme
16:10 - insert here
16:13 - because if you have been following the
16:15 - landscape of deep learning algorithms to
16:18 - synthesize media generate images i mean
16:20 - you know that where we are today is
16:23 - something more like stylegand3
16:25 - which is uh you know
16:28 - the latest and greatest uh generative
16:30 - adversarial network to
16:32 - um
16:35 - that can be trained on a data set of
16:36 - images and create new images in that uh
16:39 - style and uh we can all be sort of
16:42 - freaked out by the sort of
16:43 - hyper-realized realism of these faces
16:45 - that do not exist
16:47 - and um
16:49 - so yes that is true um i don't think but
16:52 - my knowledge
16:53 - i after i have this journey through
16:56 - learning machine learning
16:58 - my knowledge is kind of still like i'm
17:00 - still like just taking little steps
17:02 - forward from those old days where i was
17:04 - like let me try to at least just program
17:06 - in processing or in p5 and javascript
17:08 - and neural network and i think for me
17:12 - when i am working with one of these
17:15 - newer generative models let's say style
17:17 - i've never actually worked with style
17:18 - game 3 but let's say style gan 2
17:21 - and i'm trying to understand wait what
17:23 - is this thing called the latent space
17:25 - why does that exist how does it work how
17:28 - is it that i pick these random numbers
17:29 - and pass them through here i get this
17:31 - image and then as i there's a fly by the
17:33 - way on my uh confidence monitor there go
17:36 - away fly
17:37 - as i change those numbers and then feed
17:39 - them in again how does all this stuff
17:40 - work so to me if you are interested in
17:43 - working with synthetic media working
17:46 - with
17:47 - gans to create images
17:50 - whether for art or science or whatever
17:53 - kind of creative expressive potential
17:55 - that those tools and models might afford
17:57 - you
17:59 - if you want to understand the sort of
18:00 - like core basic
18:02 - elements of how those things work
18:05 - just an auto encoder is an amazing place
18:08 - to start that's my point of view
18:10 - so this article i remember seeing it
18:12 - being like oh i think i understand what
18:13 - an autoencoder is kind of and look at
18:15 - this code i remember looking at it being
18:17 - like i don't know what um what any of
18:20 - this is
18:22 - keras what's keras
18:24 - uh
18:25 - so i don't know to what extent keras is
18:27 - still
18:28 - used as a term in uh the python
18:32 - implementation of tensorflow or the
18:34 - python bindings to tensorflow keras is a
18:37 - sort of high was or is a high level api
18:41 - for working with neural networks created
18:43 - by francois chole
18:45 - who is an amazing ai researcher and
18:48 - pioneer in a lot of the
18:50 - this stuff um
18:52 - it's made its way i work into
18:54 - tensorflow.js in tensorflow.js it's
18:56 - called the layers api i don't believe
18:58 - the keras word is there at all and
19:00 - someone again in the chat can tell me
19:02 - why it was called keras i think there's
19:05 - um
19:06 - i forgot why the name
19:08 - um and and martin is saying i follow
19:09 - that guide to create my first auto
19:11 - encoder as well the undershirt chroma
19:13 - key passed through
19:15 - is this undershirt being chroma keyed
19:18 - let me just see
19:20 - oh it certainly is that it's very
19:21 - distracting that would drive me totally
19:22 - crazy how about i do this whole stream
19:26 - okay hold on
19:30 - that'll help
19:31 - i was gonna like button the top button
19:33 - but
19:34 - let me just clip the lav mic to here i'm
19:37 - probably like way louder now too because
19:38 - the lav mic is much closer to my mouth
19:41 - okay i had to fix that jim
19:43 - that would have that totally would drive
19:45 - me crazy hopefully it might still be
19:46 - there a little bit
19:47 - um
19:49 - so um
19:52 - i'm just looking at this so i i lost my
19:54 - train
19:57 - of thought um but
19:59 - here we are auto encoders so
20:02 - a couple things one is
20:04 - i would like to before i begin attempt
20:08 - to record this session to disk i still
20:12 - am ironing this out
20:14 - but with i bought a new streaming
20:16 - computer got this big gpu in it huge
20:19 - hard drive lots of ram
20:21 - in theory i should both be able to be
20:23 - live streaming to you right now as well
20:25 - as recording
20:27 - i screen capture both cameras all as
20:30 - separate video files to disk so that if
20:32 - i wanted to this session could be
20:34 - chopped up and edited later i probably
20:36 - won't do that with this session but i at
20:38 - least want to see what the footage looks
20:40 - like after the fact so let me hit that
20:42 - button start recording
20:44 - um
20:45 - friendly viewers
20:48 - pedro asked is this going to be a python
20:50 - stream no so i'm going to do this
20:52 - um
20:54 - sorry i'm just looking at the uh member
20:56 - chat and discord
20:58 - i would like to do this
21:00 - i'm going to do this with tensorflow.js
21:02 - my goal is to eventually see if an
21:04 - autoencoder can be demonstrated with ml5
21:07 - and the ml5 neural network which is a
21:09 - sort of high level layer on top of the
21:12 - layers
21:13 - api of tensorflow.js which all dates
21:15 - which is all you know keras is kind of
21:17 - like
21:18 - the big source of inspiration for um but
21:21 - we shall see all right so
21:23 - um
21:25 - ah so um uh christian vekman how did i
21:29 - do like i would say b-minus
21:31 - writes keras means horn in greek it is a
21:34 - reference to a literary image from
21:36 - ancient greek and latin literature first
21:38 - found the odyssey ah so i now i'm
21:40 - embarrassed more that i didn't know that
21:42 - because while i am not greek um
21:45 - there's a lot of greek in my family my
21:47 - wife is greek my children have greek
21:49 - names
21:50 - uh we like greek food haven't been to
21:52 - greece
21:54 - i think i was in greece in 2015.
21:57 - it was a good time
21:59 - that's what i'll do january see you all
22:01 - later i'm going to greece
22:03 - okay let me let's go over to the
22:04 - whiteboard and talk about um kind of
22:07 - conceptually what's going on here now
22:09 - one thing i should say
22:11 - is that and i'm just looking to make
22:13 - sure my audio is going
22:15 - um
22:17 - one thing i should say is that even
22:19 - though i've got this new setup which i
22:22 - hope the whiteboard looks a little bit
22:24 - better focus wise and lighting wise um
22:28 - still very shaky i don't know what i'm
22:30 - going to do about that buy a new
22:31 - whiteboard
22:33 - tighten this one up uh i don't as i'm
22:35 - standing here have any access to really
22:38 - being able to see the chat i can kind of
22:41 - see out of the corner of my eye the
22:42 - youtube chat going by so i suppose if
22:44 - something goes really wrong and now
22:47 - everyone's just gonna troll me if i say
22:48 - this but just flood the youtube chat
22:50 - with sirens emojis i might be able to
22:53 - see that
22:54 - um but at some point i am planning to
22:56 - set up a secondary monitor maybe over
22:59 - here or over here where while i'm at the
23:02 - whiteboard i can also see the chat and
23:04 - see what's going on but all right so
23:06 - let's start with just
23:08 - the sort of core let's
23:10 - start back to what is
23:12 - a neural network
23:15 - that's not a good place to start
23:18 - let's start back with
23:20 - what is a computer how about um
23:23 - i don't know where to start i want to
23:25 - just draw a kind of classic diagram of a
23:27 - neural network and let's think about a
23:29 - sort of classic
23:31 - image classification diagram so what if
23:33 - what i wanted to do was demonstrate that
23:36 - i'm saying classic way is it wait this
23:37 - is too classic for you
23:40 - uh there is the mnist data set
23:44 - right which is a data set of
23:47 - handwritten digits
23:49 - all 28 by 28 pixels
23:52 - meaning uh
23:54 - 784 pixels each
23:57 - so uh if you watched three blue one
23:59 - browns
24:00 - but what is a neural network or
24:03 - looked at this keras
24:05 - tutorial or anything else on the
24:07 - internet that's kind of like a basic
24:08 - like let's learn about machine learning
24:10 - and i i kind of have this like
24:12 - goal in my life which i am now
24:14 - completely failing at which is to never
24:16 - use amnesty and just try to always have
24:19 - other creative examples but
24:21 - uh
24:22 - such as life this is where i am right
24:24 - now
24:25 - if i wanted to build a neural network
24:28 - that could classify these images i would
24:31 - probably do something as follows
24:34 - i would have a set of inputs
24:37 - and i'll represent all of those as
24:40 - circles
24:42 - there would be 784 of them
24:46 - each one
24:49 - being fed essentially and a big fed is
24:52 - like a good way to put it by a given
24:54 - pixel
24:56 - okay
24:57 - so this pixel
24:59 - goes into the this input of the neural
25:01 - network here
25:02 - this pixel goes into it here etc etc etc
25:06 - so this is actually not a layer of the
25:08 - network these are just the inputs the
25:10 - first layer of the network might be
25:12 - called a hidden layer
25:16 - and of course there are i'm i'm kind of
25:19 - i'm talking about the most basic vanilla
25:22 - neural network uh right now so while of
25:25 - course if this is image data and i'm
25:27 - really doing image classification i
25:28 - might want to use convolutional layers
25:30 - which apply like filters and all sorts
25:32 - of other stuff and i have videos on that
25:34 - but right now i'm just sticking with the
25:37 - most basic idea of a neural network and
25:39 - in fact i'm going to make it so basic
25:41 - it's just going to have one hidden layer
25:43 - and this hidden layer would also have
25:45 - some number of
25:47 - neurons in it nodes units lots of
25:51 - different words are good for let's be
25:52 - really really uh unrealistic for a
25:55 - moment and just pretend it has just four
26:01 - now if what i was ultimately doing was
26:04 - the goal of this neural network was to
26:07 - take this input image feed it through
26:10 - the neural network and out the other
26:12 - side
26:13 - have a classification of the image is it
26:16 - a zero one two three four five six seven
26:18 - eight or nine right there's ten
26:19 - possibilities then the output
26:22 - layer would have 10 outputs
26:31 - i think that's 10.
26:34 - and
26:35 - as i like to do obsessively and any of
26:37 - my students who take my actual classes
26:39 - know if i draw if i draw one of these on
26:41 - the board i can't not fill it out by
26:44 - connecting everything this these are
26:47 - fully connected dense layers
26:50 - you hear that term and machine learning
26:51 - a lot what does it mean that they're
26:53 - dense or fully connected it means every
26:56 - unit of one layer connects to every unit
27:00 - of the next so this hidden layer
27:02 - connects to every single output and i uh
27:05 - you know this is just like you know okay
27:08 - is there like a fast forward jump
27:09 - through time thing i could do
27:11 - uh i just i mean it's like it's a
27:13 - meditation
27:15 - drawing all the connections
27:17 - the silly thing is i'm probably just in
27:19 - about like
27:20 - 30 seconds going to erase this so i'm
27:23 - not sure what the point of me going
27:24 - through this is but once i start i can't
27:27 - stop it's a problem
27:29 - at least i only picked four i should
27:31 - have tried maybe just picked three if i
27:32 - just picked three i would be done by now
27:36 - just wait till i have to do these okay
27:38 - i'm gonna stop maybe this is the first
27:39 - time in my life
27:41 - that i'm gonna manage to stop doing this
27:43 - i don't think so or the sirens going off
27:45 - in the chat
27:48 - okay i i i think i might have missed one
27:52 - okay
27:55 - don't you all feel better that i took
27:56 - the time to do that
27:59 - uh i'm gonna do just one input okay one
28:02 - like let's say this input is also going
28:04 - just also because i think it'll be
28:05 - easier to explain
28:07 - so now we have to imagine that every
28:09 - single one of these also feeds into each
28:12 - one of these hidden nodes
28:13 - so remember there are 784 of these
28:19 - there are 10 of these
28:22 - and
28:23 - so this is what i would say what is
28:24 - known as the architecture by the way i
28:26 - did not necessarily think that i was
28:28 - just going to start by explaining but i
28:30 - have to like warm up and get into this i
28:31 - don't have a watch on me i don't know
28:32 - what time it is i can't see the chat
28:35 - i'm gonna keep going
28:37 - this is what i would say is known as the
28:39 - architecture of the of the of the model
28:42 - of the neural network
28:43 - there are two layers a hidden layer and
28:45 - an output layer there are 784 inputs and
28:49 - then we have a process
28:50 - and the same process will be used in an
28:53 - auto encoder
28:55 - called supervised learning so the idea
28:58 - of supervised learning is
29:01 - let's say i have um
29:04 - oh i see sirens i think it's trolling or
29:07 - just for fun
29:09 - but i'm gonna come over here uh
29:13 - with hidden node three
29:17 - all right i'm just uh whoops uh this i
29:20 - um i think i think i'm okay i don't
29:21 - think there was a real siren i missed a
29:24 - connection says joseph i think that's
29:25 - what the sirens that's fair
29:27 - that's fair
29:28 - i miss the connection
29:30 - um
29:31 - all right so presumably there would be a
29:34 - a database of training images and each
29:37 - one of those images in the database of
29:39 - training images
29:41 - oh you know what an auto encoder you
29:43 - might consider like unsupervised
29:45 - learning in a way right
29:47 - interesting we'll come back to that
29:50 - because the labels don't matter with
29:51 - what i want to do
29:55 - so you might have like
29:57 - a bunch of
29:59 - images of digits
30:01 - right each with their label the
30:03 - supervised learning process involves
30:06 - feed one of these in what does the
30:08 - neural network guess
30:10 - like if you feed in the zero digit and
30:12 - it guesses it's a four
30:14 - nope that's not right
30:16 - go back and uh adjust the neural network
30:19 - according to the error
30:22 - and rinse and repeat so what do i mean
30:24 - by adjust according to the error i mean
30:25 - i'm hand waving a ton of stuff here i
30:27 - think i have probably a 10 part series
30:30 - that kind of goes through all of this
30:31 - much more methodically step by step and
30:33 - writing the code for it
30:35 - but the the thing that's important here
30:37 - is that each one of these connections
30:39 - is what's known as a weighted connection
30:42 - so there's a weight and i think an
30:44 - analogy that i've heard is that you can
30:46 - think of each connection like a dial on
30:50 - you and that weight can be tuned up or
30:52 - down you know what is the relative
30:55 - importance of this particular
30:57 - input
30:58 - um
31:00 - as related to some particular output
31:02 - and so as you feed this the training
31:06 - data through
31:07 - if i fed in this digit of a one
31:11 - and the neural network output said one
31:13 - there's no need to change any of the
31:15 - weights because it got it correct but
31:17 - then if i fed this next one in of a one
31:19 - and it gets to nine i've got to adjust
31:21 - the weights and the process of doing
31:23 - that with large data sets over long
31:25 - periods of time yields a sort of
31:28 - optimized set of weights that would in
31:31 - an ideal world will perform well with
31:34 - new data data that's not part of the
31:36 - training set there's so much more to say
31:38 - about this but i just wanted to sort of
31:40 - talk through the very basic
31:43 - uh
31:43 - um kind of process of what it means to
31:46 - train a neural network for image
31:48 - classification
31:51 - let me take a pause a short pause here
31:54 - and look over and see if there are any
31:55 - questions in the
31:58 - chat and i also want to um
32:02 - i also want to check what time it is
32:05 - because uh yeah um
32:08 - and
32:10 - um
32:11 - sorry okay i see that there's a
32:12 - discussion about shaders
32:14 - that was last stream i by the way i'm so
32:17 - obsessed with shaders and i'm i do have
32:20 - a fantasy of doing a whole like
32:22 - shaders tutorial kind of like learn
32:25 - shaders with me might be the title of it
32:27 - or something
32:28 - but um
32:30 - this has been this is part of the course
32:31 - that i'm teaching right now and i've
32:33 - been talking about auto encoders and
32:34 - generative models all semester and i
32:36 - really want to have a running example
32:38 - that i can kind of demonstrate so um all
32:40 - right supervised means we have correct
32:43 - output layers france francello
32:46 - yes
32:47 - supervised learning means
32:49 - that you have a training data set a
32:52 - training a labeled training data set so
32:54 - you are supervising the learning process
32:56 - with the input data and the correct
32:58 - answers
33:00 - can you complete your diagram second
33:03 - question good resources for fast
33:05 - iteration of neural networks and machine
33:07 - learning i don't know that actually
33:09 - sorry i'm reading the questions in real
33:10 - time i don't actually unders i don't
33:12 - know if i understand that question um
33:15 - but um hopefully the chat people can
33:16 - provide some good resources you know if
33:18 - you're interested you know not to plug
33:20 - things but i guess that's what i'm
33:22 - that's what i do that's what i mean
33:24 - you're doing ultimately it's all just a
33:26 - giant plug for me right no that's weird
33:29 - um
33:30 - join the coding train discord uh let's
33:32 - see if this will um that button didn't
33:34 - work but somebody will post it the
33:35 - codingtrain.com discord um you can it's
33:38 - a good place to have this kind of
33:39 - discussion uh lauren laurent strodio
33:42 - writes do you check all pixels from the
33:45 - initial pictures
33:48 - so um let me go back to the whiteboard
33:50 - here uh i believe the answer to that
33:53 - question is yes
33:55 - so i mean it depends
33:57 - right
33:59 - this is a
34:01 - totally made-up scenario now
34:04 - it's been
34:05 - you know some very
34:06 - smart thoughtful people designed this
34:08 - kind of scenario thought through it and
34:11 - i am here just sort of telling you how
34:12 - it works and maybe implementing it even
34:14 - with like a hot from a higher level with
34:16 - a library that has all the lower level
34:17 - details but there's no reason why we
34:19 - couldn't say like hey i got an idea
34:21 - let's see if it works with we just do
34:23 - every other pixel
34:25 - um but um so um so yes but um you know
34:29 - the max if we want the maximum amount of
34:31 - information from the input image we'd be
34:33 - looking at all the pixels there is
34:35 - something known as dropout
34:38 - which is a
34:40 - term in machine learning i believe that
34:43 - refers to the process during the
34:45 - training process of disconnecting
34:47 - certain connections right i talked about
34:48 - this being a fully connected dense layer
34:50 - we want everything to be connected
34:53 - but um
34:54 - uh you know you don't well there's a
34:57 - there's an issue that can happen which
34:59 - is known as overfitting so if the neural
35:01 - network is so good at producing the
35:03 - correct results for some training data
35:06 - set of images
35:07 - it might
35:09 - it might have learned it so well that it
35:10 - kind of can't perform when it's faced
35:12 - with new data
35:14 - and so allowing a little bit of noise a
35:17 - little bit of kind of like mistakes in
35:19 - there uh will uh could result in the
35:22 - neural network in the trained model
35:24 - having some more sort of flexibility a
35:26 - little bit of chaos if you will to be
35:28 - able to accommodate uh newer data and
35:31 - not be so rigid about its uh evaluations
35:34 - i don't know if that's a sort of helpful
35:36 - way to explain the concept of dropout or
35:42 - or overfitting but um you know i'm sure
35:45 - some people in the chat will write some
35:46 - comments with better explanations okay
35:48 - so i think i'm ready to move on to an
35:51 - auto encoder right now i'm just coming
35:52 - back uh to check the chat one more time
35:55 - um
35:56 - right uh okay wikman writes it's a
35:59 - random turning off of neurons during
36:01 - training thanks okay
36:03 - um
36:04 - all right so now the whole point of this
36:06 - is i'm not here to do this
36:09 - i have examples that do this uh and ml5
36:13 - uh which is a javascript library that is
36:15 - a layer on top of tensorflow.js
36:18 - has ways to create image classifiers and
36:21 - other kinds of classifiers and
36:22 - regression models and all sorts of
36:23 - things it's ml5.neural network i'll
36:26 - refer you to
36:27 - insert here in post production all of
36:29 - the videos i've made about training your
36:32 - own neural network with ml5.js
36:35 - and if you want to just go and watch
36:36 - those now and leave the live stream be
36:38 - my guest um
36:40 - what i want to do is
36:42 - is is kind of talk about an idea
36:46 - what if
36:47 - okay
36:48 - what if instead of image classification
36:51 - let's take out this idea of image
36:53 - classification entirely
36:56 - um erasing
36:57 - sort of things have nothing to do with
36:58 - image classification but i'm erasing
37:00 - just to make this point and um
37:05 - and what i want to do is create i'm
37:08 - going to say a copying machine
37:11 - let's say that and by the way um i
37:13 - didn't watch it today but last week i
37:16 - watched the video from
37:19 - two minute papers
37:23 - which is called like what is an auto
37:25 - encoder
37:30 - so
37:32 - i would really recommend you just get
37:33 - turn off this live stream
37:35 - or come back to it later and watch this
37:37 - video or watch this video later if
37:38 - you're kind of invested in in my process
37:40 - here but um so apologies if i'm
37:42 - regurgitating any of the language or
37:45 - concepts from that video it just really
37:46 - stuck with me um but and i and i recall
37:49 - the video talking about a copying
37:51 - machine so what if my goal was to create
37:54 - a copying machine meaning
37:56 - these pixels these 784 pixels that are
37:59 - fed in to the inputs
38:02 - the outputs
38:05 - also have
38:06 - 784
38:07 - units
38:09 - and i want
38:11 - to see with the neural network i want to
38:13 - see all the pixel values come in
38:16 - and the same exact pixel values come out
38:20 - you would be rightfully asking the
38:21 - question to yourself
38:23 - well that's
38:24 - ridiculous like why would i want to do
38:25 - that first of all i could write a for
38:27 - loop
38:28 - for i equals zero i is less than 784 and
38:31 - i could make an inputs array and an
38:33 - outputs array and just say outputs index
38:34 - i equals index input i right so the
38:37 - reason why
38:38 - i'm doing this is not to actually create
38:41 - a copying machine in the most exact and
38:44 - efficient way because with a low
38:46 - resolution image an algorithm to copy
38:48 - one image to another
38:50 - done finished two seconds turn the
38:52 - stream off
38:53 - go have dinner whatever go to bed i have
38:56 - so much stuff to do
38:58 - but um
38:59 - um so the reason
39:01 - but what it so so so why why why are we
39:04 - talking about this copying machine well
39:06 - with this process
39:08 - and i know i obsessively drew all of
39:11 - those
39:12 - but i need to erase them now
39:14 - for me to continue i'm looking for i
39:16 - don't have an eraser so i'm using this
39:18 - paper towel
39:21 - i'm so sad
39:25 - and um
39:26 - i'm gonna sort of mirror a diagram from
39:29 - i don't know if it's from that video or
39:30 - a different paper so what if this hidden
39:32 - layer
39:33 - right
39:35 - you think of this hidden layer
39:38 - you know i said it has
39:40 - four units to it what if there were some
39:43 - other hidden layers
39:44 - like here's another one
39:46 - and maybe this one has eight
39:51 - one two three four five six seven eight
39:53 - and there's another hidden layer
39:56 - right and maybe this one has
39:59 - eight
40:01 - right
40:02 - and these are fully connected layers oh
40:05 - it's not so bad it's only eight
40:07 - right i can do this
40:14 - if i start one i can't stop it's really
40:16 - weird like what is something is
40:18 - something strange things happen in my
40:20 - brain so you can get the idea that this
40:22 - is also
40:23 - these are also going and that these are
40:24 - coming in so the idea here like looking
40:26 - at the scenario is it possible to take
40:30 - this input image
40:32 - send the data through a neural network
40:35 - reducing the amount of information and
40:38 - then expanding the amount of information
40:40 - back out
40:42 - right
40:42 - this is a not only a copying machine but
40:46 - it is essentially something like a
40:48 - compression
40:51 - um
40:52 - engine or a compression
40:54 - right could we encode by the way and
40:57 - this is called
41:00 - this half is essentially called the
41:02 - encoder
41:04 - and this latter half
41:08 - is called the decoder
41:11 - could we somehow encode
41:13 - all of the pixels of an image
41:16 - into less data
41:18 - and then decode that smaller amount of
41:21 - data back into the full image now again
41:24 - uh the two minute papers video talks
41:26 - about this
41:27 - um this is not a uh particularly
41:32 - great great way to actually do image
41:34 - compression right if we want a smaller
41:37 - file size
41:39 - to uh for a lot of pixels there are lots
41:41 - of known ways to do image compression
41:43 - jpeg
41:45 - the algorithms behind jpeg compression
41:47 - being
41:48 - probably uh the most well known
41:51 - but the the point of doing this is not
41:55 - to have an efficient image compression
41:58 - algorithm rather
42:01 - if the neural network
42:03 - can learn how to encode essentially the
42:06 - features of an image
42:09 - encode the idea of an image
42:12 - it can then generate new images right
42:16 - what would happen the idea of an auto
42:18 - encoder is if we can create the encoder
42:20 - and the decoder
42:22 - in terms of like sort of this sort of
42:24 - creative arts world and lots of other
42:25 - things too but the idea is generative
42:27 - images what if i want to dream up
42:30 - new
42:31 - digits new cats new whatever i think i'm
42:34 - going to create a data set in processing
42:36 - and just like draw a bunch of shapes so
42:39 - if i want the neural network to be able
42:41 - to dream up new shapes could i train an
42:44 - auto encoder with a data set of images
42:47 - then essentially
42:49 - slice off the encoder i have this
42:51 - trained model and start just from here
42:55 - feeding in noise random numbers
42:58 - vectors
43:00 - latent vectors
43:02 - so i want to get into this idea of the
43:04 - latent space
43:06 - latent vectors um
43:08 - but uh i think i'm kind of like i'm
43:10 - trying to explain this i've sort of
43:11 - reached the point where i think i need
43:13 - to start writing some of the code we
43:14 - could double back to this diagram and
43:16 - kind of get into the reality of how it
43:18 - works but this is the idea and i feel
43:21 - very disconnected from you because i'm
43:22 - not looking at the chat and
43:24 - all of that but this is really exciting
43:27 - this is the foundation i mean again
43:29 - works in a very different way there are
43:31 - two neural networks but ultimately the
43:33 - idea of a latent space
43:36 - generating images and the ability to
43:39 - navigate
43:40 - and experiment with that latent space to
43:42 - generate animations uh um um
43:47 - of those generated images there's so
43:48 - much there to explore and auto encoder
43:51 - understanding it building your own auto
43:52 - encoder i think is a great place to
43:54 - start to see how all of the pieces work
43:56 - um as you then
43:59 - as you then later find yourself just
44:00 - running collab notebooks big models and
44:02 - different things um learning the getting
44:05 - used to this process understanding the
44:06 - vocabulary of it will give you a leg up
44:10 - in kind of working with more cutting
44:11 - edge
44:12 - research into generative models let me
44:15 - see what questions they have or if there
44:16 - are other things i mean the other thing
44:17 - i was going to say i think this also has
44:19 - some pretty interesting applications
44:21 - because if um so denoising i think it's
44:24 - mentioned on the the keras page that i
44:27 - want to look at so imagine if we train
44:30 - this auto encoder to copy images
44:33 - essentially so it knows how to look at
44:36 - an image of a one and kind of recreate
44:39 - that same image as best as it can
44:41 - if if to learn to do that very well and
44:44 - i pass in a very noisy image it's like
44:47 - fuzzy it's got some method like just
44:49 - grainy extra random noise in it
44:51 - the
44:52 - autoencoder is trained to generate
44:55 - non-noisy digits
44:57 - so it it can actually work as a denoiser
45:00 - because it will take that input
45:02 - information and try to create its best
45:04 - approximation of it but it's learned how
45:07 - to do best approximations of non-noisy
45:09 - images so its best approximation of a
45:11 - noisy image is hopefully going to be
45:13 - that
45:14 - that the content of that image without
45:16 - the noise so that's one application of
45:19 - this as well
45:20 - that you can think about let me go over
45:21 - to the chat see what's going on and see
45:23 - if we can get started writing some code
45:25 - i also need to take a break and look at
45:27 - the brilliant logic course um
45:29 - shortly um
45:32 - so hold on i'm seeing some interesting
45:35 - uh oops and this
45:36 - computer went to sleep i'm okay i'm
45:39 - seeing some interesting uh comments in
45:41 - the chat here
45:43 - uh mark booth says really want to
45:45 - understand but it gets so abstract so
45:46 - fast sorry
45:48 - uh
45:49 - uh lee writes got an idea put the board
45:52 - behind the camera you're normally at and
45:54 - then you can look to the right instead
45:55 - of the left
45:57 - put the board
45:59 - behind the camera
46:05 - but i don't oh i go over there i don't
46:06 - know i have to think about that
46:10 - okay so um
46:14 - hopefully this has been helpful to folks
46:17 - i'm looking at the time 4 45 all right
46:19 - i'm gonna start let's so this is my this
46:21 - is my plan i am going to generate a data
46:24 - set
46:25 - i'm going to get my node.js
46:27 - tensorflow.js environment setup
46:29 - take a short break and then start come
46:31 - back and start writing the code for
46:34 - the autoencoder itself so let's open up
46:36 - processing
46:37 - um i you know
46:39 - i what i would like to do is create a
46:42 - data set of images
46:45 - one that is pretty sort of simple to
46:46 - work with
46:49 - okay so let's call this i'm going to
46:51 - save this onto the desktop
46:54 - um what size is my font that looks good
46:58 - let's save this as a
47:02 - auto encoder
47:03 - training
47:05 - data
47:07 - all right so i'm going to write a
47:08 - processing sketch by the way look at the
47:11 - beautiful
47:12 - processing four gotta love that
47:15 - uh
47:17 - and
47:18 - let's do the following so
47:20 - i don't know what would be so i'm gonna
47:22 - work with 28 by 28 images like really
47:24 - low resolution images you know soon we
47:26 - can get everything working we can try to
47:28 - see how much far we can push it with
47:29 - more training data higher resolution
47:32 - um so let's just actually i'm going to
47:34 - though what i think what i'm going to do
47:36 - is i'm going to make my processing
47:37 - window
47:38 - 280 by 280 then when i save the images
47:42 - um i'll i'll sample them down just so we
47:44 - can see so let's make a
47:47 - black background i'm just going to do
47:49 - rec let's just do squares
47:52 - so let's pick a random value between uh
47:56 - so
47:56 - um i'm going to say uh wrecked mode
48:00 - center
48:01 - and uh stroke weight
48:05 - 4
48:06 - and then if i said square
48:09 - width divided by 2 height divided by 2
48:13 - 100 let's just try that let's get rid of
48:15 - this
48:16 - right now
48:19 - so there we go there is a square so what
48:21 - i um i think i'm going to make it a
48:22 - little bit thicker
48:24 - uh let's make the stroke weight eight
48:27 - because again i'm going to have to like
48:29 - sample it down i mean
48:31 - why not
48:33 - make it 16. so i think what would be
48:35 - interesting is to ultimately do a data
48:36 - set that's many different kinds of
48:38 - shapes but let's just do squares that's
48:41 - 100 pixels so let's have a value between
48:45 - 100 and 200 and use that as the width
48:53 - so this is sorry for the flickering but
48:55 - now i want to save all these images
48:58 - so but i want to say and i'm just going
49:01 - to say no loop just to do one right now
49:03 - so let me and i'm sorry that i'm uh
49:06 - coding standing in front of the code so
49:08 - we move this over here so let's do i
49:10 - think i can use get
49:12 - p image
49:14 - image equals
49:16 - can i just say get
49:19 - save
49:20 - square dot uh should i use a png pro or
49:23 - jpeg i don't know
49:25 - is this going to work let's just see
49:27 - what happens
49:29 - so i run this
49:30 - let me go to the folder with this
49:32 - processing sketch yeah
49:34 - so that worked but the reason why i
49:36 - wanted to get it make a copy of it is
49:38 - then i should be able to say
49:40 - image.size resize
49:46 - i think this is right so basically i
49:47 - want to draw something in processing
49:51 - um then i want to just create a copy of
49:53 - that image resize it down and save it
49:56 - to the uh
50:00 - so let's look at this
50:02 - yeah you can see it's fuzzy looking
50:03 - because it's now
50:04 - a very low resolution 28 by 28 image
50:07 - fantastic
50:09 - um so i want to do this multiple times
50:12 - and
50:14 - i gotta
50:15 - processing this is really nice feature
50:16 - if you use save frame
50:18 - it will like
50:19 - number all the images as you're saving
50:21 - them but because i'm copying it using
50:22 - save i can just use frame count though
50:25 - so i think i could say plus
50:27 - number format frame count four i think
50:30 - number format will always give it four
50:33 - digits you know i don't think i'm gonna
50:34 - make more than a thousand so let's just
50:35 - do three
50:37 - plus
50:39 - dot png
50:41 - and let's put that let's make a folder
50:44 - called data
50:47 - so this should be saving every image in
50:50 - a data folder numbered according to the
50:52 - frame count
50:53 - always using formatting the number
50:55 - always to be zero zero one zero zero two
50:58 - and let's see
50:59 - uh let's see what happens i mean it's
51:01 - going to bother me that the first image
51:02 - isn't zero let's run this apologies for
51:05 - the flickering oh no i have no loop so
51:07 - let's see yep square oh that really
51:09 - drives me crazy that it's not square
51:11 - zero zero zero
51:14 - i'm sorry i have to use my own counter i
51:15 - mean
51:16 - uh let's do a counter equals zero let's
51:19 - change this to counter
51:24 - let's say counter plus plus and then
51:26 - let's just do 100 images if counter
51:29 - equals 100
51:31 - exit
51:32 - so now i'm going to run this sketch this
51:34 - is a really simple processing sketch
51:36 - just to generate 100 images of squares
51:39 - to train our auto encoder and obviously
51:41 - i'd like to
51:43 - do something better now
51:47 - so i'm like taking a look at the chat
51:49 - okay so let's see what happens here
51:53 - right we should get 100 images i exited
51:56 - let's look at the data folder
51:59 - and we can kind of scroll through this
52:01 - and we can see here are my 100 images
52:03 - all right so that
52:05 - step one
52:07 - create a training data set of images
52:10 - just squares i really want to also make
52:12 - them circles no
52:14 - so one of the things that i have learned
52:16 - is that as tempting as it may be right
52:18 - now for me to
52:20 - uh build a more sophisticated scenario
52:23 - um example
52:26 - i just want to know
52:28 - that my code works even if it produces a
52:32 - sort of obvious and trivial result so if
52:34 - i can get whatever i build to produce a
52:37 - very obvious trivial result
52:40 - then
52:41 - i can
52:43 - then i know that things are in the right
52:45 - place and working and i can try to start
52:48 - exploring with more complex data and
52:50 - more complex scenarios
52:51 - right so next step so step number one is
52:55 - create my training data image set
52:58 - and i'm looking at the
53:00 - member chat
53:02 - um
53:05 - yes yes yes yes yes
53:07 - um
53:09 - simon is giving me some good advice in
53:10 - there i'm sorry i don't have my the
53:12 - discord is like really really small
53:14 - so i don't see it too well today
53:16 - apologies for that uh okay
53:20 - now what is
53:22 - next what is next
53:26 - you know how people used to make all of
53:28 - these like weird musical remixes of my
53:30 - videos that doesn't happen anymore
53:33 - that's the internet did tick-tock happen
53:34 - and nobody wants to make weird musical
53:36 - remixes of my videos anymore come on
53:38 - people it brought me so much joy it
53:41 - brought the world so much joy
53:47 - [Music]
53:48 - okay
53:49 - um
53:53 - what was i doing i believe ah okay let
53:55 - us go now to i terminal window okay
54:00 - so i'm going to go to the desktop
54:04 - i'm going to make directory auto encoder
54:08 - tf demo
54:13 - all right so
54:14 - now what i want to do is write the code
54:18 - for the auto encoder now ultimately what
54:20 - i would love is to someday
54:24 - open up the p5 web editor
54:27 - and like demonstrate the auto encoder
54:29 - running visualize the training process
54:31 - maybe uh then generate new images
54:35 - have like sliders to play around with
54:37 - all the latent vectors
54:38 - but i'm at the beginning of my journey
54:40 - understanding this and it's it's sort of
54:42 - i don't know whether it's fortunate or
54:44 - unfortunate for you but what i often try
54:46 - to do with my videos is come from a sort
54:48 - of high level place
54:50 - and use a lot of other tools to
54:53 - demonstrate a concept and offer the
54:56 - audience a chance to explore that
54:58 - concept with their own creative in their
55:00 - own creative direction
55:02 - so i think eventually it might be nice
55:04 - if i kind of have a lot of pieces ready
55:07 - to go in a video that can be right at
55:09 - this part where people can kind of make
55:11 - their own creative version but i just i
55:13 - want to understand how all this stuff
55:14 - works i think for me being able to just
55:17 - work with node and tensorflow.js
55:20 - directly without any interface will
55:22 - allow me to sort of figure out the um
55:26 - um allow me to figure out how how the
55:29 - autoencoder stuff works and then i can
55:30 - come back to later to see if i want to
55:32 - do it in the browser with more sort of
55:34 - visual flair
55:35 - so i'm going to create a node project by
55:38 - saying npm init
55:42 - then i'm going to like
55:43 - just like hit enter enough times
55:46 - that the fact that i just hit enter and
55:47 - didn't think at all about what i'm doing
55:50 - good
55:51 - um let's also hit git init
55:54 - um to
55:58 - oh can i change
56:00 - look at this git
56:02 - config
56:03 - dash dash global init
56:05 - default
56:07 - branch this is new
56:09 - main i want my default branch to be
56:11 - called main to match what github does
56:15 - main trunk development and then i could
56:17 - say git
56:18 - branch dash
56:20 - m
56:21 - main right there we go okay great so now
56:23 - i'm in so i also want to just keep this
56:25 - project as a git repository because
56:28 - that way i can like track the history of
56:29 - what i'm doing and then you know at the
56:31 - end of today certainly
56:33 - upload what i have to github and then
56:36 - come back on friday to complete this
56:38 - project
56:40 - um
56:42 - so
56:43 - what do i need i need tensorflow.js
56:51 - uh all right so import blah blah import
56:55 - blah blah blah import blah blah
56:59 - tensorflow.js for node okay but i guess
57:02 - i do tf.js-node
57:05 - uh okay so let's see
57:12 - so i want to install the tfgs node
57:15 - package
57:18 - error
57:20 - no
57:21 - not what it's called
57:23 - you can see by the way that i in case
57:24 - you were thinking like did i do all this
57:27 - earlier and now i'm just rehashing it
57:28 - clearly i did not
57:30 - um oh oh i think i call it i have to do
57:32 - this
57:38 - there we go
57:39 - so i think i am now installing
57:41 - tensorflow.js node is it time for me to
57:44 - switch over and use um
57:46 - es6 imports
57:49 - um i think it might be so i'm going to
57:51 - try doing that i'm not going to do the
57:53 - gpu i'm not going to do this with any
57:55 - gpu stuff
57:58 - oh this might take a little while
58:00 - because i don't i didn't okay so also um
58:04 - let me open this up in visual studio
58:06 - code
58:08 - uh yes so
58:11 - here i am
58:12 - and all i have so far is the
58:14 - package.json
58:15 - so you can see this is the name of my uh
58:18 - project the
58:20 - version might call this version 0.01
58:26 - and maybe i'll give it a description
58:28 - coding train attempts
58:31 - auto encoders
58:35 - so i recognize that some of you watching
58:37 - might not be familiar with node.js or
58:39 - node programming this is not as sort of
58:41 - friendly as me just opening up a
58:42 - processing sketch or a p5.js web editor
58:45 - but ultimately i'm creating a project a
58:48 - software project built in javascript
58:50 - this package.json file is the sort of uh
58:54 - configuration of the project um it's
58:58 - telling me
58:59 - i don't know why it wants to do this
59:02 - that the
59:06 - it's telling me that the
59:08 - file to run the code for this project is
59:10 - called index.js and one of the other
59:13 - javascript libraries it's using is
59:14 - tensorflow so
59:16 - let's create an index.js
59:20 - file let's just say console.log
59:24 - hello
59:25 - auto encoder
59:31 - and then
59:33 - let's go back to my terminal
59:36 - and i'm going to say run it by saying
59:38 - node index.js and i'm seeing that
59:40 - console log so i am executing
59:43 - javascript code
59:45 - from
59:46 - the console via node.js and this is
59:50 - going to be this is because i'm
59:52 - importing the tensorflow library i'm
59:53 - going to be able to write in javascript
59:56 - hooks into the tensorflow machine
59:57 - learning library in here and program my
60:00 - auto encoder and in theory like i should
60:03 - be able to uh to some some sense just
60:06 - kind of really follow this and like
60:08 - port this code um
60:11 - which is sort of python keras library
60:13 - into javascript with tensorflow.js okay
60:17 - close this
60:18 - um
60:20 - but where am i um so i do i think i want
60:24 - to uh just as an experiment so typically
60:26 - what i will do
60:28 - is next say something like equals
60:30 - require
60:32 - and i don't even know if this would work
60:36 - would this work
60:37 - like this is what i would typically do
60:39 - next
60:40 - which is require the package and take
60:44 - basically everything from that library
60:46 - and put it in my own variable
60:48 - i'm just curious
60:52 - so that seemed to have worked i'm
60:54 - curious what this uh weird messages is
60:56 - giving me tensorflow binary is optimized
60:59 - with one api deep neural network library
61:01 - to use the following cpu instructions to
61:03 - enable them in other operations i don't
61:06 - i don't know so this is telling me about
61:08 - how i built tensorflow and maybe i'm
61:10 - using cpu and maybe i could do it a
61:11 - different way to make it more
61:16 - efficient but i don't actually care
61:17 - about any of that because i'm doing some
61:19 - a very much of a toy example with just a
61:21 - few images at very low resolution but i
61:24 - am kind of curious
61:26 - i you know this is not germane to the
61:30 - tutorial but i'm just curious what
61:32 - happens if i change this to an import
61:36 - and then i think if i do this it's going
61:38 - to say cannot use an import statement
61:41 - and so to use import statements
61:43 - don't i do something like
61:45 - something module
61:48 - uh
61:49 - package.json es6 module
61:52 - import
61:57 - what do i put in it
62:00 - uh
62:01 - what do i put what do i put input type
62:03 - type
62:05 - type module there we go
62:07 - so
62:08 - i can add
62:12 - type module
62:14 - and this is so not important to what i'm
62:16 - doing right here but
62:19 - great so if i add type
62:22 - module to package.json that tells
62:27 - the
62:27 - [Music]
62:29 - node engine that i want to use import
62:32 - statements instead of require which is a
62:35 - newer
62:36 - fancier
62:37 - better
62:39 - way of doing it i think you know this is
62:42 - coming from somebody who refuses to type
62:43 - yarn
62:44 - no npm npm that's what i've been doing
62:48 - for 100 years and i will still do it
62:50 - tomorrow npm
62:52 - and then like i like what i like
62:55 - um but i do sort of the one thing i
62:57 - think that's important here is
63:00 - i'm on node version 16.11.1
63:04 - and um
63:05 - [Music]
63:07 - i think
63:08 - the import syntax is only supported in
63:12 - node version blank and above
63:16 - um
63:17 - type module okay
63:19 - so again not super important and simon
63:21 - says yarn isn't as good anymore anyway
63:24 - see if you wait long enough and never
63:26 - bother to use the new good thing it
63:28 - eventually it just goes away gets
63:29 - replaced by something else
63:33 - lessons
63:34 - deep thoughts or lessons about
63:36 - programming with your host dan schiffman
63:39 - don't bother learning anything new
63:41 - because if you eventually just wait
63:42 - there'll be something else new that you
63:44 - need to learn if you don't bother
63:45 - learning that that'll go away too
63:49 - stick with
63:51 - java
63:52 - never going away people
63:54 - all right
64:00 - all right i'm looking i'm looking
64:01 - looking i'm looking v13 is the minimum
64:03 - version for es6 imports okay it took you
64:06 - three years for var to let yeah
64:09 - um
64:10 - all right so now i believe i am set up
64:13 - and ready to go
64:16 - um
64:18 - oh there's a lot to be done here all
64:20 - right i'm trying to think this is
64:21 - probably a good pause time oh the couple
64:24 - things one let me take my images this
64:27 - data
64:29 - let me go to
64:34 - um this folder
64:37 - reveal can i do like reveal
64:41 - come on reveal in finder
64:45 - let me put this data folder here okay
64:47 - so um i'm actually gonna i'm gonna throw
64:50 - this project up on github real quick so
64:52 - people can take a peek at it but one
64:54 - thing that i want to do before i do that
64:57 - is
64:58 - um
65:01 - i don't want in my get history this
65:04 - images to be there so i'm i'm going to
65:06 - rule if you are someone
65:08 - grabbing this code and wanting to run
65:09 - your own version of it um
65:12 - you'll need to generate your own images
65:13 - or download sample images from somewhere
65:15 - else i don't want that polluting my git
65:17 - repository and git history and i also
65:19 - don't want the node modules so i am
65:22 - going to create
65:24 - a
65:25 - dot get ignore file
65:30 - and i'm going to put the data folder in
65:33 - there
65:34 - or maybe i could also just do star.png
65:36 - there's different ways i could do it but
65:38 - um i don't know which matters i'll just
65:39 - do them both
65:40 - i don't want the node modules
65:43 - folder
65:44 - and um i don't have any environment
65:47 - variables yet or anything like that i
65:49 - mean i could add that in just in case
65:52 - these are some sort of standard things
65:54 - i also like nothing bothers me more than
65:56 - the
65:57 - mac os ds store files so this is some
65:59 - pretty good git ignore stuff
66:02 - i'm going to say git status
66:06 - just to see where i am
66:07 - [Music]
66:08 - let us add all of this stuff
66:12 - and i'm going to say initial
66:14 - project setup
66:17 - um let's go to
66:19 - uh github.com
66:23 - oh no
66:27 - i'm not signed in if i'm not signed in
66:29 - this means you're gonna have to wait
66:30 - about 45 minutes for me to do like all
66:32 - of my various
66:34 - randomized passwords lookups and
66:36 - two-factor uh but oh no look it's saved
66:38 - all right it's not so bad so i just have
66:40 - to do my two-factor
66:42 - i forgot that i did that in my for my
66:44 - streaming account
66:46 - so let me just get my um
66:48 - authentication code i'm gonna just move
66:51 - over to here no reason for you to see me
66:52 - type it in
66:54 - um
66:57 - one
66:58 - i don't care
67:00 - you know the first digit is one
67:03 - uh okay i'm in
67:06 - i'm in
67:08 - uh i am going to make a new repository
67:12 - um let's put it in the coding train org
67:16 - auto encoder
67:18 - demo
67:20 - public
67:21 - uh create the um
67:24 - code from live stream
67:28 - uh started what's today 11 15 21.
67:33 - let's create this repository
67:36 - and i can uh just add you know i don't
67:40 - need to do this is showing me
67:41 - instructions about how to link my local
67:43 - repo on my computer but i've kind of
67:45 - done uh uh done oh yeah i could just go
67:48 - right here so i can just add this repo
67:51 - as a remote
67:55 - and then i can
67:56 - send it along i don't need to worry
67:57 - about the branch i've already made my
67:58 - branch main
68:01 - and so now
68:02 - uh if you are following along i need to
68:05 - add read me and do more um the code so
68:08 - far the project configuration is here on
68:10 - github
68:13 - put the whiteboard facing the green
68:15 - screen
68:17 - oh but it would be in front of the
68:18 - camera oh behind the camera so i'd walk
68:20 - over there all right the camera's
68:21 - actually quite far from me like if you
68:23 - don't realize i have to walk all the way
68:25 - around
68:26 - walk over some cables and stuff and then
68:28 - here i am
68:29 - at the camera because i like a wide sort
68:32 - of view
68:35 - but anyway
68:37 - i'm taking your suggestions putting them
68:39 - in my mind
68:40 - uh so it is 507 i am going to be
68:43 - streaming until six o'clock so i think
68:45 - we have some time to get started on the
68:47 - actual tensorflow code
68:50 - and i will be returning this friday to
68:52 - completely this is by the way this is
68:53 - the new dan
68:55 - i'm just gonna see how i'm gonna give
68:57 - myself a lot of time remember like i'm
68:59 - gonna do shaders and auto encoders and
69:01 - look at community contributions and then
69:02 - i'm going to also uh demonstrate this
69:05 - whole other fractal pattern that i just
69:06 - learned about yesterday from watching a
69:07 - three blue one brown video
69:09 - all in 45 minutes no
69:11 - i'm starting this auto encoder project
69:13 - getting as far as i get today i'm going
69:15 - to turn this off and come back and i
69:17 - could continue where i last left off
69:18 - that's the wheat this week is the auto
69:20 - encoder week but
69:22 - before
69:24 - um
69:25 - i get any further
69:26 - i would like to take a moment to
69:31 - i'm just opening this up here thank
69:34 - i have some notes boy my setup is really
69:39 - not the best
69:45 - i would like to thank
69:48 - it's coming i'm going to press the
69:50 - button it's all going to work today's
69:51 - sponsor
69:53 - brilliant
69:56 - whether you're looking to learn
69:58 - something completely new brush up on a
70:00 - few topics uh you're interested in stem
70:03 - there's no better place than brilliant
70:06 - it is an interactive stem learning
70:07 - platform that helps you learn concepts
70:09 - by working through them in visual
70:11 - hands-off ways
70:13 - hands-on
70:15 - look at me reading a script i'm so bad
70:16 - at it
70:17 - fired always fired let me tell you i
70:20 - know that i'm reading for the script
70:21 - here but i actually really love
70:22 - brilliant and one of the things that i
70:24 - love about it for me right now is that i
70:26 - do it with my kids because my daughter
70:28 - is learning how to like do factors with
70:30 - numbers i was like oh look there's a
70:31 - course on factorizations little
70:32 - interactive lessons and we can do them
70:34 - together there's so much awesome stuff
70:36 - extensive course catalog constantly
70:38 - expanding um and
70:40 - you know some of my favorite courses
70:41 - i'll bring them up here
70:43 - one is the oh right there's a whole
70:44 - course on neural networks so do you
70:46 - remember this ridiculous uh drawing that
70:50 - i was trying to do to explain neural
70:51 - networks look at that look at that
70:53 - look at this on uh in the brilliant
70:55 - neural network course you can actually
70:58 - read about understand interact with
71:00 - neural networks as they recognize digits
71:03 - right there in real time
71:04 - so much to explore
71:06 - with that the the logic course is
71:10 - one that they have just completely
71:12 - is all brand new so it's a
71:15 - revamped edition has new lessons
71:17 - challenges and a much higher level of
71:19 - interactivity so um what i would like to
71:22 - do what i always enjoy to do with my
71:24 - sponsor segments rather than kind of
71:26 - play these pre-rendered clips is head
71:29 - over to
71:31 - brilliant itself
71:34 - and let's take a look um at the courses
71:37 - i'm going to um
71:41 - yeah what is a factorization is in there
71:43 - pre-algebra there's also a great what is
71:45 - a derivative course if you're interested
71:47 - like if you want to like learn some
71:48 - basic math stuff there's really really
71:50 - great okay so
71:53 - let's go over here sorry i just wanted
71:54 - to be able to see the chat again i lost
71:56 - the chat um so let's find um the logic
71:59 - course so i'm going to click here on the
72:00 - logic course it says continue
72:03 - because uh i clicked on it earlier today
72:05 - and then i was like whoa this is way too
72:07 - much fun not gonna look at it gotta save
72:08 - it for the stream so let's go to
72:10 - continue and see how it works okay
72:13 - so let's try this one first
72:17 - rey nook and lex are robots from and
72:19 - let's see if i can make this a little
72:20 - bigger for you and that's hopefully
72:22 - going to help a little bit are robots
72:24 - from three different models
72:26 - rey is not the newest
72:29 - knuck is the oldest
72:31 - lex is not the oldest
72:34 - so what's the correct order from newest
72:36 - oldest i think i'm going to be able to
72:37 - do this one
72:39 - um by the way i love these little robots
72:41 - just like as an exercise like could you
72:43 - make your own little robot characters in
72:44 - p5.js so much inspiration here okay so
72:48 - knuck is the oldest so nuck has to go
72:50 - here
72:52 - uh rey is not the newest meaning it's
72:54 - only other option is here so lex is the
72:57 - newest
72:58 - and i'm gonna check
73:01 - yes did you hear that little ding by the
73:02 - way it went in my ear i don't know if
73:04 - the sound is going out that was exciting
73:06 - okay let's hit okay go to the next one
73:09 - arrange the robots to make the following
73:11 - true
73:12 - loy is in one of the two middle spaces
73:16 - mig is to left of lex and right of rey
73:20 - rey is directly next to mig so let's
73:23 - just try putting loy here
73:27 - and then is there anything
73:29 - okay so mig is to the left of lex
73:33 - and rey
73:34 - is
73:35 - is directly next to mig okay hold on
73:38 - so what happens if i were to do this
73:40 - if meg is the left of lex and rey is
73:43 - here ah that can't work because lloyd's
73:46 - got to be in a middle space
73:48 - oh
73:49 - is left of mex and right of ray oh but
73:52 - lex could be here and loy could be here
73:54 - so are there are there more
73:55 - possibilities
73:57 - so this this satisfies right loy is in
73:59 - one of the two middle spaces
74:02 - meg is to the left of lex and right of
74:04 - re and re is directly next to mig i have
74:07 - a feeling if i did this
74:09 - yeah
74:10 - it wouldn't work
74:12 - right because then we couldn't have rey
74:13 - directly next to mig so let's check
74:16 - okay i got it right
74:19 - i don't know how many of these i'm going
74:20 - to do but this is like
74:21 - i mean
74:22 - are you not having fun i'm having fun
74:26 - one of these i'll get wrong eventually
74:27 - three robots compete in a race
74:30 - marv and lex do not place next to each
74:32 - other so the thing is first of all i
74:35 - should know about this because uh many
74:37 - many many years ago i was a
74:40 - i majored in math and philosophy as an
74:41 - undergraduate wasn't a double major it's
74:43 - like a combined major and what is what
74:45 - is math and philosophy together combined
74:47 - is one thing it's the study of logic so
74:50 - what i love about this is i'm kind of
74:52 - just enjoying this right now as a puzzle
74:55 - as a game i mean this is kind of like
74:56 - the stuff i love to you know
74:58 - you know i don't want to name other
74:59 - kinds of puzzle activities i like to do
75:01 - on my phone but like uh
75:04 - brilliant being one of them i like to
75:05 - just solve puzzles and play games um but
75:08 - what you i don't really what you don't
75:09 - realize maybe is that um i'm learning
75:12 - all of these really important
75:14 - foundational concepts in logic and i
75:15 - have a feeling that as we go through
75:17 - this course that will be revealed
75:19 - three robots compete in a race marv and
75:22 - lex do not place next to each other rey
75:25 - beat marv
75:27 - so if rey beat marv
75:30 - i think the only way for this to be true
75:32 - is this configuration
75:34 - because rey beat marv and marv and lex
75:36 - are not next to each other so the only
75:38 - way for marv and lex not to be next to
75:40 - each other would be either ones in third
75:42 - and one's in first
75:43 - but the other way around but for lex
75:48 - but for ray to beat marv
75:50 - it's got to be um marv's got to be in
75:52 - last
75:54 - still correct eventually i'm going to
75:56 - get this wrong
76:00 - okay
76:03 - in the next
76:04 - race give myself a few more minutes oh i
76:07 - think i can maybe get to the end of this
76:09 - let's see if we can get to the end of
76:10 - this
76:11 - um because let's see in the next race
76:14 - one robot finishes between rey and lex
76:18 - two robots finish between lex and ty
76:22 - so if two robots finish between lex and
76:25 - ty
76:26 - they one has to be first one has to be
76:28 - last
76:30 - and one robot finishes between ray and
76:33 - lex i think i might have just gotten it
76:35 - because i mean i got lucky but let's try
76:37 - doing it the other way right if ty was
76:40 - first
76:42 - and
76:45 - lex was last
76:47 - rey didn't finish second
76:49 - but two robots
76:52 - wait
76:54 - oh no wait hold on
76:56 - one robot finishes between ray oh yeah
76:58 - yeah but so tied in so then there's no
77:00 - robot between these two so tie has to be
77:03 - last yeah
77:05 - and marv
77:07 - has to be
77:08 - the other thing about this is honestly
77:10 - like
77:11 - imagine programming your own
77:13 - interactives like this so while this is
77:16 - a little meta for you the coding trained
77:17 - audience i'm emphasizing again like so
77:20 - many of my coding challenge ideas have
77:22 - come from working through these
77:23 - brilliant lessons
77:24 - uh got it right okay
77:26 - we're almost there
77:29 - um arrange the racers in the order they
77:32 - finish okay
77:34 - rey isn't first and tai isn't last okay
77:38 - lex doesn't place next to ty or rey
77:43 - mar finishes the head of ray so my
77:45 - strategy for doing this is trial and
77:47 - error
77:47 - like let me put one in that because it's
77:49 - interactive i wonder i'd be curious here
77:51 - from you what are some more methodical
77:53 - ways of doing this but rey isn't first
77:56 - so re could be last
77:59 - tai isn't last so tai could be first
78:02 - probably not right lex doesn't place
78:04 - next to tai or re nope
78:07 - so
78:10 - so lex would have to be like ty and rey
78:13 - have got to be in like the first two or
78:15 - the last two in order for lex to be not
78:18 - next to either of them and then marv
78:19 - finishes ahead of rey so i think this
78:21 - satisfies everything
78:24 - um
78:25 - so
78:26 - rey isn't first rey is last lex doesn't
78:29 - place next to ty array correct marfish
78:33 - is ahead of rey so i think i've got it
78:36 - let's check
78:38 - by the way i like seeing their
78:40 - explanations
78:41 - um and seeing the explanations we can
78:43 - see from the second clue we can conclude
78:46 - that only marv finishes next to lex so
78:48 - either lex finishes first with marv
78:50 - second or last with marv sir so the
78:53 - explanation is following something
78:54 - similar to me there's only two
78:55 - possibilities let's try one
78:57 - the third clue tells us marvin is ahead
78:59 - of rey so that means lex must finish
79:01 - first with marv second okay right then
79:03 - you've eliminated with another clue okay
79:05 - back to problem
79:07 - let's go to the next one
79:10 - okay three more the final race is
79:12 - between five robots oh boy this is
79:15 - getting harder now
79:18 - um
79:19 - let's see rey finishes faster than mars
79:24 - the smallest difference in finishing
79:25 - times was between rey and lex
79:29 - the largest difference in finishing
79:31 - times was between lex and tai
79:33 - well that means
79:37 - doesn't that mean
79:38 - either lex has to be first and tie last
79:40 - or vice versa
79:42 - right
79:43 - smallest finishing time just means that
79:45 - rey has to be next to lex
79:49 - we don't know the difference but
79:51 - obviously that if it weren't next to lex
79:53 - something else so this is this is
79:56 - these two give us this possibility or i
79:58 - could put lex here and re here
80:02 - mig finishes in first or third
80:04 - so mig could be third
80:07 - marv
80:08 - ray finishes faster than i think i got
80:10 - it luckily so i think i had a 50 50
80:12 - chance and i got it luckily i think
80:15 - let's see
80:16 - got it correct i'm really rocking and
80:19 - rolling here
80:20 - review and reflect
80:22 - the key see this is what i mean i was
80:25 - just having fun playing with a logic
80:27 - puzzle
80:28 - working my brain
80:29 - um i wish my kids had been here to do
80:32 - this with me because they would have
80:33 - really enjoyed this or they might have
80:34 - actually been like oh my god dad again
80:36 - with the brilliant puzzles
80:38 - but they like it i know they do
80:41 - the key concept from this lesson is
80:43 - start where you have the most
80:44 - information given multiple pieces of
80:46 - information start with the one that lets
80:48 - you deduce the most
80:50 - the next challenges are a bit harder
80:52 - recognizing useful information is the
80:54 - skill you will hone throughout this
80:55 - course well i want to hone that skill
80:58 - for sure
80:59 - the next challenges
81:01 - are a bit harder they'll require you to
81:03 - process more information and recognize
81:05 - what's most useful
81:07 - all right i have completed five percent
81:10 - of the logic course
81:11 - solve problems by visualizing
81:13 - relationships did i like this lesson oh
81:15 - yes i did
81:17 - continue
81:19 - abstract order logic strategic order
81:22 - logic so i um next time that i am
81:26 - doing a live stream sponsored by
81:27 - brilliant uh i might be much further
81:29 - ahead in this if i've been going on on
81:30 - my own otherwise i will return to do
81:32 - this um if you like what you see here um
81:35 - and want to try brilliant out yourself
81:37 - um please uh take a minute i'm gonna
81:39 - take uh just a short break just for a
81:41 - couple minutes i'm looking for oh it's
81:43 - already there
81:44 - you can sign up for free at
81:46 - brilliant.org codingtrain that lets them
81:48 - know that you found uh brilliant from me
81:51 - the coding train yay that's a good thing
81:54 - um and uh there's a lot that you could
81:56 - do on brilliant for free there's uh
81:57 - daily puzzles and different things if
81:59 - you want to unlock all of the premium
82:00 - content all of the courses um then uh
82:04 - through that link you will get a uh the
82:06 - first 200 people to sign up to that link
82:07 - will get a 20 off uh description it's
82:10 - not it's not really the holiday season
82:12 - just yet but i might also just make a
82:14 - note that buying somebody a brilliant
82:16 - subscription as a gift is a wonderful
82:18 - thing i mean a it's not just more
82:20 - plastic nonsense it's educational and
82:23 - learning and fun i mean that's like that
82:25 - if you want to i already have it but if
82:27 - i wanted a gift that's what i would want
82:29 - can you get me like the uber super
82:30 - awesome extra
82:32 - uh premium brilliant then that you get
82:34 - me as a gift okay um thank you brilliant
82:36 - for sponsoring the coding train for
82:38 - keeping this engine going for allowing
82:40 - me to uh set up this new studio for
82:42 - helping really
82:44 - make all of the all my dreams come true
82:47 - you the audience though
82:49 - i love you all
82:50 - i'm going to take a short break i'm just
82:51 - putting up this intermission card here
82:54 - i'm gonna try to just limit my break to
82:55 - about uh a minute or two
82:59 - um put on some music here um just um so
83:03 - i can check and then i will be back
83:06 - uh in just a minute or two so i can keep
83:08 - working on the um
83:11 - auto encoder project see you in just a
83:13 - minute or two
83:17 - [Music]
83:26 - [Music]
83:32 - oh
83:35 - [Music]
83:37 - so
83:42 - [Music]
83:50 - so
83:54 - [Music]
84:42 - [Music]
85:02 - do
85:08 - [Music]
85:09 - [Applause]
85:11 - [Music]
85:17 - do
85:19 - [Music]
85:32 - do
85:38 - [Music]
85:45 - okay
85:46 - pretty short break
85:48 - i'm just getting myself back to being
85:51 - set up
85:52 - [Music]
85:57 - and
85:59 - let's get my code here
86:05 - [Music]
86:28 - all right
86:33 - all right i
86:34 - suspect
86:36 - that
86:37 - um
86:39 - nobody just happened to join at this
86:41 - very moment
86:43 - but if you did i am working on making a
86:47 - tensorflow.js
86:49 - auto encoder example i spent the first
86:52 - half of this live stream
86:54 - and by the way my the boiler in the
86:56 - garage is running so apologies for that
86:58 - extra noise but i spent the first half
87:00 - of this live stream kind of talking
87:02 - through this diagram oh boiler went off
87:05 - um
87:07 - in terms of what a neural network is and
87:09 - what an autoencoder is and why we might
87:10 - want to try this and where how this is
87:12 - going to lead to understanding latent
87:14 - vectors and all of that kind of stuff
87:17 - so i am now right here
87:20 - wanting to work with
87:22 - tensorflow.js in
87:24 - um node itself um so i need to start
87:27 - building the autoencoder using
87:29 - tensorflow.js code so um
87:32 - let me go
87:35 - to
87:36 - tensorflow
87:37 - i'm going to look at the tensorflow.js
87:40 - api docs
87:46 - so
87:47 - i haven't done this in a while and i
87:49 - want to use the layers api
87:51 - so the layers api
87:54 - is essentially and sorry this is so
87:56 - small
88:00 - um
88:03 - if i understand it correctly
88:06 - is essentially the same as
88:10 - i can't get to the right place
88:12 - okay um the layers api is
88:16 - the same as the original keras just
88:19 - without the name keras
88:21 - so the first thing that i need to do is
88:25 - create a sequential model so i'm going
88:28 - to do that right here so i have imported
88:31 - the tensorflow library i'm using the
88:33 - node implementation of tensorflow.js
88:37 - i am now creating a model and i is do i
88:41 - dare i rename this to be called
88:43 - autoencoder is that bad for some reason
88:45 - to me that feels good because what i'm
88:46 - doing is creating an autoencoder it is a
88:48 - sequential model in the sense that uh it
88:52 - is a feedforward neural network the
88:56 - layers are um
88:58 - architected in a linear sequence
89:01 - sequential that's why the word
89:02 - sequential comes there
89:06 - the next thing that i need to do is
89:08 - start adding layers
89:10 - so the way i like to do this um
89:14 - is i think i'm going okay so let's first
89:16 - look at this
89:17 - um
89:18 - this this is gonna i would love to sort
89:20 - of like read all of this out loud for
89:22 - all the explanation hopefully
89:24 - i
89:25 - gave something of a helpful explanation
89:27 - but let's look at this so the first
89:29 - thing that we need to do
89:31 - is create the input shape which has
89:34 - 784 pixels
89:37 - a lot of people are asking about shaders
89:39 - in the chat is it just because
89:41 - i did shaders the last couple times or
89:44 - is there something straight like still
89:46 - in the thumbnail or the description
89:48 - that's mentioning shaders that i forgot
89:50 - to take out so not today for shaders
89:52 - unfortunately
89:53 - so um
89:55 - interesting so i want to create the
89:56 - encoder layer
89:58 - and the encoder layer had in this
90:01 - example has 32 units
90:03 - so how do i let's see basically i want
90:05 - to write code that's like this i want to
90:07 - create the encoder
90:09 - which is a
90:10 - tf layer
90:12 - that has like 32 units
90:15 - and the input i'm making this up i don't
90:17 - think this is right is like 784
90:22 - pixels or something like that
90:24 - so i don't recall the syntax
90:26 - and then i want to say auto encoder add
90:31 - layer
90:32 - encoder like this is basically the idea
90:35 - um clearly i've gotten something
90:38 - a
90:39 - tf layer
90:41 - like is that a function i don't know
90:43 - so i'm now just like making up code like
90:46 - i want to create this layer right i'm
90:49 - creating
90:51 - this
90:52 - layer this decoder layer
90:54 - that is going to receive 784 pixels and
90:57 - have 32 units
90:59 - so let's see if i can actually find the
91:01 - right syntax for this in the tensorflow
91:04 - documentation
91:06 - so going back to that
91:08 - which is here
91:11 - tf layer
91:12 - is that like is
91:14 - tflayers.den oh look at this
91:17 - all right so i was pretty close
91:21 - like if i just put this in here
91:24 - so i want to create tf layers.dense so
91:27 - this is a function that creates a dense
91:29 - layer
91:30 - with 32 units and the input shape
91:34 - is 784
91:36 - so input shape okay great
91:41 - so that's the encoder now
91:45 - in the original keras example
91:48 - i just make oh just one ah so so this is
91:51 - so we're gonna i'm gonna definitely want
91:52 - to expand this but this very very basic
91:55 - example is just two layers
91:59 - the a hidden layer and output layer
92:01 - essentially the hidden layer is the
92:03 - encoder the output layer is the decoder
92:06 - the inputs remember are not a layer
92:07 - that's the data being fed into the first
92:09 - layer
92:12 - so on a very very basic
92:16 - level here i'm then going to create
92:19 - the decoder
92:23 - the decoder
92:24 - which has 784
92:28 - units now interestingly enough ask
92:30 - yourself this question
92:31 - what is the input shape
92:34 - to
92:36 - the decoder
92:39 - i should like put a poll up and have
92:41 - people vote on it like is it 784
92:45 - is it 32 is it something else
92:48 - so remember the encoder has 32 units
92:52 - we're putting 784 pixels into it the
92:54 - decoder has 784 pixels and we're
92:57 - decoding what those 32 units so the
93:00 - input shape is 32. however
93:03 - i believe that this does not need to be
93:06 - stated because tensorflow.js like i must
93:09 - specify the input shape for the first
93:12 - layer because how is it going to infer
93:14 - that i mean maybe it could infer it from
93:16 - the data somehow but that's
93:18 - ml5 kind of does that but that's not
93:20 - going to happen here but the decoder can
93:23 - infer the input shape if i add it
93:26 - directly after
93:29 - the encoder
93:32 - so i'm creating my auto encoder model it
93:35 - has two layers an encoder which receives
93:39 - 784 pixels
93:41 - and a decoder which pulls from the
93:43 - encoder to decode it to 784
93:48 - values um okay
93:52 - yeah and uh
93:54 - um eat in practice and i'm repeating uh
93:58 - okay weekmans from the chat like in
94:00 - practice you would have multiple encoder
94:02 - layers and multiple decoder layers i'll
94:04 - add that in if we can get this to work
94:10 - okay input image
94:13 - okay i'm not going to worry about that
94:15 - so this is right
94:17 - so compile so
94:23 - i forgot how to use tensorflow.js
94:27 - so
94:28 - i have video tutorials on how to do this
94:30 - but i'm going to just right here so what
94:32 - is the next thing i would typically need
94:34 - to do
94:35 - is
94:37 - once i create the model
94:40 - is
94:43 - just looking isn't there like a
94:50 - i should look at my old examples
94:52 - right i have examples where i do this
94:54 - kind of thing
94:55 - like tensorflow
94:58 - js coding train
95:00 - github and these are probably so way out
95:03 - of date
95:05 - but like i need a bunch of
95:07 - uh examples like if i go look at this
95:10 - doodle classifier for example
95:15 - we can see
95:17 - i'm adding a convolutional layer with
95:19 - all sorts of stuff
95:22 - and then oh right then i have to do this
95:24 - i have to compile it so let's
95:26 - let's grab this
95:29 - code here
95:33 - and see if this is kind of the right
95:35 - idea so this is just setting up the
95:37 - layers compiling the model what is that
95:40 - doing
95:41 - well it's connecting all the layers and
95:44 - setting all the functions that are the
95:46 - math for how the elements are processed
95:49 - um but if i if i if i look at this right
95:55 - this basic example this is such an old
95:57 - example
95:58 - right the activation function is just
96:00 - sigmoid
96:02 - so oh and this one is
96:04 - relu which is not at all french but i
96:07 - can't help but say it's a french word so
96:10 - if i wanted to follow this also i missed
96:12 - that i could say uh
96:15 - is it um
96:17 - and apologies for not taking the time to
96:20 - explain activation functions although
96:22 - now that i said that i think i'm going
96:23 - to have to just briefly touch on it
96:27 - but i think
96:29 - i can put the activation functions in
96:32 - like this right just looking at my old
96:34 - examples
96:35 - yeah activation right um okay
96:40 - so what is an activation function so if
96:43 - i go back to my diagram and there's a
96:45 - you know ton more to say about this
96:46 - obviously and some of my other video
96:48 - tutorials will go through this in more
96:49 - detail
96:50 - but um these dense layer connections
96:53 - right there's some number is being
96:56 - outputted from here
96:58 - and outputted from here and remember
97:00 - there's all these weights
97:02 - so the
97:04 - all of the values all of the stuff
97:06 - that's coming into this particular
97:08 - neuron is the weighted sum of all of the
97:12 - the
97:13 - the units that are connected to it in
97:15 - the previous layer so all of the output
97:17 - values multiplied by their weights all
97:20 - added together get get processed inside
97:23 - of this particular neuron and how do you
97:26 - process those things with an activation
97:28 - function basically the um the way to
97:31 - think about this is if you know if you
97:32 - think very loosely about you know
97:34 - a you know i should say like a fictional
97:37 - version of how our brain works because
97:39 - i'm obviously not a neuroscientist and
97:40 - i'm not going to speak with any rigor
97:42 - here but you know oh my brain all the
97:44 - neurons are connected and they're
97:45 - lighting up or turning off and i see
97:47 - this delicious
97:49 - blueberry and i smell the blueberry and
97:51 - those are the inputs and all my neurons
97:53 - start lighting up right so does the
97:56 - neuron light up or not does it activate
97:59 - so we want to process all of those
98:01 - numbers and process them through a
98:03 - function which will essentially like
98:05 - squash that weighted sum weighted sum
98:07 - could be some big number small number
98:09 - into some range like between zero and
98:11 - one or is it just a positive or negative
98:14 - number is it on or off so that
98:16 - activation function sigmoid you know
98:18 - it's way
98:20 - it's this now is not the time for me to
98:21 - start going through the math of
98:22 - different activation functions and why
98:24 - this one is used and not that one is
98:26 - used i think
98:27 - um this is reading that i would
98:28 - encourage you to do maybe some people in
98:30 - the chat could offer some resources i
98:32 - certainly touch on it in other videos of
98:34 - mine but um
98:35 - sigmoid is a sort of like classic
98:38 - if this is all about classic machine
98:40 - learning sigmoid is sort of like the
98:42 - classic activation function not used
98:44 - very much these days but let's use it
98:47 - just to match this particular example
98:50 - then i was remembering i need to
98:53 - create an optimizer with a learning rate
98:56 - okay
98:59 - so i need to compile like this is just
99:01 - the sort of architecture and i need to
99:02 - tie everything together what's a good
99:04 - way of explaining what compile is doing
99:06 - i mean understand what it means to
99:07 - compile the code but i don't know that
99:09 - it's
99:10 - i don't i'm kind of struggling to
99:15 - find the words to describe what it means
99:16 - to compile this model after i've set up
99:19 - all the layers but a learning rate is
99:22 - there a learning rate specified in
99:25 - this particular tutorial
99:30 - learning rate
99:33 - space rate no so probably it's using a
99:36 - default one let's just keep that
99:39 - an optimizer i thought i saw
99:41 - in the code here
99:46 - the
99:46 - optimizer is atom okay so let's match
99:50 - that
99:54 - i think i can just do this atom
99:57 - i think actually i probably could just
99:58 - do this
100:01 - but um i'll do it this way
100:04 - and then the loss function is binary
100:06 - cross entropy so let's
100:09 - and metrics
100:11 - i don't know that i let's just comment
100:13 - this out for right now
100:14 - so these are you know i'm i'm kind of at
100:17 - the point of the day it's like 5 40 p.m
100:19 - eastern
100:20 - my brain is not
100:22 - uh functioning very well i need to eat
100:24 - dinner i'm tired i don't know what to do
100:26 - i've gotta go teach my class in person
100:28 - tomorrow
100:30 - um i didn't finish this but um i'm gonna
100:32 - i'm gonna do my best here so um
100:35 - you know when i come back on friday
100:36 - maybe i can come back and sort of talk
100:37 - through some of these elements a bit
100:39 - fresh
100:40 - but essentially the loss function is the
100:43 - mathematical function that's going to
100:45 - calculate
100:46 - how well the network is doing so in this
100:49 - case if i'm trying to create a copying
100:51 - machine how closely do the output images
100:54 - match the input images a loss of zero
100:57 - would mean they're exact reproductions
101:00 - and binary cross entropy is a particular
101:03 - kind of loss function like what would be
101:05 - something what did i have before there
101:07 - would be like a categorical cross
101:09 - entropy i'm trying i'm trying to just
101:10 - think of what
101:12 - um
101:13 - it's escaping me right now but um
101:18 - uh root mean squared error or something
101:21 - it's what i'm i think is what i'm
101:22 - looking for okay sorry
101:24 - uh let me comment this out okay
101:26 - so let's just see if this even runs
101:29 - like this is going to allow me to
101:31 - build this model compile it you know i
101:34 - haven't actually done anything yet but
101:36 - let's let's just try running this node
101:37 - code see if i get any errors okay i got
101:39 - an error
101:40 - auto add layer is not a function i just
101:43 - made up a function called add layer
101:46 - let's go back to the
101:48 - api add it's just add okay great simpler
101:52 - so it's not add layer it's just add
102:01 - okay
102:02 - uh
102:04 - unknown loss binary cross entropy so
102:07 - that is not the name of a loss
102:10 - that is in tensorflow.js interesting so
102:13 - let's look for tf
102:16 - loss
102:26 - loss hold on
102:29 - what was the one that i had in my other
102:30 - example because i can search for it
102:33 - categorical cross-entropy
102:39 - so let's look for it
102:41 - no whoops
102:43 - sorry on this page ah so much going on
102:46 - aha here are the
102:49 - here are the loss functions ah so binary
102:51 - cross entropy is the one i'm looking for
102:54 - um
102:57 - so i can just uh i assume i just wrote
103:00 - it incorrectly because i'm kind of
103:02 - that's like
103:03 - the python way of doing things with an
103:05 - underscore
103:08 - and the javascript way of doing
103:10 - everything is with camelcase
103:13 - so let's see if this runs with no errors
103:15 - now
103:17 - okay
103:18 - hello autoencoder so i realize that
103:20 - those of you watching this if you've
103:22 - been really following this whole thing
103:24 - this is very much going to be a 2b
103:26 - continued operation i mean i do have 20
103:28 - minutes and in previous live streams
103:30 - you'll see me scramble be like i got 20
103:32 - minutes i'm going to like try to just
103:33 - jam it all in there and get it to work
103:36 - not doing that today um
103:41 - so um but i'm gonna let's see i do have
103:44 - a little bit of time before i wrap up
103:46 - let's see if i can get a little bit
103:48 - further here so let's look at the keras
103:50 - code so i need to somehow figure out now
103:53 - ah
103:55 - so i could just create like noisy data
103:58 - what if i just made noise
104:00 - like random data and see if the auto
104:02 - encoder could produce random data
104:06 - would that be interesting or should i
104:08 - try to first import my
104:11 - uh images
104:14 - hmm
104:16 - well
104:17 - the next thing is
104:19 - yeah so this is what i need to do next
104:28 - um
104:32 - oh interesting i'm like what is going on
104:34 - here this is so crazy i'm like where's
104:36 - the y's where's the y's where are the
104:39 - y's i just realized you know what i
104:41 - think i can do this with fake data uh in
104:44 - the next
104:45 - and then the next stream will be
104:48 - actually
104:51 - the next stream will be
104:54 - actually using the real data
104:56 - so i'm reading some interesting comments
104:58 - without activation functions you will
105:00 - get pca components principal component
105:02 - analysis
105:04 - add gaussian noise then denoise
105:06 - interesting
105:08 - input noise yeah so let's just for a
105:10 - second
105:12 - let's put the let's try to create
105:15 - some training data
105:16 - so this would be known as x train
105:25 - so just for a second here
105:28 - just for um let me
105:31 - um
105:32 - let's create
105:34 - um a
105:36 - let's write a function
105:39 - random um
105:41 - i'm trying to think of what to do here
105:48 - let's consider an image
105:51 - to be an array
105:57 - of 784 values
106:01 - each value being a random number
106:07 - so this would be
106:09 - generate
106:10 - image it's not really an image
106:14 - wait why is my auto format not working
106:16 - okay
106:18 - so if i were to say
106:21 - uh x train oh
106:24 - x input
106:26 - is an array
106:33 - x
106:34 - inputs
106:37 - index
106:38 - i equals generate
106:41 - image
106:42 - so this is me
106:43 - creating like 10
106:46 - arrays of 784 numbers
106:52 - and
106:53 - kind of unnecessary to put that in a
106:54 - second separate function and i'm not
106:56 - really being thoughtful about how i'm
106:57 - organizing my code so this is the
106:59 - training data
107:01 - but
107:02 - that's just it as a raw like if i just
107:05 - do console log
107:08 - console.log x inputs
107:12 - and run this code
107:16 - huh
107:17 - so i have a mistake
107:20 - oh
107:21 - return
107:23 - image
107:25 - and let's just make these with seven
107:27 - values just for simplicity's sake for a
107:29 - second
107:30 - right these are now my this is my
107:33 - training data
107:34 - and i want these images to be the image
107:37 - eventually these values to be mapped to
107:38 - the images from processing but i'm not
107:40 - there yet so i just have
107:42 - array array array 10 of them
107:46 - um so but they need to be 784
107:49 - and the thing is
107:51 - they cannot be
107:54 - raw javascript arrays
107:56 - tensorflow works with tensors a tensor
107:59 - is just a
108:02 - bunch of numbers with a shape right is
108:05 - it an array of arrays there's an array
108:06 - of an array an array of arrays how many
108:08 - elements are in each array of array
108:10 - right um you know a
108:13 - an array
108:14 - is a list of numbers a matrix is like a
108:16 - two-dimensional array a tensor is a much
108:18 - more sort of generic
108:20 - view of of this
108:22 - um
108:23 - and can you input your logo that would
108:24 - be interesting to hear um
108:27 - to try so i need to convert these plain
108:29 - vanilla javascript arrays into tensors
108:33 - and i believe
108:36 - the way it's like re it's doing this
108:37 - like reshape i don't remember how to do
108:40 - this
108:40 - so
108:42 - i can look at the um
108:46 - ml5 does oh when i've been working with
108:48 - this all this for you i bet you i did it
108:50 - here in
108:52 - this example
108:55 - um
108:56 - classifier batch size data
108:59 - reshape yeah
109:02 - batch data oh my goodness reshape
109:06 - fit oh
109:07 - where am i making the tensors in this
109:09 - example
109:17 - oh yeah there we go
109:18 - tf tensor2d
109:20 - yeah
109:22 - so that's this is much simpler than i
109:24 - so
109:25 - the x
109:26 - train could just be
109:29 - tf tensor let me just paste this in here
109:32 - yeah tensor2dx
109:35 - inputs
109:36 - now i think like i could give it batch
109:38 - sizes and all sorts of things but
109:40 - i think it's going to infer things
109:42 - correctly and if i just say x train dot
109:45 - print
109:47 - let's see what happens so this is
109:48 - basically i generated these 10
109:51 - arrays of 784 numbers
109:53 - and then i'm looking at my watch that
109:55 - does not exist it's four hairs till i
109:56 - have to go
109:58 - and then i'm creating a 2d tensor it's
110:00 - 2d
110:02 - because it is an array of arrays
110:10 - yeah this looks good look at this
110:13 - my memory of how to work with tensorflow
110:18 - is really um
110:22 - is really really coming along here i'm
110:23 - i'm enjoying seeing some of the nice
110:25 - feedback in the chat um from ali thank
110:28 - you so much from anurag i don't know if
110:31 - you're referring to this class or
110:32 - something else but thank you
110:35 - um and i know that i'm kind of standing
110:37 - in front of i need a little like to move
110:39 - this over here okay
110:40 - so now i should be able to go back to
110:43 - essentially doing the equivalent of
110:47 - the fit function
110:51 - so for example this is python but i got
110:54 - to do this in tensorflow.js i'm going to
110:56 - fit
110:57 - x train and x train and then my
110:59 - assumption is
111:02 - like these
111:02 - so this is really really weird x-train
111:04 - x-train i'm gonna come back to that this
111:06 - is why it's like is this supervised
111:08 - learning or unsupervised learning it's
111:10 - kind of interesting to think about
111:11 - um
111:12 - but then i assume i would do have an
111:15 - object that would have like epochs 50
111:19 - batch size
111:21 - uh two like 256
111:24 - shuffle uh true
111:26 - i'm not going to worry about the
111:27 - validation data right now
111:30 - that's probably really important but so
111:32 - i feel like the equivalent must be this
111:34 - now this is
111:36 - um
111:38 - and this must be as well is this async
111:40 - an asynchronous function
111:42 - tf
111:44 - tensor fit is so let me look at
111:46 - model.fit
111:48 - the fit function
111:52 - x y args
111:58 - fit
112:00 - compile oh right so look this uh a
112:02 - weight model dot fit
112:04 - batch size epochs model dot fit
112:07 - the x's and the y's that's a weight
112:10 - but to create a tensor the tensor is
112:13 - synchronous so
112:14 - this is asynchronous
112:16 - so i could use
112:18 - the then but i'm going to do this
112:21 - i'm going to write an async function
112:23 - called train model
112:29 - and
112:30 - i got it the format on save is gone i'm
112:33 - not going to deal with that right now
112:34 - come back to that
112:36 - then i'm going to say await
112:39 - now there should be
112:41 - a callback that i can give this so that
112:44 - i can
112:45 - sort of console log the loss as it's
112:48 - training over 50 epochs
112:50 - so
112:51 - i could call and and by the way if
112:53 - you're like what
112:55 - is a weight
112:57 - what is async hey boy do i have a set of
113:00 - video tutorials to sell you
113:03 - i have no magic way to make them appear
113:05 - here but i'm sure if you search await
113:07 - async coding train you will find those
113:09 - video tutorials that go over promises
113:12 - and all of this sort of syntax
113:14 - okay um
113:16 - so
113:17 - now
113:20 - um i want to look for the callbacks
113:23 - x y args verbose
113:26 - will it just log things automatically if
113:28 - i
113:29 - make verbose equal true
113:35 - maybe it'll log stuff automatically for
113:37 - me so what i was planning to do is put
113:39 - these callbacks in
113:41 - because basically i can have oh there's
113:42 - a lot of them i can have a call back on
113:44 - train begin on epoch begin and then i
113:47 - can look at the logs which have the loss
113:48 - let's just try running this
113:51 - i turn into a pumpkin in eight minutes
113:57 - hey that worked what
114:00 - now the loss
114:02 - didn't really seem to do anything i mean
114:03 - i am training it off of random noise
114:06 - that was like so fast
114:08 - okay hold on
114:10 - let's make um
114:12 - let me give it up maybe make a thousand
114:14 - random images just to make it uh more
114:16 - data
114:17 - that was way too fast for me to look at
114:20 - and
114:20 - also um i want to artificially slow it
114:23 - down
114:24 - okay great
114:27 - so i have a feeling that i'm not getting
114:30 - anywhere because i'm feeding it random
114:32 - noise
114:33 - but i don't have any errors
114:38 - so i could look at one of its outputs
114:39 - and make it into an image but it would
114:41 - just be noise so i have to assume that
114:44 - i'm doing this correctly on some level
114:48 - um i did kind of one thing that i might
114:51 - like to do is
114:53 - i did in the code specify a learning
114:57 - rate which was not specified in the
114:59 - example
115:01 - so like for what for example what if
115:02 - would this work
115:04 - if i just do this
115:07 - and this will be sort of more default
115:09 - stuff just curious
115:14 - same same results but i just
115:18 - you know there's no reason for me to get
115:20 - really specific about the hyper
115:22 - parameters here
115:24 - when um
115:27 - what is the i'm gonna put this back
115:30 - in this is very exciting to see this
115:33 - work
115:39 - um
115:41 - zarus phil why don't you apply gaussian
115:43 - noise that's a good idea
115:46 - but i'd have to like
115:48 - write a gaussian noise function in
115:52 - javascript
115:53 - although i think i could get one really
115:54 - quick all right that's i like this i
115:56 - have five minutes
115:58 - um
116:01 - i i think i might have implemented the
116:03 - gaussian the random gaussian function in
116:06 - p5
116:07 - so i think i could just grab that i know
116:09 - there's one in there
116:11 - source
116:12 - math
116:14 - noise no noise would be actually noise
116:17 - math just math no random
116:21 - uh where's the random gaussian
116:27 - so this is the
116:29 - implementation of a random
116:37 - mean
116:41 - okay i think i can
116:42 - i think i can manage this
116:48 - oh but
116:50 - it's not really going to be
116:51 - gaussian the gaussian noise i was sort
116:53 - of thinking
116:54 - of i think this is this is too much
116:57 - effort right now it's not really going
116:59 - to give me i should move on to actually
117:01 - generating the shapes so
117:05 - if you ever wanted to have a reason to
117:08 - tune into the next live stream which
117:09 - will be this coming friday if i had to
117:12 - guess around 10 a.m eastern it will be
117:14 - part two of this auto encoder like i've
117:17 - got
117:18 - all the code
117:19 - with tensorflow.js for an auto encoder
117:22 - right here in node the the only i've
117:25 - spent some time explaining what an auto
117:27 - encoder is i can't emphasize it enough
117:30 - that um
117:33 - you know if you're looking for something
117:34 - to wah
117:35 - uh two minutes like um this particular
117:39 - video will be incredibly helpful it's
117:42 - just like three minutes long so this
117:43 - will give you excellent background to
117:45 - what i'm trying to do to wait uh for
117:47 - next uh for friday when i continue this
117:50 - but what i want what i need to do now is
117:53 - replace this generate image function
117:56 - with
117:57 - some code that
118:00 - actually goes into this data folder
118:03 - and pulls out each one of these images
118:06 - and translates that into an array of 784
118:11 - numbers
118:12 - then
118:13 - will the loss as i train the auto
118:15 - encoder
118:16 - consistently go down and
118:20 - could i do start to try
118:22 - applying the auto encoder to some
118:24 - applications like denoising
118:26 - or generating new squares what happens
118:30 - if i train it with circles and squares
118:32 - can i morph through the latent space of
118:35 - square squirkles
118:37 - oh there's so much that could be done
118:39 - um
118:40 - so um but i'm gonna just leave this as
118:43 - where we are today
118:45 - uh this is this has been like the most
118:48 - like semi-serious
118:51 - coding lecture
118:54 - uh live stream that i've done in a while
118:56 - curious for your feedback how this
118:58 - compares um
119:01 - um i hope you know we'll see we'll see
119:02 - what the future brings but
119:04 - uh i um i doubt this is i'm gonna hit
119:07 - stop on my record to disk engine
119:10 - let's stop i'm just curious by the way
119:12 - to look at that file
119:14 - i'll try to answer some questions but
119:16 - the file i just recorded today
119:19 - is
119:21 - gate modified
119:25 - 4k obs
119:26 - 11 15.
119:29 - gigabytes ladies and gentlemen and
119:32 - others
119:34 - sorry uh
119:36 - um
119:37 - uh yeah so that probably worked without
119:41 - a lot of uh
119:42 - that's probably a high quality video 57
119:44 - gigabytes of the entire all my different
119:47 - feeds today if this ever wanted to be
119:49 - edited into
119:50 - a more step-by-step tutorial just from
119:52 - this live stream
119:54 - uh training on purlin noise would be
119:56 - interesting oh and uh i should probably
120:00 - pick another loss function so uh
120:02 - uh k weekman if uh let's chat in the
120:05 - discord um
120:08 - later so maybe you can give me some
120:09 - helpful tips and advice of some things i
120:10 - might want to revisit when i come back
120:12 - on friday
120:13 - let me go back to the chat to see if
120:16 - there's any questions i can answer
120:18 - [Music]
120:20 - before i go
120:24 - is
120:25 - is tf slower in node.js so actually this
120:28 - is a really interesting question
120:31 - um
120:32 - and there's no like easy answers to
120:34 - these questions because there's so much
120:35 - it depends but
120:37 - tensorflow.js
120:39 - in node
120:40 - should be faster than tensorflow.js in
120:42 - the browser because it is
120:44 - uh um it is linked to native tensorflow
120:48 - so tensorflow in the browser is running
120:49 - a tensorflow.js implementation that all
120:51 - the math happens with um webgl context
120:54 - or just the browser cpu
120:56 - tensorflow.js in the browser sorry in
120:59 - node is running actually native
121:00 - tensorflow so i what i hear is that
121:03 - cpu tensorflow.js and node is equival is
121:06 - mostly equivalent to gpu webgl
121:09 - tensorflow in the browser i don't know
121:10 - if that's totally true but obviously the
121:12 - fastest thing i could do would be to run
121:14 - tensorflow.js in node linked to like
121:18 - the
121:18 - the gpu of my computer i don't know if
121:20 - i'd have to install cuda or some other
121:21 - kind of thing for that but i'm not doing
121:23 - that now
121:24 - um yep uh what type of a bunch of other
121:27 - questions are being asked that i don't
121:28 - know the answers to
121:30 - um thanks everybody for tuning in i'm
121:32 - just gonna keep playing this song i will
121:34 - be back
121:35 - on friday
121:37 - to continue this auto encoder project
121:41 - i don't know if it's going to happen but
121:42 - a whole new
121:44 - coding challenge video it's about 30
121:45 - minutes long
121:47 - a lot of
121:48 - production value stuff went into it
121:50 - which i don't which is who knows that's
121:52 - a good or bad idea but it's coming out
121:53 - this week
121:55 - it is the video
121:56 - from the adopt-a-function p5.js uh
121:59 - series um if you're um if you're if
122:02 - you're on nebula or if you're a coding
122:03 - trained member
122:05 - you will get to see that early
122:08 - so
122:09 - you can join through youtube memberships
122:10 - or sign up for the curiosity stream
122:12 - bundle that i should probably not be
122:14 - talking about because today's
122:16 - video is sponsored today's stream is
122:18 - sponsored by brilliant um if you love
122:21 - the cody train and learning stuff for me
122:23 - i think you'll also love learning from
122:24 - brilliant um sign up for free
122:26 - brilliant.org coding training okay um
122:29 - join the discord say hello there i will
122:32 - see you all next time this coming friday
122:34 - probably in the morning stay tuned
122:36 - follow my twitter join the discord
122:39 - all that we'll get announcements uh
122:40 - subscribe and click the bell i guess
122:42 - that'll do something if you want to just
122:44 - get there's lots of ways you can get
122:45 - notifications about when i'm live
122:46 - streaming but really turn off all your
122:48 - notifications you don't need them from
122:50 - me but if you wanted them you could get
122:52 - them i don't know what to say about that
122:54 - you probably have too many notifications
122:56 - it's really fine you don't need to have
122:58 - another one
123:01 - goodbye everybody
123:03 - as always i always forget that this stop
123:05 - this stop this stop this stop i'm gonna
123:07 - do this stop this stop i'm gonna do this
123:09 - this stock this stop just stopped
123:15 - [Music]
123:45 - [Music]
123:54 - never forget this
123:57 - [Music]
124:07 - never forget this dot somebody composed
124:10 - that song for me
124:20 - [Music]
124:27 - i'm going to say once again
124:29 - here we go
124:33 - [Music]
124:40 - it's look forward to cartesian
124:42 - coordination
124:44 - [Music]
124:52 - [Music]
124:58 - autotune and the internet will fix that
125:00 - for me
125:12 - [Music]
125:18 - song
125:26 - cartesian coordinates
125:28 - [Music]
125:36 - unicorns and rainbows and cupcakes what
125:38 - else is there
125:42 - yes kittens thank you very much kittens
125:44 - and rainbows and cupcakes notice that
125:46 - look what i get i'm really losing my
125:48 - mind
125:50 - okay let's do it
125:52 - [Music]
126:07 - the kittens the
126:09 - kittens the kittens kittens and kittens
126:13 - and kittens the kittens
126:20 - [Music]
126:29 - the kids
126:31 - kids
126:33 - [Music]
126:39 - [Music]
126:59 - [Music]
127:06 - i feel just sort of like a nice
127:09 - feeling of relaxation
127:11 - everything's gonna be okay today
127:13 - dream is not broken it has not frozen
127:15 - this is a this is a wonderful thing
127:17 - okay we're gonna do it i'm really
127:19 - getting to something i need my sound
127:21 - effects
127:23 - [Music]
127:34 - what else is there unicorns and rainbows
127:41 - [Music]
127:52 - generation analysis things
127:55 - that i will use continuously over and
127:57 - over again
127:58 - first thing i need to do is yes
128:01 - [Music]
128:16 - [Music]
128:54 - you