00:00 - oh hello and welcome to another coding
00:02 - challenge now this coding challenge is
00:04 - number 99 which means the next coding
00:07 - challenge is number 100 and I'm going to
00:11 - go what I feel this pressure to do
00:12 - something special so please in the
00:14 - comments write your suggestions for
00:16 - coding challenge number 100 and maybe
00:18 - I'll think of something or you'll help
00:19 - me think of something ok so what's
00:21 - happening now I am going to do a coding
00:24 - challenge to make a neural network color
00:26 - predictor this is based off of project
00:28 - made by Jabril I would check out his
00:30 - YouTube channel just link in this
00:33 - video's description he has a video
00:35 - called color predictor machine learning
00:36 - demo that I'd encourage you to watch he
00:38 - also actually came on as a guest and
00:39 - I'll link to a video with Jabril where
00:41 - he talks through this color predictor
00:43 - but I'm gonna make my own version of it
00:45 - and I'm gonna use my toy neural network
00:48 - JavaScript library ok so first before I
00:51 - start coding I want to spend some time
00:54 - with you you were just taking deep
00:58 - breaths together think about flowers
01:00 - okay well III guess I should talk
01:03 - through what the problem is so here's
01:05 - here's the problem so to speak now one
01:07 - of the reasons why I love this idea
01:09 - which came from Jabril is that I'm
01:11 - always looking for really simple almost
01:13 - trivial scenarios to demonstrate a
01:16 - machine learning concept where they all
01:20 - the pieces of how the algorithm works
01:21 - it's visual it involves interaction
01:24 - involves drawing because this to me is a
01:26 - good basis for people watching and
01:28 - learning to then build their own more
01:29 - complex or sophisticated design machine
01:33 - learning system things so this is
01:35 - incredibly simple and in fact just to be
01:37 - clear you do not need a neural network
01:39 - for this it almost makes no sense at all
01:41 - to use a neural network for this but it
01:43 - makes the point you might have heard
01:45 - this you might have heard this idea that
01:47 - a neural network is a universal function
01:51 - approximator so I think that this video
01:57 - in this topic in this demonstration will
02:00 - unpack what this means in a in a nice
02:02 - way what do I mean by that so what is
02:05 - the problem that we're trying to solve
02:07 - so the problem is let's say I have a
02:11 - color some RGB
02:13 - color some RGB color and I want to put
02:18 - text on top of that color so I could
02:20 - make a more complex problem which I
02:22 - would encourage you to do as an exercise
02:23 - after watching this what would be the
02:25 - most pleasantly looking or complementary
02:28 - that's a technique that's actual thing
02:30 - color to overlay on that RGB color but
02:33 - I'm just gonna ask a simple question
02:34 - which looks better black or white and we
02:42 - could get an old discussion of why you
02:43 - know perception and what looks better
02:45 - but I just mean just in the sort of
02:47 - arbitrary sense like which is easier to
02:48 - read which is more legible and we could
02:51 - write a function right we could write a
02:53 - function a JavaScript function I'm just
02:59 - checking to see right and that
03:00 - JavaScript function takes as its
03:02 - arguments on our a G and a B and what it
03:07 - does is it returns maybe it returns I
03:11 - mean black or maybe somewhere else in
03:14 - the function it returns white and maybe
03:17 - we just have like this if statement and
03:19 - maybe I'm doing something like if R + G
03:22 - + B is less than 100 or less than 200
03:26 - returned black otherwise return white so
03:30 - this is the idea this is a function it
03:33 - takes inputs how many inputs 3 and it
03:39 - returns an output how many outputs 1 but
03:42 - out of 2 possibilities is important here
03:45 - there are 2 possible out out - 2
03:47 - possibilities
03:48 - it takes one output it to function it
03:52 - takes three inputs and returns one
03:54 - output the inputs are numbers between 0
03:58 - and 255 and the output is one label
04:02 - which is a string but another way I
04:04 - could think about this is it could
04:06 - return a kind of probability value how
04:09 - likely is it that black looks better and
04:11 - how likely is it that white looks better
04:12 - and that would be that would be kind of
04:15 - also 2 so 2 floating point numbers you
04:18 - could think of it that way so this is a
04:20 - function so a lot of machine like
04:23 - imagine this so now this function takes
04:24 - the RGB color now let me tell you
04:26 - let me give you another function right a
04:28 - function that takes a image data of 200
04:32 - by 200 pixel image and then returns
04:34 - what's in that image now you could
04:36 - imagine in this case deciding whether it
04:39 - should be black or white is just a
04:40 - matter of okay should i if it bright as
04:43 - a dark which color is gonna be like a
04:44 - bright color looks better on a dark
04:46 - color a dark color looks better on a
04:47 - bright color but if I took in a full
04:49 - image I needed to return whether it's a
04:51 - cat a dog a turtle a coffee mug cell
04:54 - phone a walking stick a conductors baton
04:57 - I don't know where my brain is going
04:59 - here a toy tricking right try writing a
05:05 - bunch of if statements to do that well
05:07 - if the pixel colors are this and shaped
05:10 - like this right having to hard code and
05:12 - algorithm a function that takes inputs
05:15 - and generates an output would be really
05:17 - difficult this is what a neural network
05:21 - is for and just to make this case here
05:24 - the idea here is that a neural network
05:28 - can approximate any function it can
05:32 - learn to receive inputs and return the
05:36 - outputs for any input data for any sort
05:40 - of problem in field is this true that at
05:42 - Google any in capital letters the big
05:45 - underline is true that's an open
05:46 - question what are the limitations what
05:48 - should and should not we be doing should
05:50 - we even be using a neural network for
05:52 - this task are we causing harm by doing
05:54 - this machine learning task but those
05:56 - those questions aside now we can say
05:58 - well if I have this quote-unquote neural
06:01 - network thing what if I were to just
06:04 - send three inputs into it our G B and
06:09 - then I want to receive two outputs
06:14 - probability of black probability of
06:18 - white this is now a universal function
06:22 - up approximator it is going to stand in
06:25 - so what is the neural net machine
06:27 - learning doesn't necessarily replace you
06:29 - can think of it as I mean it will
06:30 - machine learning replace the need to
06:32 - write code completely at some point
06:33 - maybe but here what I would make the
06:36 - case is that
06:37 - machine learning a neural network might
06:38 - replace the guts of a function that you
06:41 - might hard code otherwise okay boy am i
06:44 - spending a long time explaining this so
06:47 - now how what goes here what goes here
06:50 - now if you want to learn more about the
06:52 - structure of a neural network and the
06:54 - internals of it I'd refer you to the
06:56 - three blue one brown video series as
06:58 - well as my video series which goes
07:01 - through building this neural network
07:02 - library in JavaScript for us as the user
07:06 - of the neural network library the only
07:08 - things we need to decide are how many
07:10 - how many inputs and how many outputs and
07:19 - then so this is inputs and outputs are
07:23 - the things we as the end user of the
07:25 - neural network look at and control we're
07:28 - sending in the input we're reading the
07:30 - output we're doing something with the
07:31 - output we're sending you the input we're
07:34 - reading the output we're doing something
07:35 - with the output but those sort of
07:37 - quote-unquote magic which isn't magic
07:39 - it's just math numbers multiplied and
07:41 - added together all sorts of other stuff
07:43 - is this idea of a hidden layer and there
07:47 - could be multiple hidden layer there can
07:49 - be hidden layers of different nodes but
07:51 - for the sake of argument this is such an
07:53 - incredibly simple problem who knows if
07:55 - we even need the hidden layer for it we
07:56 - probably do but we can just kind of come
08:00 - pick something somewhat arbitrarily so
08:02 - I'm gonna say there are three inputs
08:06 - there are two outputs and what I'm going
08:11 - to do is just say this is what Jabril is
08:13 - so why not use the same I'm gonna add
08:15 - three hidden nodes and the idea of a
08:19 - neural network is the inputs all go into
08:23 - each hidden node they get processed by
08:26 - the hidden node they each had node
08:28 - connects to every output whoops I do
08:31 - that and then they get processed by the
08:32 - outputs and we get the results that's
08:34 - known as feed-forward what is that
08:37 - processing it has to do with the weights
08:39 - of the connections the summing of the
08:41 - values the activation of the neural
08:42 - network I think at this point it
08:44 - probably makes more sense for me to
08:46 - refer you to my other tutorials that go
08:48 - through the Macan
08:49 - this I just want to now use it and in
08:52 - the sort of higher level way as a
08:54 - library where I'm going to send in my
08:55 - inputs and look at the output and of
08:57 - course I'm gonna have to train it I'm
08:59 - gonna have to teach their neural network
09:00 - to give me certain outputs that I want
09:02 - so that's what I'm gonna get into when I
09:04 - go and write the code right now
09:07 - okay so first let's take a look at
09:09 - gibreel code he might have a newer
09:11 - version by now but this is what he
09:13 - demonstrated last week on the coding
09:15 - train so I could say like oh I think
09:17 - white looks better on this color by the
09:20 - way I'm like have no ability for our
09:25 - talent for visual design whatsoever saw
09:27 - him to get all the track
09:28 - I don't know black looks better black
09:30 - what's better white looks better so you
09:32 - can see this is me active this is this
09:35 - dot represents the computer guessing
09:38 - which ones it thinks it should be and me
09:40 - clicking has to do with me giving this
09:44 - or like training information like hey
09:45 - neural network it should be this one so
09:47 - I'm gonna go through a bill all the
09:49 - pieces of this there's some other stuff
09:50 - going on in here where Jabril is using a
09:52 - genetic algorithm and there's like this
09:54 - sort of voting thing going on but let's
09:55 - let's go let's just start building some
09:57 - code from scratch and we can kind of
09:58 - compare and contrast or you can compare
10:01 - test on your own later ok so this is my
10:03 - color predictor I'm going to go to an
10:05 - empty sketch the first thing that I want
10:07 - to do is I'm just going to create
10:09 - variables for r g and b and when the pro
10:14 - i'm gonna write up maybe i'll write a
10:16 - function pick color and I'm just gonna
10:20 - say R equals random 255 GB and I am
10:27 - going to then draw the background RG B
10:32 - and I'm gonna say mousepressed pick
10:38 - color so let me make a few key points
10:42 - here me in creating this example in
10:44 - writing this code I'm not thinking about
10:46 - interaction design I'm not thinking
10:48 - about visual design I'm not thinking
10:50 - about optimized efficient code I just
10:52 - want to sort of demonstrate the idea and
10:54 - get something up and working quickly you
10:56 - the viewer can then take this and make a
10:59 - more interesting thoughtful designed
11:02 - version of it even
11:03 - perhaps with a different algorithm or a
11:05 - different problem altogether but let's
11:07 - just see now this should be enough code
11:08 - for me to every time I click the mouse
11:11 - get a new random color okay so I might
11:14 - as well also pick that color in setup
11:17 - now I also want to draw let me say text
11:20 - size 64 then I want to say I mean - no
11:26 - stroke I think if text can have an
11:28 - outline in a fill I'm gonna do fill 0
11:31 - text black and let me do
11:35 - text-align:center also so black and that
11:42 - should be what is my let me make the
11:44 - dimensions of this a little simpler 400
11:46 - by 300 so this would be 150 then I guess
11:51 - Oh 150 150
11:54 - I don't know and 250 150 and this would
11:59 - say white so let's see how this goes all
12:04 - right so that's a little bit too big but
12:06 - I could also just make it wider 600 and
12:10 - then this would be 200 and 400 right
12:16 - there we go okay this one should be fill
12:23 - 255 okay so now I have a system where at
12:28 - least I am seeing which one it should be
12:32 - black or white I mean I'm seeing both
12:34 - colors written on top of the background
12:36 - let's draw a line down the middle I
12:38 - think maybe visually it needs that I
12:40 - don't think i centered these correctly
12:42 - but whatever okay okay we're getting
12:48 - somewhere
12:49 - Center center someone in the chat is
12:51 - telling me to use center center why not
12:53 - so that aligned it Center vertically -
12:56 - beautiful thank you well that was an
12:57 - excellent suggestion okay so now what I
12:59 - want to do is I guess what
13:01 - we're ready this is what I love about
13:04 - this problem we're ready for the neural
13:07 - network because we could do it so what
13:13 - do i what do I need I want to make a I'm
13:15 - gonna call it brain
13:16 - I'm gonna make a variable called brain
13:18 - it's gonna be the neural network now I
13:19 - just don't get a neural network in
13:21 - JavaScript just by the nature of
13:23 - programming JavaScript I'm getting it
13:25 - because I have imported already into my
13:28 - HTML file to files and nsj and matrix
13:31 - digest this is a little toy neural
13:33 - network library that I developed in a
13:35 - whole set of video tutorials at some
13:37 - point in the future I'm going to replace
13:38 - this with this new project called
13:40 - tensorflow j/s which is a lower level
13:42 - machine learning library and almost also
13:44 - ml5 is this other library but I'll come
13:45 - back to that another time I'm still
13:47 - using this little toy neural network so
13:49 - what I want to do now in the code is I
13:51 - just want to say brain in setup I want
13:54 - to say brain equals a new neural network
13:57 - now it expects three arguments three
14:02 - arguments now this is not universal to
14:04 - how neural network libraries work this
14:06 - is a very simple one and is very basic
14:08 - features and what it expects is how many
14:12 - inputs
14:13 - how many outputs and how many hidden
14:16 - nodes but not in that order inputs
14:18 - hidden outputs so this we can see is 3 3
14:20 - 2 that's the architecture the model
14:23 - architecture that I have designed three
14:26 - three two wonderful now I've got them
14:30 - done I got it boo boo boo you would know
14:32 - I keep going now what I could do is
14:34 - let's say every time so let's make let's
14:37 - let's let's make a variable called which
14:41 - like which one is better black or white
14:44 - and I will just start with saying black
14:50 - and what I'm gonna do let's do the same
14:54 - sort of technique that gibreel did if
14:56 - which equals black then then I'm gonna
15:02 - draw a circle a circle which is where at
15:10 - two hundred two hundred three hundred
15:14 - sixty sixty and I there and then else if
15:22 - it's white then draw it at four hundred
15:25 - and so this would be fill zero this
15:28 - would be fill two
15:29 - fifty-five and we're still no stroke
15:31 - okay so now we still have to be very far
15:35 - down so let me move this up to 200
15:42 - that's no sense of dimensions whatsoever
15:47 - perfect oh this looks weird now it's not
15:50 - all centered but fine oh my god I can't
15:52 - I can't take it I can't take it let's
15:54 - let's move this I really shouldn't be
15:57 - doing this but I'm going to let's make
15:59 - this 100 100 and let's make this 200 200
16:06 - oh okay I feel better now
16:10 - okay so it's always going to it's always
16:12 - going to pick black right now because no
16:15 - matter what's I've just made which equal
16:18 - to black but I can use the neural
16:21 - network now I could use the neural
16:23 - network the neural network is my
16:24 - function approximator let's actually
16:26 - let's let's actually write this code
16:28 - with our own non neural network first
16:31 - just to make this case I'm gonna write a
16:33 - color predictor and I'm gonna say get an
16:36 - RGB and now if I'm gonna just say if R +
16:40 - G + B is greater than 300 then return
16:44 - black else return white so I'm gonna do
16:50 - a hard coded this is my own human
16:52 - learning algorithm I've decided that
16:54 - this is what it means to predict which
16:56 - color would be better and then I'm going
16:58 - to say let which equal color predictor
17:03 - RGB so now we can see it's making that
17:08 - prediction based on my algorithm I wrote
17:11 - an algorithm to make that prediction now
17:14 - so we've got this we could be done know
17:16 - was she learning necessary I finished
17:18 - this project now what I want to do
17:20 - though is I want to chim to comment this
17:23 - out and I'm going to say what am I going
17:25 - to say I'm going to say first I need to
17:28 - make some inputs so the neural network
17:30 - library expects as inputs right my
17:34 - library expects and this is pretty
17:36 - typical of any kind of machine learning
17:38 - based library that you might use it
17:40 - expects the inputs to come in
17:43 - an array of three numbers and typically
17:47 - you're going to want to have those
17:48 - numbers normalized between zero and one
17:51 - so this is what I need to send into the
17:53 - neural network so inputs equals an array
17:58 - and so how do i normalize these values I
18:00 - can just divide them all by 255 and
18:03 - again more likely this is going there's
18:05 - going to be a much longer process of
18:07 - sort of cleaning and normalizing your
18:08 - data but in this case of a single color
18:11 - super easy to do now what I'm going to
18:14 - do is I'm going to ask for the output
18:16 - from the neural network let outputs
18:19 - equal and I'm going to say brain dot and
18:22 - the function write the function to do
18:24 - the feed-forward algorithm to send the
18:27 - data through and get the result back in
18:29 - my library
18:30 - it's called predict because I'm making a
18:31 - prediction another term for this might
18:33 - be inference guess that type of thing so
18:37 - I'm gonna say brain dot predict and I'm
18:40 - gonna pass in the inputs now let me just
18:43 - let me just console.log those outputs
18:46 - just so we can see and this is gonna
18:50 - sort of break but let's just see what
18:52 - the outputs look like whoa hold on why
18:58 - is this to okis draws right so one thing
19:01 - I just realized is I'm kind of I'm doing
19:03 - all this in the draw loop which is sort
19:05 - of silly so let me actually just say no
19:08 - loop and then in pick color in pick
19:14 - color which is where where does the pick
19:17 - color right here I'm gonna say redraw so
19:20 - I only want to like redraw the canvas
19:21 - update I don't have anything animating
19:23 - so I don't need the draw loop to be
19:24 - going over and over again so cannot read
19:28 - property predict of undefined Sketch up
19:30 - yes oh you know what oh why do I have
19:35 - that bug I created the neural network
19:37 - after I call to pick color the neural
19:39 - network needs to exist before I call
19:41 - pick color okay that's good to know
19:44 - great so we can see look at this and why
19:46 - do I have this happen twice
19:48 - twenty nine why is it happening twice
19:52 - you know I guess it's going through the
19:54 - draw loop once
19:56 - so maybe yeah interestingly okay I'm not
20:03 - going to worry about I'm not going to
20:04 - get I'll fit all of that later
20:06 - the point is oops every time I click we
20:12 - can see these this is the output of the
20:14 - neural network it's an array with two
20:17 - floating-point numbers and those I'm
20:19 - considering to be like the probability
20:21 - right if this number is higher it should
20:25 - be a white maybe black is the correct
20:27 - color if this number is higher the other
20:29 - one what's my hand disappeared the white
20:31 - color should be the one of ik now I have
20:32 - to I haven't implemented some things
20:34 - there's a particular algorithm which I
20:35 - really should put into my neural network
20:37 - library called soft max have to make a
20:39 - video tutorial about that in the future
20:40 - which would ensure that these two
20:43 - numbers these add up to a total of one
20:46 - and really represent a probability but
20:48 - my neural network is very simple I can
20:49 - just look at which of these output
20:51 - numbers is bigger so I can say then
20:54 - right here I can say now if outputs
20:58 - index 0 is greater than outputs index 1
21:02 - will make that mean return black
21:08 - otherwise return white so now I have my
21:15 - color predictor function no longer uses
21:17 - a hard coded algorithm it uses the
21:20 - results of sending the input data
21:22 - through a neural network so let's go
21:25 - ahead and run this and I can click that
21:28 - you can see here it's kind of always
21:30 - picking white by refresh still always
21:34 - picking white by refresh it's kind of
21:36 - always picking black so what's going on
21:38 - here how come this isn't working why is
21:40 - this not learned properly which color
21:43 - should go on top of the other color
21:45 - guess what the the entire mechanic and
21:50 - all of the settings all the parameters
21:52 - all of the weights of all these
21:53 - connections on the neural network were
21:55 - initialized completely randomly a neural
21:58 - network isn't just going to learn as if
22:00 - by magic it needs to be taught and there
22:03 - are lots of different strategies for
22:05 - training and working
22:06 - the neural network one of those
22:08 - strategies is something called
22:09 - supervised learning and you probably
22:12 - can't supervised learning which I have
22:13 - covered in other videos in particular my
22:17 - doodle classification coding challenge
22:19 - so you might look at that as an example
22:21 - but what's going on here so in a sort of
22:24 - normal bit more true data science driven
22:26 - machine learning context we might
22:28 - prepare a giant training set like I'm
22:32 - going to make a big spreadsheet of every
22:34 - RGB color I can think of and which one
22:36 - looks better black or white that's my
22:38 - training data set to pass through and
22:41 - train this neural network with then I'm
22:43 - going to have a testing data set and
22:44 - that testing data set I'm not it's not
22:47 - part of the training data set because I
22:48 - don't I don't want the neural network to
22:50 - know about it but it also has a bunch of
22:52 - labeled data colors with black or white
22:55 - labels then I'm gonna pass that through
22:57 - and see how well the neural network does
22:59 - guessing against those and if it starts
23:01 - to do well then I could say my model is
23:03 - complete it has been trained I can save
23:05 - it and I can deploy it in some
23:06 - application which has to pick black or
23:08 - white on the fly but I'm not gonna do
23:10 - any of that in this video I'm gonna live
23:12 - in sort of a loosey-goosey interactive
23:14 - world where I'm just gonna let it guess
23:17 - randomly and I'm going to click in order
23:19 - to correct it so I'm gonna I'm going to
23:21 - train the neural network one data point
23:24 - at a time with no training data no
23:26 - testing data just random data as I go so
23:29 - you might think about how would you
23:31 - restructure this to in a more sort of
23:33 - traditional training testing deployment
23:38 - context okay so I want to click what I'm
23:41 - gonna do here is as the trainer I'm
23:43 - gonna click on the side of the canvas
23:45 - that I think looks better like I think
23:47 - white looks better so I'm going to click
23:48 - over here just to make this a little bit
23:51 - easier to follow I'm also going in to
23:53 - draw I'm going to draw a stroke wait for
24:01 - stroke 255 0 I guess I'm going to align
24:05 - with / to 0 with width / 2 height there
24:14 - we go so I'm gonna draw this so I can
24:16 - click wise these are totally not
24:18 - centered at all I'm like a lunatic
24:21 - either they're not in the right place i
24:23 - I'm sorry I have to correct that it's
24:26 - making me crazy it is how wide is the
24:29 - window it's 600 wide 300 is the middle
24:33 - Oh silly me 15350 thank you very much No
24:39 - 450 450 thank you very much okay 152
24:45 - please bear with me 450
24:49 - okay now we're doing well okay so now
24:52 - the idea here is every time I click over
24:55 - here I want to teach the neural network
24:57 - which one I think it should be so how do
25:00 - I do that so I told you there was a
25:02 - function called predict and the function
25:05 - called predict would send in the input
25:09 - data and give me an output prediction
25:11 - now what I want to do is I want to use a
25:13 - different function called train so each
25:16 - time I click the mouse where is that
25:18 - mouse press before I pick the new color
25:21 - I want to determine is the mouse on the
25:24 - right side or the left side
25:25 - so if so so I want to create some inputs
25:30 - which is an array and we just let put
25:35 - inputs and if Mouse X is greater than
25:39 - width divided by 2 then the correct the
25:44 - correct actually so I'm sorry I want to
25:46 - create some targets this is known as
25:48 - targets I mean there's gonna use
25:49 - different terms for all these things but
25:51 - targets are the target outputs I want so
25:53 - if I click on the right side I want the
25:57 - target outputs for white and white means
26:00 - the second number is greater than the
26:02 - first number so the targets if I click
26:05 - on the right should be 0 1 these is the
26:10 - correct this is the correct output if
26:14 - that I that I'm telling the neural
26:17 - network should be if I'm clicking on the
26:18 - right side else the targets and I know I
26:26 - could use one of those ternary bla bla
26:28 - bla things but this is just going to
26:29 - have
26:30 - do the targets are if if the left should
26:35 - be one come zero let's pick up the pace
26:36 - here people by people I need me not you
26:39 - you're doing you're doing great if
26:40 - you're actually still watching this and
26:43 - now what I'm gonna do is I'm gonna say
26:44 - brain dot train up I need those inputs
26:48 - so the inputs are the same exact thing I
26:50 - did here the inputs are the current RGB
26:53 - and what I want to do is I want to say
26:55 - hey train brain train yourself with
26:58 - these inputs with these targets and in
27:02 - fact this now is going the neural
27:05 - network is going to what's it going to
27:06 - do I'm saying here are the inputs here
27:08 - are the correct outputs that go with
27:10 - those inputs do whatever adjustments you
27:12 - need to do whether you were right or
27:13 - wrong just figure it out and what is
27:16 - that figuring out so interestingly
27:17 - enough I knew this is worth even though
27:19 - this is covered in much more detail in
27:21 - my other videos let's say I let's say
27:24 - the neural network I feed in some inputs
27:27 - and what it actually gives me is like
27:30 - 0.8 0.2 right this is what it gives me
27:35 - as the outputs but ice cave it I'm
27:39 - training it I'm gonna give it targets
27:40 - and the correct targets are 0 1 that's
27:45 - what that's the output that I wanted to
27:48 - get that's the correct output so what
27:50 - the neural network does is actually
27:52 - calculate something called an error and
27:54 - the error is really simple it's simply
27:57 - the desired the desired - the guess or
28:02 - the targets - the prediction or the
28:05 - targets - the outputs so the error would
28:08 - actually be negative zero point eight
28:10 - one - and point zero point eight
28:13 - interestingly enough very symmetrical
28:15 - there so this would be the error and
28:17 - then what happens inside that train
28:19 - function an algorithm called back
28:21 - propagation happens the back propagation
28:24 - takes this error and sends it backwards
28:26 - so when I do prediction I'm sending the
28:28 - data forward through the neural network
28:30 - the training process is about looking at
28:33 - the outputs calculating an error and
28:34 - sending the error backwards through the
28:36 - network and all these little changes all
28:38 - these weights that are adding up numbers
28:39 - new
28:40 - they all get adjusted so the errors
28:42 - would adjust all the parameters and
28:43 - that's what's happening again you could
28:45 - dive into my other tutorials which go
28:47 - through this in more detail but that's
28:49 - what's happening right here in this
28:50 - function so we are ready to go right all
28:58 - right so I'm gonna what I'm gonna do
29:01 - maybe we'll do I'm gonna train this for
29:03 - a while you'll watch if you're watching
29:05 - the edited version this it'll speed
29:07 - through fast if you're watching this
29:08 - live here we go okay I'm back so I tried
29:21 - training this for a while I tried
29:22 - talking about it for a little bit I
29:23 - didn't really get very far even though I
29:25 - think you can see like I I'm gonna like
29:27 - I'm picking and it's kind of actually
29:29 - whoops no I should really move it's
29:31 - giving me sort of different results
29:33 - that's black this one is black that's
29:35 - correct that one is white that's correct
29:36 - look at this yeah hey I think we're good
29:40 - we could see that it's not kind of
29:41 - making some decisions we think this one
29:42 - should be white let's correct it that
29:44 - seems right this is definitely right
29:46 - that seems right this seems right this
29:48 - seems right right right black is better
29:53 - with this one white is better I don't
29:57 - know why anyway you can see it's kind of
30:00 - getting I don't know that I really give
30:02 - it enough training data to really work
30:04 - optimally and maybe I could be an
30:06 - interesting project if this were like
30:07 - deployed in a distributed way on the web
30:09 - and thousands of people could all come
30:11 - and click on it and like through and
30:13 - train it together as a group of people
30:16 - in the world but let's try training it
30:18 - automatically to see if that works a
30:21 - little bit better so how are we gonna do
30:22 - that so let me go back to the code
30:24 - remember this nice little bit of code I
30:27 - had here why not let's train it to
30:30 - actually learn a certain threshold so
30:33 - I'm going to I'm gonna write a function
30:36 - here called train color and it gets an
30:46 - RG and B and it's going to return black
30:49 - or white and what I'm going to do now is
30:52 - in set up the
30:54 - a little bit silly before I do anything
30:57 - I'm just gonna say for let a equal zero
31:00 - is less than 1000 I plus plus and I'm
31:04 - going to pick a I'm going to pick a
31:08 - different set of random colors that are
31:12 - different from the global random colors
31:18 - then I'm going to I'm going to say the
31:22 - answer is what does a train color train
31:30 - color with RGB and you know what I'm
31:33 - gonna do I'm gonna do this targets let's
31:38 - let's skip a step here and this I can't
31:41 - remember which is which whoops let's
31:44 - just return the targets is this right
31:47 - somebody in the chat tell me if I've got
31:48 - these back routes or not let's just
31:51 - return the targets I'm kind of skipping
31:53 - some steps here and not now I'm not
31:54 - being a thoughtful about how I'm
31:55 - organizing this but I want to get those
31:57 - targets then I want to say the inputs
31:59 - are are divided by 255 g g / 255 b / 255
32:07 - and this should say inputs and then i'm
32:10 - going to say brain train inputs with
32:13 - these targets so this is me just running
32:16 - through and kind of quickly using a
32:18 - thousand colors to train it and i'm
32:21 - being told that this is probably
32:23 - backwards there's no way I could have
32:25 - possibly guessed that correctly
32:26 - okay so let's and actually I'm gonna
32:29 - even I'm just gonna let's let it run ten
32:31 - thousand times so I'm gonna run ten
32:33 - thousand colors through the network
32:35 - right and set up I was like training
32:37 - data basically okay so now let's just
32:43 - and actually in a way what I'm gonna do
32:45 - now just to see I'm not even gonna click
32:48 - I'm going to not bother to train it
32:51 - anymore I'm just going to be I'm just
32:54 - gonna pick let me comment out my own
32:55 - interactive training and let me just
32:58 - pick new colors okay so so every time I
33:02 - click yeah you can see it's making
33:05 - guesses are they good guesses I don't
33:07 - know but they
33:08 - I bet you those guesses are pretty
33:10 - accurately aligned with that threshold
33:12 - of 300 so I could continue to train it a
33:15 - little bit but I feel pretty happy now
33:18 - with this color predictor okay what's
33:22 - what's going on I've finished this
33:25 - coding challenge I'm gonna release this
33:26 - code what can you do with it so a couple
33:29 - things one is could you make this same
33:31 - exact project but instead of having it
33:34 - just pick whether black or white goes on
33:37 - top could you pick a RGB color that
33:40 - looks nice maybe it's a maybe you could
33:42 - have a neural network solve the formula
33:45 - for complementary colors could you think
33:47 - of a more thoughtful way to design this
33:49 - could you use some other data entirely
33:51 - could you train based on like font which
33:54 - font to pick could you train a system to
33:57 - make design decisions based on you some
34:01 - set of training data or some user
34:02 - interaction something like that so I
34:04 - hope you make your own neural network
34:06 - design predictor thingy and share it
34:10 - with me you can go to the Cote trained
34:12 - comm website there's some instructions
34:13 - there for how to contribute your version
34:16 - of a project like this you can write in
34:18 - the comments you can tweet me at
34:19 - Schiffman I guess I'm supposed to say
34:21 - you should subscribe to the channel blah
34:23 - blah blah thank you for tuning in and
34:25 - there is the color predictor wait hold
34:31 - on stop timeout I'm getting a good
34:33 - suggestion in the chat what it might be
34:35 - nice to see like what the number is so
34:38 - hold on let's this is a good idea let's
34:41 - do this hold on hold on timeout
34:43 - everybody where do I have I have some
34:46 - console.log going on here let me get rid
34:47 - of this console.log and let me in here
34:51 - let's console log R + G + B so let's see
34:59 - if this value is bigger and I'm just
35:01 - going to floor it so it looks I don't
35:05 - need to see the decimal let's see if
35:07 - this let's see if it really learned the
35:08 - threshold of 300 right 319 that should
35:15 - be white so it didn't get that right
35:17 - woops 376 ah 4 42
35:22 - - 89 oh wait no no he did get it right
35:25 - I'm done I've got it backwards if it's
35:27 - if it's higher than 300 it should be
35:29 - over black if it's lower than 300 it
35:31 - should be over white and we can see here
35:33 - right 289 white 431 black 550 13 black
35:39 - 561 black 527 right this is working and
35:42 - just to prove this point let me run it
35:44 - again with a different threshold where
35:50 - do I add that in the training let me
35:53 - give it a silly threshold of 100 that's
35:55 - much too low for it to be visually
35:56 - correct probably whatever that means but
35:58 - we can see now it's going to only go to
36:02 - white if it's below 100 oh it didn't
36:06 - actually 97 it didn't even get there now
36:08 - the quite I'm gonna have to do this for
36:09 - quite a while to get lucky enough to
36:11 - pick something lower than 100
36:15 - I'm very unlikely to get a number lower
36:19 - than 100 because I'm picking three
36:23 - random numbers between 0 and 255 so I
36:26 - actually have I'd have to pick three
36:29 - random numbers basically lower than 33
36:32 - and which has a pretty low probability
36:35 - of doing that in a row so let's do the
36:37 - opposite thing let's say let's do this
36:39 - only if it's greater than 500 296 white
36:45 - so if I ever get it greater than 500
36:47 - black write 393 is white so it is
36:51 - learning that threshold whatever I kind
36:54 - of whatever I in and I pick 300 and
36:56 - probably what would make sense for me to
36:58 - pick is just you know 256 or 20 55 times
37:02 - 3 / yeah - or 55 times 3i / - I really
37:09 - should have stopped this video of two or
37:11 - three minutes ago when I had the chance
37:12 - so we can see now here's my color
37:14 - predictor it's trying to predict which
37:16 - text looks better over the colorbond
37:19 - season now we're finally done oh please
37:20 - please creative wonderful people of the
37:22 - internet make a more interesting better
37:24 - version of this and I will see you in a
37:27 - future coding challenge good bye thank
37:28 - you again - gibreel for this particular
37:30 - idea subscribe to his channel link in
37:33 - this video's description
37:34 - [Music]
37:43 - you