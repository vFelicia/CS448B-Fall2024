00:02 - [Music]
00:21 - do
00:24 - [Music]
00:33 - hello
00:35 - [Music]
01:25 - [Applause]
01:27 - [Music]
01:44 - [Applause]
01:45 - [Music]
01:59 - do
02:08 - [Music]
02:09 - [Applause]
02:12 - [Music]
02:19 - [Applause]
02:24 - [Music]
02:42 - do
02:43 - [Music]
02:56 - do
02:58 - [Music]
03:10 - do
03:13 - [Music]
03:34 - hello good morning or afternoon good
03:37 - evening
03:38 - a little bit of a sound check here quick
03:41 - sound check
03:42 - um there's probably a loud pun because i
03:45 - am currently running the heater in the
03:47 - garage
03:48 - but other than that let me know how my
03:50 - voice is sounding and i'll be getting
03:52 - started in approximately two and a half
03:55 - minutes
03:59 - [Music]
04:07 - [Music]
04:20 - do
04:22 - [Music]
04:35 - do
04:36 - [Music]
05:25 - me
05:28 - [Music]
06:00 - do
06:02 - [Music]
06:13 - do
06:17 - [Music]
06:28 - hello
06:29 - happy monday welcome to another session
06:32 - of the coding train my name is dan i
06:34 - will be your
06:35 - 2 conductor for today's session i'm
06:39 - still setting up a few things here and
06:41 - there
06:42 - last time i forgot to record my session
06:44 - to disc
06:46 - uh so i am going to make sure that i do
06:48 - that this time and i want you to think
06:51 - about
06:52 - today's sponsor of the coding train as i
06:54 - go and set those settings today's
06:56 - sponsor is
06:57 - curiosity stream
07:00 - uh let's see how come that did not open
07:04 - obs 64. oh obs is already running launch
07:08 - anyway yes
07:09 - okay thank you
07:12 - and now i am going to hit
07:14 - um start recording
07:18 - and there we go all right so
07:20 - um
07:21 - [Music]
07:23 - boy boy am i unsure about what's
07:25 - happening in the world of the coding
07:27 - train but i am preparing i don't know
07:29 - where it is maybe this is it
07:31 - this here
07:33 - is a stool a stool actually it's like
07:35 - one of these weird stools that like you
07:37 - sit on and it wobbles it's supposed to
07:38 - be good for your back
07:40 - but i am now
07:41 - hereby
07:43 - proclaiming that this is a reset button
07:46 - it's a giant reset button
07:48 - and very soon it will be 2022
07:52 - and i am going to
07:55 - place my bell
07:57 - on top
07:59 - of the reset button and i can't do it
08:00 - now the ball will drop
08:03 - drop onto the bell
08:05 - we'll make that sound
08:07 - uh and i'm gonna everything's gonna be
08:08 - reset um
08:10 - in the year uh 2022
08:14 - because this boy
08:16 - um and um
08:17 - this has really been quite a difficult
08:20 - uh i know year two years for so many
08:22 - people just for me speaking personally
08:24 - just a really difficult month of
08:26 - december and i haven't been able to sort
08:29 - of keep up with the pace of sort of
08:32 - coding train activities like i would
08:34 - really like to but
08:36 - i'm finishing up a whole bunch of things
08:39 - and have this clear path ahead of me
08:41 - so this is the time by the way if you
08:44 - ever wanted to get in touch with like
08:46 - your suggestion of what you think the
08:48 - coding train should really be
08:50 - should it really just be
08:52 - daily live streams every day
08:55 - should it be more
08:56 - sequenced video tutorials should it be
08:58 - project videos should it have high
09:00 - production value low production value
09:02 - uh should should it have a brand new
09:04 - website that allows you to share all the
09:07 - things you're making based on the coding
09:08 - trade videos back should we be doing
09:10 - more things on social media should
09:11 - coding train have a tick tock
09:15 - i'm thinking about all these things and
09:17 - um ramping up my plans to uh
09:20 - to activate uh all of the all of the
09:24 - cars on the train
09:26 - and the various different engines and
09:28 - the components it's all gonna happen in
09:30 - 2022 but here i am still in 2021 just
09:34 - eeking out one more live stream there's
09:37 - gonna be another one at some point
09:40 - i really would like to do my annual
09:43 - holiday
09:44 - slash new year's processing foundation
09:46 - telethon to support the work of the
09:49 - processing foundation i think
09:51 - this is this is not official yet this is
09:54 - unofficial this is like a little
09:56 - unofficial pre-announcement announcement
09:58 - i think it's going to happen after the
10:00 - christmas holiday but before new year's
10:03 - um this year i don't think i can get it
10:05 - together to do it
10:06 - this week or next so most likely my uh
10:10 - new the holiday livestream which will be
10:11 - a new year new year live stream
10:14 - launching the new year of the coding
10:15 - train will happen
10:18 - it's probably i'm gonna guess uh
10:20 - december 29th or 30th or 31st
10:24 - one of those dates if you want to be the
10:25 - first to know when i've scheduled it you
10:27 - should sign up for the coding train
10:29 - discord
10:32 - i just pressed a button
10:34 - and i don't know if that message is
10:35 - going to go into the chat didn't seem to
10:37 - do it but it's uh
10:39 - codytrain.comcodingtrain.comdiscord
10:43 - discord.gg codytrain somebody will put
10:45 - it in the chat hi peter glad that you're
10:48 - here catching the stream
10:49 - um
10:51 - but uh what am i talking about if you
10:54 - want to be the first to know about when
10:55 - this special end-of-year new year
10:58 - spectacular coding train telethon
11:01 - spectacular will happen maybe i'll even
11:04 - break out my ukulele to sing a new year
11:06 - song would you like to write that song
11:08 - the lyrics of that song get in touch
11:10 - because i got nothing i got
11:12 - nothing if you want to be the first to
11:15 - know sign up for the discord because the
11:16 - discord oh it has this new feature let's
11:18 - see if i can even show it to you
11:21 - um
11:22 - i'm going to open up discord here on my
11:24 - computing machine that you cannot see
11:26 - just yet oh no okay wait wait wait
11:30 - this is fine i have to log in
11:32 - everything's going to be fine it's got
11:34 - this magic qr code thing
11:37 - so
11:37 - this is really what i should be doing on
11:39 - a live stream i should be logging into
11:41 - things
11:42 - start talking
11:44 - um
11:45 - i'm talking already i don't need to
11:47 - start talking discord why you're
11:49 - reminding me
11:52 - if i had a co-host i wouldn't have to
11:54 - just continuously speak the entire time
11:56 - i should be good with the silence or i
11:57 - need more music going on
11:59 - um
12:00 - now let me just do this little special
12:03 - trick thing that i'm going to do
12:05 - then let me go back to ah the coding
12:07 - train oh
12:09 - i'm really doing something very
12:10 - important but you can't see it
12:13 - because otherwise it will reveal all of
12:15 - my
12:16 - coding train oh my god
12:20 - secrets um
12:23 - um we wouldn't want to do that um
12:27 - now okay yes yes yes no no no i got one
12:30 - more button to press boy i really should
12:32 - have prepared this
12:34 - did i tell you about today's sponsor
12:36 - look at that well i'm still doing this
12:40 - hidden
12:41 - option command i
12:44 - uh turn this off
12:47 - oh boy this was boy this was worth the
12:49 - wait everybody oh you have no idea
12:52 - what's coming to you you have no idea
12:54 - the excitement i'm about to
12:57 - show you
13:13 - such a letdown but you'll see here in
13:15 - the coding train discord
13:17 - now has this events feature so whenever
13:20 - i have a live stream event i schedule it
13:23 - in the discord which there's a way for
13:25 - you to get a notification about that you
13:27 - can see the youtube link the details
13:29 - about it multiple it's if it's happening
13:30 - now it have a big happening now button
13:32 - so i fully expect that there are now
13:35 - hundreds of thousands of viewers in real
13:38 - time the kodi trade right now because of
13:40 - this new happening now button
13:42 - thing
13:43 - card tag discord
13:46 - extravaganza all right
13:49 - so um
13:50 - you can also just subscribe to the
13:51 - youtube channel and there's like a bell
13:53 - or something it'll also give you a
13:54 - notification in theory when i schedule
13:57 - the next live stream
13:59 - uh and simon is reminding me um in the
14:02 - member discord remember
14:04 - oh remember when you did advent of code
14:07 - on the stream
14:09 - yeah
14:10 - december is
14:12 - i really want december to be like a
14:14 - really active month of streaming and
14:16 - coding and fun
14:18 - but it's just not happening this year
14:23 - but mark my words
14:25 - streaming and coding and fun and all of
14:27 - that stuff is coming in next year so
14:29 - what are we here to do today
14:32 - if you've enjoyed my last three live
14:35 - streams
14:37 - do i have good news for you
14:39 - i'm gonna be continuing the project this
14:41 - is kind of a new thing that i started
14:44 - which is i'm just going to come back
14:46 - over here for a second
14:48 - which is to work on a larger project
14:51 - over multiple sessions
14:55 - i don't know how effective or
14:58 - entertaining or insightful this is
15:02 - so right now the kinds of things i do in
15:04 - the coding train are divided into
15:06 - sort of different
15:08 - different buckets and actually one thing
15:10 - i might just do right now just to talk
15:12 - about that for a second
15:14 - is to come here to the channel so this
15:16 - is great for anybody who's who's new
15:19 - uh today
15:21 - so i have what the most popular thing
15:24 - that i do which youtube likes to tell me
15:26 - is very popular
15:28 - are these coding challenge videos from
15:30 - at least four or five years ago so
15:32 - apparently the way that i work is i
15:34 - discovered something really popular that
15:36 - people love and want to get more of and
15:38 - then kind of went did something
15:40 - different
15:41 - but so
15:42 - uh these are the coding challenge videos
15:44 - they're sort of standalone one-off
15:46 - videos where i build a project
15:49 - i also have and this is kind of where
15:52 - what i'm kind of very much dedicated to
15:55 - always having at least this feels very
15:57 - primary and fundamental to me
15:59 - um hi christine in leeds england
16:03 - welcome to leeds england lovely to see
16:05 - you here um these are the sort of
16:07 - sequence tutorial videos so first of all
16:10 - if you are new or if you have a friend
16:12 - who's like oh i'd love to learn to code
16:14 - or where should i start or i'm
16:15 - interested in generative art or creative
16:17 - coding or javascript
16:19 - this playlist is for total beginners and
16:23 - one of the things that i have been doing
16:26 - and the reason why i like having it
16:27 - sectioned into different videos is
16:29 - because i can over time replace them so
16:32 - if i look at this right now
16:34 - these were um you can see like these are
16:36 - from three years ago the sort of intro
16:39 - to the series and using the web editor
16:42 - then all of a sudden oh yeah then we
16:43 - still got three years ago then all of a
16:45 - sudden we go and we get some videos from
16:47 - six months ago more gray hair so these
16:50 - were so out of date and old that i
16:52 - started to replace them new thumbnail
16:54 - style i don't know what people think of
16:55 - that um but then we go back and we
16:59 - continue
17:00 - like suddenly then the video goes to six
17:02 - years ago so definitely high on my list
17:05 - is
17:06 - anything that's five plus years old
17:09 - in this sort of tutorial series i want
17:11 - to redo
17:13 - i have been working this is what i'm
17:15 - kind of focusing on today i would like
17:17 - to make a video about auto encoders
17:20 - uh matt is saying i could probably get a
17:22 - co-host in songwriting help from gpt-3
17:25 - great point
17:27 - actually that's been my sort of pet
17:29 - procrastination project is playing
17:31 - around with a lot of the new large
17:32 - language models
17:34 - that are available through open ais
17:35 - gpt-3
17:37 - and
17:38 - also hugging face uh hosts a tremendous
17:41 - amount of different language models with
17:42 - lots of exciting applications although i
17:44 - think it's important to be very cautious
17:47 - and conscientious when using these large
17:48 - language models so there's a lot to say
17:50 - about that um
17:52 - nature of code is a big project for me
17:54 - in the new year i don't know where i'm
17:55 - scrolling
17:56 - so oh so so
17:59 - but
17:59 - what i was talking about which i wanted
18:01 - to just sort of get off my chest here
18:03 - is that
18:04 - standalone project videos like these
18:08 - sequence tutorials and then
18:11 - if i go to
18:16 - live streams i thought there was a place
18:18 - where i could just see like my live
18:19 - stream playlist i'm not seeing it i'm
18:21 - not going to to try to find that now but
18:22 - that's what you're watching right now
18:24 - apparently 166 of you
18:26 - lucky lucky lucky people are here with
18:29 - me
18:30 - um
18:31 - and
18:32 - uh would you redo the game you started
18:35 - says nico writes would you redo the game
18:37 - you started with the triangles moving
18:38 - around the map on their own
18:41 - i'm not sure
18:43 - what the pot redo them but never remove
18:45 - them yes so this is a good point i am i
18:47 - have no plans
18:49 - to ever delete any of the older videos
18:51 - and in fact um another way to browse the
18:54 - videos is through the coding train
18:56 - website and if i go to beginners if you
18:58 - really enjoy the sort of classic coding
19:00 - train style
19:02 - uh you can find these really ancient uh
19:05 - intro to processing
19:07 - tutorials which are
19:09 - even though it says 2015 i'm pretty sure
19:11 - these were recorded in 2012.
19:14 - it's just that i only got around to
19:16 - uploading them to youtube all at once on
19:18 - july 10
19:20 - 2015.
19:23 - ah time flies
19:25 - i'm getting older too what's that song
19:28 - that i'm thinking of you're getting
19:29 - older i'm getting older too i don't know
19:31 - i'm getting older you're not you're you
19:33 - look lovely you look
19:35 - beautiful you look younger than you ever
19:37 - have and actually the irony here is
19:40 - while i'm talking to you the viewer i'm
19:41 - just staring at an image of myself so
19:44 - i'm saying it to me but really i'm
19:45 - saying it to you all right we got to get
19:47 - we got to get moving here
19:49 - i've been alluding to it
19:51 - i want to tell you
19:52 - about the best
19:55 - deal in streaming available
19:58 - today
19:59 - oh anything think of any streaming
20:01 - service with any content i have to tell
20:04 - you about the best deal
20:07 - available better than all of the ones
20:08 - you're thinking of
20:10 - um so how do i get to it if i go to
20:12 - youtube.com
20:14 - the coding train and the community tab i
20:16 - just made a post about it
20:18 - and here it is holidays start early so
20:21 - um you've heard me talk about this
20:23 - before um it is the curiosity stream and
20:26 - nebula bundle it gives you access to all
20:29 - of curiosity's stream tons of
20:31 - educational documentaries nature science
20:34 - math
20:35 - um just
20:37 - nature nature nature nature those are
20:38 - the ones that i love
20:40 - so many amazing documentaries and
20:43 - with it
20:45 - you also get full access to nebula which
20:48 - is a streaming service that my content
20:50 - is on you can even see here this picture
20:52 - so all ad free if there's any all
20:55 - sponsor free
20:56 - um really nice player you've got like a
20:58 - roku app and a fire tv app some new
21:01 - stuff um i think i wrote about it here
21:03 - um picture and picture on ios
21:06 - and
21:07 - like i stole this from renee ritchie who
21:09 - is i'm a big fan of
21:11 - all for less than the cost of a usb
21:13 - dongle so um you can get all of the
21:16 - nebula content all of curiosity stream
21:18 - thousands of documentaries for less than
21:19 - 12 a year this is exclusive only for the
21:21 - holidays it's a 42 discount 11.59
21:25 - uh if you sign up through the link it's
21:27 - pinned in the chat um
21:30 - curiositystream.com codingtrain so if
21:32 - you're wondering like what's a way for
21:33 - you to support the coding train
21:35 - actually going to that link and signing
21:37 - up will uh supports me and supports all
21:39 - these other wonderful creators that are
21:41 - on nebula
21:43 - i'll come back in the middle and just
21:44 - basically say what i just said now again
21:46 - but if you have any requests to poke
21:48 - around and look at anybody's any
21:50 - particular content i can make some
21:51 - recommendations for you all right now
21:53 - coming back
21:56 - i am really excited about this project
22:00 - uh because it is one of these things
22:02 - like uh
22:03 - as simon likes to tell me um
22:07 - wait i'm sorry i'm reading
22:10 - i'm reading the the chats in multiple
22:12 - places uh thank you viveshop vivesvan um
22:18 - simon likes to remind me um i have this
22:22 - habit if i go to the rainbow topics
22:24 - github repository
22:26 - i have this habit of making these like
22:29 - to-do lists
22:30 - fall 2020 spring 2021 summer 2021.
22:34 - notice i didn't make one for fall 2021 i
22:36 - was like forget it i just make the to-do
22:38 - list don't get to anything that's on it
22:40 - i think i would really like to make one
22:41 - for 20 20 20 20 20 20 22
22:45 - and uh really develop a schedule oh
22:47 - something that i'm thinking about tell
22:48 - me what you think about this here's an
22:49 - idea for you uh think about like some
22:52 - cool illustration graphic design twitch
22:54 - tuesdays coding train
22:57 - twitch tuesdays like a little music bump
23:00 - or something
23:03 - um i think you've experimented with
23:04 - streaming on twitch but that's so cheap
23:07 - so a little different vibe try some more
23:09 - interactive features something i'm
23:10 - thinking about
23:11 - um
23:14 - but i believe like if i just go to
23:15 - summer 2021 you can see all these lists
23:18 - of things that i want to do and on the
23:20 - list
23:21 - it's been there so many times auto
23:23 - encoder so vivisvan asks what are you
23:25 - building today
23:28 - auto encoder except i'm not really
23:30 - building it today i am finishing it
23:32 - today i have been building it you have
23:34 - guess what you have about six to seven
23:36 - hours of old content you can go back and
23:38 - watch
23:39 - so i have been working on this auto
23:41 - encoder uh with tensorflow.js and p5.js
23:45 - uh for the last three live streams i
23:47 - don't think i should go past this one
23:50 - and the thing that i'm thinking about
23:51 - doing and i would love to hear from you
23:53 - is then
23:55 - um not on the level of say like two
23:57 - minute papers or some other like three
24:00 - blue one brown
24:01 - is another channel that i love sebastian
24:03 - lag
24:05 - um
24:06 - jordan herron i'm just naming youtubers
24:08 - that i like
24:09 - but um
24:11 - but i am thinking about what would it
24:13 - mean for me to do a scripted i know
24:16 - shocker scripted video about
24:20 - what is an auto encoder and how to build
24:23 - one using tensorflow.js and p5.js
24:27 - and
24:28 - cut and paste that's not the right term
24:31 - for edit together highlights from the
24:34 - live stream sessions
24:36 - with narration and some additional
24:39 - demonstration and that could be maybe in
24:41 - 20 minutes that's kind of a goal that i
24:44 - have the only video that i've done
24:46 - anything remotely close to this
24:49 - is the mouse
24:51 - learning
24:52 - um
24:54 - let's see if this comes up um this this
24:57 - video if you haven't watched it um let
25:00 - me just pull this up for a second
25:02 - um this is a video that i made that had
25:05 - a script
25:06 - and um i love you too do do do venom
25:10 - okay you just made me say doo doo venom
25:12 - that was a trick
25:14 - good job
25:16 - uh and andrew's asked me i've looked at
25:18 - advent of call so uh if you haven't
25:20 - watched this video i would love for you
25:21 - to go check it out and tell me what you
25:22 - like or didn't like about it
25:24 - but the idea here is could i um could i
25:28 - could i pull could i could i
25:31 - kind of have the best of both worlds
25:33 - like
25:34 - one of my mantras one of the things i
25:35 - really try to do is show every every
25:38 - every piece of building a project start
25:40 - to finish and all of the pain and bugs
25:43 - and mess in between at the same time
25:47 - how many of you realistically if you're
25:49 - like i want to learn how to build an
25:50 - auto encoder oh there's seven hours of
25:52 - video i could watch
25:54 - where at the end you get a fuzzy circle
25:58 - um really have the time for that or
26:00 - going you know is that really going to
26:01 - be uh useful for you so i want to try to
26:03 - have the best of both worlds that's
26:04 - something that i'm thinking of planning
26:06 - to do matt says great plan matt gorbay
26:08 - gorge from the french gold
26:12 - no maybe
26:13 - sorry if i'm butchering your name
26:16 - um
26:18 - so
26:19 - um that i
26:22 - am thinking about um
26:24 - um doing so anyway
26:28 - new area of exploration look at all this
26:30 - stuff
26:31 - this this
26:32 - so much stuff that i want to do oh
26:33 - remember how i was going to do these i
26:35 - actually i have some like just videos
26:38 - that i sh recorded and they're kind of
26:40 - like half edited that i never got
26:42 - together to finish
26:43 - uh so much oh
26:45 - plotter i want to buy a plotter so many
26:47 - i want to get a knitting machine
26:50 - so much to do in 2022.
26:52 - i'm a poet and i didn't even know it
26:56 - all right so let's get back to the task
26:58 - at hand before i take up too much time
27:01 - with this introduction to today's
27:03 - session thank you for everybody too for
27:05 - being here let me go to terminal
27:09 - i'm going to walk you through now all
27:11 - the pieces of the project that have
27:13 - already been built
27:16 - so
27:18 - first piece is a processing sketch
27:22 - to uh generate training images for the
27:26 - auto encoder and i realized that if
27:28 - you're totally new and haven't tuned
27:30 - into the last three live streams the
27:32 - question what is an auto encoder might
27:34 - be on your mind
27:36 - i'll come to that at some point i'm sure
27:37 - i won't be able to help myself but just
27:39 - imagine at least for the one sentence
27:41 - version i'm using an auto encoder to
27:44 - create images in the style of an
27:46 - existing data set and this here
27:51 - if i run this sketch this is now
27:52 - generating that existing data set it is
27:55 - just a series of random circles or
27:58 - squares
27:59 - um um i believe i'm making some number
28:02 - of them as we will find out i'm making
28:04 - 1100 of them so at some point it will
28:07 - stop
28:13 - and
28:15 - we can see now in this data folder here
28:17 - are all these images that i generated so
28:20 - i'm hoping by the end of today i can try
28:22 - to work with something more
28:23 - sophisticated should i try to use letter
28:26 - forms
28:27 - color
28:28 - different kinds of shapes i'm not sure
28:30 - yet more abstract patterns again i don't
28:33 - know
28:34 - um but let's leave that oh fractal trees
28:37 - we could try that would be kind of
28:38 - interesting learn blender so sake
28:42 - yeah i kind of into this idea of
28:44 - learning unreal engine and then turning
28:46 - this garage into a like a virtual set i
28:49 - have this huge garage now
28:52 - can i make it into a volume like the
28:54 - mandalorian set and just put like
28:55 - screens over everything instead of a
28:57 - green screen that just actually be
28:59 - this giant screen behind me
29:03 - now i don't have the budget for that i'm
29:04 - going to need a lot of you to sign up
29:06 - for that curiosity stream bundle if i'm
29:08 - going to do that
29:09 - ah and andrea
29:11 - asks are you working on a new version of
29:13 - the nature of code
29:14 - um and stig writes um oh just crack the
29:19 - playback speed to 28x i hope by the way
29:21 - all of you just watch me on 2x i mean
29:23 - obviously you can't right now
29:24 - well maybe good no touch designer i
29:27 - don't think is for me i appreciate the
29:29 - suggestion from rodrigo but probably not
29:33 - for me
29:34 - um
29:34 - wait wait wait i was talking about
29:36 - something
29:39 - generating images we're doing the auto
29:40 - encoder let's talk about the mandalorian
29:42 - set
29:47 - ah nature of code it was andrea's
29:49 - question uh yes so i you know i don't
29:52 - know why i'm dancing around this i am on
29:53 - sabbatical starting it's actually not
29:55 - the you know i still have a lot of admin
29:57 - and other uh nyu related
29:59 - responsibilities that i'll be continuing
30:01 - to do for the first three weeks of
30:02 - january but my sabbatical from my
30:05 - teaching job begins january 24th um i
30:09 - don't i'm not suddenly going to be full
30:11 - time coding train but if i'm at best you
30:14 - know one fifth time right now one eighth
30:17 - time right now coding trade honestly
30:19 - this month
30:20 - um i'm hoping to ramp up to like a
30:22 - quarter time a half time like really
30:24 - spend two or three two to
30:27 - two like at least two full days per week
30:29 - working on coding train um i also i've
30:32 - got a um there's an expression that uses
30:35 - naughty language if you will that i'm
30:37 - not going to say
30:39 - i have to like
30:40 - do something or else get off the other
30:43 - thing
30:45 - i got to do this nature of code book
30:46 - like it's now and forget it like if i
30:48 - don't have a new version of the nature
30:50 - of code book done in 2022 forget it it's
30:53 - never gonna happen you heard it here
30:54 - first mark my words
30:57 - sign me onto the piece of paper
30:59 - everybody record this broadcast it put
31:01 - it out into the universe
31:03 - i'm either going to have a new version
31:05 - of the nature of code book
31:07 - completed that means you can buy it a
31:09 - print version and it will be all online
31:11 - for free as a website both of those
31:13 - things by the end of 2022
31:16 - all with p5.js a new chapter on neural
31:18 - networks
31:19 - if that's not done that's it that
31:21 - project is dead
31:23 - i don't think i'm going to do a
31:24 - kickstarter for it which is what i did
31:26 - for the first book i think i've got
31:28 - enough kind of momentum with the sort of
31:30 - support but so those of you who are
31:32 - supporting the coding train whether it
31:33 - is signing up for a membership
31:34 - supporting the sponsors um all the other
31:36 - kinds of ways just watching
31:39 - tweeting sharing recommending it to your
31:41 - friends all the things that all of you
31:43 - do that i so appreciate um
31:46 - i think that's enough to kind of keep me
31:48 - going in terms of nature of code book um
31:52 - yeah
31:52 - uh
31:53 - [Music]
31:54 - unity and godot would be better
31:56 - alternatives to unreal
31:59 - says uh simon okay i'm gonna take that
32:02 - advice very seriously
32:04 - um
32:05 - and thank you kathy wrote this really
32:08 - uh oh nicole shader expert nicole is in
32:10 - the chat oh shaders i actually really
32:13 - would like i don't know if i'm qualified
32:15 - to do this i got to see uh the great
32:18 - pattucio author of the book of shaders
32:21 - i'm in new york city recently and i said
32:23 - oh thank you thank you thank you thank
32:26 - you thank you thank you i feel like
32:27 - that's what i
32:28 - people sometimes like have that reaction
32:30 - to me and i'm like no no no no please no
32:33 - stop oh no no oh if you insist and then
32:35 - i get out my ukulele and play them a
32:36 - song no okay um
32:40 - christmas
32:41 - gift yes okay um
32:46 - nicole uh thank you for your help when i
32:48 - tried i stumbled through learning
32:49 - shaders thank you of course to eliza and
32:51 - aletheia in the uh curiously minded
32:53 - stream i was thinking i might like to do
32:55 - a little basic introduction to shaders
32:58 - as like similar to my intro to p5.js but
33:01 - i don't know i i to do that i really
33:03 - have to think about how i'm kind of
33:05 - crediting
33:06 - um all of the sources that i'm sort of
33:08 - learned from i mean this is something
33:10 - that i do throughout throughout
33:11 - everything but also like whether
33:13 - i'm really the right person for that i
33:15 - mean in some ways i lo that's the idea
33:17 - of the coding train like i'm a beginner
33:18 - at this too so let's learn together
33:21 - i have to think about how to do that
33:22 - effectively okay um
33:24 - [Music]
33:26 - yeah uh nicole you are an expert
33:29 - relat
33:30 - in my eyes but no one expert is uh just
33:33 - a word that maybe we should just remove
33:35 - from the vocabulary here i mean it's
33:37 - it's nice to be an expert in something
33:39 - but i feel like in the so i don't
33:41 - there's nothing wrong with being an
33:42 - expert people who are experts should be
33:44 - celebrated for their expertise
33:46 - especially in like the sciences and
33:49 - things that we sort of like rely on to
33:50 - keep our
33:52 - world
33:53 - turning and our society moving forward
33:56 - but um in the in creative coding i like
33:59 - to think of all of us as um
34:01 - expert amateurs
34:03 - or amateur experts i'm not no i think
34:05 - it's more like we're expert at being an
34:07 - amateur like that's what i am ah i've
34:08 - decided i am but i'm not i'm not saying
34:11 - i'm good at it but like the thing that i
34:12 - like to do is try to learn the new thing
34:15 - and then help
34:16 - others learn it as well and sometimes i
34:18 - fail sometimes i succeed who knows
34:21 - back to the autoencoder project kendri
34:26 - i'm not prepared for this
34:29 - kendri
34:32 - welcome to your coding train membership
34:36 - [Music]
34:41 - you have just boarded the coding train
34:42 - passengers
34:44 - manifest please make sure you sign up
34:45 - for discord check the community tab for
34:48 - a post where there's a google form that
34:50 - you can fill out make sure you link your
34:52 - youtube discord accounts and you also
34:54 - get
34:56 - a random number
34:58 - 2022 2022 is going to be the year that
35:01 - i'm going to get back to reading this
35:03 - book of random numbers in a logical and
35:05 - organized way
35:08 - but your random number kendri is on page
35:10 - 169 it is row 8420 column
35:15 - one two three four
35:17 - and the number sequence
35:19 - is five six zero two nine
35:22 - again um we've kind of lost a little bit
35:24 - of momentum on this but we'll get it
35:26 - back a bunch of you if you're in the
35:27 - chat you received one of these please
35:29 - let give a shout out but um
35:32 - members uh uh at certain levels will
35:36 - receive this beautiful custom laser
35:38 - etched train whistle with a random
35:40 - number
35:41 - with a random walk
35:43 - according to the sequence of your random
35:44 - number of the random number book oh
35:46 - that's a mouthful okay
35:50 - um
35:50 - [Music]
35:52 - ah so um kd kydz i got to get to the
35:55 - auto encoder um it's 11 35 so i'm i'm
35:58 - going to start that but i do want to
36:00 - address this is an excellent question
36:02 - from kydz
36:04 - how do you see the use of your projects
36:06 - on
36:08 - on
36:09 - websites either following the internet
36:11 - video or changing up code i love the
36:12 - flock animation are you okay with
36:14 - crediting great question so let me
36:15 - rephrase the question
36:18 - let me just create a scenario you're a
36:19 - viewer of the coding train
36:21 - you saw one of the coding challenges
36:25 - maybe uh and i'm gonna just go to them
36:28 - and you're like
36:30 - oh this self-avoiding random walk
36:33 - this pattern is perfect for this design
36:37 - that i've uh that i've been hired to do
36:39 - for a movie poster or for my own
36:40 - personal portfolio website i want it to
36:42 - be running in the background um can i
36:44 - use it
36:46 - so the answer the short answer that
36:48 - question is yes
36:52 - with no other caveats
36:55 - all of my uh
36:57 - example code
36:59 - is released under a very permissive
37:01 - license typically the mit license
37:04 - hopefully
37:06 - um
37:07 - it's here in the website i think it's in
37:09 - the faq uh license here we go
37:12 - mit license so this is a short and
37:15 - simple permissive license conditions
37:17 - only requiring preservation of copyright
37:19 - and license notices
37:20 - license works modifications larger
37:22 - workspaces from under different terms
37:23 - without source code so basically you can
37:25 - you can um use it for anything you want
37:27 - you can modify you can distribute it it
37:29 - can be private you don't have to you
37:30 - don't have to provide credit um so
37:33 - there's not a lot of restrictions in
37:34 - terms of the example code um
37:38 - let me say a few things about that
37:40 - um
37:42 - it's nice if you can give credit i
37:43 - appreciate it
37:45 - i'm saying this less for me
37:47 - i get plenty of credit i don't need any
37:49 - more credit for stuff
37:51 - but
37:53 - we live in this sort of ecosystem of
37:55 - creative coding open source
37:57 - everybody's got different sort of
37:59 - comfort level with things being reused
38:01 - not reused so always check to see if
38:04 - there's a license
38:05 - regardless of what the license is i
38:07 - would provide credit a reference a thank
38:09 - you i would be overly generous i would
38:11 - go above and beyond whatever is required
38:13 - by the license and the thing this
38:15 - doesn't apply to my code examples but
38:17 - you will often find artistic works
38:21 - that are released under an open source
38:23 - license so in theory there's no
38:26 - legal issue
38:28 - with you
38:29 - taking that code and using it say on
38:31 - your own website but i do think there is
38:34 - something different
38:36 - to copying example code and
38:39 - remixing it for your own creative vision
38:42 - and taking somebody else's
38:44 - artistic intent and applying that um
38:49 - to you within your own work without sort
38:51 - of proper reference and credit so it's
38:53 - muddy it's murky um certainly there are
38:56 - sort of like clear scenarios like oh
38:58 - look example code under mit license
39:00 - please go forth and use
39:03 - artistic work without the source code
39:06 - being open source
39:08 - you may not like
39:10 - copy that put it out on your own name
39:12 - sell it you know make prints of it sell
39:14 - it on your local corner store market or
39:16 - whatever kind of digital currency things
39:18 - people are doing these days i don't know
39:19 - what i got to talk about right now
39:22 - so um and i think actually um golan
39:25 - levin has a really excellent guide to
39:27 - this
39:29 - i'm just want to like i know where i can
39:30 - find this
39:32 - so i'm just going to
39:33 - pull it up
39:35 - i'm very
39:36 - actually i think i can probably show you
39:38 - this pretty sure that i keep a note to
39:41 - it in my syllab syllabi
39:43 - i know i do for my my undergrad course
39:45 - that is in nyu's learning management
39:48 - system which i can't pull up
39:50 - but i can go to my public syllabi for my
39:52 - uh programming from a to
39:56 - a z course
40:00 - by the way if you're looking for some of
40:01 - my most recent stuff um
40:07 - pablo is saying open processing now
40:08 - requires to give credit to all you yes
40:10 - so open processing
40:12 - is definitely a site where people are
40:14 - publishing both their code and their
40:16 - sort of creative artistic vision and so
40:19 - if you're helped by the code and you
40:21 - provide credit i think that's very
40:23 - reasonable
40:24 - if you are just you know if you took
40:26 - something on open processing and like
40:27 - turned it in as your homework assignment
40:28 - for my class i think that would there be
40:30 - an issue even if that's like not
40:32 - something that's
40:34 - you know that you know you could be sued
40:36 - for you know according to whatever the
40:38 - laws of wherever you are let me just go
40:40 - here to a to z let's see if i can find
40:42 - the reference to golan levin's
40:45 - um yeah here we go so i adapted this um
40:49 - it's called um a statement use of free
40:51 - and open source code from examples uh
40:53 - this is adapted from i'm sure hopefully
40:55 - goal 11 may have an up more up-to-date
40:57 - one from when i adapted it from fall
41:00 - 2018 but i just thought this um
41:04 - this is a really useful uh section
41:06 - um
41:07 - that is is is uh speaking of giving
41:10 - credit
41:11 - adapted from golan levinson written by
41:13 - golan levin be careful tonight happens
41:15 - that an artist places the entire source
41:17 - code for their sketch or artwork online
41:19 - as a resource from which others can
41:20 - learn
41:22 - assignments given in new media arts
41:23 - courses are often similar you may also
41:25 - discover the work of a student in some
41:27 - other class or school with posted code
41:29 - for a project which responds to a
41:30 - similar assignment or even the
41:32 - assignment for your class that you're
41:34 - taking right now you should probably
41:36 - avoid this code or at the very least be
41:39 - careful about approaching such code for
41:41 - possible reuse if it is necessary to do
41:43 - so it is best to extract the components
41:46 - that solve a specific technical problem
41:48 - giving credit there i would add and um
41:51 - rather than those parts which operates
41:52 - to create a poetic experience again
41:54 - these are tricky things to define in
41:57 - really strict boundaries uh with really
41:59 - exact right or wrong we're all trying
42:02 - our best it's very hard i think
42:04 - transparency and narrating and
42:07 - documenting your process is the most
42:09 - important thing you can do so even if
42:12 - you did something that you felt like
42:14 - yeah make your make it your own even if
42:16 - you did something that you know could be
42:19 - characterized as
42:22 - repurposing the poetic aspects of
42:24 - somebody's project into your own
42:26 - if you've documented through your blog
42:29 - post through code comments through your
42:31 - website your entire process of how and
42:34 - why you did that then at least i think a
42:37 - um
42:38 - a dis good faith discussion around that
42:40 - can happen and can be corrected if their
42:42 - mistakes were made so um
42:46 - so yeah so you can re you know you
42:48 - should you can uh hopefully i don't know
42:49 - if this let's see if this link still
42:50 - even works
42:53 - yeah so this is the original
42:55 - um
42:56 - policies from golan's uh celeb syllabus
42:59 - i assume there's a more recent one in
43:01 - 2018 you can find it under my
43:03 - programming from a to z and other
43:04 - courses if that's helpful to you if you
43:05 - have suggestions about a phrase and
43:07 - write that better boy would i love those
43:10 - because this is a very
43:12 - uh it's like you know talk about faqs
43:14 - for people who are new to teaching
43:16 - people are students new to coding uh i
43:19 - ask this question all the time and get
43:21 - confused myself so
43:23 - okay
43:24 - now auto encoder we're really gonna get
43:27 - this project this is why it takes by the
43:29 - way this is why it takes seven seven
43:32 - hundred
43:32 - three hour live streams because i spend
43:35 - 45 minutes i haven't even started
43:37 - working on the code for this project
43:43 - how about we start now i did
43:45 - i started demonstrating okay generated
43:47 - the training images the next step
43:49 - um and let's check
43:51 - i have a node
43:54 - a piece of node code
43:56 - that
43:58 - runs through a series of steps
44:01 - basically it builds the architecture of
44:03 - this machine learning autoencoder model
44:08 - um and sorry i'm just reading k y d z zs
44:11 - i'm gonna this balancing act of like
44:13 - just having this discussion with the
44:14 - chat going through this code example is
44:16 - quite difficult but
44:18 - um recreating the flock type animation
44:20 - um is yeah and and so
44:23 - again to be clear
44:25 - i am making and releasing my examples
44:27 - for you to use
44:30 - use them and you're not required to give
44:31 - credit
44:32 - which is different than if i had some
44:35 - sort of like artistic
44:37 - project that i was displaying that had
44:40 - some other kinds of intentions behind it
44:42 - for you and how you might reuse that
44:45 - so copying my code
44:47 - exactly and putting it on your website
44:48 - is fine that's what it's there for of
44:50 - course you probably want to make it your
44:52 - own that's the exciting part of all this
44:54 - okay
44:56 - um
44:57 - sgl
44:59 - let me see if hopefully somebody in the
45:00 - chat can post that link otherwise tweet
45:03 - at me or follow up after i can try to
45:04 - put it in the video description
45:06 - later okay so back to the auto encoder
45:09 - the code that i've written so far
45:10 - basically does everything
45:12 - it creates a
45:14 - loads all those 1100 training images
45:17 - it trains the auto encoder with the
45:20 - training images i'm using just the first
45:22 - 1000 images to train the model
45:25 - it then saves
45:27 - the model to a
45:31 - to a local file because i'm going to
45:33 - load that model from a p5 sketch and
45:35 - then it also generates test images just
45:38 - to sort of see
45:39 - um
45:41 - okay
45:42 - so
45:44 - um let's run that
45:48 - let's first look at the directory and um
45:52 - i'm going to delete all of the
45:55 - the output images that i generated last
45:57 - time to make sure this is actually
45:58 - working
46:01 - and i'm going to run
46:04 - the training now
46:06 - it was suggested to me i think over
46:07 - social media after last live stream
46:11 - that
46:12 - i
46:12 - absolutely need a song to play or sing
46:16 - by the way i do have my ukulele here in
46:18 - the studio
46:22 - it's
46:24 - been over a year
46:26 - since you know where's the joy in my
46:29 - life that it's been over well over a
46:31 - year
46:32 - since i actually even unzipped this case
46:37 - i mean there's no way this is going to
46:38 - be in tune
46:40 - even this is the night this is my nice
46:42 - one has a strap
46:46 - it's not in tune at all
46:50 - none of the chords i play will work but
46:52 - we need a training song
46:55 - okay i'm gonna have to deal with this
46:56 - later
46:58 - um
46:59 - but so i'm uh anybody who wants to write
47:02 - me
47:03 - a training song maybe it would go
47:06 - [Music]
47:07 - epoch 34 out of 100 eta 1.1
47:12 - 1771 milliseconds so this is not good
47:16 - this is not good this is not good
47:20 - uh the loss is going down it's at .06
47:27 - this is very embarrassing
47:34 - the voice in the back of my head always
47:35 - when i start to like um the silliness
47:38 - starts to take over a little bit is um
47:40 - people who comment i would have enjoyed
47:42 - your video if you just would stop it
47:43 - with the clown act
47:46 - i can't help it that's my that's my
47:48 - inner that's my inner
47:50 - inner
47:51 - soul
47:52 - is a clown
47:54 - it just
47:55 - wants to break free i never made it to
47:56 - the shock le cox school of mime in paris
47:59 - that was like my childhood dream and i
48:01 - just never made it there and now i
48:03 - reduce to
48:04 - machine learning javascript examples
48:06 - while
48:08 - clowning around
48:14 - [Music]
48:23 - like getting 100 epochs was definitely
48:25 - too long
48:27 - yeah chris sears
48:29 - um
48:30 - it should be in the style of a rocky
48:32 - montage i like
48:37 - um i really don't need to let this go
48:39 - all the way but um
48:41 - especially because i already trained a
48:43 - model but it's it's almost there so i
48:44 - can let this go
48:46 - um
48:49 - uh all right so
48:51 - we're almost there to getting this to
48:53 - train and as i start to iterate and work
48:55 - on this more um i'm going to not
48:58 - you know take
49:00 - the full five minutes or whatever this
49:01 - has been for it to train
49:03 - but we're almost there so once the model
49:04 - is trained
49:08 - um manus asks are you plotting the law
49:10 - so questions would have been good so i
49:12 - am not the loss the loss
49:15 - value which is the result of a loss
49:17 - function is sort of summarizing the
49:19 - overall error of the model how well is
49:22 - it at reproducing those original
49:24 - training images and you can see that
49:26 - it's going down over time although it
49:28 - kind of went up here so one thing that i
49:30 - could do is analyze like when did it
49:31 - really stop like clearly at epoch 34 it
49:35 - was quite higher
49:36 - than at epoch 54. but you can see
49:39 - somewhere around here actually
49:41 - maybe not even until like the 90 around
49:44 - epoch 90 or so
49:45 - um
49:46 - did it sort of stop really going down um
49:50 - kathy asked a great question
49:52 - it is possible to set an acceptable loss
49:54 - or maybe this is a question is it
49:56 - possible to set an acceptable loss
49:57 - before running a stop when it reaches
49:59 - the desired loss that's uh absolutely i
50:01 - could write that into the code i'm not
50:03 - going to do that right now because that
50:04 - would be sort of an additional thing to
50:06 - engineer but i would certainly encourage
50:08 - anyone watching to try to do that and
50:10 - that seems like a really interesting
50:11 - idea yeah so
50:13 - again just to emphasize
50:15 - um
50:16 - hi michael k ah i posted something on
50:19 - twitter and somebody came to join the
50:20 - live stream
50:23 - look at this amazing um so okay so many
50:27 - interesting questions here so let's let
50:29 - me address these questions
50:30 - by the following so first of all this is
50:33 - the output that i have now generated
50:35 - let's take a look at these images
50:38 - and i'm going to just scroll through a
50:39 - bunch of them
50:41 - so you can see i'm getting what i was
50:43 - hoping for which is these kind of like
50:45 - squirkles they're sort of they're mostly
50:47 - circular but you can see the sort of
50:48 - corners of squares and sometimes i got a
50:50 - full square as soon as i have a full
50:52 - circle sometimes i have something
50:54 - somewhere in between
50:56 - now
50:57 - a couple things to mention about this
50:59 - one
51:02 - this is an incredibly trivial example
51:06 - right what i am reproducing with the
51:08 - auto encoder
51:09 - are
51:10 - very low resolution
51:13 - simple shapes that are either only i
51:15 - mean there's really only two variables
51:16 - here there's a switch is it a square or
51:19 - a circle and then there's the radius so
51:21 - you can think about i mean this actually
51:22 - came came to me i mean i think it was
51:25 - based on some of the chat messages but
51:27 - if i go over here to the whiteboard if i
51:28 - were to like come over here and sort of
51:30 - re-explain what an auto encoder is and
51:32 - again
51:33 - uh what is autocoder go and check out
51:36 - the two-minute papers autoencoder video
51:38 - on youtube uh where it describes an
51:40 - autoencoder as a copying machine right
51:42 - it's a neural network that takes an
51:44 - image in as an input and the idea is we
51:46 - want to get that same image out as an
51:48 - output that's a very easy thing to do
51:50 - right we could just cut in terms of
51:52 - without a neural network i just iterate
51:54 - over the pixels and make a new image
51:55 - with all the same pixels however the
51:58 - idea of an auto encoder is the data is
52:00 - being passed layer upon layer upon layer
52:03 - through a neural network being
52:04 - compressed down to from however many
52:07 - pixels to some other layer with a
52:09 - smaller number of nodes and then
52:11 - decompressed back up so if you think
52:13 - about it
52:14 - i technically only need
52:16 - two nodes in this sort of center layer
52:19 - for what i'm doing because one variable
52:22 - right i need to keep track of what is
52:24 - the size of this shape and the other
52:26 - variable is it a square or a circle so
52:28 - in theory if i go to the architecture
52:33 - of this auto encoder
52:37 - and i look at how i've built it right oh
52:40 - i'm sorry i didn't i didn't switch over
52:42 - if i look at how i built it the first
52:44 - layer receives
52:46 - um it has 256 it receives the number of
52:49 - pixels of the actual image and it
52:51 - compresses it down i mean it's not this
52:53 - isn't really compression i'm just using
52:55 - that as kind of a in a sort of
52:57 - metaphorical way to describe the process
52:59 - although i mean it is
53:01 - compressing it essentially the data and
53:03 - 256 to 128 and then down to eight
53:06 - and then back up to 128 back up to 256
53:10 - and then eventually back to a full pixel
53:13 - image
53:15 - um right and we could do a convolutional
53:17 - autoencoder and a variational auto code
53:19 - and then a thank you astro penguin for
53:21 - answering about overfitting
53:23 - um
53:25 - so um so
53:27 - let's we can address that in a bit i
53:29 - feel like
53:30 - i was getting some good suggestions
53:31 - about changing what loss function i'm
53:33 - using but just out of curiosity i hate
53:35 - to do this
53:37 - let's
53:38 - add one more layer
53:42 - and bring it down to two units
53:45 - and then have the decoder also have one
53:48 - more layer
53:53 - with eight
53:54 - units then let's see if i can still get
53:57 - it to work and i know i said i wasn't
53:59 - going to do this again with a hundred
54:00 - epochs
54:03 - but i can't help it
54:06 - so here we go we are training the model
54:09 - again let's see if that loss can go down
54:13 - and see if we can get um
54:15 - a mean squared error loss function for
54:18 - auto encoders yeah
54:20 - um
54:21 - and astral let me just read astro
54:23 - penguin's comment
54:25 - overfitting is when your model doesn't
54:27 - just represent your data but also your
54:29 - noise it is so well trained to your data
54:31 - that works very well on it but poorly on
54:33 - another data set right you can train a
54:35 - model so well
54:37 - that it can
54:38 - re-produce
54:41 - the training data perfectly
54:44 - but because it's just so locked into
54:46 - that training data if the real world
54:48 - data has any kind of variability to it
54:51 - that's just not there in the training
54:53 - data it's going to explode and do a
54:55 - terrible job so there are lots of
54:57 - techniques to reduce overfitting in
54:59 - terms of how you collect your data set
55:02 - using something called dropout which is
55:03 - adding some sort of randomness and
55:05 - disconnecting parts of the neural
55:06 - network as it's learning
55:07 - um
55:08 - this seems to have settled on a loss of
55:10 - 0.23
55:12 - i'm going to just run this again
55:15 - and just give it 30 epochs so we can i
55:18 - think that's faster than waiting for it
55:19 - to get to 100.
55:22 - uh where did i where do i set the number
55:24 - of epochs
55:25 - um
55:26 - train here it is so let's just let's
55:28 - just train it with 30
55:31 - um and let that go
55:39 - um
55:40 - ah yeah um
55:43 - and uh simon's reminding me that i was
55:45 - gonna try to do this with um
55:47 - try to see if i could de-noise some
55:49 - images so i'm i'm getting like sort of
55:50 - scattered here of all the different
55:52 - things i want to try
55:53 - but it's okay it's not even noon yet
55:57 - i've only spent an hour
55:58 - um
56:00 - place the auto encoder song
56:06 - cyber said this is great
56:08 - cyber gus says it's like preparing for a
56:11 - math exam by memorizing the solutions to
56:14 - the problems right so like if you have
56:16 - like a sample test you just memorize all
56:18 - the answers but don't look at how any of
56:20 - the problems work
56:22 - and then you got a new test you could
56:23 - put all those correct answers in but
56:25 - they won't match the actual problems
56:26 - it's kind of a wonderful okay so i think
56:28 - we're at epoch 30. i'm just curious to
56:31 - see oh there's a lot of randomness in
56:33 - how well it does
56:35 - i didn't let you let it go more i didn't
56:37 - realize but let's just see what kind of
56:38 - images we got even from that
56:42 - from that training so they're
56:44 - they look pretty good they're just much
56:46 - fuzzier
56:47 - so this is what it was able to do with
56:48 - just two parameters
56:50 - but also i didn't let it train
56:52 - for as long
56:54 - as i could have
56:56 - nicole wants to know what is in my mug
56:58 - first of all love this mug fellow mug
57:00 - not a sponsor
57:02 - you never know though um it is coffee
57:05 - and oat milk
57:10 - delicious
57:11 - sometimes it is ginger tea depending on
57:13 - how i'm feeling
57:15 - i'm either like a coffee and oat milk or
57:17 - i'm a plain ginger tea
57:19 - kind of fellow that's in my felt with my
57:21 - fellow mug
57:22 - that's me
57:24 - all right
57:27 - moving along
57:28 - um let's go back to um
57:34 - yeah
57:35 - i'm reading simon's commentary and i
57:37 - totally agree
57:38 - let's look at whether or not our auto
57:40 - encoder can
57:42 - effectively denoise a shape this is you
57:46 - know an actual application of auto
57:48 - encoders what do i even mean by denoise
57:51 - hold on
57:52 - so i'm going to put this back to
57:54 - 100 epochs
57:57 - and i'm going to go back and get rid of
57:59 - this like little layer
58:02 - uh the and just leave the the middle
58:05 - layer
58:06 - um as having um eight units
58:10 - um i want to just try it with a
58:13 - different loss function
58:16 - um is it this
58:20 - is this what i should put in here let's
58:22 - just try a little a little risky here to
58:24 - introduce that at the moment
58:26 - but okay
58:28 - let's train i'm just gonna let it train
58:30 - oh look at that
58:34 - huh
58:37 - look at that it like with that loss
58:39 - function it's like
58:42 - not improving after just a few epochs
58:44 - interesting so hold on this will be
58:46 - great
58:47 - if that was
58:48 - that much of an improvement
58:51 - let's have it go
58:54 - just 10 epochs
58:58 - sometimes it's totally unnecessary but i
59:00 - just like to delete
59:01 - the output just to know that i'm getting
59:03 - new output for sure
59:05 - let's run this for 10 epochs
59:10 - and see what we get look at that like
59:12 - basically after two
59:15 - four five
59:17 - oh no it's still improving huh
59:20 - oh it's still it's always why does this
59:22 - happen to me
59:23 - it's still improving so the other time
59:25 - it kind of like was waffling but let's
59:27 - take a look
59:28 - at what i've got after just 10 epochs
59:34 - all right fine
59:36 - torture me so go back to 50.
59:40 - this is one of the problems with this
59:42 - project is just running again takes so
59:44 - long
59:45 - uh mse
59:47 - did i not type the right thing in
59:55 - let's let it go we're gonna let it go
59:56 - for let's let's actually look in the
59:57 - tensorflow documentation
60:00 - um
60:00 - [Music]
60:03 - where is that is this tensorflow.js i
60:05 - don't think so
60:09 - um
60:12 - these are all the tabs i was looking at
60:18 - yeah look at this
60:23 - going way down
60:26 - still going down
60:28 - whoops
60:29 - um
60:36 - this is what i want
60:39 - api
60:41 - um
60:42 - i want the tensorflow.js api
60:46 - uh mean
60:48 - mean squared
60:51 - yeah no i think i got it right
60:54 - mean squared error
60:59 - now do i want the stochastic gradient
61:02 - descent
61:04 - the learning rate was too high
61:06 - um
61:06 - [Music]
61:08 - might be getting stuck in a local
61:09 - minimum the opposite of a t all right um
61:12 - so that's interesting i wonder if i
61:13 - should be also trying this to cast sgd
61:15 - um optimizer instead of atom
61:18 - um but anyway
61:21 - it was still the loss even uh even at
61:24 - that 50th epoch was still going down
61:26 - pretty consistently although it did pop
61:28 - back up there so let's take a look now
61:30 - at the images we generated
61:34 - all right these look really good
61:37 - so what i want to
61:40 - see now if i can get it to do is denoise
61:44 - an image but i'm going to go into the
61:46 - browser to do that that's what we didn't
61:48 - get to do last time okay everybody
61:50 - um okay so
61:53 - the next step of this
61:57 - was
61:58 - um
62:00 - if i run a local web server
62:03 - i have a p5.js sketch
62:05 - which is loading the model
62:13 - that's interesting i
62:14 - i thought i would have to go into like
62:16 - the public
62:18 - oh it's serving it knows to serve dot
62:20 - public that's so funny because i have a
62:22 - directory in there okay so this is now
62:24 - the p5.js sketch which is loading that
62:27 - model and i am feeding it just random
62:30 - noise like a a sort of
62:32 - purlin-esque no perlin noise there's
62:35 - always sort of discussion around whether
62:37 - this is true perlin noise or not or
62:38 - simplex or gradient or whatever but this
62:40 - sort of cloudy noise pattern is what i'm
62:42 - feeding into the model and i'm getting
62:44 - this shape out meaning the model is
62:47 - working and this is kind of like leading
62:50 - the way to what i want to really focus
62:52 - on today which is a latent space walk
62:56 - but before we get to that what i would
62:58 - like to do is draw
63:01 - a um an image of a circle and see how it
63:05 - copies it an image of a square and then
63:07 - add noise and see what happens
63:10 - bear with me
63:11 - or join me for this part so i'm going to
63:13 - go into
63:18 - i'm going to go into
63:23 - the
63:24 - um
63:27 - sorry sketch.js i lost my train of
63:30 - thought here and
63:32 - um
63:33 - [Music]
63:35 - let me just do
63:43 - uh
63:46 - training new model
63:50 - so
63:52 - i am going to
63:54 - i know sorry
63:57 - comment out
64:01 - i think i'm just going to take out the
64:03 - noise thing because we don't really need
64:04 - that
64:06 - so
64:07 - it'll be in the code history do i want
64:09 - to add a tag
64:10 - people going to want to find this
64:13 - well
64:15 - i know where it is
64:17 - so we'll finally i'm going to take out
64:18 - all of the noise stuff
64:22 - and just go back to
64:27 - a random image and saying no loop
64:34 - so if i do this
64:38 - um
64:43 - and then
64:47 - next image sorry i'm forgetting how i'm
64:49 - doing
64:52 - this uh
64:56 - does this work
64:58 - and then put no loop in i just want to
65:00 - know this is silly i don't
65:03 - need to add the no loop but i'm just
65:04 - curious too
65:06 - all right forget it keep the no loop
65:10 - have it be a random image wait sketch
65:12 - sorry hold on
65:14 - what did i do
65:17 - oh i lost this ah
65:21 - okay this is what i want to do so this
65:23 - is what it looks like when i'm feeding
65:24 - random noise into it
65:28 - it's trying to find and and
65:30 - month nonsense
65:32 - we see a machine trying to find shapes
65:34 - in the random noise so
65:36 - what i would like to do instead
65:39 - is and i'm going to create
65:41 - a um
65:43 - i know what to call this the um
65:47 - the i'll call it input canvas
65:51 - and let's say input
65:52 - canvas equals create graphics
66:00 - at
66:04 - um
66:05 - i've done this in sort of like a weird
66:07 - backwards way but
66:10 - bear with me um what is the size oh yeah
66:12 - create graphics w comma w no no we're
66:14 - fine create graphics i have i forgot i
66:17 - had that w value
66:18 - so i'm working with 56 by 56 pixel
66:21 - images
66:22 - um
66:23 - and the input canvas
66:27 - i'm going to say
66:30 - input canvas dot background i'm going to
66:34 - draw a background of white
66:36 - then i'm going to draw i'm going to say
66:38 - a stroke of
66:40 - zero
66:42 - a stroke
66:45 - weight and this i should essentially be
66:46 - matching what i did in processing so i'm
66:49 - going to say a stroke weight of 16
66:51 - 16
66:53 - then i'm going to say um
66:56 - input canvas
66:58 - circle uh
67:00 - w divided by 2 w divided by 2 and just
67:03 - give it um
67:05 - a
67:07 - a radius or diameter of w divided by 3
67:12 - and i'm going to say input canvas
67:16 - no fill
67:18 - then
67:19 - um
67:21 - i'm still this is still going to be
67:22 - random i'm just doing this one the only
67:25 - thing i'm trying to do right now is i
67:27 - want to see a drawn shape drawn with p5
67:30 - on this left part
67:32 - so now i should be able to in draw
67:34 - instead of rendering this input image it
67:37 - should be able to say image
67:39 - input canvas
67:41 - 0 0
67:43 - and resize it up to w times w
67:48 - wait why won't it
67:49 - why won't it do that
67:51 - doesn't my variable names are terrible
67:54 - where was
67:56 - okay
67:57 - and then let's see if this now gives me
68:02 - oh
68:03 - this always happens it's trying to
68:05 - import ah
68:08 - it's trying to import something i really
68:10 - have to work on my vs code settings
68:14 - okay good
68:15 - oh the stroke oh i forgot i was drawing
68:18 - it as a larger image than resizing it
68:20 - down so this stroke weight was you know
68:23 - a bit much
68:24 - uh technically it should be
68:27 - um
68:30 - uh 16 where to
68:33 - this is very silly but i'm just going to
68:34 - do this
68:36 - okay great so now the idea here is that
68:40 - the auto encoder should take this input
68:43 - circle and produce an exact copy of it
68:47 - on the right now however what's
68:48 - important to note is i'm not feeding it
68:50 - into the auto encoder so the next thing
68:52 - i want to do
68:54 - is feed the image into the auto encoder
68:59 - so
68:59 - [Music]
69:00 - that happens here so i'm going to need
69:02 - to do it by looking at the
69:04 - pixels so i need to say
69:09 - input canvas
69:10 - load pixels
69:14 - and then i equal 0 i is less than
69:18 - w times w
69:20 - times four
69:22 - because there's four elements of the
69:24 - pixel array per oh no no no i'm gonna
69:27 - have to do the multiply by four
69:28 - somewhere else
69:29 - same thing because my input image array
69:32 - has w times w spots in it but instead of
69:35 - a random i want to say input canvas
69:38 - pixels i times four
69:41 - okay that should work because i could
69:42 - just take the r channel if it's if it's
69:45 - a full grayscale like black and white
69:47 - image i times 4 if the array is rgb
69:50 - alpha rgb alpha then the r channel is 0
69:54 - 4 8 12. and so if the i is going up 0 1
69:59 - 2 3 i times 4 is 0 4 8 12 et cetera so i
70:02 - believe
70:04 - this should work
70:07 - look at that look at that beautiful auto
70:08 - encoder it copied that shape perfectly
70:11 - now
70:13 - just you wait and see
70:16 - let
70:18 - r equals map mouse x which goes between
70:22 - 0 and width
70:23 - to between 0
70:25 - and width
70:29 - this is the most brilliant code i've
70:30 - ever written in my entire life
70:32 - i'm gonna map this range between zero
70:35 - and width now hold on everybody just
70:36 - hold on a second i'm gonna blow your
70:38 - mind right now to between the minimum of
70:40 - zero and the maximum width but in case i
70:43 - wanted to change that later it's nice to
70:44 - have the map function in there and then
70:46 - this
70:47 - should be r which is really a diameter
70:50 - so let's call it diameter
70:55 - and we should see
70:57 - [Music]
71:00 - i wonder if it never got
71:04 - interesting so this is not working as
71:10 - expected hmm
71:16 - am i
71:20 - i'm definitely redrawing the image
71:23 - redoing the pixels into
71:26 - the auto encoder
71:35 - let's try a square
71:37 - just out of curiosity
71:39 - and also wait wait wait i have an idea
71:41 - the range was 25 to 200.
71:47 - so in theory like only range that it
71:49 - learned
71:50 - is
71:51 - uh between 25 divided by little w
71:55 - and
71:56 - 200 divided by little w
72:00 - um
72:02 - so
72:03 - that might help
72:07 - let me just say input if i'm going to do
72:09 - a square input canvas
72:12 - rectmode center
72:14 - let's see what happens here
72:23 - i'm like suspicious that it's not
72:26 - something is changing all right do i
72:28 - need to train the model
72:29 - i feel like the model picked up the
72:31 - average radius of the circle it does
72:32 - seem that way
72:34 - all right i feel like let me just go
72:37 - back
72:38 - to
72:43 - um what i had originally
72:46 - which was
72:52 - um
72:53 - i just want to make sure i'm using the
72:55 - right model
72:57 - so let's
72:59 - um i'm sure
73:00 - it is but
73:03 - let's go to
73:08 - um
73:14 - where's the model saved
73:16 - oh it's here
73:18 - today at 12th grade
73:21 - it's a little bit silly but let me um
73:29 - i'm going to put this
73:30 - back to what i started with today
73:36 - so i i'm just putting it back to binary
73:39 - cross entropy adam even though it kind
73:40 - of doesn't make any sense
73:42 - and a hundred epochs and i'm gonna once
73:45 - again
73:46 - train this model
73:49 - and let it go the full 100 epochs this
73:52 - time all right everybody
73:54 - the decoded images look like the average
73:56 - of all parameters half circle half
73:58 - square with a medium radius side i know
74:04 - um so i wasn't getting that issue before
74:07 - so i'm just going to let this
74:09 - kind of power through
74:11 - a longer training process and see what
74:13 - we get so this will be a new the way i
74:15 - have this configured is when i train the
74:17 - model it saves the model in the
74:20 - directory of the p5 sketch and the p5
74:22 - sketch should should pull that up
74:29 - all right
74:30 - while this model is training and since
74:32 - i'm halfway through the live stream this
74:34 - is a perfect time
74:35 - for me to do my sponsor segment
74:39 - today's coding train is brought to you
74:41 - by
74:43 - curiosity stream thank you crosstalk
74:46 - stream now i'm just going to repeat what
74:47 - i said at the beginning of the live
74:48 - stream
74:49 - but those of you who i know most of you
74:51 - probably weren't here at the beginning
74:52 - so guess what i have something exciting
74:54 - to tell you about it is the best deal in
74:57 - streaming today so i am going to go up
75:00 - here uh whoops and show you something
75:05 - curiosity stream
75:10 - let's come back over here
75:12 - okay
75:14 - whoops wrong thing
75:20 - curiosity
75:23 - stream
75:31 - um i'm signing in here okay so curiosity
75:33 - stream is a amazing streaming service
75:38 - with thousands literally thousands of
75:40 - documentaries
75:42 - um all in so many um
75:45 - areas related to things that i do here
75:47 - on the coding train in particular my
75:50 - favorite part of kinds of documentaries
75:52 - that are on oh my god i've got to watch
75:54 - this one
75:56 - whale wisdom i love whales are the
75:58 - nature document documentaries um secret
76:02 - lives there's a whole bunch of secret
76:03 - lives of blank um
76:05 - nature documentation these are great for
76:06 - kids um science space and tech um
76:10 - infinite rainbows
76:12 - wait a second here
76:13 - i mean it's worth signing up for
76:14 - curiosity stream just for infinite
76:16 - rainbows alone how did i not know about
76:18 - there's only 22 minutes long
76:20 - in the time span of one single coding
76:22 - train coding challenge you can watch an
76:24 - entire documentary about what exactly
76:26 - are rainbows learn the science of i'm
76:28 - sorry this live stream is over
76:31 - it is done
76:34 - i don't know if the music is playing i'm
76:36 - out of here i'm going to watch this
76:37 - right now um but if curiosity stream
76:41 - isn't enough
76:42 - with this special one-time well it's not
76:44 - exclusive
76:46 - 42 off discount
76:48 - you also
76:50 - get access to uh nebula let me sign in
76:53 - here
76:54 - um
76:55 - nebula is a streaming service uh made
76:58 - created by creators youtube creators
77:00 - hopefully many of you might recognize
77:01 - many of your favorites here uh not not
77:04 - just bikes is new to curiosity stream
77:06 - i'm sorry new to nebula and i've been uh
77:08 - really enjoying not just bikes even
77:10 - though now i live somewhere where i have
77:12 - to drive everywhere
77:14 - so nerdsync is great um all of these
77:17 - wonderful channels um you can watch all
77:19 - of the videos from these youtube
77:21 - channels on nebula with no ads no
77:24 - sponsor segments and many of them have
77:26 - extended versions this is something i'm
77:28 - hoping to get into in 2022 so you could
77:30 - sign up now
77:32 - and so um
77:36 - the other thing about it is there are a
77:37 - ton of originals so if you look at the
77:41 - nebula originals
77:42 - you can see different
77:45 - um kinds of video content that you can't
77:48 - find look at this next officially you're
77:50 - in in gaming next level world building
77:52 - why games are better than movies is a
77:54 - wonderful nebula original series none of
77:56 - these these are only available through
77:57 - nebula and
77:59 - uh i'm going to take this from renee
78:01 - ritchie this is i just bought a dongle
78:04 - yesterday i needed a dongle for one of
78:07 - my laptops
78:08 - it cost more than an entire year it's
78:11 - like less than one dollar a month
78:13 - for both curiosity stream and nebula for
78:15 - the whole year it's 11.59
78:18 - um if you just sign up through this link
78:20 - um it lets them it lets them know you
78:22 - found out about curiosity's stream and
78:24 - the nebula bundle through me helps the
78:25 - coding train out gives you access to all
78:27 - this wonderful content supporting
78:28 - educational content creators so i hope
78:30 - you will consider it um something that
78:33 - you think about doing for your streaming
78:35 - and entertainment and education needs uh
78:37 - for
78:38 - 2022 i don't know what your new year's
78:39 - resolution is but my new year's
78:41 - resolution was to watch more wonderful
78:43 - youtube con educational content creators
78:45 - on nebula all right let's check in uh
78:48 - back to our uh training
78:52 - uh by the way the link is in um a pinned
78:55 - message in the chat if you're looking
78:57 - for it's also in the video description
78:59 - okay
79:01 - so this is presumably
79:04 - the
79:05 - the new model was
79:06 - trained got down to a loss of zero point
79:10 - sorry for all the scrolling 0.644
79:13 - i'm gonna refresh this page
79:17 - weird
79:18 - i'm like suspicious that my code isn't
79:20 - working
79:22 - because
79:24 - did i delete i deleted all of the let's
79:26 - go back to the random noise
79:30 - so first of all
79:31 - let's just check
79:33 - here
79:34 - oh wait a second no public yeah
79:37 - this is the model from 12 16 p.m that's
79:39 - the new model
79:41 - this project i'm not making any progress
79:44 - today at this project which is very
79:45 - distressing
79:49 - i feel like it did something a moment
79:51 - ago like when i switched back in
79:53 - um
79:55 - hold on we're going to debug this
79:58 - where's my next image okay i got to go
80:01 - back to the sketch
80:04 - next image function
80:11 - what if i go back to oh
80:18 - who knows what the problem is i know
80:19 - what the problem is
80:22 - come on come on chat
80:24 - come on you can think about it
80:26 - what's wrong what are the numbers coming
80:29 - out of inputcanvas.pixels
80:32 - if it is a white pixel what value is it
80:35 - 255
80:37 - i didn't normalize the values i didn't
80:39 - normalize the values this needs to be
80:41 - normalized divided by 255 okay
80:49 - all right that didn't seem to change
80:51 - anything
80:52 - ah
80:54 - um
80:55 - okay let's just for the sake of argument
80:58 - put in random noise again
81:05 - so i am getting a
81:07 - variety
81:08 - again ignore the fact
81:10 - this is
81:11 - in the
81:16 - hmm
81:27 - i times 4 that's right right
81:33 - it's pixels
81:41 - should i give it
81:43 - it's not in the draw let's check the
81:45 - input all right
81:47 - but
81:51 - i mean let's just make sure
82:05 - it's continuing to run
82:08 - and make new input
82:17 - whoa no that's right 56 by 56 3136 okay
82:22 - but like
82:24 - a bunch of zeros yeah i mean this looks
82:27 - right
82:30 - all right let's try like why is the
82:32 - model not able to give me a range of
82:34 - sizes it was not having that problem
82:38 - in the version that i made where i was
82:40 - passing pearl and noise into it
82:43 - and look it's like
82:48 - what's it it's doing something
82:52 - okay
82:53 - use the mouse click to switch between
82:54 - square and circle
83:01 - am i getting alpha my
83:03 - i don't think i'm getting the alpha i
83:05 - times 4 should be the r channel
83:09 - all right this is a good idea
83:13 - so
83:14 - if mouse pressed
83:18 - mouse is pressed
83:20 - draw a square
83:26 - otherwise draw a circle
83:37 - okay
83:39 - that's definitely something
83:50 - is the scale wrong the mods that map oh
83:53 - no but it's symmetrical
83:55 - it could be that i'm not reading the
83:57 - pixels in the right order no
83:59 - it's totally symmetrical so i don't
84:01 - think
84:03 - that should matter
84:05 - all right here's the thing that i could
84:07 - try
84:08 - let's go back to our model
84:13 - let's
84:18 - let's look at okay so let's think about
84:20 - the model architecture for a second
84:23 - yeah many jimmy's saying accumulate the
84:25 - rgb and divide by three
84:27 - that shouldn't matter the mouse mapping
84:29 - seems a little wrong yeah i don't
84:30 - understand
84:35 - so hold on let's do this without the
84:36 - mouse mapping just to be
84:38 - more consistent here
84:41 - let me go here and let me say
84:50 - diameter let me make diameter global
84:52 - variable
84:59 - um
85:13 - start at the smallest
85:15 - and then
85:19 - where do i set it yeah and then i'm
85:21 - going to say
85:38 - just have it cycle back so i'm just
85:40 - going to have the diameter cycle
85:43 - automatically
85:54 - it's weird like this to me like the fact
85:56 - that it's not changing at all
85:58 - makes me suspicious
86:01 - that i'm not doing something
86:03 - correctly
86:08 - because
86:10 - in the neural network
86:12 - right like in the output folder in my
86:14 - test images
86:17 - i'm getting
86:20 - really um
86:25 - right
86:28 - this is this is what i'm getting when
86:30 - i'm testing it
86:32 - so like why is p5 not doing this
86:39 - so this is what this is why i'm
86:40 - suspicious because the model
86:43 - otherwise is performing as expected just
86:46 - not when i bring it into p5 so i feel
86:49 - like maybe the way that i'm drawing
86:50 - these images is somehow wrong
86:52 - all right i have another idea
86:58 - just bear with me for a second let me
87:00 - take a training data image
87:08 - oh this is no no let me take
87:12 - let me take 10 images from the training
87:14 - data
87:18 - and let me put those in
87:20 - a folder called data
87:22 - we're going to figure this out
87:24 - okay
87:25 - so now
87:27 - i am going to
87:34 - um
87:37 - joseph asked when you were using noise
87:39 - were you using the noise value or the
87:41 - pixel value
87:42 - oh i was definitely using the um
87:48 - the noise the noise the noise value hold
87:51 - on
87:53 - let me add preload
87:59 - so we're going to call these test images
88:03 - test images index i equals load image
88:08 - data what are these called square
88:13 - i
88:14 - dot
88:18 - dot png
88:23 - and the oh i need to use the back tick
88:27 - and this should be number format
88:31 - four
88:33 - uh and then i need a loop
88:37 - do you have 11 for some reason
88:42 - okay
88:43 - so now
88:48 - um let's just
88:52 - for a second
88:53 - take this out all this out
89:00 - i'm going to draw
89:02 - image
89:05 - test images
89:07 - zero
89:16 - now again i'm not let's let's okay so
89:18 - let's take a look at this
89:22 - oh you know what there's a little bit of
89:23 - an issue here
89:28 - i'm worried that i wasn't refreshing the
89:31 - code hold on don't worry okay so this
89:34 - looks better
89:36 - um let's get rid of this
89:39 - now um
89:43 - function mouse pressed
89:47 - let's have a
89:49 - test
89:50 - index
89:51 - equals zero
89:54 - so this is test index
89:56 - and then test
89:58 - index plus plus
90:04 - okay that's the first image
90:06 - okay see
90:09 - nothing is changing now is nothing
90:11 - changing
90:12 - because
90:14 - i am incorrectly
90:20 - i'm pretty sure that i have the cache
90:23 - disabled but let me just check
90:28 - under network is what i'm looking for
90:31 - yeah i have this setting should
90:34 - should stop me from
90:36 - caching the model file
90:40 - um but why
90:45 - so now i'm going to do this
90:48 - let's actually load the
90:58 - let's load the pixels of this image
91:04 - and this should be no
91:07 - this shouldn't be
91:09 - oh yeah i don't need this input canvas
91:11 - anymore
91:13 - this was silly
91:20 - right i can just draw that test image
91:22 - directly
91:24 - load pixels
91:41 - pixels i times four
91:56 - okay i'm reading the chat because
92:00 - okay
92:01 - ah
92:03 - okay
92:05 - so something about the canvas was wrong
92:10 - okay
92:11 - i knew something was weird
92:15 - well this is much
92:16 - more what i was expecting oh whoa boy
92:19 - did i just go off on a direction forever
92:21 - why what was wrong with the canvas
92:24 - input canvas pixels
92:30 - input canvas draw the image
92:35 - like what's the difference okay put this
92:37 - and just put this back
92:44 - okay so and now
92:46 - why
92:49 - why if i say
92:50 - input why if i do this instead of the
92:53 - test image
93:01 - the load pixel this must be a p5 bug
93:08 - this has got to be a p5 bug
93:10 - oh this is so sad but i guess this is
93:12 - good that i discovered this because
93:13 - maybe it would
93:15 - cause me some problems later
93:17 - why is the canvas can i not seem to get
93:20 - new
93:21 - pixels from it
93:26 - i mean one thing i could try to do
93:28 - is
93:30 - recreate the graphics context each time
93:39 - still not working
93:42 - is this asynchronous or something
93:48 - i commented out the update
93:51 - what am i missing
93:57 - right there's no difference here
94:03 - i mean i i guess to be 100 sure
94:10 - i need to draw the input canvas
94:17 - oh but
94:20 - but that's gonna
94:22 - cause problems
94:25 - if i'm
94:27 - recreating it so i have to put this back
94:29 - into setup
94:34 - yeah why
94:36 - why what
94:45 - i mean
94:50 - okay let's try this
95:07 - what if i were to say test image copy
95:11 - input canvas
95:17 - i mean i'm just like copying the image
95:18 - in extra time
95:27 - so right instead of using the pixels
95:30 - from the actual canvas
95:35 - i am
95:37 - i mean do i need to update the
95:39 - is it as simple as i just didn't update
95:41 - the pixels because i did load pixels
95:43 - that could be it
95:46 - well this works
95:50 - so i like copied the pixel from the
95:52 - canvas
95:54 - into
95:55 - an image but
95:56 - could it have been
95:58 - hold on this does kind of make sense
96:11 - all right this is what doesn't work
96:15 - i mean i have a workaround now
96:19 - so that doesn't work
96:21 - but what if i were to put input canvas
96:24 - update pixels
96:31 - no is that the wrong place for them
96:36 - i don't no what i'm doing
96:39 - no i think it's just broken
96:43 - i think the input canvas is broken so
96:48 - i'm going to go back to this ridiculous
96:51 - solution
96:58 - i don't
97:04 - this is working
97:07 - but now i'm going to go back to
97:10 - this
97:11 - and forget about the test images
97:17 - there we go
97:22 - and now in theory
97:25 - it's interesting how it's having trouble
97:27 - distinguishing the circle in the square
97:29 - but i'm not going to get too bent out of
97:30 - shape about that i kind of like that
97:34 - anyway
97:38 - yeah so i definitely eric is saying what
97:40 - if you train a data set that randomly
97:42 - rotates the square i 100 want to do that
97:44 - so i'm just unfortunately like i'm i'm
97:47 - this this is like the slowest thing i'm
97:49 - ever because i'm running into so many
97:52 - small little bugs but i have this
97:55 - working
97:57 - so
97:58 - what i would like to do
98:00 - is i would like to
98:04 - uh add the noise oh my god
98:08 - so just to finish close the loop on this
98:13 - uh
98:14 - [Music]
98:15 - and i see some comments here
98:17 - um in the discord chat as well so
98:21 - just to close the loop on this what i
98:22 - would like to do is let me add some
98:24 - noise
98:25 - so i'm gonna say
98:26 - i'm just gonna add
98:30 - 10
98:31 - random dots
98:35 - so let's give me a
98:38 - random x
98:40 - and a random y
98:43 - and do a point
98:44 - at x y
98:46 - with the same stroke weight
98:51 - so how come i don't
98:54 - see those
98:56 - oh i don't need this last argument rgb
98:59 - uh point
99:02 - oh input canvas sorry input canvas
99:05 - xy
99:10 - so
99:10 - you can see that the noise is i mean
99:13 - this is like a sort of
99:15 - pretty terrible demonstration of noise
99:18 - um let's do the following
99:21 - um
99:22 - let's give it like a hundred points
99:25 - uh
99:27 - stroke
99:29 - weight
99:30 - um this is so silly that i have this
99:31 - like divided by two at w everywhere but
99:34 - let's just make it stroke weight one
99:37 - um and then
99:40 - also we can do the stroke like a little
99:42 - bit lighter
99:49 - [Music]
99:52 - oh i forgot to do input canvas that's
99:54 - why
99:57 - input canvas input canvas
100:00 - uh can i get away with like 500
100:04 - yeah so this is what i wanted to show
100:06 - you of course we have this weird
100:08 - squirkle thing going on
100:10 - but this is how an auto encoder can
100:13 - denoise
100:15 - and let's try doing
100:16 - 1500
100:20 - right the noise is completely eliminated
100:22 - and yet i am drawing a nice circle or
100:26 - square
100:27 - you can see it's a little bit more
100:28 - squarey as it gets larger
100:31 - a little bit more squarey
100:36 - wizzy says unsure what this is all about
100:38 - i just got here from the quadtree so
100:39 - first of all welcome i hope the quadtree
100:41 - video was helpful to you wizzy what i am
100:44 - doing currently is i am building and
100:46 - this is the diagram of it an auto
100:48 - encoder in uh javascript using both
100:51 - tensorflow.js and p5.js and what i'm now
100:54 - demonstrating
100:59 - is and and monos is saying this isn't
101:01 - really denoising
101:03 - the model wasn't trained on it so the
101:05 - way that i'm approaching denoising here
101:08 - is not giving it noisy images with a
101:11 - target output
101:12 - i'm just having it learn
101:14 - a singular kind of output
101:16 - and then if i give it a noisy image the
101:20 - only thing it knows how to do is make a
101:22 - copy of that input with a certain kind
101:25 - of style output thus removing the noise
101:27 - so that's really how i think of this as
101:29 - denoising um
101:32 - so this is exciting to see
101:34 - the interesting thing would be like what
101:35 - happens if i let the circle
101:37 - be bigger
101:39 - than the range in the training data set
101:41 - i assume it won't be able to reproduce
101:42 - that but that'll be kind of interesting
101:44 - to see
101:45 - so like for example right now
101:47 - um this diameter its
101:50 - range is going up to 200
101:53 - but what if i actually like let it go
101:55 - from zero all the way to the full width
102:03 - so you can see as it gets to 0 it
102:05 - doesn't know what to make of that
102:07 - oh whoops
102:14 - oh sorry up this should be to this sorry
102:20 - so at a certain point it's going to get
102:23 - larger than any training image it ever
102:25 - looked at and it's going to get confused
102:29 - let's see what happens yep there that
102:31 - happened right there so it's like trying
102:34 - to make sense of that but it had no it
102:36 - can't extrapolate beyond what it learned
102:39 - but if i were to retrain the model
102:46 - with images that were
102:48 - the full size
102:53 - i'm giving it a bigger range of images
102:55 - now
103:09 - but if you input an image of mario
103:10 - brothers it will draw a squirkle anyway
103:11 - exactly it's going to draw everything
103:13 - into a squirkle
103:15 - and if i uh retrain the model
103:18 - now i kind of want to
103:21 - just
103:23 - for the sake of argument now now that i
103:25 - understand what wasn't working
103:27 - what the issue was let me go back to the
103:30 - model training code
103:31 - and
103:32 - i'm really determined to finish this
103:34 - project today so i'm obviously going to
103:36 - go past one o'clock
103:40 - but let me just return to this i am
103:42 - curious to
103:44 - [Music]
103:46 - see what happens if i try
103:49 - go back to mean squared error as the
103:51 - loss function
103:53 - and let's just change the optimizer to
103:55 - sgd i don't know
103:57 - if this should be
104:00 - better or not
104:01 - but let's retrain the model
104:05 - you can sing the model training song
104:06 - okay so i don't sgd doesn't seem to be
104:11 - maybe i need a higher learning rate with
104:12 - sgd
104:18 - um
104:19 - so let's go back to um
104:22 - i can't remember if i specify the
104:23 - learning rate anywhere
104:26 - i didn't i didn't i'm using a default
104:28 - learning rate
104:29 - but let's try mean squared error
104:36 - and let's see
104:37 - um
104:39 - let's see how well this does
104:42 - um the inside of the rectangle looks
104:45 - bent in this processing sketch so i
104:47 - think that's just an optical illusion i
104:49 - don't want to run this again although i
104:50 - can without saving the image
104:53 - i think that's just an optical illusion
104:55 - because of the
104:57 - rapid pace of circle and squares
105:00 - if i were to change the frame rate
105:03 - to like five
105:08 - i don't think you would see that
105:14 - traditionally we use noisy inputs while
105:16 - trading model rather than just a test
105:18 - set but this is perhaps the best way to
105:20 - do it given the simple nature of the
105:21 - problem thank you monas that's a very
105:23 - useful commentary all right so what's
105:24 - happening next while this is training
105:27 - um
105:28 - and let me just put this
105:30 - back
105:31 - um
105:33 - i want to go to the github repo for this
105:35 - and this this isn't going to work yet
105:37 - because it's still training the newer
105:38 - model
105:39 - although it seems to have like got stuck
105:42 - on a local minimum like which can happen
105:44 - from time to time i don't know if i
105:46 - should adjust the learning rate does
105:48 - anybody have a suggestion
105:51 - i kind of want to just run it again
105:55 - and see
106:03 - though it's it's stuck in that same spot
106:11 - where do i put the learning rate is that
106:13 - here so let's go to tf.js
106:24 - fit
106:27 - dot fit
106:30 - um
106:32 - call backs validation split
106:35 - sample weight initial epoch yield every
106:37 - where does the learning rate get
106:44 - ah
106:45 - it goes with the optimizer
106:49 - okay
106:51 - so if i wanted to try adjusting the
106:53 - learning rate
107:02 - would go here
107:08 - like this
107:10 - so let's give it like
107:11 - just curious like a super high learning
107:13 - rate
107:14 - oh whoa
107:16 - it found its way past that so it just
107:18 - took a little bit okay whoa okay i'm
107:20 - gonna i'm gonna let it this looks like a
107:22 - much better model with mean squared
107:24 - error now
107:25 - i'm gonna let it keep going and not
107:28 - worry about
107:33 - so i'm just gonna keep this
107:34 - in the back of my pocket if i wanted to
107:39 - i'm going to let this model i'm going to
107:40 - let this model finish training
107:42 - the loss is like
107:44 - very very very lower than anything i've
107:46 - seen to date yet working on this project
107:49 - and now
107:51 - what i want to do is go to the github
107:53 - repo for this
107:56 - and
107:59 - um
108:02 - i didn't
108:03 - i didn't see this one
108:05 - um sorry mini james but i want to look
108:07 - at this one
108:09 - so um this particular
108:12 - github issue was filed
108:14 - um
108:14 - [Music]
108:16 - had us has some really really helpful uh
108:19 - tips in it so first of all
108:21 - um i managed um so thank you so much to
108:24 - java gt who writes
108:28 - so this is how you can you can access
108:30 - the individual layers with
108:31 - autoencoder.layers
108:33 - so i made a little helpful function to
108:35 - split the auto encoder by looking for an
108:37 - increasing number of nodes
108:39 - so this is the way i'm going to be able
108:41 - to do that so
108:43 - but you can't just loop over these
108:44 - layers adding them to another sequence
108:46 - they don't carry the weights
108:48 - so i solve this with another helper
108:49 - function that creates a new dense layer
108:52 - so
108:53 - this is interesting to look at i suppose
108:54 - i can use this methodology
108:57 - um
109:00 - and um there's a lot of other helpful
109:03 - like tips in here
109:05 - about things so that's what i want to do
109:07 - next um also uh generating a gif like
109:10 - all this in the nodes in the node
109:12 - program make sure that decoder is fed
109:15 - with values zero through one
109:18 - um okay
109:20 - so but i'm going to come back to that i
109:21 - want to work on splitting the model next
109:25 - um but where is it
109:27 - um
109:28 - managed to get a 28 by 28 encoder
109:30 - reduced down to a single value
109:33 - couldn't do this at larger sizes which
109:35 - worked well down to four variables one
109:38 - makes sense because there's only one
109:39 - variable changing the the that radius
109:43 - um okay
109:45 - are we done all right we have a new
109:46 - model
109:48 - let's see how this new model looks
109:52 - so this new model should be much better
109:59 - yeah you can see like at the larger size
110:02 - it's really distinguishing the circle
110:03 - versus square
110:05 - and denoising
110:12 - now interestingly at lower at a lower
110:15 - size it's having a lot of trouble
110:18 - um it's having a lot of trouble um
110:21 - distinguishing the um the circle and the
110:24 - square because the bends probably of the
110:26 - circle are obviously much less extreme
110:29 - and harmony is doing a really great
110:31 - suggestion which is what happens when
110:33 - you translate the input image all right
110:36 - so what happens if
110:38 - i'm doing too many things at once here
110:41 - but
110:42 - i'm going to get to the latent space
110:43 - thing in a moment i have to make a new
110:46 - clearly make a new sketch here
110:50 - what happens if i draw that image
110:57 - at
111:07 - um
111:11 - at an x y position
111:13 - of my own
111:15 - design
111:23 - so let's see what happens here
111:29 - so you can see as i move it around
111:36 - it's confused but when it's centered
111:39 - that's kind of cool to see
111:46 - you can see like if i put it over here
111:47 - it thinks it's a it's like that must be
111:49 - a big square because there's dark pixels
111:51 - over there but maybe it's a small one
111:53 - and i don't know why i've lost the
111:56 - oh this one's supposed to be um circle
111:59 - no wonder
112:02 - so a good thing now what would happen if
112:05 - i trained it with in circles and squares
112:08 - that are anywhere in the image oh can i
112:10 - do that
112:12 - but i want to do the latent space
112:14 - thing if you use cosine annealing
112:17 - learning rate you can use a high
112:18 - learning rate the schedule or lower yeah
112:19 - yeah yeah
112:20 - so i don't know that i'm going to get
112:21 - that sophisticated with this but quick
112:23 - summary of the comment from manas is
112:25 - that
112:26 - you can start with a high learning rate
112:28 - and then over time like as it gets
112:30 - closer and closer to the optimal weights
112:32 - you can lower the learning rate so that
112:34 - it can fine tune it better but i cannot
112:37 - resist
112:39 - we must not stop
112:40 - let's try
112:42 - um
112:44 - having this also be
112:54 - let's
112:55 - try having
112:59 - the squares and circles in the training
113:01 - data set
113:03 - be
113:04 - in a random position
113:07 - and this has to be float because i'm not
113:09 - in javascript land anymore
113:14 - uh
113:16 - wait a sec
113:17 - something is wrong oh because i'm doing
113:19 - center
113:20 - no
113:21 - that should still be fine
113:28 - oh i'm resizing it down so this has to
113:31 - actually be these values should be the
113:32 - actual canvas size
113:36 - yeah all right this is going to be
113:37 - really tricky is it really going to be
113:39 - able to learn this
113:40 - convolutional layers would solve this i
113:42 - probably should not be trying to do this
113:46 - this is just asking for trouble
113:49 - but i cannot resist
113:56 - and
113:58 - remember my auto encoder
114:01 - only has
114:04 - eight units in the middle maybe i should
114:06 - give it
114:06 - 16. maybe for this i should give it 16.
114:09 - let's give it 16.
114:14 - uh i kind of want to save that previous
114:16 - model in case i need to go back to it
114:19 - so hold on
114:23 - um
114:26 - model
114:27 - squirkle
114:31 - now
114:31 - and then i think i might need to create
114:34 - the model directory again but it's empty
114:40 - okay
114:44 - so now i am attempting
114:49 - to see uh
114:54 - uh i think somebody might be here that i
114:56 - need to speak with hold on a sec
114:58 - everybody while this is training
115:13 - um sorry i'm just checking something
115:15 - here
115:17 - it might just be a delivery truck but i
115:19 - hear a loud noise
115:28 - oh
115:29 - maybe just retrieving something okay
115:32 - how's this going here oh no this seems
115:33 - kind of stuck
115:38 - i i think
115:43 - with many sizes placements you'll want a
115:44 - larger training set that makes a lot of
115:47 - sense the model size is less important
115:48 - than the data all right so that's a
115:50 - really good point okay i think i need to
115:51 - backtrack
115:53 - because my goal was to demonstrate
115:55 - latent latent variables
115:59 - so let me backtrack and not go down this
116:02 - road right now
116:03 - i think i could have done like
116:05 - if like a rotation maybe would have been
116:10 - so let's go back to
116:16 - um
116:23 - oh no that's wrong
116:30 - so let me put it back
116:32 - i had saved the model but i realized i
116:34 - need to
116:35 - deconstruct the model so
116:37 - um
116:40 - let me quit this let me just start the
116:43 - training again all right let's take a
116:44 - look at what i want to do so ultimately
116:47 - and let's put this back to eight
116:52 - i wonder if i could get it down to four
116:53 - oh let's do eight that's fine
116:57 - let's see if the loss does well with
116:59 - four
117:02 - okay
117:03 - so i'm trying to put it down to four
117:05 - just to see how we do
117:11 - oh i didn't make the new training data
117:16 - i have to make the new training data
117:17 - sorry everybody my brain has melted here
117:20 - uh
117:21 - what is going on
117:30 - okay
117:31 - let us go back to
117:35 - this wonderful
117:40 - let's go back to this wonderful
117:43 - code here
117:45 - so this is taking out the layers
117:48 - creating a new layer
117:51 - setting the weights
117:53 - okay
117:54 - so this makes sense i feel like there
117:56 - must be a way to do it
117:58 - um
118:01 - so i don't i think because it's such a
118:03 - simple amount of
118:06 - layers right now
118:10 - i don't know that i need i'm going to
118:11 - use this as a reference
118:13 - but i think i might be able to
118:15 - just even just save those layers in a
118:17 - variable
118:19 - and do this more simply
118:26 - um okay
118:27 - um let's see how this training is going
118:30 - wait what just happened oh yeah no the
118:32 - images are done okay
118:36 - i didn't take a break that's all kind of
118:38 - a problem
118:39 - um
118:41 - andrea says those sigmoid activations
118:43 - seem strange shouldn't you have only one
118:44 - after the final layer i think that's
118:46 - correct
118:48 - let's do that as well let's have all of
118:51 - them
118:55 - let's be able to expand it out only the
118:58 - last one
118:59 - should be sigmoid
119:03 - let's see how this does for us
119:08 - okay so now just examining
119:13 - just examining the code
119:20 - i know i just want
119:22 - the last three layers so let's look at
119:25 - this
119:31 - so now what i want to write some code is
119:35 - create a new model with
119:37 - just the the the decoder
119:40 - so i think that probably
119:43 - the way that i should be doing this
119:44 - though
119:45 - is rather than extract the layers
119:47 - shouldn't i just save them as i'm going
119:49 - like for example
119:53 - what if i were to say
120:01 - what if i were to create an array
120:08 - sorry for the noise everybody
120:12 - [Music]
120:15 - yeah i could do
120:17 - all right
120:21 - um
120:27 - all right so what if i
120:37 - i'm just gonna do this
120:41 - oh yeah
120:42 - i have an idea sorry
120:47 - couldn't i
120:48 - change do this
120:50 - and then have decoder layers
120:56 - and then basically
120:58 - do exactly this
121:09 - um
121:11 - decoder layers
121:13 - push
121:15 - yeah
121:28 - just the helicopter landing outside
121:29 - don't be alarmed he's picking me up i've
121:31 - gotta g i've gotta get somewhere fast
121:37 - uh
121:41 - all right so
121:45 - i'm gonna add all these decoder layers
121:51 - okay
121:52 - then
121:54 - i'm going to say
121:55 - 4 let i equal 0 i is less than
121:58 - decoder layers dot length i plus plus
122:04 - then i'm going to say add
122:06 - decoder layers index i
122:26 - um okay
122:30 - so
122:34 - now
122:35 - i put the decoder layers in a separate
122:38 - array
122:43 - then i'm adding them to the auto encoder
122:45 - so this should be the same
122:46 - i hate to just constantly retrain the
122:48 - model
122:49 - but let me just make sure this still
122:51 - sort of like looks right
122:56 - yep this seems reasonable so so
122:58 - everything is the same same as it was
123:00 - before
123:01 - now if i go back to this reference i
123:04 - want to create a new model
123:09 - so let's it's nice to put this in a
123:11 - separate function but i'm going to pull
123:13 - this code from java gt
123:15 - and see if i can kind of unpack it but
123:17 - with my
123:18 - methodology
123:22 - so
123:23 - oh i see but
123:27 - so i'm actually going to return
123:30 - both
123:32 - the
123:33 - decoder layers
123:35 - and the auto encoder
123:37 - as like an object because i might want
123:39 - to make use of both of these
123:41 - and then i can say
123:54 - do this
123:55 - so
123:56 - now i'm building the autoencoder but
123:59 - saving the decoder layers in a separate
124:02 - array
124:04 - okay
124:06 - um
124:07 - by the way banning if there's like spam
124:10 - happening in the chat
124:12 - is perfectly thank you nicole for
124:14 - stepping up and doing some moderation
124:17 - um
124:22 - i'm just gonna
124:25 - okay i don't know if it's possible to
124:26 - ban or not
124:28 - okay
124:30 - okay
124:31 - so
124:32 - okay
124:34 - so now i have access to the decoder
124:36 - layers separately so what i want to do
124:38 - here is create the new model with just
124:40 - the decoder
124:43 - create decoder
124:46 - with both the decoder layers and the
124:49 - auto
124:50 - encoder
124:53 - i don't know if this is going to work
124:56 - so now
124:57 - i just want
124:59 - uh
125:00 - create decoder is that what i called it
125:03 - decoder layers
125:05 - and the auto encoder
125:08 - and then i can go and take a look at
125:11 - this
125:12 - and say create the new model the decoder
125:18 - is a sequential model
125:21 - then
125:22 - for every
125:31 - for every decoder layer
125:44 - right this is the sort of i'm kind of
125:46 - doing the same thing so this there might
125:48 - be a lot of redundancy here
125:50 - so we can clean it up later refactor
125:52 - this later but
125:54 - i am creating the decoder
125:56 - creating a new model just by
125:59 - taking the list of decoder layers that i
126:01 - saved
126:02 - to kaya suzuki
126:06 - someday there'll be too many of these
126:07 - and i won't be able to do it it's good
126:12 - tsukaya suzuki
126:16 - welcome to
126:17 - the coding train you are boarding right
126:19 - now
126:21 - slow down train we're pulling into the
126:22 - station and opening the door and letting
126:25 - kaya on board
126:27 - for your coding train membership
126:30 - you win
126:32 - not this ukulele my prize ukulele
126:35 - but your very own random number
126:43 - uh on page 163 line uh row
126:47 - 8125 column one your sequence is
126:51 - get ready zero five three four eight
126:56 - okay
126:57 - um
126:59 - so close here
127:01 - so i'm adding all of the decoder layers
127:04 - to this new decoder model
127:07 - then i need to compile it
127:13 - i'm going to compile the decoder
127:18 - with the same settings that i used for
127:20 - the auto encoder
127:23 - so let me just make a 100
127:26 - sure that i'm doing this correctly by
127:27 - actually copying this up here
127:29 - and just changing this to decoder again
127:31 - any returned in code that i can
127:33 - consolidate and do in a better way i
127:35 - will
127:37 - um but the issue is i believe maybe we
127:40 - don't have the weights
127:44 - so
127:47 - oh it's making a new layer
127:49 - why do i have to make a new layer and
127:51 - copy the
127:52 - weights oh is that really why can i just
127:56 - add the layer with the weights
128:00 - manually copying the weights
128:07 - huh
128:08 - so let's
128:09 - i feel like there's a different way to
128:11 - do this
128:13 - with um tensorflow.js but if this works
128:16 - then awesome so sorry i'm gonna do it
128:19 - i'm gonna i'm gonna follow this way so
128:22 - i'm actually not adding the decoder
128:24 - layer directly i'm creating a new layer
128:31 - with
128:32 - so the old layer
128:36 - is that decoder layer and i'm making a
128:39 - new layer
128:40 - with
128:42 - the same number of units the same
128:44 - activation function and the same input
128:48 - shape in theory i shouldn't have to do
128:51 - that because the input shape should be
128:52 - inferred but
128:54 - and then
128:58 - i'm going to add that
128:59 - new layer
129:03 - but i also need to copy over the weights
129:11 - like this
129:14 - okay
129:16 - and i don't need the auto encoder
129:18 - to be passed in
129:21 - because i thought i was going to need
129:22 - that to pull the weights please use four
129:24 - of loops you know what
129:26 - i would like to do that as well
129:30 - let layer of decoder layers
129:41 - yeah then i don't need this much better
129:45 - so this should be the function
129:48 - that and again i i feel like there's got
129:50 - to be a different way of doing this but
129:52 - i don't i'm fine with it if this works
129:54 - great
129:56 - um in which
129:58 - in where i am
130:01 - [Music]
130:02 - and by the way i shouldn't have to
130:04 - retrain the model now i should be able
130:06 - to just
130:08 - um pull in the auto encoder load it
130:10 - because i have it saved
130:14 - um but where did i save it is the
130:17 - question file public model
130:20 - so i have to do this
130:23 - so
130:25 - oh the last training got kind of stuck
130:29 - at like a not a great loss let's go
130:32 - should i just go back to 16
130:35 - let's go back to 16 units in the center
130:40 - um
130:43 - oh this needs a lot of work 16 units
130:47 - or eight let's go back to eight
130:50 - eight is fine i can do eight
130:52 - we're gonna go back to eight
130:55 - um now i've added the decoder layers
131:04 - all right and then returning them both
131:07 - so now create deco okay so let decoder
131:12 - equals create
131:13 - the decoder
131:17 - and then i want to save decoder
131:23 - save decoder equals public file public
131:26 - model decoder
131:28 - so i'm going to save the decoder to a
131:30 - different directory okay everyone
131:36 - isn't there a model.getlayer method
131:38 - there certainly is marius so i i feel
131:41 - like there's there's probably a much
131:42 - more proper tfjs way of doing this but
131:46 - i think this should work let's see what
131:48 - happens
131:50 - unfortunately i'm gonna have to train
131:51 - the whole model again
131:56 - and hopefully we're gonna start seeing
131:58 - um
132:03 - i wonder if i do need to play with the
132:04 - learning rate
132:10 - or is it just going to break out of this
132:11 - somehow
132:20 - so let's take a look here
132:30 - i could just load the model i had
132:32 - earlier
132:38 - why why why why why why why why why
132:44 - am i just too impatient and i should let
132:46 - it
132:54 - what is the deal with it being
132:55 - completely stuck did i not put the new
132:58 - training data in
133:00 - there hold on
133:03 - let's make sure the new training data is
133:05 - in there
133:07 - yeah that's the new training data
133:43 - what is going on
133:53 - yep this is the new training data
134:01 - i'm not saving the decoder
134:05 - there's a typo in the code oh thank you
134:08 - well that's good that gives me another
134:10 - excuse to run this again
134:22 - i mean i'm tempted to just load the
134:24 - previous model i have that i know is
134:26 - working well and then
134:29 - but what
134:34 - let's just generate a new
134:36 - training data set again just to be sure
134:43 - lower the learning rate
134:47 - okay
134:51 - so to do the learning rate
134:56 - right now i'm just using the default
134:59 - atom
135:07 - so what would be a good learning rate
135:09 - i'm just going to try this point zero
135:11 - one
135:33 - uh
135:35 - now this is weird
135:54 - the loss is not going down
136:08 - hmm
136:12 - did this mess up something it really
136:14 - shouldn't have i just put the layers in
136:16 - here
136:19 - and then i'm putting them in
136:22 - the auto encoder one at a
136:30 - time this is not going well
136:35 - change in the activation function
136:38 - i don't think so i mean i can put these
136:41 - back
137:04 - hmm
137:17 - maybe it's thing with your layers array
137:19 - i know
137:22 - well
137:23 - now now i've now i've got it
137:26 - it seems to have caught
137:32 - so it
137:37 - all right i'm gonna go with this
137:42 - and let this model finish training
137:46 - because now the learning rate is
137:48 - and this by the way is now
137:52 - just with
137:56 - whatever the default learning rate is
138:00 - what is it tensorflow
138:03 - js default learning rate
138:05 - atom
138:12 - point zero zero i don't know if that's
138:13 - from 2018.
138:18 - so this is probably the default learning
138:20 - rate for adam
138:38 - okay
138:40 - we're still going down
138:45 - why is the accuracy zero
138:58 - let's just see how this model does
139:02 - it's so hard
139:03 - oh okay i like this
139:08 - epoch 85.
139:16 - oof
139:21 - what was that why was that one time that
139:23 - i uh
139:25 - got this incredibly low loss
139:33 - oop
139:42 - cannot read
139:47 - oh you know what
139:50 - i forgot to return it
139:55 - hilarious but that's fine let's just see
139:58 - now
140:07 - um let's go back to my p5 sketch
140:10 - why is this model so much worse all of a
140:12 - sudden
140:23 - okay
140:26 - so look at this
140:28 - model
140:31 - i mean it's definitely
140:33 - doing something
140:39 - what just happened i see the chat going
140:41 - a little bit
140:42 - crazy um
140:45 - but if i go here
140:47 - and
140:49 - load model dash squirkle
140:56 - look
140:57 - what what did i do for this model this
140:59 - model is working so well
141:06 - like this is what
141:08 - i train like when i train this model
141:10 - like what what happened
141:16 - i don't remember like what settings were
141:18 - different
141:19 - okay
141:20 - ah
141:27 - this is driving me crazy
141:32 - auto encoder
141:34 - 256 128 8
141:37 - 128 256.
141:40 - and these are the decoder layers
141:42 - that i then add one at a time
141:48 - just make sure for
141:50 - a layer
141:53 - of decoder layers
141:59 - add that layer
142:02 - then compile it mean squared error
142:05 - yeah i don't need this accuracy metric i
142:07 - guess
142:09 - just take that out
142:14 - and
142:18 - let's just be explicit about the
142:20 - learning rate so i can sort of see what
142:22 - it is
142:26 - i wonder if i got lucky with the train
142:28 - let's i could give it more images
142:34 - let's generate another set of training
142:36 - images
142:38 - use i'll give relu another chance okay
142:54 - but i want to use sigmoid for the last
142:56 - one because i want to
142:58 - uh i want to
143:00 - [Music]
143:01 - make sure that i'm bound between zero
143:04 - and one
143:06 - and maybe i shouldn't okay
143:11 - okay here we go everybody wait hold on
143:13 - let's just see here
143:15 - um
143:21 - this is like really awful how i have
143:22 - like this duplicate code
143:25 - but
143:29 - this shouldn't matter actually though
143:30 - because i'm not going to be training
143:32 - this model
143:33 - so i'm not sure why i need this but i'm
143:34 - going to
143:35 - okay
143:36 - okay okay everybody
143:55 - i want to give relu another chance
144:00 - model summary
144:03 - okay
144:05 - i like this
144:06 - idea
144:08 - i can't believe that i'm gonna be
144:09 - another one of these live streams and
144:10 - not gotten to the part that i wanted to
144:12 - go to
144:16 - want to go to save train model
144:21 - okay
144:33 - is this right what you're suggesting
144:37 - oh my uh
144:43 - yeah it's completely
144:46 - stuck learning rate okay
144:48 - like lower learning rate
144:51 - okay
144:57 - i would have thought i need to raise the
144:58 - learning rate but
145:08 - like to me i need to raise
145:11 - yeah i could
145:20 - [Music]
145:31 - lower the rate divide by 10 until it
145:33 - works
145:36 - this does not seem like
145:50 - what if i have a high learning rate
146:02 - eight eight three two is just like
146:09 - where it wants to be
146:16 - what is going on but what
146:19 - what did i do
146:22 - like did i change something in the
146:24 - training data
146:30 - i don't think so training data looks
146:32 - reasonable
146:56 - yeah
146:57 - interesting
147:00 - okay what just happened here
147:03 - no sigmoid
147:05 - no sigmoid a terrible sigmoid okay wait
147:08 - this is good
147:09 - hold on but i was like messing around
147:11 - with the learning rate okay i'll leave
147:13 - that default learning rate okay
147:15 - i think we might be in good shape now
147:16 - people
147:18 - i think maybe
147:20 - i think this
147:22 - sigmoid was not helping me
147:33 - i'm sorry
147:35 - i'm sorry
147:48 - in my head because i'm doing something
147:50 - that's the most sort of like basic
147:52 - simplistic
147:55 - like demonstration
147:58 - that i should go back to the classics
148:00 - like sigmoid
148:03 - but i guess that was really standing in
148:05 - the way of progress here
148:08 - standing in the way of the progress did
148:09 - i tell you about today's sponsor
148:11 - another hour
148:12 - curiositystream.com codingtrain are you
148:15 - asleep
148:17 - do you need to wake up
148:18 - as the coding train board you
148:21 - you could try watching something on
148:22 - curiosity's dream or nebula for less
148:24 - than one dollar a month for the entire
148:26 - year
148:28 - oh my god
148:32 - okay we've stopped
148:34 - no it's still going down little little
148:36 - bits and pieces
148:41 - little bits and pieces
148:46 - what did i do that one time
148:48 - that we got that crazy low loss
148:52 - was it just like luck
148:56 - drop the non-linearity for the last
148:58 - layer
149:04 - ah k weekman is here
149:08 - probably could have saved me like at
149:10 - least two hours of wasted time right the
149:13 - losses definitely seems to be nope still
149:15 - going down i want to see that like
149:17 - scientific notation though then i know
149:20 - i'm really doing something right
149:30 - okay
149:32 - oop
149:33 - hiccup a hiccup
149:35 - the number went up this is very exciting
149:37 - i mean needs really needs some kind of
149:39 - like something
150:03 - all right
150:05 - 256 128 8 128 256
150:09 - 3136 that's right total parameters
150:12 - trainable parameters non-trainable
150:13 - members okay we got the model summary
150:18 - might need more epochs or a higher
150:20 - learning rate well let's just see
150:23 - how this
150:25 - i refresh this should be oh no this is
150:27 - still whoa what
150:32 - okay this is insane i've not seen it do
150:35 - this
150:36 - wait but am i loading the correct model
150:43 - yeah look at look at this crazy model
150:45 - what it's like outputting
150:51 - so funny i was there was a time earlier
150:54 - today where my model trained perfectly
150:57 - and now
150:59 - what is going on
151:02 - uh
151:03 - k weekman this is our current
151:08 - setting
151:10 - um
151:12 - where oh sorry i mean the wrong code the
151:15 - current this is the current setting
151:21 - um
151:23 - yeah where's the noise coming from right
151:26 - yeah let's let's
151:28 - let's remove the noise at least in our
151:31 - input image
151:33 - just to see how well the model is
151:34 - performing otherwise
151:38 - um
151:50 - this is so weird
151:53 - the model was trained and has some like
151:56 - i think this is because of
151:58 - relu in the last no
152:04 - i mean where did that noise come from
152:07 - where are those dots come why are they
152:09 - there
152:16 - correct i know everyone in the chat is
152:18 - like 30 seconds behind me but the left
152:20 - is the input image the right is the
152:22 - output and i'm not sure where this new
152:24 - noise is coming from
152:27 - uh the dots are because of the rayleigh
152:29 - on the last layer negative values
152:30 - becomes zeros
152:32 - oh over 255
152:40 - um okay so maybe
152:45 - maybe it's just an issue with me drawing
152:47 - it i have an idea hold on hold on
152:53 - i think there's an issue just with me
152:54 - drawing it so
152:57 - uh where am i
152:59 - where am i getting the values predict
153:01 - await output array output image
153:05 - render output image
153:07 - fill
153:09 - so um
153:17 - let me
153:18 - get that value and let me constrain it
153:23 - to between 0 and 255.
153:35 - no it's still there it's very consistent
153:39 - relu is in the last layer clip the
153:41 - values i thought that's what i was doing
153:46 - um
153:50 - this shouldn't make any difference
154:02 - all right what if
154:07 - hold on
154:12 - if val is less than okay hold on
154:19 - get rid of the constrain
154:21 - maybe what i don't want to do is
154:22 - constrain
154:25 - if val is
154:29 - less than zero
154:30 - val equals 255.
154:39 - let me just make sure
154:41 - i'm actually editing the right code
154:45 - okay
154:59 - i'm totally lost
155:05 - all right try sigmoid okay we're going
155:07 - back to sigmoid people
155:15 - so i want the last layer to be sigmoid
155:20 - and i want
155:23 - to just say atom here
155:30 - this is what i want i want this
155:32 - simplicity and this worked
155:37 - yeah
155:38 - um
155:41 - i mean
155:43 - do i just need more units i shouldn't
155:58 - why why why why why what's going on
156:06 - this was working two hours ago no
156:08 - problem
156:11 - it was training perfectly and it was
156:13 - reproducing it perfectly
156:17 - oh we can ignore this nonsense
156:29 - i mean maybe i should really be
156:31 - controlling the learning rate
156:48 - i'm reading the comments right now
156:51 - and i'm appreciating them i've got to
156:53 - figure this out
157:09 - shuffle i didn't change anything the
157:12 - only weird thing i did was like adding
157:14 - the layers through this weird other way
157:16 - but i don't understand how that could
157:17 - possibly be different
157:22 - and the model summary makes sense
157:31 - i'm so frustrated oh my god it's 1 40.
157:37 - this
157:38 - i have me i have a meeting i have to go
157:40 - to
157:48 - the input is a 56 by 56 image i had
157:51 - upped the resolution because why not
157:54 - i could certainly lower it back down
157:57 - just to like
158:00 - yeah i mean we could lower it back down
158:02 - until everything will run a lot faster
158:04 - let me try that
158:07 - i'll make a new set of images
158:18 - stroke weight at 8.
158:28 - well there we go
158:33 - there we go
158:34 - so
158:42 - okay
158:44 - so why
158:46 - was 56 by 56
158:49 - freaking it out so much
158:52 - like it's really not that different of a
158:54 - problem to learn
158:57 - i guess it's just the orders of
158:58 - magnitude higher
159:00 - all right well i'm going to go with this
159:04 - just because
159:12 - so this has to change i got to change
159:14 - this to 28
159:16 - which would be the only thing that
159:17 - matters
159:25 - this is done
159:31 - okay
159:32 - i must have some kind of
159:34 - scaling thing off because i changed it
159:37 - to 28
159:38 - somewhere
160:00 - i'm not using these anymore
160:05 - where did i mess up
160:07 - this is not a thing
160:14 - this is not a thing i'm doing
160:40 - what is going on are my output images
160:42 - correct
160:51 - no
160:52 - oh no something is totally messed up
160:56 - when i changed it to 28 by 28 that's
160:59 - weird
161:01 - am i hard coding in
161:07 - oh wait no
161:08 - okay
161:09 - 28 by 28.
161:19 - where
161:37 - huh
161:41 - what have i done
161:47 - why did i destroy everything
161:56 - look at the chat regenerate images all
161:59 - right
162:00 - okay okay did i not regenerate the
162:02 - images
162:05 - i didn't regenerate the images
162:17 - is that really true
162:36 - i thought i did but i guess i didn't
162:45 - oh hi gloria
162:47 - gloria woke up
162:50 - oh but now i'm stuck again oh no i'm not
162:53 - okay
163:04 - [Music]
163:08 - okay okay everybody i forgot to generate
163:12 - them
163:14 - gloria
163:15 - come here come here girl you need to go
163:17 - outside huh
163:18 - come here do you want to say hi
163:23 - okay
163:25 - she does not love to be picked up oh
163:27 - come here oh you're a good doggy
163:30 - but she does let me pick her up
163:33 - okay oh yes
163:39 - look at that loss function
163:41 - that is a good loss function okay would
163:43 - you like to go back down
163:46 - okay
163:47 - go back down gloria okay oh god she is
163:51 - shedding like crazy okay
164:02 - okay
164:03 - all right well
164:04 - at least this is working now
164:08 - let me put the noise back in although i
164:10 - had it working at a higher resolution
164:12 - which was
164:13 - nicer
164:16 - oh i'm good i'm gonna lose my mind here
164:19 - let me put the uh points back in
164:25 - and put some noise back in
164:32 - and we're denoising again
164:37 - and we're denoising so now
164:40 - now i can do the latent variables
164:49 - the smooth version of relu is soft plus
164:52 - okay so simon i see your messages about
164:55 - the activation function
165:00 - um so i but i think i'm gonna have to
165:02 - investigate that for right now what i
165:04 - just want to do is see if i can get the
165:05 - decoder only to work okay everybody
165:09 - and i've got 15 minutes to do this
165:12 - so first of all did
165:17 - did i save
165:23 - the decoder
165:25 - yes
165:26 - so this should be the decoder
165:32 - and it has half the number of parameters
165:34 - so that makes sense that it's half the
165:35 - weights
165:38 - so now
165:39 - let's see if i
165:43 - i'm going to make a separate
165:47 - folder called decoder
165:51 - and then i'm going to take indexed
165:54 - index.html
165:56 - sketch.js
166:01 - put that into here
166:03 - and make a folder called model
166:07 - and that will go into here
166:10 - and then in the code where it is saving
166:13 - the decoder
166:18 - um
166:19 - [Music]
166:22 - so many things here
166:24 - i had so many ambitions of like some
166:26 - things i was going to do with this that
166:28 - i am definitely not getting to
166:30 - um
166:31 - if i am the the it should be public
166:34 - decoder slash model it's where it should
166:36 - be saved
166:39 - i just changed it to that
166:41 - now i should be able to go slash decoder
166:44 - this is going to break
166:46 - right okay this is going to break
166:51 - increase either the layer sizes or the
166:53 - amount of training data yes 100 right
166:57 - more layers and nodes but resolution is
166:58 - a matter of data size thank you so if i
167:01 - create some versions of this after today
167:03 - or anybody helps with this i'm gonna get
167:05 - back to a higher resolution but right
167:08 - now
167:11 - this i'm gonna i'm gonna close things
167:13 - because i don't know where i am
167:15 - this is now the decoder sketch
167:19 - and the decoder sketch
167:23 - does not need an input canvas
167:27 - an input it does need an output image
167:32 - which i'm going to make random and we're
167:34 - going to load
167:36 - model.json this is the decoder
167:42 - get rid of this diameter
167:46 - now next image
167:52 - is
167:54 - the i need to make it it's not an input
167:57 - and image anymore it should just be
168:00 - six
168:01 - the decoder should take
168:04 - uh let like the z vector the latent
168:07 - vector
168:08 - should have
168:10 - how many values in it
168:13 - did i end with 8 or sixteen i think i
168:15 - did eight right
168:18 - so this middle layer
168:22 - oh sixteen i i had sixteen okay i gotta
168:26 - redo this
168:27 - with less i wanted to get it down to
168:28 - four but fine 16. that's why i trained
168:31 - the model i have a trained model that
168:33 - works so let's just find out 16 values
168:39 - z index i equals random one so i'm just
168:42 - going to give it a random vector
168:45 - and then
168:46 - x
168:47 - test it's not really a test isn't really
168:50 - exactly right should be
168:55 - just the one z vector
168:59 - predict await
169:02 - and then everything else should be the
169:04 - same
169:05 - except i am only rendering there's no
169:07 - input image anymore
169:10 - i am just rendering the output image
169:14 - and it should be 280 by 280. so i have
169:16 - no idea if i did this right but let's
169:18 - see
169:20 - uh
169:25 - error due to auto encoder
169:27 - so decoder oh this is decoder
169:33 - square was expecting the number for the
169:35 - third parameter
169:41 - let's get rid of
169:44 - doing it again
169:48 - output
169:49 - print
169:54 - so it got a tensor
169:57 - okay
170:00 - weight output array
170:11 - it got an array of values oh i think
170:14 - maybe
170:15 - no i'm filling it at the beginning
170:19 - so let's let's not call this for a
170:21 - second
170:24 - ah
170:25 - w is 28
170:32 - i'm going to look at the chat
170:37 - okay so what
170:46 - it's getting something
170:48 - it's getting
170:51 - 784 pixels
170:55 - i plus j times w
171:11 - oh wait oh let me no loop please sorry
171:18 - but this worked
171:19 - so where was the error
171:22 - and why isn't it drawing anything
171:26 - square is expecting a number for the
171:27 - third
171:34 - oh does w not
171:38 - oh my goodness
171:41 - so for all this
171:44 - sorry everybody
171:47 - i forgot about it's just that
171:50 - okay boy tiny little mistake there
171:54 - so now
171:59 - we should actually be able to
172:03 - all right
172:04 - so that's
172:06 - one image i got from the model
172:15 - uh
172:23 - oh
172:25 - am i supposed to put a weight here
172:28 - i think i might have killed this
172:35 - let's take out that print
172:45 - oh i still have some other crazy console
172:47 - log
172:56 - so i would have expected
173:01 - this model not to produce such
173:06 - like fuzziness
173:13 - but let's just out of curiosity if i
173:15 - give it like all point five
173:18 - yeah
173:24 - hmm
173:31 - oh but this is the input is like part of
173:39 - could it
173:40 - am i like
173:42 - oops no no no no
173:46 - interesting
173:50 - so the question is did i make a mistake
173:52 - somewhere
173:54 - yeah
173:56 - right okay
173:58 - so i guess i can't really i'm not really
174:01 - going to be able to
174:02 - sit onto saying this generate just as
174:05 - just using the d you have to
174:06 - re-parameterize the latent vector
174:11 - so i was going to just make sliders so
174:13 - my my plan was this follows
174:20 - um so take a look at this
174:30 - um
174:34 - uh sliders
174:42 - push
174:45 - create slider so the range should be
174:47 - between 0 and 1
174:49 - starting value of 0.5
174:51 - and an incrementation value of 0.01
174:56 - and then what i wanted to do was have
174:58 - this do sliders
175:00 - index i value
175:08 - output image not being defined what did
175:10 - i do here
175:26 - oh line 34.
175:29 - what did i mess up
175:34 - oh did i lose that
175:39 - i still lost that by accident
175:41 - no
175:44 - oh
175:44 - let sliders
175:48 - equal an array
175:49 - oh not sliders index i sorry
175:53 - okay
176:11 - so i want to get this down to many fewer
176:13 - than just do like four
176:18 - and then see what i could i can see oh
176:20 - this makes it more square
176:25 - squared a circle
176:27 - this parameter
176:33 - yeah
176:35 - i know i know i need to use a
176:36 - variational auto encoder i just thought
176:39 - maybe
176:40 - the scale of relu is unbounded
176:45 - yeah so do i should i change that to
176:47 - sigmoid also
176:49 - would that help
176:51 - or
176:52 - like
176:53 - should i let them
176:55 - like the other thing i could do is just
176:57 - let the sliders
177:00 - have like a really higher range
177:03 - oops i keep doing this
177:08 - right i can get all sorts of interesting
177:10 - stuff
177:22 - all right so why don't i'm going to try
177:24 - the following
177:26 - and i realize i just
177:28 - i keep running this by accident so i'm
177:29 - going to let this run again
177:32 - and i'm going to go back to my
177:34 - model
177:37 - and i would like
177:43 - this i would like this let me get this
177:45 - down to eight i kind of want to make
177:46 - this four
177:49 - and then this activation should be
177:51 - sigmoid
177:53 - meaning
177:54 - these four units coming into here
177:57 - and i could add more layers
178:00 - but i don't know that i really need to
178:03 - um we'll all will be between zero and
178:05 - one
178:10 - yeah and i could look at some of the
178:12 - compressed images to see some values
178:14 - yeah but let's let's try this
178:26 - okay
178:28 - i'm stuck at a
178:30 - loss
178:32 - uh
178:52 - oh so close so close
178:55 - lower latent space i know would give
178:57 - worse results i just don't want to have
178:59 - so many sliders
179:17 - yeah it is good results so far
179:31 - so i
179:35 - is it going to help at all if i add some
179:38 - more layers
179:53 - increase the training data size oh wait
179:58 - oh oh
180:01 - it
180:02 - i just wasn't patient enough
180:04 - it like was stuck and then it caught
180:06 - okay hold on
180:09 - let me undo that let me undo that last
180:11 - little
180:17 - little extra thing i added
180:19 - okay
180:21 - now
180:23 - um go back to the sketch
180:27 - and it's still 16.
180:30 - it's still 16
180:32 - but i used sigmoid
180:39 - yeah this is much better
180:47 - it's just
180:48 - too many
180:50 - latent there we go
180:55 - so i'm able to control all the different
180:58 - variables
181:00 - and i can kind of try to figure out
181:02 - which ones do which
181:04 - i'm trying to figure out how to make
181:09 - whoa
181:10 - there certainly is some
181:13 - extra weirdness here
181:24 - anyway this is exciting but i i really
181:26 - want it to be like eight
181:30 - so what if
181:33 - let me let me just
181:35 - it's two o'clock so i've got to be done
181:38 - i can't believe how much time i spent
181:40 - doing this
181:41 - um
181:43 - but this will be my last attempt
181:47 - i'm just going to like
181:48 - pump it up a little bit
181:51 - i don't know that this matters
181:57 - i'm going to give it an additional layer
181:59 - with 64.
182:01 - i'm going to keep the 16.
182:04 - i really think i should be able to get
182:05 - it down to 4.
182:08 - then i'm going to put it down to 4 and
182:10 - make that sigmoid
182:14 - then i need to add back in
182:22 - a 16
182:26 - and a 64 right
182:30 - and should i make many more training
182:32 - images is that going to help me
182:35 - like if i make um
182:39 - 2100 i'm going to double the training
182:41 - images
182:46 - i really want i really want it to be
182:49 - all right let's do let's do 50 100
182:51 - images i'm gonna get it down to four and
182:54 - i'm gonna let it train for 200 epochs
182:59 - um
183:02 - 200 image so this has to be
183:05 - 5 000 i know i need to make the images
183:08 - and 5 000. we run this
183:15 - i could also constrain the squares and
183:17 - circles to be less
183:20 - yeah so flubby everybody's telling me
183:22 - this really good suggestion which is to
183:24 - pass images through the encoder and look
183:26 - at latent vectors because that would
183:28 - certainly
183:30 - help give me a sense and that's
183:32 - a very important uh analysis that i
183:34 - could do
183:36 - right two should be enough one for the
183:38 - type of shape and one for the radius
183:54 - this is going to take a while i'm still
183:55 - just generating the training i'm just
183:56 - going to tell you about today's sponsor
183:58 - curiosity stream are you still watching
184:01 - this have you been watching this for
184:03 - three hours
184:05 - i can't believe how much time i'm
184:06 - spending on this auto encoder i hope
184:08 - that this will
184:09 - add to my life in some meaningful way
184:19 - this has got to be the last attempt and
184:21 - now that i have a model for this i can
184:23 - off on my own and you i'm going to push
184:25 - all this to github
184:26 - all of you can try
184:29 - tweaking this in different ways and let
184:30 - me know
184:32 - what configuration architecture of the
184:34 - model
184:35 - how many units you're able to get them
184:37 - to
184:39 - what i'm missing here i will accept pull
184:41 - requests because this is my last live
184:43 - stream one more line needs to be
184:44 - modified from one thousand to five
184:46 - thousand okay where's that
184:49 - i think i got both of them
184:51 - oh is it where i'm loading the images no
184:55 - i think i'm good
184:59 - i think i'm good
185:02 - yeah think of how many eternal rainbows
185:04 - you could all be has anybody
185:07 - signed up for curiosity stream and
185:08 - watched the rainbow documentary you
185:10 - could have watched it like 10 times
185:12 - crossing stream flat coating train
185:20 - okay
185:21 - okay
185:22 - let's try this
185:29 - okay
185:31 - okay
185:32 - patience
185:34 - patience everybody
185:39 - line 17
185:44 - oh
185:45 - thank you
185:47 - [Music]
185:50 - got it
185:51 - [Music]
186:01 - oh this took a long time
186:03 - [Music]
186:09 - come on lower that loss
186:12 - you can do it lower that loss
186:18 - [Music]
186:21 - oh yes
186:23 - [Music]
186:28 - oh i like that i like that oh my god
186:35 - somehow i signed up for 200 epochs of
186:37 - this
186:40 - [Music]
186:42 - yeah so
186:44 - more data
186:45 - was clearly something i needed to do
186:48 - i also added more layers
186:53 - how long is it taking
186:55 - three seconds
186:57 - per epoch
186:59 - so i got like a little bit more so i got
187:01 - like 600 seconds left to go
187:04 - 10 minutes
187:05 - [Music]
187:08 - i mean i'm not going anywhere
187:11 - [Music]
187:14 - oh this is just the last live stream
187:16 - related to this auto encoder decoder
187:19 - project i mean i'll probably come back
187:24 - [Music]
187:30 - yeah i've got a really nice gpu sitting
187:32 - over here on the machine i'm using
187:33 - stream
187:36 - well the point of doing this was just
187:38 - like
187:39 - little bits of data
187:40 - [Music]
187:45 - oh that is a beautiful loss as soon as
187:47 - that scientific notation comes in
187:52 - i definitely do not need 200 epochs
187:55 - but i'm afraid to stop it
187:59 - [Music]
188:01 - oh yeah everybody
188:02 - while this is training
188:04 - you should sign up
188:06 - for the one year
188:08 - curiosity
188:10 - package
188:12 - it's less than it comes out to less than
188:14 - one dollar per month
188:16 - i'm not talking about less than one
188:17 - dollar per day
188:19 - [Music]
188:32 - at the local coffee place it's very
188:34 - expensive
188:36 - two cups of coffee for the entire year
188:38 - there you go two cups of coffee you know
188:42 - i get the oatmeal which costs 50 cents
188:44 - extra and then you can just watch this
188:46 - documentary about rainbows which is 22
188:48 - minutes long
188:50 - over
188:51 - again you can tweet me and say
188:54 - thank you so much i watched the rainbows
188:56 - over and over again
188:59 - mark edward
189:01 - i haven't so my battery died simon
189:03 - [Music]
189:10 - ah pca
189:12 - yes
189:13 - code parade was doing projects like this
189:16 - uh so wait hold on
189:19 - come back
189:20 - see how this is going
189:22 - uh we're at epoch 63.
189:25 - oh why didn't i put in the lower north e
189:26 - box i just i could put in 150 epochs run
189:30 - it again
189:31 - but it's still going down let's get it
189:34 - let's let it
189:35 - look simon says oh
189:37 - sorry this
189:38 - i guess i could try to plug this in
189:40 - do i have a plug for it somewhere
189:45 - code parade was doing some projects like
189:47 - this the music was loud sorry about that
189:50 - i thought i turned it down
189:56 - um it always saves models every 10 ebox
190:00 - i know i don't think i put that in there
190:02 - i don't think i added any code to like
190:04 - save the model every so often
190:06 - and it's not improving anymore oh no
190:08 - there we go huge jump down
190:10 - um but simon is suggesting that i can
190:13 - use
190:14 - basically uh pca or principal component
190:16 - analysis to sort the sliders from most
190:19 - to least
190:21 - important um
190:30 - if you change your clock on your laptop
190:32 - it would already be finished
190:34 - don't think that's how it works
190:36 - hold on i can send some important text
190:38 - messages i'm going to be done in 10
190:40 - minutes
190:42 - okay
191:08 - uh
191:11 - like the nice thing is didn't get very
191:13 - cold in here sunny out
191:16 - um
191:17 - where's gloria hopefully gloria didn't
191:18 - like
191:19 - pee somewhere because it's i've been
191:22 - taking her outside and this whole time
191:23 - i've been live streaming
191:25 - um
191:28 - are we i've lost track of what the loss
191:30 - is doing
191:34 - oh yeah it's going down further because
191:35 - i've got a
191:39 - if anybody could work out the sort of
191:41 - time travel i mean i just have to let it
191:42 - go at this point um i'll answer
191:44 - questions i don't know i could i could
191:45 - do some other work i could tell you more
191:47 - signing up for curiosity stream
191:51 - uh oh okay mark edwards today i just got
191:53 - here can i get a quick recap
191:56 - yes thank you for asking
191:58 - i'm gonna move over here just to have
192:00 - just to like get my legs moving a little
192:02 - bit so i'm building this is now my
192:05 - fourth live stream
192:06 - i'm building an auto encoder project
192:09 - and i'm using the tools of tensorflow.js
192:12 - which is a machine learning library in
192:13 - javascript and p5 which is a creative
192:16 - coding library in javascript that is
192:17 - good for like drawing and animation
192:19 - images
192:20 - i this diagram is completely sort of
192:22 - like not that useful anymore so me
192:25 - standing by it take that for what it is
192:27 - but um an auto encoder a great summary
192:30 - of what an auto encoder is you can find
192:32 - in this two minute papers a youtube
192:33 - channel
192:35 - what is an auto encoder and the idea
192:38 - is for a neural network to learn
192:41 - the um
192:42 - like a sort of like lower dimensional
192:44 - representation of
192:47 - an image
192:48 - that's a terrible way to explain it
192:51 - an autoencoder is a mechanism for taking
192:53 - an input image and copying it to an
192:56 - output image which is a very simple
192:59 - thing to do
193:00 - with just basic image processing
193:03 - algorithms like
193:04 - take every pixel copy every pixel but
193:07 - the hook here is that the auto encoder
193:09 - is not just taking all the pixels and
193:11 - copying them to the output it's sending
193:13 - all the pixels through a neural network
193:15 - that with each layer of that network has
193:18 - less and less and less numbers that it's
193:20 - allowed to work with so it's like an
193:22 - image compression algorithm and then a
193:24 - decompression algorithm can the neural
193:26 - network
193:27 - learn
193:28 - how to
193:30 - um sort of encode the represent encode
193:32 - an image into a smaller number of
193:34 - numbers and right now i'm actually
193:35 - trying to take these images of simple
193:38 - shapes they're squares and circles and
193:39 - encode them down to four numbers and
193:41 - really it should just be two
193:43 - theory we should be able to do two
193:44 - because there's only two variables it's
193:46 - either a square or a circle and it's the
193:48 - other variable is how big is it
193:50 - but i'm going with four
193:52 - so i have that
193:54 - working i've built all the code for it
193:58 - now i am training the model and i i just
194:01 - put in 200 epochs because
194:05 - i wanted to give it enough time to train
194:08 - and then when it's done
194:10 - what i hope to see this was like an
194:12 - earlier version of it is something that
194:15 - produces a much higher quality image
194:17 - than what you're seeing in terms of like
194:20 - it appearing to be a circle or a square
194:22 - and that i only have to play with four
194:24 - sliders to kind of manipulate it that's
194:26 - what i'm going for
194:31 - is there an epoch training dance
194:34 - no i'm so tired and hungry and exhausted
194:38 - and lost
194:40 - that i don't have one but if i could get
194:42 - it back
194:46 - it was only like
194:47 - [Music]
194:50 - this is how i feel this is my epoch
194:53 - training dance
194:58 - 164
195:07 - [Music]
195:12 - 168.
195:17 - yes yes so mikhail is this i love this
195:21 - comment i still don't get how the
195:22 - compression works you've gone from shape
195:24 - and radius to shape and radius and a few
195:26 - hundred kilobytes of weights so to be
195:28 - clear
195:30 - i'm not actually doing anything of any
195:32 - utility whatsoever
195:35 - i'm trying to demonstrate the concept
195:39 - to and to help my understanding of how
195:43 - to architect
195:44 - machine learning models
195:46 - how to experiment with them
195:48 - how to
195:49 - perhaps make creative output with them
195:52 - and in a way like
195:53 - the concepts that i'm demonstrating with
195:56 - this very very basic
195:58 - scenario
195:59 - would hopefully extend how the music is
196:04 - would hopefully extend
196:06 - to
196:07 - use of say something like a more you
196:10 - know a gan or a style gan model sort of
196:13 - like looking at how generative models
196:15 - work thinking about how latent space and
196:17 - latent variables work i'm hoping that
196:19 - this whole process
196:22 - could
196:23 - um
196:24 - could provide something
196:26 - of note there but yes i mean i could
196:28 - write the code to just make the slider
196:31 - to a button and a slider and just
196:33 - manipulate them to get a circle or a
196:35 - square of a variable size
196:38 - um so there is um
196:41 - a coding trained group this is uh sa
196:43 - mckenzie asks i'm sorry if i tell me how
196:45 - to fix my name pronunciation um are you
196:48 - doing advent of code this year not so
196:50 - much personally although maybe now i
196:52 - might have some time to
196:54 - i'm just on my own but i don't think
196:55 - i'll be streaming it
196:58 - but there is a coding train advent of
197:00 - code team
197:01 - or whatever it's called and you can um
197:06 - if you're in the discord somebody please
197:08 - post the discord link
197:10 - you can find out information about
197:11 - joining and having your advent of code
197:13 - contribute to the leaderboard uh kobe
197:15 - who is the discord manager is organizing
197:17 - that so apologies for not knowing too
197:18 - much about it but you can definitely
197:20 - check into that
197:26 - yes so this is the older version with a
197:28 - less a poorly trained model and 16
197:31 - latent variables
197:32 - when this finishes oh it finished oh my
197:35 - god
197:36 - so let's just look at this for a second
197:38 - 256 128 64 16 4. 16 64 122 okay that's
197:44 - right now hopefully
197:47 - oh it's a made-up name essay mcquenzy so
197:50 - it's a made-up name i don't know how
197:51 - it's pronounced great my friend seizure
197:52 - was great okay so now
197:55 - if i come back to my sketch that loads
197:58 - the decoder only
198:00 - i should be able to do this with just
198:02 - four sliders
198:03 - i think that's the only thing i need to
198:05 - change
198:06 - let me just make sure was this
198:09 - a new model from 2 16 p.m all right
198:12 - everybody i really should not do this
198:15 - any time and every time i've ever played
198:17 - this
198:18 - sound effect means it's not going to
198:20 - work
198:21 - but i'm about to hit refresh
198:23 - and hopefully we're going to see a nice
198:25 - squirkle there in the center
198:27 - four sliders that allow me to
198:37 - wait okay
198:39 - reading value undefined hmm
198:43 - at least it was just a syntax error ah i
198:45 - hard coded
198:52 - late in total equals four
198:56 - now that was
198:58 - anticlimactic
199:05 - okay
199:11 - i'm so excited
199:14 - oh let me tell you about today's sponsor
199:15 - oh no sorry sorry sorry okay refresh
199:20 - oh i like it i like it
199:25 - okay circle to square
199:28 - to square okay interesting
199:34 - so
199:34 - how what these variables do
199:36 - your guess is as good as mine
199:39 - maybe i um and i think i would love to
199:41 - do the random walk now
199:46 - but this is really
199:49 - really everything i ever wanted
199:52 - in an auto encoder
199:54 - latent vector exploration
199:57 - p5.js sketch
200:07 - i've only had an hour until i have a
200:08 - meeting in 10 minutes and i was planning
200:11 - to eat lunch in between this live stream
200:13 - and this meeting and answer all my
200:15 - emails and do everything else i needed
200:16 - to do
200:17 - so i can't do the random walk part
200:20 - uh because i would be like oh i have 10
200:21 - more minutes i'll do it
200:23 - i have to just stop
200:26 - but um i will do that on my own let me
200:28 - push the code
200:32 - so the new things i'm adding are
200:35 - adjusted the data generation
200:38 - i guess this uh i added the the node
200:41 - cert the nodes
200:43 - code now trains the model and siphons
200:46 - out the decoder only
200:48 - i've got a new model
200:51 - and a new sketch
200:52 - a new model adjusted the sketch a little
200:54 - bit and then there's the new decoder and
200:57 - then i saved that earlier squirkle model
201:01 - so let me add all this
201:05 - live stream 4.
201:10 - um and if you're wondering oh
201:16 - if you're wondering
201:22 - um oh those models must be big
201:28 - if you're wondering where you can find
201:29 - all this
201:33 - um
201:36 - oh yeah
201:38 - it's here
201:39 - so
201:41 - uh
201:42 - i will accept i'm accepting now um
201:46 - pull requests on this
201:48 - um this was super helpful the way that
201:52 - java gt wrote an issue just to explain
201:54 - some improvements and some ideas
201:57 - i think this project is in a place where
202:02 - i can
202:03 - accept pull requests again i'm not at
202:05 - the moment looking to totally refactor
202:08 - it i i i need to write a message here
202:11 - because i've been i reply to this via in
202:13 - my like live stream many times i want to
202:15 - thank the chief here
202:17 - chief um
202:18 - for this incredible refactoring and
202:21 - contribution but it's too different than
202:23 - what i wrote during the live streams so
202:26 - i would love much rather link out to
202:28 - that but if you can help sort of
202:30 - optimize the sort of like architecture
202:34 - uh the learning rate
202:36 - um so that could get slightly higher
202:37 - resolution
202:39 - i think having four latent variables is
202:41 - good like little design improvements i
202:42 - would gladly take those
202:44 - um
202:45 - but i would very much especially love
202:47 - just documentation so images screenshots
202:50 - gif animations explanations in the
202:52 - readme it's not really your job to do
202:54 - that it's mine
202:55 - but if you're looking to contribute i
202:57 - gladly would take any form of
202:59 - contributions i'm going to put this to
203:00 - bed
203:01 - i think i've only got one more thing on
203:03 - the docket for
203:05 - uh 20
203:07 - 21 and then i'm hopefully relaunching
203:09 - the coding train and new in 2022 it will
203:12 - be the processing foundation end of year
203:14 - fundraiser i think that's going to
203:16 - happen now
203:17 - probably the 20 it's going to happen
203:19 - after christmas before new year's
203:21 - so uh stay tuned sign up for the discord
203:25 - thank you
203:26 - to um
203:28 - sponsor uh please check out i'm you know
203:30 - uh curiositystream.com codingtrain for
203:33 - full access to over a thousand over a
203:36 - thousand documentaries everything that's
203:38 - on nebula all the extra content so many
203:40 - wonderful educational creators for less
203:43 - than one dollar a month for the whole
203:44 - year it's 11.59
203:46 - special 42 off discount check that out
203:49 - and um i really appreciate all of you
203:52 - sticking with me for this
203:54 - and
203:55 - um
203:57 - i will see you
203:59 - on the next live stream and i'm looking
204:01 - forward to all sorts of new content and
204:04 - community initiative now is the time to
204:05 - join the discord if you want to have a
204:07 - voice in the future of the coding train
204:09 - join the discord
204:10 - i would love to see you there
204:12 - um goodbye i gotta go i gotta i gotta
204:15 - have another meeting in like literally
204:16 - seven minutes i'm gonna do it from right
204:17 - here just i gotta sign out of this
204:19 - computer but hopefully i won't still be
204:20 - live streaming by accident it's the zoom
204:22 - call so i gotta i gotta play my outro
204:25 - music and all of that uh thanks
204:27 - everybody goodbye see you soon oh my god
204:31 - i cannot believe i cannot believe this
204:32 - day maybe i'll make the random walk
204:34 - happen uh just really quickly while i'm
204:35 - playing the outdoor music that's a good
204:37 - idea
204:39 - i didn't even find the outdoor music i
204:41 - don't even know what the outdoor music
204:42 - is anymore as always i always forget
204:44 - that this stop this stock this stop this
204:46 - stop i'm gonna do this stop this stop
204:48 - i'm gonna do this this stop this stop
204:50 - this stop i'm gonna do this stop
204:55 - [Music]
205:25 - [Music]
205:32 - this dot
205:33 - [Music]
205:47 - this dot song never forget this dot
205:50 - [Music]
206:02 - i'm gonna say once again here we go sing
206:05 - it with me
206:09 - [Music]
206:15 - it's look forward to cartesian
206:17 - coordination
206:19 - [Music]
206:33 - autotune and the internet will fix that
206:35 - for me
206:40 - take it with me
206:43 - to cartesian
206:44 - [Music]
207:03 - [Music]
207:09 - unicorns and rainbows and cupcakes what
207:11 - else is
207:12 - there
207:14 - yes kittens thank you very much kittens
207:16 - and rainbows and cupcakes notice that
207:19 - look what i get
207:20 - i'm really losing my mind
207:23 - okay let's do it
207:25 - [Music]
207:42 - and kittens the kittens getting some
207:45 - kittens and kittens the kittens the
207:50 - kittens the kittens kittens and kittens
207:54 - and
207:56 - [Music]
208:07 - i just quickly adapted this to move the
208:09 - sliders randomly
208:11 - which is sort of demonstrating
208:13 - a uh oh yes i wanted my stream called
208:16 - three minutes okay goodbye everybody
208:18 - that's hilarious
208:20 - i'm going i'm muting my microphone now
208:21 - i'm gonna let this play for another like
208:23 - few seconds
208:24 - just to the end of this song it's got
208:25 - one minute 30 seconds on the song bye
208:27 - everybody
209:22 - over again
209:24 - all sorts of text generation analysis
209:26 - things
209:27 - that i will use continuously over and
209:30 - over again
209:31 - first thing i need to do is yes
209:37 - okay we're gonna do it
209:39 - kittens the kittens the kittens and
209:41 - kittens kittens and kittens and kittens
209:42 - and kittens kittens the kittens and
209:44 - kittens and kittens kittens and kittens
209:46 - and kittens and kittens kittens and
209:47 - kittens and kittens and kittens kittens
209:49 - and kittens and kittens and kittens
209:50 - kittens the kittens the kittens have
209:52 - dusted
209:54 - [Music]
210:09 - you