00:00 - [WOODEN TRAIN WHISTLE]
00:00 - Hello, and welcome to a very
special episode of the Coding
00:03 - Train.
00:04 - Today, I am so excited to
demonstrate something to you.
00:07 - I am going to show you a project
from Google Creative Lab called
00:11 - Teachable Machine.
00:12 - Now, you might say, Ha-ha!
00:13 - I have heard of this
Teachable Machine
00:15 - before, in fact
you referenced it
00:17 - in some other
videos you've made,
00:18 - that are floating
over here right now.
00:21 - And in fact, I have,
and in fact, I've
00:23 - talked a lot about
the kind of thing
00:25 - that Teachable Machine does
called Transfer Learning.
00:28 - But this video, I'm going
to show you something
00:30 - that just launched today!
00:32 - Which is Teachable Machine 2.0.
00:34 - And Teachable Machine
2.0 allows you
00:36 - to train a machine learning
model in the browser,
00:38 - you can train it on images,
you can trade it on sounds,
00:41 - you can trade it on poses!
00:44 - And more to come in the future.
00:45 - And then you can save
the model you trained
00:48 - and use it in your own project.
00:50 - So I'm going to make a few
examples, images and sounds,
00:53 - train a model,
demonstrate that, and then
00:55 - bring the train model
into my P5 JS sketch
00:59 - with the ML5 JS
library, and have
01:00 - some fun making a goofy
project and giving you
01:03 - some starter code for you
to make your own project.
01:06 - Let's get started by training
an image classification model.
01:09 - And what do I need to create
an image classification model?
01:12 - Props!
01:13 - I've brought a lot
of props with me.
01:15 - I think this will make it fun.
01:16 - I should point out that
a bunch of these things
01:18 - have green in them, and you
can't see the color green,
01:21 - because I'm standing in
front of a green screen.
01:23 - But if I show you
the green screen,
01:24 - you can see the color green.
01:26 - To get started from
Select a Project,
01:28 - I'm going to choose
Image Project, because I
01:30 - want to start with images.
01:32 - Here, there are
three steps, and I'm
01:34 - going to go through all of
them, but the first step here
01:36 - is the data collection step.
01:39 - So what do I want?
01:40 - I want to collect a whole
bunch of images of something,
01:42 - and provide a label
for those images.
01:45 - Teachable Machine
is going to assume
01:47 - you're at least going to have
two kinds of images, otherwise
01:50 - why are you classifying
images if you
01:51 - don't at least have two
different kinds to distinguish
01:54 - between?
01:54 - And it's going to create
automatic labels, like Class 1,
01:58 - or Classification 1.
01:59 - But it's much more fun
to pick our own names,
02:01 - so I'm going to click here
and switch this to unicorn.
02:04 - And we'll give it some
images of this unicorn.
02:06 - So I'm gonna click
Add Samples, Webcam,
02:09 - and get my unicorn placed
nicely in front of the camera.
02:16 - So there we go, I've given
it 413 example images
02:20 - of a unicorn.
02:20 - One thing I would
like to mention--
02:22 - in my excitement and enthusiasm
for demonstrating this project,
02:24 - I collected a lot of images--
02:26 - 400 plus for some
of the categories--
02:29 - and that's really
quite unnecessary.
02:30 - It makes the training time
take quite a bit longer,
02:33 - and with this transfer learning
process that I've described,
02:36 - I could probably get the same
exact performance and accuracy
02:38 - with many fewer images.
02:40 - So if you're following
along, collect fewer images.
02:42 - The training will happen
faster, it will be easier,
02:44 - then you could try it again with
more images, with less images,
02:46 - just to experiment and see
what works and what doesn't.
02:48 - But probably for
getting started,
02:50 - I might start with, say, 25
to 50 images per category.
02:53 - Next of course is
a train whistle.
02:55 - We'll call Class 2 "Train".
02:58 - Add samples.
03:04 - Now I definitely want
to move on and show
03:05 - the ukulele and the
rainbow as well,
03:07 - but let's at least
see-- we've done two,
03:09 - let's see if it works.
03:10 - The next step is for
me to click Train Model
03:12 - and actually train the model.
03:14 - So what happens when I
press train the model?
03:16 - What is a model?
03:17 - What's the training process?
03:18 - What's going on?
03:19 - There is so much to say here.
03:21 - And let me give you a
brief high level overview.
03:24 - Teachable Machine
is using a technique
03:26 - called transfer learning.
03:27 - I've actually made
several videos
03:29 - all about transfer learning
with ML5 JS, and if you want,
03:32 - you could go back
and look at those
03:34 - for a bit more of a deeper dive
in how transfer learning works.
03:37 - But the short explanation is,
there is a pre-trained model.
03:41 - Somebody else already trained
a model on many, many images,
03:45 - and this model is
called MobileNet.
03:47 - And there's a paper written
about it that you could read.
03:49 - And the training data for
this model is called ImageNet,
03:52 - and there's a paper about
that that you could read.
03:54 - And you could do
a lot of research
03:55 - into what is this base--
03:57 - what is this foundation
model upon which
03:59 - we're going to add our images?
04:02 - MobileNet is a model that runs
fast, works in the browser,
04:05 - and knows about 1,000
different kinds of things.
04:08 - But it doesn't know about
unicorns or train whistles
04:11 - or rainbows, necessarily.
04:12 - Maybe it's in there,
maybe it's not.
04:14 - But what we could
do is take the fact
04:16 - that it's learned how to boil
the essence of images down
04:19 - into a bunch of
different numbers,
04:20 - to then retrain it
with our own images.
04:24 - And this allows us
to get something
04:25 - that works with just
400 images of unicorns
04:29 - and 400 images of
train whistles.
04:31 - Because if you were training
an image classification model
04:34 - from scratch without
this base model,
04:36 - you probably would need
a much larger data set.
04:39 - So now that I've given you
that brief explanation of how
04:42 - it works, we can actually press
Train Model and watch it go.
04:46 - So one thing to note is, it's
telling me "don't switch tabs".
04:50 - Don't switch tabs!
04:52 - The reason why it tells
you not to switch tabs--
04:54 - and this is very
important-- is it's
04:56 - training the model in
here, in the browser.
04:58 - None of your images
went anywhere.
05:00 - They have not been
uploaded to any server,
05:03 - everything is happening right
here locally in the browser.
05:06 - The model is training
in the browser.
05:08 - Now, Teachable Machine gives
you options to save your data,
05:12 - you could upload it to--
05:13 - I think there's an
integration with Google Drive,
05:15 - and once the model
is trained, I am
05:17 - going to upload that
model to a server.
05:19 - But this is one of
the wonderful things
05:22 - about working with JavaScript
in machine learning,
05:24 - is you can do it all right
here from your local computer.
05:28 - You have to be connected
to the internet
05:29 - to access the Teachable
Machine website,
05:31 - but otherwise the actual
data processing and training
05:34 - is happening right
there in the browser.
05:36 - It's finished!
05:37 - So now I am [TRAIN WHISTLE]
most definitely a train.
05:43 - Unicorn!
05:45 - Amazing.
05:46 - So this is a lot of fun,
and we could keep going
05:48 - and add more classes and
more training images,
05:50 - and I'm going to do
that in a second.
05:51 - But the point of why
I'm showing this to you
05:53 - is you can now take this model--
05:55 - see that Export Model button?
05:57 - You can take that and bring
it open to your own project.
05:59 - So I want to do that, but
before I do that, let me just
06:02 - add two more classes, and give
it some more training images.
06:04 - Turn this off, and
let's add Rainbow.
06:09 - By the way, this is
my daughter's drawing
06:11 - of a rainbow.
06:17 - Let's add one more, a ukulele.
06:19 - I've been struggling
to collect images
06:21 - while I'm playing the
ukulele, and you might
06:23 - run into this as a problem.
06:24 - So one of the things
you can do is,
06:26 - you can click the Settings
icon, and you can turn off
06:29 - the Hold to record.
06:31 - And if you do that,
I can actually
06:33 - just give me a two second delay,
and record for six seconds.
06:36 - So I think that'll be
enough to demonstrate it,
06:38 - so I'm gonna hit Save Settings.
06:40 - I'm going to get my camera
focused here on the ukulele,
06:43 - and then I am going to
do Record six seconds.
06:50 - I have all of my data for one,
two, three, four classes--
06:54 - categories--
classifications-- labels.
06:56 - You can use any of those words.
06:58 - And I'm going to
train the model.
07:00 - So here we go.
07:02 - (SINGING) Don't switch the
tabs, don't switch the tabs!
07:08 - Don't--
07:09 - We're trained and
we're ready to test.
07:11 - Here I am, a train.
07:12 - [TRAIN WHISTLE] And
here I am, a unicorn!
07:17 - Rainbow.
07:18 - (STRUMS UKELELE) Ukelele!
07:22 - Now that I've trained the
model on these four categories,
07:25 - I'm ready to move into my own
code, into my P5 ML5 project.
07:29 - But before I do that, I need
to make sure I save the model.
07:32 - And to save the model--
07:34 - the model is running
right here in the browser,
07:35 - but I want to save the model
by clicking this Export Model
07:38 - button.
07:39 - Once I press that button,
I'm going to see this pop up,
07:41 - and I have a lot of
different options.
07:43 - For example, I could
export the model
07:45 - to work with TensorFlow,
or with Tensorflow Lite,
07:48 - and you could click
on the little i
07:50 - to find out more
about those things.
07:51 - I couldn't possibly cover
all the options right here
07:53 - in this video.
07:54 - But for me, I want to use
it with Tensorflow.js.
07:58 - I am going to use it with
a library called ML5 JS,
08:01 - but ML5 JS is built on
top of Tensorflow JS,
08:04 - and so the compatible
model for ML5
08:06 - and Tensorflow JS
is the same model.
08:09 - So I could locally download
it-- again, this is important,
08:12 - if you really-- if you
don't want anything
08:14 - related to your data, this
is not uploading your data,
08:17 - it's [? uploading ?] the
model trained on your data.
08:19 - It's a subtle difference, and
a complex one to fully unpack.
08:23 - But if you don't want
to upload anything,
08:25 - you could just locally
download your model.
08:27 - It's going to be easier for me
to work with it to upload it,
08:30 - so I'm going to choose Upload.
08:32 - You might actually see a
slightly different URL,
08:34 - if the Google changes the way
it's stored on their server,
08:37 - but whatever is here is
the URL that you want.
08:39 - After you're done, if you
have uploaded your model,
08:42 - you then get a permanent web
page where you can play around
08:45 - and test your model still,
even after the training process
08:48 - is done.
08:48 - So this is a really good tool
for debugging your model,
08:51 - because I'm going to
start coding with it,
08:52 - and if it starts acting weird,
I could come back to this
08:55 - and sort of test it out
right here in the browser.
08:57 - I am finally ready
to start coding.
08:58 - So there's a couple different
ways I could get started.
09:01 - You might remember
actually, when I first
09:02 - uploaded the model, there
were some code snippets there.
09:05 - There was native JavaScript
and TensorFlow JS code.
09:08 - If you're an experienced
JavaScript developer,
09:10 - that might be where you
want to get started from.
09:12 - There was also actually a
P5 and ML5 code snippet,
09:15 - that I could just go and copy
paste right here into where I
09:18 - am, which is the P5 web editor.
09:20 - But I'm going to do it a
little differently here
09:21 - to try to step you
through the process.
09:23 - I'm starting with a
template that I've created,
09:25 - that all it does is one thing.
09:27 - It captures video
from the camera
09:29 - and displays it on the canvas.
09:31 - And I'm going to add all the
bits of code to load the model,
09:35 - give the video to the model,
get the result back, and display
09:38 - that back on the canvas as well.
09:40 - Now, if you've never programmed
before, never in JavaScript,
09:43 - never in P5, you can still
follow along with me,
09:45 - but I'll also refer you to some
beginner tutorials that I have,
09:48 - that'll give you the
fundamentals and the basics,
09:50 - which will help you understand
all the bits and pieces that
09:53 - are going on in this video.
09:54 - But in terms of what's
happening so far,
09:56 - we have a single
variable for video,
09:57 - we connect to the capture
device-- the webcam--
10:00 - in Setup, and in the
draw function right here,
10:04 - we draw the video on
the canvas, and that's
10:06 - what I'm seeing right there.
10:07 - I should also mention
that I recommend
10:09 - that you start with
my template because it
10:11 - has the ML5 library imported
along with the P5 library.
10:15 - Just in case you're not
working in the P5 web editor
10:17 - from my template, you can
import the ML5 library
10:20 - by following these Quickstart
instructions on the ML5 JS web
10:23 - page.
10:24 - And you can see that my
example has that script
10:27 - tag in its index of HTML file.
10:29 - But back to the code.
10:30 - Let's follow and
fill in these steps.
10:32 - Step 1, load the model.
10:34 - The easiest way for
me to do this with P5
10:37 - is to write a new
function called preload.
10:39 - And preload will load any
important assets, images,
10:43 - data files, models, before
the program starts in Setup.
10:48 - And I want to create
another variable,
10:50 - I'll call it classifier,
and in preload, I'll
10:53 - set the classifier equal to
ML5.imageClassifer, and then
10:58 - the URL of my model.
11:01 - I'm going to copy it
from the training page,
11:03 - and paste it right in here
in the ML5 imageClassifier
11:05 - function.
11:07 - Let's run the sketch to make
sure we don't have any errors.
11:10 - Looks good.
11:11 - You might see something
like a 404 error--
11:13 - 404 meaning File Not
Found, if for some reason
11:16 - there's a mistake or
error with your model URL.
11:19 - Next step, start classifying.
11:21 - All right, I'm going to want
to have a function called
11:23 - classifyVideo.
11:25 - That function doesn't exist,
so I've gotta write it,
11:28 - classifyVideo.
11:30 - And what I want to
do in that function
11:32 - is call the ML5 classified
function on the video.
11:36 - Am I just saying the same
words over and over again?
11:38 - I kind of am.
11:39 - So how does that work?
11:40 - My variable that stores the
model now is called classifier.
11:44 - So I can say classifier--
11:45 - the function in ML5 to classify
an image is called "classify".
11:51 - And then the first
argument to the function,
11:53 - what I need to hand
to it, is the image
11:55 - that I want to classify,
which is the video.
11:58 - And then, now is sort
of the important part.
12:01 - JavaScript, if you've worked
with JavaScript before,
12:03 - handles things
asynchronously-- and by that, I
12:06 - mean it takes some
time for it to classify
12:08 - the image in the video, and it's
going to report an event back
12:11 - to me when it's finished.
12:12 - And you need to handle
that by giving it
12:14 - the name of a
function that's going
12:16 - to get called as a callback.
12:17 - And sure, there are 10 other
ways to do this JavaScript,
12:20 - but this is the way I'm
going to demonstrate it here.
12:22 - So I'm going to say
that that function is
12:24 - going to be called
gotResults, and I'm
12:27 - going to add that in here.
12:29 - Let's run this again and
see if we get an error.
12:33 - Oop!
12:34 - I did get an error.
12:35 - gotResult is not defined.
12:37 - It's looking for a callback
to give me the results,
12:39 - but that function doesn't exist.
12:41 - So guess what?
12:42 - This is now step 3-- oh,
this should be step 4.
12:46 - Step 3, get the classification.
12:47 - I need to write a function
called gotResults.
12:51 - And gotResults can
receive one of two things.
12:54 - It can receive an error, like,
I don't know what you just
12:57 - gave me, but that
was not an image
12:58 - and I don't know how
to classify that.
13:00 - Or it can actually
receive some results,
13:02 - like, it's that
unicorn friend of mine.
13:04 - So the order that those
arguments need to go in
13:07 - is "error" first,
"results" second.
13:09 - So I'm going to say
error, then results.
13:12 - Now, if there is
an error, I'm going
13:14 - to want to display that error,
and one way to do that is
13:17 - by saying console.error, error.
13:22 - And then I don't
want to continue.
13:23 - There was an error, I
don't want to continue,
13:25 - I'm going to just say return,
which will jump me out
13:28 - of that function.
13:29 - If there wasn't an error, I can
do something with the results.
13:32 - Let's just look at them by
saying console.log results.
13:38 - I've given myself some
more room in the console,
13:40 - and I'm gonna run the sketch
just to see what happens.
13:43 - All right, so look,
this is what I got back.
13:44 - Object, object,
object, object, object.
13:46 - We're done, right?
13:47 - What is in there?
13:48 - Let's take a look.
13:49 - I got four objects back--
kind of makes sense, right?
13:51 - There were four classes.
13:53 - The first one is a
rainbow, and it thinks--
13:56 - it's got an 87% confidence
that what it sees in this image
14:01 - is a rainbow.
14:03 - Train, 12%, unicorn, very
low percentage, ukulele,
14:06 - very low percentage.
14:07 - So what you get back from ML5
once you've passed it an image,
14:12 - is an ordered list of objects,
each containing the label
14:18 - and confidence score,
and the first one
14:20 - is always going to be the
highest confidence, sorted
14:23 - by confidence.
14:24 - So there's a lot that we could
do to visualize this and show
14:27 - all the labels and
their confidence scores,
14:29 - but what I want to do is just
look at the first results
14:33 - label.
14:33 - So I'm going to change
this to results,
14:36 - index [0].label
and run it again.
14:39 - Am I a rainbow?
14:43 - I am!
14:44 - I am a rainbow, it
makes me so happy.
14:48 - But more importantly,
what I want to do
14:50 - is display this
label in the canvas.
14:53 - I'm going to create a global
variable called label,
14:56 - and I'm just going to put
some text in it, like waiting,
14:58 - just so there's
something in there
15:00 - that I can see before
it gets the result.
15:02 - I want to draw
that on the canvas.
15:04 - So let's say text size 32,
text align center, center.
15:15 - Then let me draw that
label in the middle
15:19 - at the bottom of the window,
and let's make sure the label--
15:24 - the text is colored
white so I can see it.
15:27 - Once I see the text,
then I can just
15:29 - store that result in
the label itself--
15:33 - the label variable, that is--
15:35 - and run this again, and then we
should see-- we have a rainbow!
15:40 - I'm a train.
15:42 - You might notice,
that's not changing.
15:44 - I'm not getting anything new.
15:46 - So we only called classify once.
15:50 - When the program starts,
we said classify.
15:53 - Then we pass it the video,
then we get the result,
15:56 - we add the result to the
canvas, and what's next?
16:00 - Classify again.
16:01 - So this is something of a loop.
16:03 - This is a way of looping,
to just call this function,
16:05 - get the result, call it again,
get the result, call it again.
16:08 - So I'm going to add
classifyVideo right here.
16:10 - I'm going to run this sketch.
16:13 - Unicorn!
16:15 - Ukulele!
16:16 - [TRAIN WHISTLE] It's
like its default thing
16:19 - is a train, which
is interesting.
16:20 - Like if there's nothing there,
it's gotta pick something,
16:23 - and the nothing is the
closest to the smallest thing
16:25 - with the least distinguishable
features-- the train whistle.
16:28 - So this is pretty much done.
16:31 - And I could just stop here.
16:32 - But let's have a little
bit more fun with this,
16:34 - and let me change it so that
whichever one of these objects
16:39 - I show, I see the emoji for it.
16:42 - And in fact, I won't even bother
to show the video anymore.
16:45 - In draw, let's first create
a variable called emoji.
16:48 - And let's just
give it something,
16:50 - like I'll put it in
an emoji of a train.
16:54 - And then let's
actually draw that--
16:56 - same way, using
the text function.
16:59 - Put it in the center,
and say text size 256.
17:05 - Just guessing.
17:06 - And let's run this sketch.
17:08 - OK, great.
17:09 - We've got a nice big
train emoji there.
17:11 - Now we can just check,
what's the label?
17:14 - If label equals rainbow,
emoji equals rainbow.
17:22 - We can fill in the rest
with else/if statements.
17:29 - Let's throw caution to the
wind and not show the video.
17:34 - And now, unicorn!
17:38 - Rainbow!
17:40 - (STRUMS UKELELE)
And with nothing,
17:46 - we're back to the
[TRAIN WHISTLE] train.
17:50 - Thank you so much for
watching this video,
17:52 - I hope that you've enjoyed it.
17:53 - There's a lot more
to say about this,
17:54 - I mean-- number one,
what could you do next?
17:56 - First of all, try
doing the same thing,
17:58 - but train the model
on just the background
18:02 - image, when it sees nothing,
to show something else.
18:05 - So in this case, I don't want
the background to be the train,
18:07 - but I want to train a
category that is background.
18:10 - So you could try that.
18:12 - So many other
creative possibilities
18:13 - for how you could use this in
an interactive create context.
18:16 - If you make something with
it, please share it with me,
18:19 - you can write it in the comments
or you can go to the page
18:21 - on the codingtrain.com,
where you
18:23 - can submit your own project that
you made with Teachable Machine
18:26 - P5 JS and ML5 JS.
18:28 - I'm going to come back and
do at least one more video--
18:30 - and probably a bunch more.
18:31 - The two things that I really
would like to show you--
18:34 - number one, I want to show
you the sound classifier.
18:36 - So how do you do
exactly this, but have
18:38 - it recognize the train
whistle and the ukulele
18:40 - as different things?
18:41 - I will work on that
in a separate video.
18:43 - I also want to show you
an important detail here,
18:46 - and if I put the video back
for a second, it's hard for you
18:49 - to see this because
you're not standing
18:50 - in front of the computer.
18:51 - It looks to me like
you're seeing me
18:54 - with the same orientation that
I'm standing here right here.
18:57 - There's my hand, here's my hand.
18:59 - However, when I look
at it, the image
19:01 - is not mirrored, meaning I look
backwards when I see myself
19:04 - on the computer.
19:05 - When we were training the
model with Teachable Machine,
19:08 - it actually flipped
the image for you.
19:10 - It's not too hard,
and in fact, there's
19:12 - an ML5 function that will
allow you to flip the image.
19:15 - So I'm going to add that
in a second video, which
19:18 - what I wanted to
show you how to do
19:19 - is train a model that
can be a game controller.
19:22 - So if, for example, what if I
train a model where I hold up
19:25 - my right hand, and something
moves to the right,
19:27 - and I train a model and
hold up my left hand,
19:29 - and then have something
move to the left.
19:30 - So I'm going to
do that, I'm going
19:32 - to show you the
sound classifier,
19:33 - in two separate videos.
19:34 - Make stuff, let me know what
you think in the comments,
19:37 - and I look forward to all the
wonderful creative rainbow
19:40 - unicorn train ukulele
themed things that you make.
19:44 - Maybe you have other
favorite objects and emojis--
19:47 - use those.
19:48 - Those are mine.
19:49 - Those are mine, though.
19:49 - Goodbye!
19:50 - Thank you for watching.
19:51 - Mwah!
19:52 - [THEME MUSIC PLAYING]