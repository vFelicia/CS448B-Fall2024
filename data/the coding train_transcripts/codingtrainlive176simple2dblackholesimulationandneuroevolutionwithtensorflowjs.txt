00:00 - [Music]
00:12 - [Applause]
00:15 - [Music]
02:24 - [Music]
03:26 - good morning hello and welcome to the
03:28 - coding train with hello that was like I
03:31 - had my finger over this little air hole
03:33 - here and I got a higher pitch sound
03:36 - amazing science my name is Daniel
03:42 - Schiffman and I'll be your host this
03:43 - morning on a Wednesday which is every
03:45 - Wednesday I will say thank you for being
03:48 - here at this regularly scheduled time I
03:50 - have been so consistent about this I
03:52 - even I'm amazing myself however I will
03:56 - report to you that there will be no live
03:58 - stream next Wednesday I'll be back two
04:00 - weeks from today so let me just say that
04:02 - from the outset I have a trip planned
04:04 - got some stuff going on but don't worry
04:07 - underneath here in my coding train oven
04:09 - is cooking a whole set of videos about
04:12 - working with data and api's that you
04:15 - have not seen yet because I have been
04:17 - recording a bunch of videos not during a
04:19 - live stream as an experiment but that's
04:21 - my little pitch if you want to join the
04:24 - coding train as a patron or YouTube
04:26 - member and get some sneak previews of
04:27 - that stuff also a big shout out and
04:30 - thank you to brilliant org who is the
04:32 - sponsor of today's livestream on
04:34 - brilliant orgs homepage you will see a
04:38 - challenge about relativity classical
04:41 - relativity we also have the term special
04:43 - relativity general relativity oh my
04:46 - goodness my mind since last Wednesday I
04:49 - think was last Wednesday right when the
04:51 - first image of the black hole came out
04:55 - has just exploded with Wonder and awe at
04:59 - the universe we live in and I've been
05:01 - spending a lot of time reading some
05:03 - papers watching some YouTube videos I am
05:06 - NOT a physicist I do not have a
05:07 - background in that but I have been sent
05:09 - down I was gonna say rabbit hole but I
05:11 - think the appropriate term here would be
05:12 - many black holes I'm not a merge by the
05:15 - way once you're in it there's no way to
05:16 - get out I am past the event horizon but
05:21 - so that's what I want to do in the first
05:23 - segment of today so the first segment
05:24 - today I'm going to talk a little bit
05:26 - about the recent black hole image and do
05:28 - a very crude
05:30 - kind of nature of codes style physics
05:33 - simulation of light approaching a black
05:36 - hole but I will be using Newtonian
05:38 - physics and so it won't actually be
05:39 - accurate but I will talk about what's
05:43 - missing there and a little bit about
05:44 - relativity and then kind of like pose
05:46 - that as a challenge to you to think
05:48 - about and maybe next week after I've had
05:50 - more time to read these papers and
05:51 - crunch some of these numbers
05:53 - maybe I can come back and make it more
05:54 - accurate or or or such the sound come
05:58 - once again I take take over the the chat
06:01 - I see the sound sync is off
06:04 - I don't know someday I'll fix that I
06:06 - apologize oh oh oh so so then segment
06:14 - two of today's live stream look at this
06:16 - I have a plan and everything and I'm
06:18 - sure it will go haywire think technical
06:20 - problems will I'll be stuck in the black
06:22 - hole for four hours and never get to the
06:24 - next part but this is my plan segment
06:27 - two I am going to program the data
06:29 - structure a stack and look at a quiz
06:32 - that's actually if you go to brilliant
06:33 - org slash coding train right now it'll
06:35 - take you to a page which is a quiz on
06:37 - stacks and there's also a quiz on queues
06:40 - and this is part of some new computer
06:41 - science course materials that brilliant
06:43 - has which has been really terrific for
06:44 - me to review a lot of stuff that maybe I
06:46 - did 15 years ago so it's wonderful for
06:48 - both kind of continuing education for me
06:51 - like I can like look at this stuff again
06:53 - or a very what I was saying on the slack
06:56 - chat this morning in the coding train
06:58 - patreon group that the last time I think
07:00 - I had to implement a stack like actually
07:02 - implemented without just using a you
07:04 - know kind of using an array as a
07:06 - stand-in for a stack or or some other
07:08 - you know stack from a library was
07:12 - probably 15 years ago oh I'm gonna have
07:14 - to do that today and look at programming
07:16 - my own stack data structure in the
07:18 - context of that quiz and kind of leave
07:20 - that as a challenge to you to take the
07:21 - quiz and then pending time I will have
07:25 - to say this a it is in the title of this
07:26 - video which I probably shouldn't have
07:28 - put it there but at a minimum I will
07:30 - show you some new examples that I'm
07:31 - working on that do neuro evolution with
07:33 - tensorflow j/s I would love to do a
07:35 - coding challenge around that that might
07:37 - come the next time but a
07:39 - I do have a few like finished examples
07:41 - that are basically ports of some of my
07:43 - previous examples there's a steering of
07:46 - steering one and a flappy bird one that
07:48 - I will show you please say this dot once
07:55 - I'm just pleased that you didn't ask me
07:57 - to like say this dot and dab or
07:59 - something Kufa that's really just not a
08:01 - thing not a thing not a thing
08:03 - I am your entertainer
08:20 - give me your instructions and I will
08:22 - entertain you I think we could just get
08:24 - started right what else do I don't have
08:27 - anything else to say in my introduction
08:29 - I'm like efficient and organized like a
08:31 - professional YouTube livestream or
08:34 - person this won't last and there's
08:37 - nothing it wasn't even that good okay so
08:46 - oh so here we go
08:48 - so I want to talk about it come on no I
08:49 - remember what I wanted to say now it's
08:51 - it links are in this video's description
08:52 - so I want to mention a couple things I
08:56 - think let me just find it I have it over
08:59 - here let me pull up today's live stream
09:03 - this will be fun so here we are well
09:07 - there's six hundred sixty-eight people
09:08 - watching okay so I want to talk about
09:10 - two things one I want to mention a huge
09:13 - thank you to Chris Orban and stem coding
09:16 - Chris Urban from Ohio State University
09:18 - runs a wonderful youtube channel called
09:21 - stem coding with a lot of p5.js and
09:23 - other coding activities themed around
09:25 - physics with real science like me I do
09:28 - my like but you've got an actual you've
09:37 - got science people in there's PhD
09:39 - students and graduate students a
09:40 - wonderful diverse array of presenters on
09:43 - that channel so I highly recommend you
09:44 - check that out the reason why I'm
09:45 - thanking Chris in particular is Chris
09:48 - wrote up this wonderful guide which I
09:51 - just it's actually a
09:53 - called simulating a black hole so one of
09:55 - the coding challenges on the stem coding
09:57 - YouTube channel is a coding challenge
10:00 - called slingshot with gravity and it's
10:02 - very similar to some examples I have in
10:05 - the nature of codebook about looking at
10:07 - gravitational attraction and simulating
10:09 - that in a 2d world using you know
10:13 - wheeler integration and kind of simply I
10:15 - don't why I'm using like was like hope
10:17 - use a fancy term using some basically x
10:19 - equals x plus speed kind of code to to
10:24 - simulate how bodies interact with
10:26 - gravity so Chris modified the code to
10:29 - kind of talk about black holes a little
10:32 - bit and there's some nice information in
10:34 - here and a lot of explanation a really
10:37 - nice formula here which I'll talk about
10:38 - for the radius of the event horizon yeah
10:46 - the swartz yeah so otherwise no I'm
10:51 - sorry it's a Schwartz teals rate radius
10:53 - I was like trying to think how do you
10:54 - pronounce that
10:55 - it's like spelled Schwarzschild but I
10:57 - think is Schwartz yield it's very hard
10:59 - to say it's like a tongue twister so I
11:03 - want to come I'm gonna come back to this
11:05 - when I do the video but so I also wanted
11:07 - to just plug if you are a teacher a
11:10 - wonderful thing that is happening this
11:13 - summer is called the Pathfinder summer
11:16 - Institute which is professional
11:18 - development in computer science and
11:19 - making at Indiana University Bloomington
11:21 - from July 14th to 19th so if you are a
11:26 - teacher and you're interested in this
11:27 - please apply and I'm happy to help you
11:31 - can reach out to me but I would suggest
11:32 - probably reaching out to a stem coding
11:36 - or Chris or bond on Twitter to ask any
11:38 - questions about how this works alright
11:41 - so what I wanted to mention that Here I
11:44 - am mentioning that is there some kind of
11:47 - like theory of relativity going on here
11:49 - with space-time I'm curving my
11:52 - space-time into myself in the past I'm
11:54 - not even this isn't playing I'm frozen
11:57 - be live there yeah I was trying to get
12:02 - to the part where I curved
12:06 - I went there we go but a bend I'm gonna
12:12 - bend space-time you could do it oh
12:20 - they're really like the there's got to
12:23 - be like less than 500 people watching
12:24 - now right come on there you go
12:32 - this would get this time so behind all
12:38 - right I'm gonna give up on this oh there
12:44 - it's happening
12:54 - okay okay we got both hat alright so
12:57 - let's see let me get out p5.js let me
13:04 - login to coating train let me go to high
13:14 - contrast and set the text size 36 maybe
13:22 - let's see if I can get away with a
13:24 - bigger window here black oh okay alright
13:42 - I think I'm ready to go
13:44 - let me check chats yes uh-huh
13:52 - by the way Simon I see I see in my
13:56 - little message box here Simon Tiger is
13:59 - typing something will be said soon but
14:02 - you should check out
14:03 - Simon Tigers YouTube channel as well who
14:06 - has also recently made some videos about
14:07 - black holes
14:16 - ah yes that's a good point yes
14:21 - Simon Says come to the whiteboard then
14:22 - back to the screen and then bend a
14:24 - space-time I'm learning about how my
14:27 - feet are younger than my head boy it's
14:32 - amazing this this like my mind is blown
14:35 - let's go over here alright so let's see
14:39 - what do i how am I gonna start this this
14:50 - from 1978
15:23 - okay
15:28 - all right I think I have everything I
15:31 - need so image of black hole what's gonna
15:48 - be a good is it all is there a let's try
15:53 - this
16:00 - okay start with this and then what's the
16:07 - name of the group of it's the event
16:10 - horizon like the the name of the group
16:13 - the of the 200 scientists I want it like
16:16 - reference that remember how I was all
16:19 - prepared to had a plan
16:20 - event horizon scientists like it has a
16:24 - name like that
16:25 - the event horizon telescope
16:31 - maybe that's what it's called event
16:32 - horizon horizon telescope about
16:45 - organization yeah eh t Vann horizon
16:52 - telescope every Sun great okay thank you
16:54 - very much Oh someone asks someone asks
17:09 - are you going to simulate a 2d section
17:12 - of a 3d black hole or rather a genuine
17:14 - 2d black hole because the physics are
17:17 - very different in two plus one
17:18 - dimensions all right
17:20 - so I would say the answer to that
17:21 - question is neither I'm not really gonna
17:24 - do anything remotely close to accurate
17:26 - I'm gonna talk about what I've learned
17:29 - in terms of looking at some of these
17:30 - resources and I'm basically going to
17:33 - just do a Newtonian gravitational
17:36 - attraction example but kind of consider
17:39 - one body to be the black hole and one
17:42 - the other body to be a single photon or
17:44 - a beam of light and look at how that
17:46 - light curves as it approaches in two
17:48 - dimensions but I'll be basic this will
17:51 - basically be not accurate because it's
17:53 - sort of like assuming only classical
17:54 - relativity and I would need to think I
17:57 - need to like look at a part two would be
18:00 - to revise this to be more to actually be
18:04 - accurate but I think the idea can be the
18:06 - story can be told and it'll be an
18:08 - interesting kind of
18:10 - prompt for the audience who has a more
18:12 - maybe a rigorous scientific background
18:14 - to contribute here so that's kind of my
18:16 - plan so what if people are joining
18:18 - because they're gonna see some kind of
18:19 - black hole simulation prepare to be
18:22 - disappointed
18:24 - welcome to the coding train where our
18:26 - motto is prepare to be disappointed
18:29 - I need like a little like I need a
18:32 - little effect you press the button a
18:34 - little glistening winking but I cannot
18:36 - wink I cannot wake with my right eye my
18:39 - family finds this hysterical this is me
18:41 - in front of a black hole image
18:45 - attempting to wink with my right eye if
18:52 - I were inside a black hole you would not
18:54 - be able to see me doing that nor would I
18:56 - be able to communicate with you I would
18:58 - also be very very very very very dead or
19:02 - maybe not maybe I would just be millions
19:05 - of years in the future and I would be
19:08 - Matthew McConaughey yeah okay let me
19:23 - cycle the key
19:48 - hello
19:49 - and what hello welcome to a coding
19:53 - challenge simple very crude not so
19:56 - accurate to tee blaq ol simulation so
19:59 - I'm fascinated by this image this image
20:02 - which appeared on the internet a week
20:05 - ago from the event horizon telescope
20:07 - group of scientists who produce this
20:10 - image with many different telescopes all
20:13 - together timed with some kind of like
20:15 - nano Bassano bazillion au time precision
20:19 - to create this image there's over a
20:23 - thousand people watching that's not a
20:25 - record I have never broke in 2000 but uh
20:30 - it's not classical relative by the way
20:33 - Simon is giving oh sound effects or a
20:34 - hold on so much it stopped coming at me
20:36 - at once so I'm told the sound effects
20:41 - are a little bit loud so I'm going to
20:43 - turn that down
20:50 - Simon corrects me saying it is not
20:53 - classical relativity it's classical
20:55 - mechanics it's based on Galilean
20:57 - relativity okay thank you very much
21:02 - Tech riders asking how will that include
21:04 - neuro evolution it will not nor
21:06 - evolution is the third segment of
21:08 - today's livestream I mean I would love
21:10 - to neuro evolve a black hole but I don't
21:14 - think that's gonna happen
21:16 - everybody's telling my audio is out of
21:18 - sync I can't do anything about that I
21:20 - apologize the good news I would suggest
21:22 - if it bothers your tournament saw
21:24 - something else there will be an edited
21:28 - version of sort highlights if there are
21:30 - hearty highlights of today's livestream
21:33 - that will have the audio sync fixed by
21:36 - the way does everybody have the audio
21:38 - sync problem when when this has happened
21:39 - in the past I've been told that some
21:41 - people have in sync hit me baby no
21:45 - that's Britney Spears whatever um some
21:46 - people have it in sync and some people
21:48 - have it out of sink in before
21:53 - pronunciation complaints oh yeah I'm
21:56 - sure I pronounced whatever however you
21:58 - say that
22:00 - Galilean Galilean Galilean Callahan what
22:03 - did I say gun Lillian I think we should
22:10 - be able to say it the way what first of
22:12 - all gif gif gif that's how I just say to
22:15 - you you gif an alien mechanics people I
22:18 - got to start this everybody's telling me
22:23 - it's how to sync all right all right
22:25 - it's out of thing for everybody all
22:30 - right now so all right here we go
22:44 - [Music]
22:46 - hello and welcome to a coding challenge
22:48 - simple very simple very crude not so
22:52 - accurate 2d black hole simulation now I
22:54 - became interested in this topic a week
22:56 - ago when this image the first ever image
23:00 - of a black hole produced by the
23:01 - scientist from the event horizon
23:03 - telescope made this thing and it's
23:04 - amazing and I will include many links to
23:07 - explanations and papers that you can
23:09 - read up more about how this image was
23:11 - made and so I became fascinated this
23:13 - idea and sort of like in the sense that
23:14 - I have this book called nature of code
23:16 - which has a bunch of examples about how
23:19 - to look at the formula for gravitational
23:21 - attraction and then make a little 2-d
23:23 - simulation of that could we demonstrate
23:26 - some of the ideas in how this image was
23:29 - produced in how a black hole behaves in
23:32 - how a black hole bends space-time or how
23:35 - space-time is bent around the black hole
23:37 - and how light can't even escape and the
23:39 - speed of light and then there's
23:41 - relativity and there's special
23:43 - relativity and all this stuff there's so
23:45 - much stuff now as you know if you've
23:47 - watched this channel before I am NOT a
23:48 - physicist nor do I play one on YouTube
23:51 - and so this is not something that I
23:54 - would ever even remotely close to
23:55 - claiming to be an expert in so I am
23:58 - relying on the the good-heartedness of
24:02 - the Internet in particular Chris or bond
24:04 - from the YouTube channel stem coding
24:06 - which has a lot of wonderful coding
24:09 - challenges and video tutorials related
24:12 - to real science and p5.js and teaching
24:15 - about science through coding with a
24:17 - diverse set of speakers graduate
24:20 - students and various other people so I
24:22 - highly recommend you check out stem
24:23 - coding and Chris Urban on one of his
24:25 - examples one of their examples has a
24:28 - sling shot with gravity a demonstration
24:30 - much like my gravitational attraction
24:32 - nature of code example what I'm saying
24:36 - that's what I'm saying that's what I say
24:38 - edit edit point don't move don't move
24:41 - all those we heard to edit don't move it
24:43 - moving what was I gonna say next
24:49 - so Chris recently when that image came
24:52 - out made a slightly modified version of
24:53 - that example too
24:56 - talk about some of the basic mechanics
24:58 - of how a black hole behaves and there's
25:03 - more explanation on this page and you
25:05 - can link here to see the modified at
25:07 - p5.js code so I highly recommend you
25:10 - check that out there's also a wonderful
25:12 - video by veritasium wait did I say that
25:15 - right I couldn't say galilean wait hold
25:19 - on there is also a wonderful video by
25:25 - veritasium which actually came out
25:27 - before the image was released which is
25:30 - kind of amazing then there's also a
25:31 - follow-up video of when the image was
25:32 - released if you don't know the
25:33 - veritasium youtube channel what's you
25:35 - know this channel you know that channel
25:37 - probably anyway that has this image in
25:40 - it showing how the photons pass rays of
25:43 - light bend around a black hole it's like
25:46 - so insane that they bend around meaning
25:48 - if I'm standing I mean I couldn't if I
25:50 - was standing on the black hole I
25:51 - couldn't see the black back of my head
25:53 - because the light would Bend around it
25:55 - so I want to see if I can create
25:58 - something along the lines of this to
26:00 - demonstrate that idea this is like a
26:02 - tiny little inkling piece of the puzzle
26:05 - of all of the science and work that went
26:08 - into producing that image so I'm going
26:11 - to do this I'm really just going to use
26:12 - Newtonian physics basic mechanics I'm
26:17 - not gonna get into relativity and kind
26:20 - of modifying how time slows down the
26:24 - faster you're moving what did I just say
26:30 - yes I'm not going to get I'm not going
26:36 - to get into special relativity and how
26:39 - time slows down as you're moving faster
26:41 - I would like to come back to that what I
26:42 - would like to do is just make something
26:44 - that gets at this central idea and then
26:47 - as a challenge to you I hope you will
26:49 - modify it I'm going to give you some
26:51 - resources to how to look into more of
26:53 - the science of how it actually works and
26:55 - then maybe I'll come back next time and
26:57 - do a follow-up video and in theory I
27:00 - could just keep going with this and make
27:01 - it 3d and then actually try to model how
27:04 - that image will produce this could go on
27:05 - forever I don't know how far I'll get
27:07 - but you the viewing on
27:08 - hopefully will either will take it from
27:10 - me and make something wonderful which
27:11 - then I can share our cool I will
27:27 - oops I'll include links to these other
27:30 - resources in the video's description and
27:32 - some of these came from veritasium
27:33 - Barrett Oh I'll include links to what
27:39 - was I trying to say veritasium
27:40 - veritasium veritasium veritasium it's
27:43 - fair to say I will include links to
27:48 - other resources for you some of which I
27:49 - got from the veritasium video as well
27:51 - that you can read up on and I'll be
27:53 - reading these a lot over the next week
27:55 - or so as well so one is you should check
27:57 - out this how to draw a black hole which
27:59 - goes through a lot of the math and then
28:01 - some nice really computer graphics
28:03 - shader style 3d tricks that you can
28:05 - think about looking through and you've
28:07 - got something here that actually looks
28:08 - quite a bit like the artistic rendering
28:10 - of a black hole in the film interstellar
28:11 - so how they recommend you check out this
28:13 - article by I'm sorry I don't know the
28:16 - person's name by rattin ELLs on github
28:18 - you can also read this 1979 paper image
28:22 - of a spherical black hole within
28:24 - accretion disk so I'll talk about what
28:25 - accretion disk is in a moment if you're
28:28 - not familiar with it but you can see
28:29 - kind of some of the math about the
28:31 - photon trajectories and so some of these
28:33 - formulas would help me make they're over
28:35 - here so any form of those would help me
28:37 - make what I'm about to do a bit more
28:38 - accurate possibly and then oh this was
28:40 - something that was sent to me by K week
28:42 - Mon in in the chat which has some of the
28:45 - formulas also the equations for the
28:47 - radial motion of photons so I'm gonna do
28:49 - this without implementing the sort of
28:51 - with this with any kind of scientific
28:52 - precision just cuz I get out get out of
28:54 - frame work am i apologizing and giving
28:56 - you enough Gavi aughts I think that I am
28:58 - ready to move on I took some notes
29:05 - I watched very testy in this video and I
29:07 - took some notes
29:14 - all right okay let's diagram the sort of
29:20 - elements that I want to consider in my
29:23 - simulation slash visual visualization
29:25 - and of course the real world
29:28 - Oh 1978 hold on
29:44 - oh it says 9000 the book is nighttime
29:49 - all right sorry
29:51 - correction the paper is 19 from 1978
29:54 - here machen will dub the thin when the
29:56 - Edit version comes out 1978 from 1978
30:01 - 1978 there there's a few audio samples
30:03 - you can dub the overview saying 1979
30:05 - does the coding train read chat ask
30:08 - slush puppy every once in a while you
30:11 - just have to get lucky I guess let me
30:15 - try to dry it done let me try to diagram
30:21 - out some of the elements of what I want
30:24 - to include in my part simulation heart
30:27 - visualization so in two dimensions let's
30:31 - say we have a black hole here's my
30:34 - buckle and I'm gonna do this vertically
30:36 - because I think that'll work actually it
30:37 - doesn't matter here's my here's my black
30:41 - hole now what do I mean by this being
30:42 - the black hole first of all a a black
30:44 - hole is not something we can see that's
30:48 - why it's called a black hole the reason
30:49 - why it's black and we can't see it is
30:51 - because light the force of gravity the
30:54 - black hole is so strong that light can't
30:56 - even escape from it so you could not
30:57 - from inside the black hole there's no
30:59 - way you could communicate outwards so
31:00 - that's why it appears black it's often
31:04 - referred to as a shadow and maybe I'll
31:06 - sort of like get to that in a sense but
31:07 - we have so but one thing it has the
31:09 - reason why it's the force of gravity is
31:11 - so strong is it's massive supermassive
31:13 - and so this black hole has a mass now I
31:17 - wrote this Ted took notes no like I
31:21 - don't know this might be the second time
31:23 - ever I've done this but I don't know
31:25 - where I wrote this down it's not these
31:26 - notes oh yeah see there oh but I could
31:30 - have memorized this now this being if
31:34 - this is uh if I'm talking about
31:35 - Sagittarius a star which is the name of
31:38 - the black hole of the photo the image
31:39 - was made of the mass of this is 2.6
31:43 - million Suns give or take I think you
31:46 - know that's a sort of estimation
31:47 - approximately give or take you know I
31:50 - think it's point 2 on the some other
31:52 - page on the internet that I read earlier
31:53 - today 2.6 million Suns so massive that's
31:57 - important there is this idea of the
32:02 - event horizon the event horizon being
32:05 - the path oops sorry I hope people will
32:12 - correct me as I get things wrong by the
32:14 - way the event horizon being the path
32:23 - around the black hole sort of edge at
32:26 - which anything inside can never escape
32:28 - including light nothing great so another
32:31 - sort of key element here is C otherwise
32:34 - known as the speed of light this is the
32:37 - fastest anything in the known universe
32:40 - can travel nothing can travel faster
32:43 - than the speed of light and there is
32:44 - also an actual number there which is
32:51 - 299,792,458 meters per second okay
32:55 - that's gonna be great when I put that
32:57 - into a variable right here's my variable
33:01 - pixels for a second that will work I'm
33:03 - sure that'll work
33:04 - it was gonna be great so the event
33:08 - horizon now there is actually amazingly
33:10 - a formula for what this so you've
33:14 - analyzed in sorry is at a certain
33:15 - distance from the center we can call
33:16 - this a radius this is known as the
33:18 - Schwartz shield radius which I have a
33:21 - real problem saying but hopefully I'm
33:23 - pronouncing that close to correct the
33:25 - Schwarzschild radius now there is
33:26 - actually a formula to calculate this
33:28 - that's also in my notes it is the short
33:34 - shield radius is did I not write it down
33:39 - I have it in my code Oh Jane Christopher
33:42 - bond page hold on
33:43 - they didn't write that down hold on Oh
33:48 - people are telling me that neutrinos
33:50 - travel faster than the speed of light
33:51 - all right
33:55 - oh no this is not plugged in hold on my
33:58 - soundboard is not plugged in cancel uh
34:14 - here we go
34:21 - that formula is right here in Chris
34:25 - orb√°n's
34:26 - article so we have that as the radius
34:30 - the Schwarzschild radius equals two
34:32 - times the universal gravitational
34:35 - constant times the mass the mass of a
34:39 - black hole and divided by the speed of
34:44 - light squared okay so we could actually
34:46 - do this calculation right we could take
34:48 - this number square it ah
34:49 - we need one other thing we need G we
34:52 - need G the universal gravity
34:54 - gravitational constant let me okay good
35:03 - right not all black holes are
35:05 - supermassive that's correct sorry I'm
35:07 - referring to this black hole which is a
35:09 - supermassive black hole wait I want to
35:12 - find out the universal which is G
35:14 - written out on this page here G right
35:18 - okay all right so this is right all
35:30 - right so now we I'm looking at G the
35:31 - gravitational constant okay
35:36 - so G the gravitational constant is thank
35:41 - you also to Chris or Bunz article six
35:43 - point six seven times 10 to the negative
35:46 - 11 is the value for the gravitational
35:51 - constant so now we have all these values
35:53 - and I could sit here and I could
35:55 - calculate that radius
35:57 - oh let's should we do it could somebody
36:00 - do that for me you have some kind of big
36:02 - calculator I kind of probably really
36:04 - wish I had a prop this would be an
36:05 - awesome time we have a prop right now I
36:07 - could go over here and pull out a giant
36:10 - oh is this the enemy and like talking
36:14 - about our people trolling me or am i did
36:16 - I get it wrong and I'm not I thought I'm
36:18 - talking about Sagittarius a star hold on
36:21 - now I have to be sure about this right
36:23 - isn't that the one this is Sagittarius a
36:27 - star right sad
36:33 - okay
36:39 - that's that's the correct black hole
36:41 - right somebody's there is also they're
36:43 - also doing an image of another one I
36:46 - forgot what it's called I might have
36:51 - written it down somewhere but I don't
36:52 - remember okay I'm get this m87
37:12 - no but m87 okay I'm so confused
37:16 - I thought m87 is the galaxy I'm so
37:24 - confused
37:26 - [Music]
37:35 - it's m87 yeah I just got confused and
37:38 - Sagittarius a star is the blurrier one
37:40 - oh shoot oh I didn't write that down
37:45 - anywhere it does hey it doesn't matter
37:50 - but it matters for accuracy okay shoot
38:03 - yeah I don't know how to fix that but
38:10 - yeah m87 is the galaxy the black hole at
38:14 - the center that's why we say m87 star
38:16 - right star Messier yeah okay all right I
38:28 - messed up let's see if I can do some
38:31 - kind of magic editing tricks yeah okay
38:40 - so a couple options would be one this is
38:41 - one option
38:45 - oops
38:46 - I said Sagittarius a star wait no stop I
38:55 - just said Sagittarius a star
38:57 - it's m87 there's two black holes that
39:00 - the scientists are working again image
39:01 - of the first one was m87 star ma said in
39:04 - being the galaxy and the black hole
39:06 - being at the center of it and then
39:08 - they're also they're working on an image
39:10 - of Sagittarius 87 let me try another
39:19 - thing
39:26 - this black hole this particular black
39:30 - hole a supermassive black hole not all
39:32 - black holes are supermassive but this
39:34 - one known as m87 star named for the m87
39:39 - galaxy at which this black hole is at
39:41 - the center and its mass being
39:43 - approximately 2.6 million Suns give or
39:46 - take let you figure that out correct it
39:50 - somehow later all right where was I in
39:52 - this mmm-hmm no way I was gonna
39:55 - calculate this number so as a challenge
40:00 - to you calculate this number and leave
40:02 - it for me in the comments
40:15 - so okay so while you might think of the
40:21 - black hole as sort of like nothing it's
40:23 - nothing nothing can escape from there
40:25 - it's the end of everything this is not
40:27 - actually the case it's so much mass and
40:30 - the reason why it's so much mass is this
40:32 - in this one is particularly active I
40:34 - mean it's like just sucking up more
40:36 - stuff from the universe around it and
40:38 - the stuff that it's sucking up is
40:40 - orbiting it in what's known as the
40:42 - accretion disk so I'm gonna make make a
40:44 - little diagram a little bit outside here
40:46 - so this known as the accretion disk it's
40:50 - a lot of matter a lot of space stuff
40:53 - orbiting around and it's it's at a far
40:57 - enough distance that it's not being
40:58 - sucked in but here on the edge right
41:01 - this is the border of we're past this it
41:03 - will be sucked in eventually past the
41:05 - event horizon from which it cannot
41:07 - escape and outside here it's a little
41:09 - bit maybe it's a little bit more stable
41:10 - but there is actually also a measurement
41:13 - of the what that distance from the
41:16 - center is right remember this is the
41:18 - Schwarzschild radius from this formula
41:20 - and then the accretion disks sort of
41:23 - inner edge is at breaking news oh I
41:31 - really could have memorized this one
41:33 - three three short sealed radii so three
41:38 - RS so that's what's over here so these
41:40 - are things that I would first want to
41:42 - try to visualize right I could draw an
41:44 - ellipse in my code with a radius based
41:47 - on this formula and then I could also
41:50 - draw the accretion disk sort of outwards
41:53 - at three times that radius what's the
41:56 - next thing I want to look at because I
41:58 - also want to look at all right now right
42:03 - right right
42:13 - all right okay good Thank You Simon for
42:22 - the oh did I say sagitarius the 87 I'm
42:29 - the worst
42:33 - it's very hard to do this well actually
42:36 - maybe it's not yeah I just have an
42:38 - impossible time I gotta get this section
42:42 - done by 11:30 that's my time 11:30 is my
42:44 - break usually it ends up being more
42:46 - around noon
42:53 - all right well look at this I gotta
42:56 - allow this comment to come together all
43:00 - right so the next thing
43:20 - interestingly enough there's another
43:23 - ring that we could consider so we've got
43:25 - the event horizon we've got the
43:27 - accretion disk but what is the distance
43:31 - at which a photon of light would orbit
43:34 - the black hole after all a photon of
43:36 - light doesn't have any mass so all this
43:38 - matter and the accretion disk actually
43:40 - has mass the photon of light traveling
43:42 - at the speed of light doesn't have any
43:44 - mass or the mass of zero
43:45 - oh boy oh boy we're getting into
43:47 - relativity aren't we
43:48 - but it so happens that at 1.5 a
43:53 - Schwarzschild radius radii Schwartzel
43:56 - why do you say that radius radii at
43:57 - about halfway a 1.5 is where a ray of
44:02 - light a photon a photon particle would
44:05 - orbit so the question is here how would
44:10 - we look at this if light right the idea
44:12 - of seeing something is seeing light
44:15 - bounce off of something in travel path
44:17 - back into our eyes if light travels so
44:22 - fast that we it's barely like
44:23 - perceptible that time how would we look
44:26 - at something so massive so far away and
44:33 - so that's why there's this idea of a
44:35 - shadow so what if there's we wouldn't be
44:38 - able to see this if there wasn't the
44:39 - sort of matter and plasma and all the
44:41 - other stuff going around it what we're
44:43 - what we're able to see is that stuff
44:45 - with the shadow of the black hole and I
44:47 - think a piece of what's interesting
44:48 - about this it really lot really depends
44:51 - at the angle that you're looking at and
44:54 - you and there's so much to this but
45:00 - that's a bit beyond the scope of where I
45:01 - am capable and want to go right here in
45:05 - this video so what I want to do is
45:06 - diagram all of this and then imagine
45:09 - maybe I'll start I don't know where I'll
45:11 - start it from I'll just start from over
45:12 - here imagine we have a bunch of our
45:15 - telescopes on earth so in order to image
45:18 - this you would need as the scientists
45:20 - discovered a telescope the size of the
45:23 - earth and what the scientists were able
45:25 - to do was use many telescopes all
45:27 - perfectly sink
45:28 - all traveling or not traveling but the
45:31 - earth is also rotating so you have a
45:32 - bunch of different views to be able to
45:34 - compile and build this image from all
45:36 - the data from those telescopes so we
45:38 - could maybe simulate this idea in the
45:40 - most basic way by thinking of the
45:43 - signals from the telescope or beams of
45:46 - light traveling at the speed of light at
45:49 - this black hole how would we what would
45:51 - we see reflected back how do we see the
45:53 - light that is passing around here so
45:57 - let's see what happens in theory what we
46:02 - would see right so let's say okay in
46:05 - theory what we would see let's say we
46:07 - have a nice ray of light perfectly sort
46:10 - of aligned with the center of the black
46:12 - hole it's going to move in that
46:13 - direction past the event horizon never
46:15 - to be seen or heard from again something
46:18 - a little bit off would come like this
46:19 - and the gravitational pull would pull
46:22 - that ray of light in it would also go
46:24 - past the event horizon never to be seen
46:25 - again but at a certain point if we get a
46:28 - certain point outside it's going to be
46:30 - it's going to bend not go past the event
46:33 - horizon but kind of end up in that orbit
46:35 - or spin out into infinity or something
46:38 - like that and it actually so happens
46:40 - this is thank you to the veritasium
46:41 - video which explains this so succinctly
46:43 - that the the distance there for that ray
46:50 - of light is 2.6 Schwarzschild radii if
46:54 - the two point six times the
46:57 - Schwarzschild radius I don't know so in
47:01 - theory if I plug all these numbers and
47:02 - use my average force of gravity formula
47:05 - will see exactly this happen haha
47:08 - definitely not but that's the idea we're
47:10 - missing an important point fact at time
47:13 - and space bends and time slows down but
47:18 - I won't that's that's for you to think
47:20 - about and for me made me to come back to
47:22 - you all right
47:32 - okay thank you
47:33 - oh boy
47:38 - I've gotten so many things wrong in this
47:41 - explanation I really need to prepare
47:42 - more okay first of all simon is giving
47:45 - me a really excellent correction so I'm
47:51 - you know I'm gonna need to talk about
47:52 - that for a second thank you for that
47:54 - this correction about the orbits the
47:56 - difference between the the light orbits
47:58 - and the accretion the the matter in the
48:03 - accretion disk also the mass so mass of
48:08 - Sagittarius a star okay all right ah m87
48:17 - star 2.4 billion suns yeah oh boy oh boy
48:31 - Mattia when you're looking at this later
48:34 - I would be happy to do recumbent or like
48:41 - some explainer tea stuff over top of
48:43 - this maybe narrated a bit because I'm
48:45 - making some serious mistakes here so let
48:50 - me come back to this
48:59 - I really got my black holes mixed up
49:02 - there are two black holes that I'm
49:03 - talking about I mean I'm only talking
49:05 - about what I'm very sorry I have really
49:12 - gotten my black holes mixed up this is a
49:14 - thing that happens to me almost every
49:16 - day
49:16 - can't keep track of all these black
49:18 - holes in our universe the image that you
49:21 - that I showed at the beginning of this
49:23 - video is from m87 or the Oh cameras
49:34 - going off look it's a black hole you
49:36 - just saw the second image the third
49:38 - image ever of a black hole cuz I also
49:39 - made one of the Rubik's Cube the the
49:46 - black hole that I am talking about in
49:47 - this scenario the one that the image was
49:50 - published the one about which the image
49:53 - was published the one that is in the
49:55 - image that was published is m87 star in
50:01 - other words the black hole the
50:03 - supermassive black hole not all black
50:06 - holes are supermassive but this one is
50:08 - supermassive at the center of the m87
50:10 - galaxy that one is mass is approximately
50:13 - 2.4 billion suns the other black hole
50:20 - that I mistakenly referred to which is
50:23 - also currently being imaged and I'm sure
50:25 - I'm spelling this wrong is Sagittarius a
50:27 - star which is from the Sagittarius
50:31 - galaxy and that one is a bit smaller is
50:35 - approximately 2.6 million Suns which by
50:38 - the way when I say a bit smaller that's
50:39 - a lot smaller yeah it's often trusted we
50:44 - often think like oh it's just this one's
50:45 - a million this one's a billion that's
50:47 - just like up a little bit more than a
50:49 - million but no no a billion is a lot
50:53 - there's like a thousand millions and a
50:56 - billion or something like that it's
50:57 - amazing man
51:08 - so now you can revise your calculations
51:13 - here for m87 star but the math would all
51:17 - hold true for either one of those black
51:19 - holes now right
51:33 - right
51:38 - some other Corrections here some other
51:41 - corrections or perhaps further
51:43 - explanation number what the photon orbit
51:47 - which is here at one point five short
51:49 - shield radius is unstable so the photons
51:53 - circling around will eventually get
51:55 - sucked into the black hole or travel out
51:56 - towards infinity and that's kind of what
51:58 - I'm showing here with one of these that
51:59 - ends up in that order orbit it's going
52:01 - to do one of the or the other the the
52:03 - accretion disk is a more stable orbit I
52:05 - should also say that I'm saying this
52:07 - curves but it doesn't really curve see
52:10 - the fabric of space and time is curved
52:12 - there is things aren't attracted it's
52:14 - just correct you could think of it as
52:15 - like if I had a flat surface here and I
52:18 - put a giant bowling ball in it it would
52:20 - push that flat surface down and a little
52:22 - like ping-pong ball on the edge would
52:24 - roll towards it because it curved the
52:26 - fabric of space and time so this is
52:28 - actually a straight line through the
52:29 - curved space-time continuum let's get
52:33 - back to 2d canvas in javascript in the
52:36 - browser shall we oh it's not the
52:45 - Sagittarius galaxy I don't why did they
52:46 - call these things with inconsistent
52:48 - names 2,400 billions all right all right
52:58 - sorry 20 I got em 87th masse wrong party
53:05 - me actually this is not correct
53:09 - approximately 2400 billion suns which is
53:13 - quite a bit more than 2.6 million Suns a
53:17 - lot a lot more super massively more
53:32 - yeah all right
53:35 - Milky Way yeah okay here we go
53:38 - I think did I get it wrong trillion does
53:52 - that not okay I see her other correction
53:54 - Simon the black hole is unnamed the
54:00 - black hole is Sagittarius a star got it
54:03 - 6.5 billion solar masses okay
54:07 - 6.5 billion two point four trillion Sun
54:11 - masses not the black hole that's the
54:15 - galaxy oh so confusing it the mass of
54:19 - the galaxy
54:20 - ah okay I did kind of look this stuff up
54:23 - I just kind of
54:40 - let me correct this one more time I
54:42 - think I would get it right now do you
54:46 - like watching videos where the
54:47 - information is incorrect for a while
54:49 - then it just keeps getting corrected
54:50 - that's not good I don't think all right
54:56 - I have an idea
55:13 - doo-doo-doo-doo stop I have traveled to
55:15 - you from the future to come back into
55:17 - this video to correct what I just said
55:19 - but I'm actually recording this later so
55:21 - it'll look a little out of place but
55:22 - that's totally appropriate for this
55:24 - space-time continuum stuff to be clear I
55:27 - am named the incorrect black hole so I
55:29 - named a black hole called Sagittarius a
55:32 - star which is a black hole in the Milky
55:34 - Way galaxy and the scientists are
55:36 - currently trying to get it working on
55:38 - getting an image of that that's a
55:39 - smaller black hole about 2.4 million
55:42 - times the mass of the Sun something like
55:44 - that 2.4 million Suns this black hole
55:47 - the one that the image was published
55:48 - about and that I want to talk about in
55:50 - this video is called m87 star now m87 is
55:55 - the name of the galaxy the black hole
55:57 - itself is unnamed so m87 star and its
56:00 - mass is 2.6 no 6.50 now oh boy I gotta
56:09 - go wash my hand it's mass sorry I should
56:12 - not use my fingers
56:20 - it's mass is 6.5 billion suns
56:27 - okay solar masses so it's big really big
56:29 - 6.5 billion being a lot more than
56:31 - Sagittarius a star which is 2.4 million
56:34 - there we go
56:36 - returning to the scene of the crime
56:37 - where the wrong stuff will be written
56:39 - for a while and then it will suddenly
56:40 - appear correct again yeah my Google is
56:52 - for the entire galaxy it's not m87 star
57:04 - it's just m87 unnamed right
57:11 - yeah there's no m87 stars did I say star
57:14 - that was just that's a mistake we can
57:16 - all live with right
57:29 - I did talk about the unstable orbit
57:31 - Simon that will make it in that will
57:34 - make it in
57:42 - I mean just in case I can say oh they
57:45 - already have the image published already
57:46 - well whatever I'm behind I'm behind the
57:49 - times
57:49 - oh oh right I put asteroid baby I didn't
57:54 - say started first are there sorry
57:59 - no no m87 no ma no I'm sorry sorry no
58:06 - star no start just m87 that's the name
58:09 - of the galaxy Sagittarius a star's name
58:10 - a black hole Milky Way galaxy
58:12 - this is unnamed maybe the name by now
58:13 - I'm sure I hailed out at the comments
58:15 - how about a hobbits
58:19 - okay is the programming that is
58:22 - important you think oh it is a me maybe
58:24 - seven star who knows who knows no the
58:36 - star means it's something interesting
58:37 - and anomaly the black hole is unnamed
58:39 - okay alright okay we're gonna move on to
58:42 - the code now all right
58:53 - oh here 300 light years later Here I am
59:03 - about to maybe write some code so let's
59:08 - see we need some variables number one is
59:10 - we need the speed of light 299 792 458
59:18 - there we go I don't need the commas
59:21 - right because you know this is code so
59:24 - there we go there we go now we got the
59:26 - speed of light excellent things are
59:27 - going very well so far in my coding now
59:31 - we need the universal gravitational
59:33 - constant M G which is six point six
59:40 - seven times power 10 to the negative 11
59:43 - yeah
59:44 - what could go wrong there this seems
59:46 - exactly right there we go now I need to
59:52 - have my RS my Schwartz field radius
59:56 - which is two times G times o the mass
60:01 - okay now I need mm a constant M is the
60:06 - mass that was six point five billion
60:10 - that's new to zeros some more zeros some
60:14 - more zeros I don't know how much is the
60:16 - mass of the Sun mass of the Sun all
60:22 - right you see the folly here one folly
60:26 - here is while these numbers are
60:27 - incredibly meaningful and important
60:29 - they're not gonna do me so much good
60:31 - here in my p5.js editor javascript a
60:35 - program so what I'm gonna do is make up
60:38 - some numbers we're gonna create our own
60:39 - two-dimensional universe that has a
60:41 - speed of light that has a universal
60:43 - gravitational constant and in fact
60:44 - rather than put the mass of the black
60:46 - hole right here I'm gonna make a black
60:48 - coal class so let's just arbitrarily say
60:50 - like do something approximating this
60:52 - like the speed of light is 30 and the
60:55 - universal gravitational constant is like
60:57 - 6 why not right so and now let me also
61:01 - go and make I should have done this
61:04 - beforehand
61:08 - let me also go and make a you also go
61:13 - and make a black hole je s file oops
61:16 - black hole is and I'm going to add that
61:22 - to my index of HTML and then I'm going
61:26 - to say class black hole and oh I need a
61:32 - constructor just an X Y we need opes be
61:38 - even oh yeah let me use a P vector for
61:41 - this so I'm going to say this stop
61:42 - position equals create vector X comma Y
61:48 - and then I'm gonna do a function oh it
61:52 - now aha
61:53 - and this now I need a mass this dot mass
61:56 - equals six point five in our
62:00 - measurements are in billions six point
62:03 - five and then it's radius the
62:06 - Schwarzschild radius is what I say two
62:09 - times G times this dot mass divided by C
62:13 - times C now I need a little more space
62:15 - here to be able to see more code but
62:17 - fortunately actually I can do this and
62:19 - let's put these in parentheses and so
62:21 - now what I can do is I can write show
62:24 - and what am I gonna do let's make fill 0
62:28 - let's fill in the black hole with the
62:30 - color black let's draw a circle at this
62:34 - cause X this dot pause dot Y with the
62:38 - radiate rates for shield radius times
62:40 - two and so now if and I guess I should
62:45 - might as well pass in an argument here
62:47 - for mass if I were to in my main program
62:51 - say let black hole let's call it at m87
62:56 - we're gonna call our black hole m87 and
62:58 - 87 equals a new black hole I'm gonna
63:01 - place it at sort of like the top I'll
63:03 - let actually the left of my canvas so
63:06 - let's place it at like 100 comma 320 and
63:10 - we're gonna give it a mass of what I say
63:12 - 6.5 and then I'm gonna say an 87 dot
63:16 - show we have a black hole Oh R
63:19 - is not defined this stop-stop there we
63:30 - go that fixes that and where where where
63:33 - is my black hole
63:52 - I guess my black hole has sucked all the
63:56 - light out of it so I can't see it let's
63:58 - take a look at what this dot RS is ah
64:02 - way too tiny right so my units are
64:06 - really kind of all over the place so
64:08 - let's make some units that make more
64:09 - sense for our pixel space let's make the
64:13 - mass of the black hole probably much
64:16 - bigger like 6500 there we go look thank
64:23 - you good night
64:25 - I have now made my simulation of eyeball
64:28 - this is the first ever known image of a
64:32 - black hole made in p5.js I need to blow
64:38 - my nose
64:57 - all right just because I don't have a
64:59 - lot of pixel space to work with right
65:01 - now let's make let's make the mass 1/10
65:08 - as large and we can see there's my much
65:10 - smaller black hole okay fine let's make
65:12 - it a thousand let me put on auto-refresh
65:13 - which will be nicer and five thousand
65:17 - and three thousand all right this is
65:19 - looking good to me that's the size of
65:21 - the black hole that I want okay let's
65:26 - now draw the accretion disk so let's
65:30 - make some sort of accretion disk so I'm
65:33 - gonna say I am gonna say ellipse I'm
65:38 - actually going to sorry I'm gonna say no
65:39 - fill stroke and let's make it kind of
65:42 - greyish and I'm going to draw the
65:45 - accretion disk as a circle this pause X
65:48 - this pause dot y this dot RS x this just
66:10 - in from this just in from the chat I
66:13 - forgot about this I can use I did not
66:15 - know I forgot about this I can say
66:16 - ellipse mode radius which should now
66:21 - allow me to and comment this out just
66:25 - use the radius as the ellipse perfect as
66:27 - the just used the radius value as the
66:30 - size of the circle Thank You Simon Tiger
66:33 - for that great correction all right so
66:35 - now I'm gonna say this circle is that
66:37 - the radius times three and maybe I will
66:40 - give it a stroke sorry stroke weight of
66:46 - eight
66:47 - oh and I want no stroke here
66:55 - and let's make it a stroke weight of
66:56 - like 24 or 64 and let's give it some
67:00 - alpha and there we go alright so that's
67:04 - kind of my visualization of the
67:07 - accretion disk now the truth of the
67:09 - matter is this is not exactly correct
67:11 - because I have a feeling V that distance
67:14 - is right here in the center
67:15 - whereas the stroke weight kind of fans
67:18 - out the thickness there so it's a little
67:20 - bit off and I probably should you know
67:22 - be a little bit more accurate about that
67:24 - I guess what I could do is just add to
67:27 - the radius itself the half of the stroke
67:29 - weight so if I add 32 there there we go
67:31 - I think that's I think that's accurate
67:33 - now I mean know nothing about this is
67:35 - really accurate all right now let's draw
67:38 - the unstable photon orbit so that would
67:42 - be at 1.5 of the radius so I can do the
67:46 - same exact thing but this time at 1.5
67:49 - maybe I want to make that one a little
67:53 - less thick myself a little more space
67:56 - here so that make the 16 and make this
68:00 - oh and make this 32 and maybe this one
68:05 - should be like some kind of color cuz
68:09 - life is so good at design you know some
68:15 - kind of oranges truth it was better
68:16 - before I guess some kind of oranges
68:20 - color
68:20 - okay look at this we now have the black
68:25 - hole the accretion disk and a sort of
68:29 - photon or betray now the other thing
68:31 - that I want to do is I want to start a
68:33 - bunch of photons coming from I'm gonna
68:39 - try to like zoom into this here I want
68:41 - to have them coming from over here
68:42 - towards the black hole I need to know
68:44 - how far I can't jump up because my green
68:47 - screen only goes this I don't know how
68:48 - how far up does it need to be for it to
68:52 - not really curve but travel in a
68:54 - straight line around the path of curved
68:56 - path of state space of time to end up in
68:59 - an orbit to either spiral out to
69:00 - infinity or end up into the
69:02 - call so that we said was 2 point 6 2
69:07 - point 6 Schwartz yield radiate radius
69:10 - okay so now what I'm going to do is I'm
69:15 - going to create another class I'm gonna
69:19 - call this photon got J s photon j s will
69:24 - be a photon make a constructor this will
69:32 - also have a position I'll give it an X
69:35 - and a Y and let's give it a little let's
69:45 - make sure we include it in our HTML file
69:48 - and let's also write a show function
69:53 - which says let's just make this stroke
69:57 - weight for a point this dot paws dot X
70:03 - this dot paws dot Y and Stroke let's
70:07 - let's look to make this distinctly red
70:09 - just for right now actually make it yeah
70:11 - all right so now what I could do
70:15 - potentially is let me make an array it
70:19 - could be I'm gonna call it light may I
70:23 - just call it photons particles what I'll
70:24 - call particles whatever and I want to
70:27 - say for let y equal 320 Y is less than
70:38 - it really this is height divided by 2 y
70:40 - is less than or Y is greater than height
70:46 - divided by 2 minus so I'm actually gonna
70:49 - put these in two variables so I'll make
70:50 - more sense
70:51 - let's say start is height divided by two
70:53 - and is height divided by two minus m87 s
70:59 - Schwarzschild radius times two point six
71:01 - height divided by what I divided by 2 so
71:06 - y equals actually I can start it at the
71:10 - end and it's less than start and why
71:16 - plus equal like every 10 pixels so let's
71:20 - do that every 10 pixels and what I want
71:23 - to do is say particles index I equals a
71:34 - new photon at where X will be just with
71:38 - minus some amount with - like 20 comma Y
71:44 - what's wrong there I is not defined Oh
71:49 - particles oh okay so I also need it I'll
71:52 - just say particles dot push so I can add
71:56 - things to the array with the push
71:57 - function because I'm not using I to
71:58 - iterate that makes more sense and now
72:01 - here in the draw function I can say for
72:03 - every photon of particles pho so now
72:11 - there we go I have all of my points of
72:14 - light that I want to send out at the
72:17 - speed of light towards the black hole
72:19 - and watch them follow their
72:21 - straight-line path through the curved
72:23 - space-time state so now let me give them
72:31 - a velocity so if I go back into my
72:34 - photon whoops I'm also going to say this
72:40 - dot velocity equals create vector
72:44 - traveling at the speed of light in the
72:45 - negative x-direction negative C comma
72:48 - zero then I am going to do but what's
72:53 - not constructor an update function in
72:55 - which case this stop position dot add
73:01 - this dot velocity and what I can do now
73:04 - is in sketch j/s is I can say P dot
73:09 - update ready here we go everybody all
73:20 - right so what is the speed of light here
73:21 - 30 30 pixels per frame is gonna be going
73:24 - quite slowly actually like the frame
73:27 - rate seems slow 30 pixels per 4
73:31 - that's not really a nice way to watch an
73:33 - animation so I'm gonna include another
73:35 - variable them to call it DT this is the
73:37 - delta time step so even though my frame
73:40 - animation frame goes one at a time
73:43 - thirty frames per second maybe I only
73:45 - want to travel ahead a little bit in
73:47 - time so let's try 0.1 a tenth and so all
73:51 - I need to do is the what I need to
73:52 - adjust by that delta T is the photons
73:57 - velocity so mmm I guess I'm gonna make a
74:00 - copy of this so I will just say this dot
74:05 - Delta V equals this dot velocity dot
74:08 - copy and then this dot Delta this is a
74:10 - little bit awkward about using P vector
74:12 - or multiply by DT and then I actually oh
74:16 - not this dot I just want a Delta V and
74:20 - then multiply that by DT and then add
74:22 - that instead so now I can see there we
74:25 - go there are the photons traveling at
74:27 - the speed of light and I see and then
74:29 - they go ah but they're not curving
74:30 - they're not changing so now break for a
74:33 - second
74:49 - okay now we just need to have them bent
74:55 - we need to have them Bend
74:58 - according to the curvature of space-time
75:02 - this is now the moment where it makes
75:05 - sense for me to go read one of those
75:06 - papers and try to look at those formula
75:08 - but I'm going to actually see what
75:10 - happens if I just apply Newtonian
75:13 - gravitational attraction so I need this
75:16 - photon to basically have a force pointed
75:21 - in the direction of the center of the
75:22 - black hole that it accelerates its
75:24 - velocity towards it so and but but an
75:27 - interesting side note here and this was
75:29 - my guess is like an approximation of
75:30 - relativity is this we can't go faster
75:32 - than the speed of light
75:33 - I out it rule really only adjusting the
75:36 - direction so that the speed is going to
75:37 - remain constant at the speed of light
75:39 - again means your caveats to how
75:42 - inaccurate this is but it's a starting
75:44 - point so are you
76:02 - so what I want I want to add a function
76:05 - basically I want to be able to say I
76:07 - have some sort of force which is m87 I
76:10 - like you know curve pull I don't know
76:13 - it's a good say attract I'm just gonna
76:15 - say pull as a kind of arbitrary word
76:17 - pull that particle and then I want to
76:20 - say particle apply force that force so
76:24 - this is very similar to how I approach a
76:26 - very basic physics simulation in my
76:29 - nature of code example so you could
76:30 - refer back to the chapters 1 & 2 of that
76:32 - book which basically which is
76:33 - essentially what I've got here now so
76:37 - what I need is a function now in the
76:38 - black hole object called pull that
76:41 - expects expects a photon and so what I
76:44 - need is first thing I need to calculate
76:46 - this force vector is a vector that
76:50 - points from the particle itself towards
76:53 - the center of the black hole so that's
76:55 - easy because I can take this position
76:56 - minus this position and that gives me a
76:59 - vector and that gives me a vector that
77:06 - gives me a vector in the right direction
77:07 - so I can say force equals P v vector dot
77:12 - subtract this dot position minus photon
77:17 - dot position great so now I want to
77:22 - normalize that force to give it unit of
77:27 - length one then oh I'm in the wrong I'm
77:32 - in the wrong camera thank you uh okay
77:34 - thank goodness
77:41 - so to make that vector I just want to
77:44 - I'm going to cut make effect a variable
77:45 - called force and I want to say p5 vector
77:48 - dot subtract what is it this dot
77:51 - position the position of the black hole
77:53 - - photon dot position the position of
77:57 - that particular photon so that's the
77:58 - vector now what I need to calculate the
78:02 - force of gravity according to Newtonian
78:03 - of the Newtonian laws of motion is that
78:06 - force of gravity equals the universal
78:09 - gravitational constant G times the mass
78:12 - of one object guess what
78:14 - that's this times the mass of another
78:18 - object ok what's the mass of this oh
78:20 - we've got a problem now so the mass of
78:23 - this is well zero but the force isn't
78:28 - zero hmm so this makes kind of no sense
78:30 - the good news for us is we're going to
78:33 - use this in acceleration and it's
78:35 - because we also have force equals mass
78:38 - times acceleration and I want to know
78:40 - the acceleration of this acceleration
78:42 - equals force divided by mass so this
78:45 - mass will just get divided out and of
78:46 - course I couldn't divide by zero and
78:47 - this is this is why this is the essence
78:50 - of why I'm kind of going down the wrong
78:52 - direction here to do this accurately but
78:55 - it's a starting point I can just
78:57 - consider this right now the G times the
78:59 - mass of the black hole itself divided by
79:03 - R squared or the distance of between the
79:06 - photon and the black hole R squared or
79:08 - distance squared so I have that value
79:11 - actually in my code because I have R is
79:13 - the magnitude of the force then I could
79:17 - just say force dot set
79:18 - oh I'm sorry then I could get the act I
79:23 - have R which is the magnitude of the
79:25 - force then I could actually calculate
79:28 - that force magnitude which is the force
79:30 - of gravity equals what I say G times
79:33 - this mass divided by a R
79:53 - / R times R and now I could say force
80:00 - dot set magnitude F of G right Oh photo
80:09 - photon and then I could just say this
80:12 - dot velocity ad force because what I
80:15 - want to do huh
80:22 - Oh photon dot velocity then I just want
80:25 - to add I want to add that force to the
80:27 - the photons velocity okay P dot apply
80:31 - force is not a function so actually I've
80:33 - simplified this I what I could just do
80:36 - is get rid of this whole extra step of
80:38 - returning the vector and I could just do
80:40 - this there you see those photons so
80:50 - let's be able to see this a bit better
80:52 - and we'll see why this is not correct
80:54 - but first let me do let me do a couple
80:56 - things one let me say let me make these
81:02 - variables and let me let me draw a lines
81:11 - so let me say stroke zero line from zero
81:16 - start zero end and sorry sorry with at
81:27 - sorry zero start with start and let me
81:34 - say stroke wait one and then let me also
81:39 - do the same for the end you just want to
81:41 - be able to see where these are so this
81:45 - is showing that spot now you can see oh
81:48 - and guess what the speed of light the
81:52 - photon should always be traveling at the
81:54 - speed of light so I forgot about that so
81:56 - this is a huge hack here I'm going to
81:59 - say right here when I do that pull right
82:05 - in the black hole
82:06 - I do that pull I'm gonna say photon
82:10 - velocity dot set magnitude see o set
82:20 - magazine here she's just limit it let's
82:21 - just limit it it could slow down I
82:23 - suppose it could slow down let's just
82:26 - limit it and see what happens
82:27 - Oh everything got sucked in look at that
82:32 - the black hole sucked it all in okay so
82:35 - a couple things one is so this is good
82:37 - in other words this is kind of a nice
82:39 - little simulation in the sense that the
82:41 - force is so strong even in my very crude
82:44 - simulation that it's never going to
82:46 - escape now next next up let's add a
82:54 - little trail here so the photon I'm
82:56 - going to give it a variable called this
82:57 - dot history and I am going to every time
83:02 - it updates its position or every time
83:05 - before it updates its position I'm going
83:06 - to say history dot push this dot pause
83:09 - copy and so then also this dot history
83:16 - then also let's just say if this dot
83:19 - history dot length is greater than I
83:22 - don't know 100 this stud history got
83:25 - splice let's just remove the oldest
83:27 - element and now I can say stroke 255 a
83:33 - stroke zero stroke weight one begin
83:38 - shape and shape no fill for every vector
83:47 - in history vertex V dot X the type B dot
83:58 - why this dot history so now we're able
84:06 - to see those paths as well as they've
84:08 - and so again I don't have it right we
84:11 - can give ourselves a much longer history
84:12 - here but I can at least at a very
84:15 - minimum now I can look and try to see
84:18 - what I can try to
84:20 - where how this is working a bit more I
84:23 - don't know I just said that part out all
84:26 - right let me give the history a little
84:28 - bit more oomph to it and let's what I'm
84:34 - gonna do here now also is I am going to
84:37 - start some particles from higher than
84:40 - end so I'm going to say and divided I'm
84:43 - gonna just going to start all the way
84:44 - from zero like the top and then let's
84:48 - space them out by a little bit more and
84:52 - here we go and let's actually let's give
84:57 - myself a little bit more space to work
85:01 - with here and see what we've got
85:11 - Wow nothing escaped look at that nothing
85:15 - escaped my black hole let's give it a
85:19 - smaller let's give it a smaller again
85:22 - it's not accurate I've got this wrong
85:24 - because I'm not taking two accounts but
85:33 - I'm visualizing the idea here let's try
85:35 - some let's try what happens if I make
85:37 - the gravitational pull like constant
85:40 - smaller let's see if we can get anything
85:42 - to escape come on rays of light come
85:45 - back to the telescope there we go you
85:52 - can see it's there in the photon orbit
85:54 - oh but back into the center so we're
85:56 - getting the idea do we have something
85:58 - sort of similar to this I think we do
86:01 - change the color to red try shrinking
86:05 - the mass okay let's go back and change
86:09 - you want the color to be red of the
86:10 - photons paths so I can just take this
86:14 - out let's also make this stroke weight a
86:16 - little bit wider so I can see it and
86:20 - then let me let me give myself here let
86:22 - me let me actually give myself much more
86:25 - space here so I'm gonna say window with
86:27 - whatever space I have window height and
86:31 - let's also make
86:33 - this even less and see what happens and
86:40 - then I'm gonna do share share let's do
86:48 - fullscreen and here we go oops oh I have
86:55 - it hard-coded at 320 hold on one thing I
86:58 - need to fix so what do I have hard-coded
87:02 - at 320 this height divided by two there
87:08 - we go
87:10 - and let me go to fullscreen here we go
87:13 - all right here is my black hole
87:16 - simulation rays of light go I think I
87:24 - need to move it over this is bothering
87:26 - me
87:26 - sorry everybody let's move it over so we
87:29 - can have a little bit more space to work
87:31 - with 300 there we go all right now of
87:37 - course you can see this should be where
87:41 - they're able to escape but my simulation
87:43 - is completely off so I should take out
87:45 - those start and end lines and just watch
87:47 - this go there it is the curvature of
87:55 - space and time center of the black hole
87:57 - please okay that's actually not a bad
88:00 - idea Center the black hole on the page
88:02 - okay last thing let's Center the black
88:05 - hole that makes sense I'm also just
88:09 - going to unfortunately take out these
88:14 - lines which are no just because it
88:16 - really shows how incorrect it is so for
88:19 - me to have some plausible deniability
88:21 - here as my new favorite phrase oops now
88:24 - what did I get wrong invalid or
88:26 - unexpected token what did I do wrong
88:39 - once I just change
88:48 - huh 9:13 oh whoops
88:53 - some sort of typo thing happened there
88:57 - all right let's look at this full screen
88:59 - now and here we go let's see what we've
89:08 - got
89:15 - now it's running quite slow because of
89:20 - all drawing all these trails I think
89:23 - actually something that I could really
89:24 - do to make this some things that I could
89:27 - do to make this better
89:28 - a little faster is number one is in the
89:35 - photon itself I could say I don't have
89:43 - to add every single spot I could just
89:45 - say like if frame count modulus 10
89:47 - equals zero that's gonna improve the
89:52 - speed quite a bit I also feel like you
89:54 - know what's the why am I only doing half
89:57 - and maybe it's nice to do half let's
89:58 - just keep doing with half whoops and now
90:04 - let me change this twofold oops let me
90:12 - change this to full well that's kind of
90:17 - funny a little funny effect that I
90:20 - didn't mean
90:29 - and there we go
90:40 - look at this look at that perfect orbit
90:43 - huh that's kind of amazing that that
90:46 - happened and there we are
90:50 - I think this wraps this up so there's a
90:52 - lot of flaws on what I've done there's
90:54 - probably a lot more thoughtful ways that
90:56 - you could think about first designing
90:57 - this first of all it probably would look
90:59 - nicer one thing I kind of do want to
91:00 - change is just to draw the black hole a
91:05 - last because then at a minimum then at a
91:16 - ver at a minimum at least it will look
91:20 - as if because I'm drawing the Rays
91:22 - behind that black circle now I'm not I
91:26 - must not have saved
91:33 - and give draw the black hole I want to
91:39 - draw the black hole after hit save and
91:43 - then also let's as I draw it let's give
91:46 - a little alpha to this inner ring here
91:50 - and then when we hit refresh and we
91:53 - should see now we should this should be
91:57 - a little bit more nicer to look at in
91:58 - the sense that it will look as if the
92:00 - photons are disappearing into the black
92:01 - hole because it's pi
92:03 - so there we go and we've got a nice
92:07 - simulation of the idea of a black hole
92:12 - and rays of light curving according to
92:15 - space and time wildly inaccurate very
92:18 - problematic I will please I can't wait
92:22 - to hear your comments about what I've
92:23 - got right what I got wrong what kinds of
92:26 - ways I could improve this the code for
92:28 - this is linked right here in the video's
92:30 - description you can take a look at it
92:32 - and make your own version share it with
92:35 - me at the coding train comm there's a
92:37 - little way you can submit your own
92:38 - version of this challenge and I will
92:40 - hopefully come back and do a follow-up
92:41 - video either showing some of the ones
92:44 - that you have made or make one that
92:46 - maybe tries to look at how the actual
92:49 - orbits equations work to simulate what
92:54 - they a more accurate version of them I'm
92:57 - very tired after doing this for quite a
92:59 - long time thank you so much for watching
93:01 - I appreciate it and I'll see you soon
93:15 - more photons why does everybody want
93:21 - more photons all right you asked for it
93:26 - I will give you more photons I mean one
93:31 - thing I could do is just make a lot of
93:32 - random ones but I don't think that a
93:34 - look is nice so what I mean I could make
93:42 - them every like five pixels I was just
93:52 - worried about performance
94:01 - so let me fix a couple things here oh
94:06 - that's kind of nice looking let me fix a
94:15 - couple of things here one thing that I
94:20 - want to do is in the photon class I want
94:25 - to oh I have an idea of how to make this
94:31 - much better oh I got an idea what time
94:38 - is it twelve o'clock okay getting to the
94:40 - next segment very soon but let me just
94:42 - do this because this will be good the
94:45 - things that I wanted to do are number
94:48 - one is let's let's do this right here so
94:58 - that's not going to help
95:01 - yeah I don't love how that is but that's
95:04 - fine I'll just do it a little bit more
95:07 - often and what I'm gonna do is in pull
95:14 - let's just say in pull if if R is less
95:23 - than this dot the event horizon then
95:26 - photon dot stop right this is gonna make
95:30 - things run much faster
95:46 - yeah I don't think the photons are
95:52 - slowing down I think the I mean I could
95:56 - I could make sure that they aren't but
95:59 - I'm pretty sure that this will produce
96:01 - the same result
96:02 - like photon dot velocity dot set mag C
96:07 - hold on some people are talking about
96:08 - the photon slowing down I think this
96:11 - will be the same result
96:26 - oh that is kind of a different result
96:32 - oh they are okay okay this video is not
96:49 - over yet thanks to the chat I think this
96:52 - is actually kind of problematic the way
96:54 - that I'm doing this is the photons are
96:56 - actually slowing down and they should
96:57 - stay I shouldn't limit them to the speed
96:59 - of light I should actually just keep
97:00 - their magnitude at the speed of light
97:01 - again it's sort of an act inaccurate
97:03 - anyway so what's the difference I've
97:05 - also added more photons here so you can
97:08 - look at it this way and so this is a
97:10 - slight they're gonna be a slightly
97:11 - different result because now I'm locking
97:14 - them at the speed of light I think
97:17 - there's also a big performance
97:18 - improvement that I can make which is
97:19 - that once they're sucked into the black
97:22 - hole I don't need to keep tracking their
97:23 - position as well as I don't need to be
97:28 - tracking their position and keeping that
97:29 - history going so I should really like
97:30 - shut them off as soon as they've been
97:32 - sucked in so another thing that I can do
97:34 - here is since I have that distance I can
97:37 - say if R is less than the event horizon
97:40 - I mean I could remove the photon just
97:44 - delete it but I want to still see its
97:45 - path so I think I'll say photons stop I
97:48 - mean that doesn't mean anything but I
97:50 - can then in the photon class I can have
97:53 - a variable called like stopped equals
97:56 - false and then I can write a function
97:58 - called stop where I say this stop
98:01 - stopped equals true and then what I can
98:05 - do is like I don't want to continue
98:08 - updating it as long as it's not stopped
98:11 - I can just freeze its history so I still
98:16 - want to draw it where at last was but I
98:19 - can freeze its history so with that we
98:22 - now have here we go
98:25 - there's my photons flying at the black
98:28 - hole space-time starts to bend the
98:32 - photons spin around and someone gets
98:36 - sucked in some curve and there
98:38 - we go wonderful
98:42 - all right so what I've done here is a
98:45 - nice visual demonstration of this
98:48 - particular idea as explained in the
98:51 - veritasium veritasium ferret has
98:54 - explained in the veritasium video but as
98:58 - you know using Newtonian physics and
99:01 - sort of classical mechanics here there's
99:02 - a lot that's not accurate so I would
99:04 - really love to hear from you number one
99:06 - what did I get right what did I get
99:07 - wrong give me your feedback about my
99:09 - kind of journey to try to learn about
99:10 - this stuff and create a diagram that
99:12 - looks somewhat like what was a picture
99:15 - in some of the explanations about how
99:17 - that image was made also make your own
99:20 - version of this think about design think
99:22 - about color think about animation I mean
99:24 - you could certainly do this in 3d and
99:28 - share that with me you can go to the
99:30 - coding train comm link in the video's
99:32 - description to the actual page where you
99:34 - can submit your own version of this the
99:36 - code will be right there as well that
99:38 - you can play with then if you have ideas
99:40 - for how I might apply the formulas that
99:43 - I mentioned in some of these papers here
99:47 - and here which I will also link to make
99:49 - this actually behave more accurately I
99:52 - would love to hear from you about that
99:54 - thank you so much for watching I
99:55 - appreciate your willingness to indulge
99:57 - me with trying to do this for making a
99:59 - lot of mistakes through it sort of
100:01 - figuring out as I go and I really
100:03 - appreciate it thanks so much I'll see
100:04 - you in the soon right they're slowing
100:11 - down when they're going away from the
100:13 - black hole of course of course they are
100:15 - yes and they shouldn't all right
100:17 - so black background yeah a second black
100:25 - hole right that would be cool all right
100:29 - I think I'm done with this right now
100:33 - yes thank you go thank you J store for
100:38 - keeping with me in the chat to get that
100:39 - correct
100:45 - alright are you ready for segment two
100:52 - little bit late here but I think I have
100:54 - a lot of you watching stick with me I'm
100:55 - coming soon
100:56 - to talk to you about neuro evolution
100:58 - tensorflow Jess but before I do that let
101:00 - me just close this out I want to tell
101:02 - you a little bit about brilliant org the
101:04 - sponsor of today's coding Train
101:06 - livestream amazingly so if you like the
101:10 - kind of stuff that I do here and you're
101:12 - looking for some ways to practice the
101:14 - ideas outside even of coding really
101:17 - although they're what I'm going to show
101:18 - you is there are a lot of computer
101:19 - science lessons in their courses and
101:21 - puzzles and daily challenges and
101:23 - discussions you can visit brilliant org
101:26 - and in fact I have been trying it
101:28 - recently and lots of members in our
101:31 - patron slack group have been as a couple
101:33 - have been telling me they've been
101:34 - signing up and really enjoying it as a
101:35 - kind of companion to the stuff that I'm
101:37 - doing here one thing that I want to just
101:39 - point out to you if I go to the website
101:41 - and look at the daily challenges this
101:44 - one right here is a challenge about
101:47 - relativity now my brain hurts a little
101:49 - bit from doing that whole black hole
101:53 - thing so you might need to help me with
101:54 - answering this but let's look at it so
101:56 - by the way relativity we're not talking
101:59 - here about special relativity in terms
102:02 - of things moving at the speed of light
102:04 - but the idea of relativity is as follows
102:07 - you know if you're sitting in a car or
102:10 - on a train that's moving fast and you
102:12 - have a you know a bottle of water and a
102:14 - cup you can pour that water into the cup
102:18 - because you're you're at you're at
102:22 - you're sitting still relative to the
102:25 - speed of the train you and the Train are
102:27 - moving at the same speed the whole idea
102:28 - of relativity is how we observe motion
102:31 - from different perspectives relative to
102:34 - each other so in a way saying something
102:35 - is moving at a certain velocity is it
102:37 - accurate the only way to accurately say
102:39 - that is moving at a certain velocity
102:41 - relative to something else
102:42 - after all we're standing on the earth
102:44 - that's spinning around its axis and the
102:46 - earth is spinning also around the Sun
102:49 - itself so you know there but like I said
102:52 - I'm not a physicist nor do I play one on
102:54 - YouTube if you're interested
102:56 - learning more about physics and not just
102:58 - learning by reading textbooks or
103:01 - watching videos but by practicing
103:02 - through quizzes and puzzles and social
103:04 - engagement you can check out brilliant
103:06 - org you should go by the way if you want
103:08 - to sign up right now go to brilliant org
103:10 - slash coding trained to let them know
103:11 - that you came from here and that that
103:13 - helps me out a bit
103:15 - so here you are so look at this a bouncy
103:18 - rubber ball is sitting on a tee when it
103:20 - get hits by a train moving to the right
103:22 - at speed V after the collision how fast
103:25 - will the ball moved to the right
103:27 - according to an observer standing on the
103:29 - ground well if it's a perfect ly elastic
103:35 - or collision right wouldn't it be just
103:37 - BV I'm gonna get this wrong by the way
103:40 - part of learning is getting it wrong in
103:42 - fact when I get it wrong incorrect it
103:48 - gives me a nice message so let's see - V
103:51 - is the correct answer so why is that the
103:53 - correct answer moving at the same speed
103:55 - as a train to us the train is still and
103:57 - the ball is coming against the train
104:00 - with speed V what happens when it
104:02 - crashes it rebounds to the same speed
104:04 - but the opposite direction going away
104:05 - from the Train by the way yoha pedro
104:08 - Alfonso please get in touch your answers
104:10 - are always at the top your answers are
104:13 - always at the top people in the chat are
104:18 - talking about a typo so I'm not sure
104:20 - what that means but it rebounds at the
104:24 - same speed the opposite reaction going
104:25 - away from the Train in the frame where
104:27 - the train is moving with speed V that
104:29 - means a ball moving away with speed V
104:31 - Plus V the ball speed after is not
104:34 - exactly - V just like the Train would
104:36 - not continue exactly speed V because
104:38 - that would violate the momentum
104:39 - conservation law but with the difference
104:41 - of the masses between the Train and ball
104:42 - so big the practical effect is the one
104:44 - described wonderful thank you for that
104:48 - excellent explanation you can see how
104:51 - how how how I missed carrot i'm thought
104:55 - about that incorrectly but any if you
104:57 - want to learn more about things like
104:58 - relativity and science there's more
105:00 - there for you now what I want to do is
105:02 - highlight something for you and I didn't
105:04 - mention this but if you go to brilliant
105:06 - org slash coding train right now it's
105:08 - going to take you
105:09 - let me just do that from here brilliant
105:13 - org slash coding train it is going to
105:16 - take you to the stacks and queues set of
105:20 - quizzes from the computer science
105:22 - fundamentals course so you know I can
105:25 - just click here and look at all the
105:26 - courses and you can see there's a
105:27 - computer science fundamentals and
105:29 - computer science algorithms which you
105:30 - could fear my recent ones cuz those
105:32 - other ones I've been going through at
105:33 - some point I'm definitely gonna go
105:35 - through this artificial neural networks
105:36 - one and maybe I'll refer to that as I do
105:38 - a lot of videos about that topic as well
105:39 - and so if I click here on stacks we can
105:43 - find this visualization and explanation
105:45 - of a stack so give me a second to erase
105:48 - the whiteboard and I am now going to do
105:51 - a little coding challenge whoops
105:54 - about stacks and then you um those
106:02 - you're going to be able to do those
106:03 - quizzes during when I take a break and I
106:05 - would love to hear from you how it went
106:07 - and if it made sense to you and if you
106:08 - got the answers right that sort of thing
106:09 - okay so there are two there are many
106:18 - data structures and ways to store data
106:20 - and way to sort data and look through
106:23 - data in computer programming and I cover
106:26 - those I sort of weave through them
106:28 - during a lot of the different coding
106:29 - challenges that I do to data structures
106:32 - that are quite common are known as a
106:35 - stack this is also known as first in
106:41 - last out is that how you say it the last
106:47 - thing in is the first thing out know
106:49 - last in first out right I think that's
106:52 - how you say it
106:52 - that's a stack the idea of a stack is
106:54 - I'm piling things so I might pile the
106:57 - letter B then I pile the letter C then I
107:00 - Apolo the letter Z then I pile the
107:02 - letter A that's adding things to the
107:05 - stack they're stacking up so that would
107:07 - be a push operation push is adding
107:11 - something to the stack so if I were say
107:13 - push K right now we would push the
107:17 - letter K on top of the stack the other
107:19 - operation pop is taking something off
107:23 - this
107:23 - Zach if I said pop right now that would
107:26 - take ke remove it and pop it off and I
107:29 - would then have it act in a variable
107:31 - presumably you know some value equals
107:33 - pop so push is pushing a value pop is
107:36 - popping a value this is incredibly
107:38 - useful and by the way because and it's
107:41 - used in a lot of scenarios where you
107:42 - need it
107:42 - you've seen this before you've seen it
107:45 - in p5 you've seen it in processing push
107:47 - matrix pop matrix push style pop style
107:50 - or plane just push and pop that's the
107:52 - way that matrix transformations are
107:54 - stored in a stack because you want to
107:57 - save up you want to build all these
107:59 - different transformations and you want
108:01 - to peel them back backwards and if you
108:02 - want to do that push and pop is
108:03 - incredibly useful a queue is a data
108:07 - structure that would rip is just like a
108:11 - queue waiting in line so you could think
108:14 - of it as like okay there's a little like
108:15 - ticket booth tickets whoever gets in
108:18 - line first is the first one to buy the
108:20 - tickets first-in first-out does that you
108:24 - say I don't I figure what those terms
108:25 - arms one's gonna tell me nobody knows no
108:33 - one has answered me whether its first in
108:34 - first out let me let me let me look that
108:36 - up actually probably explains it here oh
108:38 - yeah there it is look brilliants gonna
108:40 - tell me last in first out
108:44 - LIFO thank you brilliant push last in Oh
108:51 - sir stack last in first out okay Q being
108:55 - the opposite or the inverse whereas the
108:59 - first one in is the first one out
109:00 - because the first person of stand
109:02 - aligned gets the tickets right so of
109:05 - course you know if I were doing this in
109:09 - a coding challenge right now and I
109:10 - needed a stack I would probably just
109:12 - make an array because I can make an
109:14 - array I can add things to the beginning
109:15 - I can add things to the end I can take
109:17 - things off the end there's a lot of
109:19 - arrays can serve as a way of storing
109:22 - data that could be a stack or a queue or
109:23 - or and manipulate it in all sorts of
109:25 - ways but if I want sort of like computer
109:29 - science bare bones way of doing this the
109:31 - most efficient way where I just need
109:33 - exactly a stack and I never need to look
109:35 - at anything but the
109:36 - last thing that went in I would
109:38 - basically use something that looks more
109:39 - like a linked list which is I would have
109:42 - nodes and I would have maybe a stack is
109:47 - the idea of a set of nodes that are
109:50 - connected to each other and if I always
109:52 - add to the beginning and pull off of the
109:54 - beginning for push and pop then there we
109:58 - go that's my stack
110:00 - let's go implement that in code okay I
110:07 - heard like some noise and the cameras
110:10 - going off
110:10 - all right so okay so I am going to now
110:28 - hold let me make sure I saved my black
110:32 - hole thing and close that let me close
110:34 - all this other stuff and here we are
110:41 - okay
110:48 - all right here we are in the p5 web
110:55 - editor i'm using the p5.js library and
110:57 - i'm going to implement a stack in
110:58 - JavaScript so I'm gonna make a class
111:00 - called stack and I'm also gonna make a
111:03 - class called node and the idea of the
111:06 - stack because it just has I don't know
111:09 - it has a first first element name I
111:11 - don't say this stock first equals null
111:14 - so when you first create a stack data
111:18 - structure you just have basically this
111:19 - idea of a pointer pointing to nothing so
111:24 - when I push to the stack and sorry I do
111:26 - you can't see that it's a stack when I
111:28 - push to the stack I'm going to add the
111:31 - first element there so the idea is that
111:35 - I might have a function in the stack
111:37 - called push with some value and what I'm
111:40 - going to do is I'm going to create a new
111:43 - node with that value and then if this
111:48 - dot first equals null then this dot
111:55 - first equals that node so this is the
111:59 - code so far for putting in for putting
112:06 - in a first node a first sorry putting in
112:13 - this is the code so far for putting the
112:16 - first for pushing an element into the
112:18 - stack when it's empty so in order for
112:21 - that to work I need to now have a node
112:23 - class so I'm gonna have a node class
112:26 - it's just a thing that has what does it
112:28 - have it has a value right that's the
112:31 - thing that's being stored in the stack
112:33 - itself this could be an object could be
112:36 - a letter it could be a number maybe I'll
112:38 - just use characters like I did in my
112:39 - diagram over there and then most
112:42 - importantly a node right if I push that
112:46 - first node in here the node has this
112:49 - empty little pointer that's pointing now
112:52 - also to null because I need to just keep
112:54 - having these things point to each other
112:56 - so what I would then do is I would say
113:00 - so then I would say this dot next I can
113:02 - call it next like where it's pointing to
113:04 - is no so this would work to push
113:14 - something in so I should be able to say
113:18 - let's get rid of the draw I don't need
113:20 - the draw loop here right now at least
113:22 - let's stack equal a new stack stack dot
113:29 - push the letter A so let's push the
113:32 - letter A now what if I were to say stack
113:36 - dot push the letter B and the fact that
113:40 - these are in alphabetical order is
113:41 - irrelevant
113:42 - I should probably pick letters that
113:43 - aren't which I will do right now just to
113:45 - make it let's go there's no lot it
113:47 - doesn't matter what the letters are
113:48 - they're not it's not going to be in
113:50 - sorted order alphabetically or
113:52 - numerically the whole point of the order
113:53 - is it's the order that I'm putting
113:54 - things in so if I now push the next one
113:57 - in what do I need to do well you would
114:03 - kind of think like Oh put it here right
114:06 - because that's the empty spot but
114:08 - actually I don't want to do that because
114:10 - I want to keep a pointer if I'm gonna
114:13 - pop I always want to get the latest one
114:14 - off so actually what I'm going to do
114:16 - where's my eraser and I'm gonna fix
114:20 - first I'm gonna fix the fact so that you
114:21 - can see the word stack here cuz stack is
114:24 - actually this is actually first that's
114:27 - where this this first is pointing to
114:29 - this which has the value M in it right
114:35 - so first has the value M in it and it's
114:38 - pointing to no so now I want to push B
114:41 - so what I actually want to do is I want
114:43 - to create a node with B in it I want to
114:48 - have B point to M as its next node and
114:52 - then I want to have first point to it so
114:58 - I basically want to insert it in between
115:01 - first and the latest thing and another
115:03 - thing would come in point to B and then
115:05 - first would point to that so I always
115:07 - have this first pointer to the latest
115:09 - thing so how would I do that let's see
115:14 - so if it's not null then what I want to
115:17 - do is say what did I say n dot next
115:21 - equals equals this dot first right
115:25 - I want a point I want to point the thing
115:28 - that I'm putting in right into what was
115:31 - first and then what do I want to do want
115:33 - to say this dot first equals n there we
115:38 - go that's it so now I have the functions
115:40 - push and I have the func I know I don't
115:44 - but let's make the function pop so now
115:49 - what I'm going to do in pop well I
115:50 - should probably test this to make sure
115:52 - it's working but let's do that just yet
115:56 - well I went on these pop as a way of
115:59 - testing it because if I push things in
116:00 - the right order and pop things in the
116:01 - right order then it should work and I'm
116:03 - gonna use the brilliant quiz to sort of
116:05 - figure that out all right pop what I
116:10 - want to do so oh this is easy I just
116:12 - want to return oh well actually I need
116:15 - to do a couple things
116:16 - what do I want to do I mean I when I pop
116:18 - something I actually get rid of it so
116:21 - popping is the process of oh you can't
116:24 - see this one I've really got off let me
116:26 - maybe make a new diagram for you over
116:33 - here
116:37 - alright I'm making a new diagram to
116:40 - illustrate the push and pop process
116:42 - better so what I have here is I have
116:46 - this when I've create sorry
116:53 - when I first create this stack I have a
116:56 - pointer our variable name called first
116:58 - which is pointing to nothing then if I
117:02 - want to say push some value like M then
117:06 - I want to make a new node called em and
117:09 - I want first to point to it
117:12 - then if I'm gonna say push B and push
117:17 - you know X then what I would do when I
117:20 - push B is I make a new node called B
117:23 - point that to em and then first I change
117:29 - first to pointing to B then when I push
117:33 - X I make a new node called X I point it
117:36 - to be because I have that and then I
117:38 - have first point over here so what do I
117:42 - want to do if I want to pop if I want to
117:45 - pop what I want to do is just take the
117:49 - value X right take the value X return it
117:53 - return basically first value and then
117:58 - what I want to do but I'm gonna have to
118:00 - do this in a different order
118:01 - because I can't once I return I'm out of
118:03 - the function but this is the idea I want
118:04 - to grab this value and then I want first
118:07 - to point to first dot next right because
118:11 - once this is popped up then this pointer
118:14 - is what first points to and this is gone
118:18 - now if I were in some programming
118:20 - language where I had to do memory
118:21 - management
118:21 - I'd have to release the memory for this
118:23 - but I'm in JavaScript it's fine it'll be
118:27 - garbage collected okay so let's try
118:30 - doing pop so I want the value to be
118:34 - first dot and what is it in the node
118:37 - value then I want first dot first to
118:42 - equal sorry this dot first and then I
118:47 - want this dot first
118:50 - first is null to equal this dot first
118:55 - dot next I think that's right so first
118:59 - get the value then point it to the next
119:01 - one and then return that value okay so
119:07 - there we go so now if I were to do this
119:09 - M be X and then I'm going to say
119:17 - console.log stacked up pop we are now
119:24 - going to find out if I did this
119:26 - correctly if my code is correct mbx pop
119:33 - off X pop off be pop off M so I'm just
119:45 - looking at the chat for a second it's
119:46 - kind of interesting what people are
119:47 - saying so it looks like things are
119:49 - working correctly now let's make our
119:53 - test a little bit more sophisticated to
119:56 - see if it really is working correctly so
119:58 - I'm going to go back to this this quiz
120:02 - on stacks and I'm gonna I'm gonna
120:04 - there's some wonderful explanation here
120:06 - that's going through with some nice
120:08 - animations it's basically going through
120:10 - exactly what I just talked about and now
120:13 - we're gonna get to our first question so
120:15 - this is and it's using numbers so this
120:18 - sequence I should be able to implement
120:20 - now with my stack so I'm actually just
120:22 - gonna copy paste this and I'm going to
120:26 - put it into my code like this and what
120:35 - I'm going to do is I'm going to say
120:37 - stack push so I'm gonna add my object
120:41 - name here for all of these and then what
120:44 - I want to do is console I guess what the
120:49 - quiz is asking me to say if I go sorry
120:54 - if I go back here with the quiz is
120:55 - asking me to say is what will the stack
120:57 - look like after the operations are
120:59 - applied so what does the stack look like
121:01 - so I should probably
121:02 - at a function here to call like traverse
121:06 - or examine and what that will do is I
121:09 - will start with cut a while so I'm gonna
121:13 - say let node equal first while note is
121:21 - not equal to null console.log no dot
121:26 - value and then a node equals no dot next
121:31 - so this is like a loop to loop go from
121:34 - node to node start with the first node
121:37 - spit out its value go to the next one
121:40 - okay so in theory if I say now if I say
121:48 - stack Traverse and I'm not gonna do it
121:51 - you I'm gonna comment it out I'm gonna
121:54 - comment this out and I'm gonna run it so
121:57 - I don't get any errors Oh pop was called
121:59 - without a matching push oh I must have
122:02 - an error fascinating all right this is
122:06 - interesting I mean this can happen oh no
122:12 - no no no I forgot oh I have a big big
122:14 - problem here so pop this is one of the
122:16 - one of the flaws sometimes I'm working
122:18 - with p5 is that p5 is a beginner
122:20 - friendly environment where there's lots
122:22 - of stuff in the global namespace so this
122:24 - has to be stack pop of course so I'm
122:27 - glad I test that and stack top because
122:29 - there is actually a function called pop
122:30 - it's popping off the transformation
122:32 - state the styles that kind of thing but
122:34 - that's not what I'm doing here so you
122:36 - know I don't there's nothing about this
122:37 - that I need p5 for although I could
122:39 - visualize diagram the stock ok stack
122:41 - alright so no more errors so that's good
122:43 - let's look at the quiz so let's try to
122:45 - answer this you think about this for
122:47 - yourself for a moment I'm going to go
122:51 - over to the whiteboard and I'm gonna
122:54 - figure out the answer myself so you
122:56 - hopefully you have the quiz up maybe on
122:58 - a different screen so you can see so
123:02 - that it's pushed 7 so push I'll just
123:06 - write it here
123:06 - push 7 push 8 pop
123:14 - push I guess I don't need to write it
123:17 - out but why not pop times three and push
123:24 - 40 and then push pop / - okay let's do
123:32 - this quiz so here's my stack first thing
123:36 - I'm doing is push seven then I'm gonna
123:38 - push eight so you could probably do this
123:42 - in your head but I'm gonna diagram it
123:43 - out I always find that to be helpful
123:45 - then I'm gonna pop so I pop off eight
123:48 - then I'm gonna push pot way I'm gonna
123:51 - pop 7 x 3 what's gone and push that back
123:56 - on 7 x 3 21
123:58 - then I'm going to push 40 so I push 40
124:02 - then on a push and then pop that off
124:05 - divide it but / - egg at 20 and push it
124:07 - back then I have this so this should be
124:10 - the state of the stack 21 20 in my other
124:16 - way of looking at it it would be this
124:18 - with this being first so let's look at
124:24 - the quiz let's see if I can get it right
124:26 - this time
124:31 - 21 20 hit submit hey yeah I got this
124:35 - correct okay I got it correct now the
124:39 - question is will my code get it correct
124:41 - so now if I add this stack dot reverse
124:45 - ah first is not to find its line 38 that
124:52 - must be down here I always have this
124:57 - trouble this dot first okay there we go
125:00 - let's try this again 20 21 now is that
125:04 - right as the order right so I think it
125:07 - is right but just to because of the way
125:10 - I'm traversing it but let's say right oh
125:12 - yeah it is because 20 is what would pop
125:16 - off first so if I console.log stack top
125:19 - hop and console.log stack pop 20 21 20
125:26 - 20
125:26 - okay so that is the correct order so now
125:29 - you have seen me implement a stack I
125:31 - will leave it to you as a challenge to
125:34 - maybe visualize and animate this so what
125:36 - if you're adding things to the stack and
125:39 - you're actually seeing them pile up you
125:42 - can use p5 canvas to draw them when
125:44 - you're popping things you see them pop
125:45 - off there could be a nice way to make an
125:48 - animated version of this but you can
125:49 - also now if you're I would be curious
125:52 - here I'm gonna take a five-minute break
125:53 - please go to brilliant org slash coding
125:57 - train that will take you directly to
125:59 - this quiz page while I'm taking a short
126:01 - break if you wouldn't you can go through
126:04 - and try to answer some of these quizzes
126:05 - questions I mean go through the stacks
126:07 - then you could go through the queues and
126:09 - when I come back after I'm gonna get
126:10 - some water wash my hands which are full
126:13 - of whiteboard marker stuff I'm gonna
126:15 - come back and oh yeah sorry
126:21 - this is very absurd before I got that
126:23 - this is what's wrong everything was
126:28 - right this is right the rat was right
126:30 - this 21st points here sorry this is very
126:34 - important that's wrong come back and I
126:39 - will be here I'm gonna talk I'm gonna
126:42 - spend a little bit of time talking about
126:44 - neuro evolution in tensorflow yes so
126:46 - thank you so much for believing torque
126:48 - to the sponsorship if you have a minute
126:50 - today to sign up for free at brilliant
126:52 - org slash coding train also the first
126:54 - 200 people to us to sign up for the
126:57 - Premium Subscription which unlocks all
127:00 - of the courses on brilliant will get 20%
127:02 - off from that link so thanks very much I
127:04 - will be back in just a short bit and
127:07 - enjoy your stacks excuse quiz let me
127:09 - know how it goes and I look forward to
127:12 - hearing about it
127:15 - [Music]
128:39 - [Applause]
128:40 - [Music]
128:57 - [Applause]
128:59 - [Music]
129:23 - [Applause]
129:25 - [Music]
129:33 - [Applause]
129:38 - [Music]
131:46 - [Applause]
131:48 - [Music]
132:42 - [Music]
133:25 - [Music]
134:36 - [Music]
134:54 - [Music]
135:09 - [Music]
135:22 - [Music]
135:27 - I'm gonna do this this star this star
135:30 - this star this star song never forget
135:32 - the best are unicorns and rainbows and
135:36 - kicks what else is there
135:39 - yes kids thank you very much
135:42 - kittens and rainbows and cupcakes notice
135:44 - that look what I get
135:46 - really losing my mind okay let's
135:51 - [Music]
136:05 - [Music]
136:53 - [Music]
137:04 - I feel just sort of like a nice feeling
137:07 - of relaxation everything's gonna be okay
137:10 - today dream is not broken it does not
137:12 - frozen this isn't this is a wonderful
137:14 - thing okay we're gonna do it I'm really
137:17 - getting something I need my sound
137:23 - [Music]
137:28 - [Applause]
137:29 - [Music]
137:30 - okay what else is there unique chords
137:35 - and keys that was a valid syntax I
137:41 - forgotten there's one other thing here
137:44 - that
137:45 - I will use meet English Lee over and
137:48 - over again all sorts of text generation
137:51 - analysis things that I will use
137:54 - continuously over and over again first
137:57 - you need to do
137:58 - [Music]
138:03 - we're gonna do
138:04 - [Music]
138:11 - I'm getting skinny
138:13 - [Music]
138:23 - hello I'm back I don't know if you've
138:27 - heard that particular remix of unicorn
138:30 - what's called kittens I know what it's
138:31 - called there's a there's a whole
138:33 - playlist on Soundcloud encoding train
138:35 - remixes there's one it's it's one
138:38 - actually that I don't know that I have
138:41 - over here that I really love I need to
138:43 - kind of redo my sound board if you're
138:45 - like making those kind of remixes they
138:47 - pretty much happiness enjoy I love to
138:50 - play them listen to them I even want to
138:52 - like learn them on the ukulele then
138:54 - there are these weird like MIDI
138:56 - instrumental versions of them so that
138:58 - said so uh Simon was just telling me in
139:00 - the chat that if you keep going I'm
139:03 - gonna screw up to this message that
139:07 - there's a fun that there's op if you
139:09 - keep going with this quiz there's other
139:11 - operations on stacks that it asks about
139:14 - and if they're really fun to do so I
139:16 - hope that you have a chance to check out
139:18 - brilliant and practice some of these
139:20 - concepts that I'm doing in my videos on
139:23 - their website as well thank you so much
139:25 - - brilliant org for the opportunity and
139:27 - sponsorship of the coding train if you
139:30 - have any questions or run into any
139:31 - issues you can post them there you can
139:32 - send me a message leave a comment in the
139:35 - video and I'd love to try to help you
139:37 - out alright so the next thing that I
139:39 - want to do here is talk about neuro
139:44 - evolution and talk about neuro evolution
139:47 - with talk about neuro evolution with
139:52 - ten's flo-jo sorry my brain is starting
139:54 - to shut off and I've got about a little
139:57 - about a half an hour or so to do this so
139:59 - I have an idea of how I'm gonna work on
140:00 - this first let me just do this stack j/s
140:05 - example so I'm saving this and I will
140:08 - put a link to this stack code in the
140:11 - video's description if somebody who is a
140:13 - mod right now in the chat wants to sort
140:16 - of post a link to that this sketch URL
140:19 - then you can access it right now okay so
140:25 - let me get these cameras but you think
140:28 - then I took my five or ten minute break
140:29 - that I would
140:32 - remember to cycle the cameras but hard
140:36 - oh yeah and peak so people talk about
140:38 - that peak so peak is the peak function
140:41 - instead of pop and push is an additional
140:43 - function in a stack data structure so I
140:47 - would say try implementing that I didn't
140:49 - implement peak you could implement it
140:50 - and let me know how that goes and you're
140:52 - gonna need to implement it if you want
140:53 - to answer the rest of the questions on
140:56 - brilliant through your code example okay
141:02 - so I'm over here for a second to erase
141:05 - this and so let's see so I'm erasing a
141:24 - whiteboard in case I need it I'm closing
141:26 - this out and what I'm going to do is I'm
141:30 - gonna go to the coding train calm and go
141:32 - to coding challenges I'm gonna look for
141:34 - by the way if you missed last week's
141:37 - live stream rubik's cube part three will
141:40 - be coming out tomorrow I have two we
141:43 - match you and I've been sort of like
141:44 - editing it together it's as if the
141:46 - content is already online in the live
141:48 - stream but the part three edited down to
141:51 - about twenty five minutes which has the
141:53 - animated turns I haven't tried applying
141:55 - a genetic algorithm for a neural network
141:56 - you know some for machine learning way
141:58 - to solve it that I've I thought I would
142:00 - take a break from the Rubik's Cube today
142:01 - but I will try to come back to that okay
142:05 - so I'm looking for neuro evolution
142:09 - flappy bird part five so improve saving
142:15 - and loading brain model let's see let's
142:19 - go to here let's look at the download
142:23 - the code don't remember which example
142:25 - I'm getting right now so let me grab the
142:28 - code for this this is not the GA one so
142:37 - I actually need to go back just fine
142:39 - let's go back to part four maybe
142:43 - and then do download the code and let's
142:51 - see if it's this one yes this is it so
142:55 - I'm gonna I'm gonna change this to
142:59 - fleckner Oh flappy tfj s-sure
143:07 - and then I'm gonna put this on the
143:08 - desktop so if you want to follow along
143:11 - I'm starting from the code base from
143:15 - this particular video and so oops I'm on
143:26 - the desktop here it is and then what I
143:28 - want to do is open up I term and go to
143:36 - the desktop and go to this say and open
143:40 - this up in Visual Studio code let's just
143:45 - go here great
143:47 - okay let me just let me do that to all
143:55 - of these
144:03 - and oh I actually have the save
144:07 - functionality built into it interesting
144:10 - okay so that I might need to take up I'm
144:12 - gonna leave everything as it is okay
144:14 - then I need to run a server and get the
144:25 - console going here and then I need what
144:35 - else do I need this this this gonna go
144:39 - away then I need a tensor flow chess and
144:48 - [Music]
144:53 - we're just like the QuickStart see
144:57 - tutorials see the guys see demos get
145:01 - started get set up there's what I'm
145:05 - looking for great actually the newest
145:06 - version i think is 1.0 0.4 so i'll do
145:11 - this okay
145:18 - and let's just also go to because what I
145:24 - would like to do here let's do this and
145:29 - speed this up a little bit okay that's a
145:34 - little bit too much okay so I'm ready to
145:41 - begin let me just make sure the code is
145:45 - visible yep
145:47 - that's fine to turn this off and I'm
145:52 - ready so in a way this could be so this
145:57 - could be a new coding challenge it could
145:59 - just be like a supplemental video as
146:02 - part of minor Aleutian series it could
146:06 - be part six of the earlier coding
146:13 - challenge yeah maybe I'll just do that
146:16 - it's sort of weird but maybe it makes
146:18 - sense to make this like part six I'm not
146:25 - sure
146:30 - tricky I don't know what to do but we
146:36 - can always fix that later all right let
146:38 - me cycle the cameras and we're gonna get
146:39 - started this probably is gonna take more
146:43 - than a half an hour but let's see okay
146:58 - Oh
147:16 - okay
147:24 - Simon is pointing out that again he's
147:27 - reminded been reminding me about this
147:28 - and it is true that Cody challenged 144
147:31 - in base 12 is actually 1 0-0 so since I
147:36 - didn't celebrate coding challenge 100 I
147:38 - could celebrate 144 and I could do
147:41 - something about base 12 but I just
147:43 - couldn't come up with an idea so I think
147:45 - that one the black hole to me is special
147:48 - so in a way that will be coding
147:50 - challenge 144 and we'll be celebrating
147:52 - in base 12100 ok all right let me just
148:12 - check one thing on the channel torch
148:15 - during hue all let me just check this
148:21 - like neural evolution like am I making
148:27 - well
148:28 - doesn't really matter it's gonna go in
148:30 - this playlist but c'est la vie okay
148:42 - all right I probably should find this
148:46 - probably a version of this that has the
148:47 - nice design in it but that's okay okay I
148:58 - think I won't say coding challenge
149:02 - because I will oh hello grave and edible
149:07 - thank you so much for your for your
149:11 - donation you're superdad it's really
149:13 - kind of you I certainly appreciate it
149:16 - okay alright hello welcome to another
149:32 - coding train video about neuro evolution
149:36 - the process of evolving an optimal
149:39 - neural network for some type of scenario
149:41 - like playing the game flappy bird or
149:44 - kind of crude version of the game flappy
149:45 - bird for hello and welcome to another
149:53 - coding training video about neuro
149:54 - evolution which it's a term that
149:57 - describes and that the sort of
149:58 - scientific term for this are neat neuro
150:00 - evolved them I never mind about the neat
150:03 - thing they've been up mul hello and
150:10 - welcome to another coding train video
150:12 - about neuro evolution so this video what
150:16 - I'm going to do is I'm gonna take my
150:18 - previous finished sort of finished
150:21 - version of neuro evolution the process
150:23 - of evolving an optimal the optimal
150:25 - weights of a neural network to solve
150:27 - some kind of perform some kind of
150:28 - machine learning tasks in this case I'm
150:30 - making a guess based on the environment
150:33 - of this very crude flappy bird game I'm
150:35 - not making this the neural network is
150:37 - making a guess whether it should jump or
150:38 - not and so this is a very simple
150:40 - actually scenario to solve and so it's a
150:43 - nice demonstration the idea I've been
150:45 - meeting to return to this topic for
150:47 - quite a while so I can try to look at
150:48 - some more complex scenarios so neuro
150:51 - volution is can be applied to a lot of
150:53 - problems at different reinforcement
150:54 - learning
150:55 - algorithms are also applied to but it's
150:56 - a pretty different technique and so if
150:58 - you if you there's like five or six or
151:00 - seven videos all about neural evolution
151:02 - that I would recommend you check out or
151:04 - you can start right here because what
151:06 - I'm gonna do in this video is I am going
151:09 - to take the existing version that I made
151:11 - which used a toy neural network
151:14 - JavaScript library that I implemented it
151:16 - yet another video series to kind of
151:18 - learn more about neural networks and
151:20 - spin up a very very basic one in
151:22 - JavaScript with out other dependencies
151:24 - but I'm gonna replace that now with
151:27 - tensorflow j/s and I think this is
151:29 - better because I will be able to build
151:31 - better more robust projects without
151:34 - having to be responsible for the sort of
151:36 - underlying machine learning framework I
151:38 - can rely on tensorflow J s to give me
151:41 - all of the sort of possible
151:43 - configurations of neural network that I
151:45 - can then use in my own system in my own
151:47 - evolutionary system yeah I should say
151:51 - what was I gonna say there's something
151:53 - that I just thought of a second ago
152:04 - there was something important oh thank
152:06 - you - there's a new member it's gonna
152:09 - come back to me what I was saying
152:10 - Nats team thank you so much if you sign
152:13 - up to be a new member and you're looking
152:15 - for your invitation to our members slack
152:18 - channel go back to the community tab
152:20 - this is all a message just from hats by
152:22 - the way going to the channels community
152:26 - tab and there's some posts there that
152:27 - are members only that will explain ok
152:30 - wait
152:31 - yeah the collision detection is not
152:33 - pixel-perfect wait I was saying
152:34 - something I don't know remember the
152:43 - worst thing I was gonna say hi that's
152:44 - fine cut okay mmm I just have to keep
152:51 - going so what you're seeing here is the
152:57 - last example from part 5 where I saved a
153:01 - trained model and I'm loading it into a
153:05 - version of the game and watching it play
153:06 - out what I did previous to that is what
153:10 - you're seeing right here which is this
153:11 - is launching 500 random neural networks
153:16 - to try to make guesses I can use this
153:19 - slider to sort of speed up the system
153:20 - and over time those neural networks are
153:23 - going to perform the processes of
153:26 - crossover and mutation it's not actually
153:29 - doing crossover it's been crossover
153:31 - which would be the act of combining
153:33 - two agents genetic material together
153:36 - into one I'm just taking one and copying
153:38 - it but then I am mutating it to
153:41 - optimally search for the configuration
153:44 - of weights that will work the best and
153:46 - just to remind you what is what am I
153:49 - talking about the weights just to remind
153:56 - you of when I'm talking about the
153:57 - weights this is what I'm talking about
153:59 - so we have the flappy bird game this is
154:04 - the agent that needs to make a decision
154:05 - in a way it's a classification problem
154:07 - should I go up or should I not go up
154:11 - right these are the only two
154:12 - possibilities a very simple
154:13 - classification problem two categories I
154:15 - have done I
154:17 - the human being have basically done the
154:19 - feature extraction I could use the
154:21 - environment the input to their neural
154:22 - network as this image like all the
154:25 - pixels of the game that would be a
154:26 - wonderful thing to try and I would love
154:28 - to do that especially once I have
154:29 - convolutional layers with tensorflow j/s
154:31 - which is not something I have in my coin
154:33 - neural network library you might not
154:34 - know what a convolutional layer is don't
154:36 - worry if I use it I will explain it but
154:39 - I have done that feature extraction so I
154:41 - have decided that the core the features
154:44 - that I want to use as inputs into my
154:46 - neural network are I think it was like
154:48 - the bird Y position the bird like Y
154:52 - velocity the top pipe location the
154:58 - bottom pipe location and then I'll call
155:03 - this like X the distance to the nearest
155:05 - pipe so these are what I've decided
155:07 - might be are the important values to use
155:11 - from this game to feed into the neural
155:13 - network so that means the neural network
155:14 - has one two three four five inputs these
155:18 - all get normalized into a value with a
155:21 - range between 0 and 1 and fed into the
155:23 - neural network then the outputs is a
155:26 - classification problem so there are just
155:28 - two outputs and they would each output a
155:31 - number if I got something like 0.8 here
155:33 - and point to here that means there's an
155:35 - 80% basically 80% probability confidence
155:38 - score that I should jump so I will jump
155:40 - now I could actually pick random numbers
155:42 - and that kind of thing but I'm just
155:44 - going to take the highest one the Arg
155:45 - max so to speak and go
155:47 - so neural networks are able to learn a
155:52 - sophisticated amount of information
155:55 - through hidden layers so the inputs
155:58 - don't pass directly to the outputs but
156:00 - the inputs pass through a hidden layer
156:01 - and I don't recall what what I picked is
156:04 - the configuration of the hidden layer
156:05 - but I think was something like 8 so if
156:08 - there were eight I think that's what it
156:09 - is well look 1 2 3 4 5 6 7 8
156:13 - these are what are known as dense layers
156:15 - meaning every single node is connected
156:18 - to every node I will not sit here and
156:21 - draw all of them but I will start that
156:23 - process and then all of these sorry are
156:26 - connected to the outputs like this so a
156:31 - Network's core data the configuration of
156:34 - that data is in a matrix because every
156:36 - one of these connections has a weight so
156:38 - if they're five here and eight here that
156:41 - is 40 weights if there are eight here
156:44 - and two here that's sixteen weights now
156:47 - the truth of the matter is there's also
156:49 - a bias so there's a bias for each one of
156:51 - these and a bias for each one these so
156:52 - there's the configuration is all of the
156:54 - weights all of the biases for each of
156:56 - these nodes but this is that these are
156:59 - the details that I cover a lot more in
157:01 - this series about building a neural
157:03 - network from scratch in JavaScript so if
157:04 - you want to learn about that you can go
157:06 - back what all you need to know for here
157:08 - is that I have a way of creating this
157:10 - neural network I have a way of feeding
157:12 - these values into it and looking at the
157:14 - stuff that comes out so let's go look at
157:16 - that code so if I go look at the code we
157:19 - can see that here there's this idea of a
157:21 - bird object and the bird object makes a
157:24 - neural network with five inputs eight
157:27 - hidden nodes and two outputs this is I
157:30 - don't know what I've said here but this
157:31 - is known as a feed-forward neural
157:33 - network multi-layered perceptron it's
157:35 - two layers the inputs it looks like a
157:37 - layer but these are just numbers coming
157:39 - in there's a hidden layer and output
157:40 - layer that's an important terminology so
157:43 - that's happening here and you can see in
157:45 - the bird the bird sort of like takes all
157:49 - of those properties its Y position the
157:51 - closest pipe the closest pipes x
157:53 - position its velocity makes that into an
157:56 - array feeds that into a predict function
157:58 - and then I just sort of like if the
158:00 - first output is greater than the second
158:02 - output jump so this is that process and
158:05 - all of this happens in o in this neural
158:12 - network library so there's neural
158:14 - network jf and matrix such as this is
158:16 - like if tensorflow J s was made by one
158:19 - person who really didn't know what they
158:21 - were doing that's what's in here so what
158:24 - I want to do is I am going to delete
158:28 - this folder right I'm just gonna I'm
158:30 - deleting it it's gone gone move the
158:33 - trash boom so now when I go over here
158:35 - and I hit refresh of course it doesn't
158:37 - work because we have no neural network J
158:40 - s can I get this you know I don't have a
158:43 - watch fun no ever long I have
158:45 - right now in the course of this video
158:46 - working again without my library both
158:48 - tension flow Jes instead that's the
158:50 - thought experiment here so in order to
158:53 - do this actually though ironically I
158:55 - think what I want to do a couple things
158:56 - I need to do whoa what's this ridiculous
158:59 - looking HTML file that I have sorry
159:02 - everybody hold on a sec let me just
159:08 - clean this up a little bit this can come
159:10 - out there we go that's better and just
159:20 - do this so the header should have all
159:27 - these script tags whoops yeah stop
159:35 - should have the p5 libraries this should
159:40 - be neuro evolution with tfj s recent p5
159:46 - is 8.0 and this this would be in the
160:03 - body
160:11 - shouldn't have like bird there also I
160:15 - must have lost that by accident
160:17 - bird and pipe too right bird type
160:34 - okay
160:41 - same thing so here's my HTML file and
160:45 - you can see that it has the p5 libraries
160:48 - it's loading my neural network library
160:50 - and then these are all the files for the
160:52 - flappy bird game itself as well as a
160:53 - file that includes some information
160:55 - about how the genetic algorithm works so
160:57 - what I want to do I need to take these
160:58 - out and then I want to import tensorflow
161:02 - chess
161:03 - so I have the attention flow days
161:04 - website up and this is the script tag
161:07 - for importing tensorflow j/s so I'm
161:10 - going to add that here and actually I'm
161:13 - pretty sure that the most current
161:14 - version is 1.0 0.4 so let's add that and
161:19 - now I'm going to go back here and hit
161:22 - refresh now of course ah neural network
161:24 - is not defined so we've got fewer error
161:25 - messages here now which is good I just
161:27 - want to make sure TF is loaded so like
161:29 - for example I can call TF memory and
161:31 - there's no memory being used but I could
161:34 - see that TF is DF TF chest is loaded
161:36 - because I can call TF functions in the
161:38 - console now which I'm going to need to
161:39 - do to figure all this out all right so
161:42 - now that now I think the thing that I
161:44 - want to do is actually I don't need to
161:46 - do this but I think it would be nice for
161:48 - me to create I'm going to create a file
161:50 - called neuro nnj s and I'm gonna make a
161:55 - little wrapper for a neural network and
161:57 - actually one of the reasons why I want
161:59 - to do this whoops sorry sometimes things
162:08 - go haywire one of the reasons why I want
162:11 - to do this is as you know I've made a
162:13 - lot of videos using a library called ml
162:15 - 5 which is a wrapper around tensorflow
162:18 - chest which allows you to work with some
162:20 - of the machine learning algorithms
162:21 - without having to manipulate the lower
162:23 - level details of tensorflow J s and so
162:26 - this is kind of a little bit of maybe a
162:28 - preview of that because this ultimately
162:29 - this idea of neuro evolution is
162:31 - something that I would like to work on
162:32 - putting into the ml 5 library so if I
162:35 - make a neural network class and I write
162:37 - a constructor we know here that in the
162:42 - bird object what it's doing is it's
162:44 - making a neural network with five inputs
162:46 - eight hidden nodes and two outputs so
162:49 - there's no reason why I can't actually
162:51 - just do keep that same structure
162:54 - and I'm gonna have three arguments I'm
162:56 - just gonna call them a B and C because
162:58 - at some point I might need to call the
162:59 - constructor in different ways and I'm
163:01 - gonna then say this dot input notes
163:07 - equals a this dot hidden nodes equals B
163:13 - and this dot output nodes equals C then
163:18 - I'm gonna put I already need by the way
163:20 - I did this in a class that I'm teaching
163:22 - so uh last week so I kind of have quite
163:25 - a bit of a sense of the plan here so I'm
163:27 - also going to write a function called
163:29 - this dot create model because I might
163:32 - need to do that in different places and
163:34 - then I'm going to make a separate
163:36 - function called create model so this now
163:38 - is the function where I want to create
163:41 - my neural network using tension flow jjs
163:45 - and I'm going to use the layers API the
163:47 - truth of the matter is this particular
163:50 - architecture right this is perhaps one
163:53 - of the simplest most basic vanilla so to
163:56 - speak neural network architectures it's
163:58 - got two layers one hidden layer very few
164:01 - nodes
164:02 - there's no convolutions no fancy stuff
164:04 - just the very basics so I could probably
164:06 - do this with just simple tensor flow
164:09 - operations itself but I'm going to use
164:12 - something called TF dot layers which is
164:14 - actually based on Keros which is a
164:17 - Python library for tensor flow and
164:19 - python so many things I've talked about
164:21 - these in videos but basically tensor T F
164:23 - dot layers is an API that allows me to
164:25 - create a model from a slightly higher
164:27 - level perspective so one of the key
164:30 - functions in tftf layers and I'm going
164:34 - to create a variable called model is TF
164:37 - dot sequential so if I say TF dots
164:39 - sequential that should create for me a
164:42 - sequential model and we can just take a
164:46 - look at that here in the console and see
164:49 - there we go it made something that works
164:52 - you can see there's all these parameters
164:53 - as a training now interestingly enough
164:55 - what I'm doing in this video it's not
164:57 - really what tension flow jess is
164:58 - designed for almost everything in
165:00 - tension flow jess has to do with
165:02 - optimization functions and algorithms
165:05 - for learning and tweaking weight
165:07 - you know that propagation I'm not doing
165:09 - any of that this neural evolution thing
165:11 - is quirky and weird all I actually need
165:13 - is a bunch of neural networks and the
165:14 - ability to feed data through them and
165:16 - then I can just delete an ad and mix
165:18 - them up so actually most of this stuff
165:20 - will not get used but what I want to
165:22 - create then is my first layer so the
165:24 - first layer I'm gonna call hidden so I'm
165:28 - gonna say let our Const hidden equals TF
165:33 - I think it's dense so I think I better
165:36 - look up the documentation at this point
165:37 - I certainly don't have this stuff
165:38 - memorized so I'm gonna go to the API and
165:42 - I'm gonna go oh boy I'm there's many
165:45 - many more revisions since I think point
165:48 - zero four but I'm gonna go here and I'm
165:51 - gonna look for dents so I want TF layers
165:56 - oh I mean tensorflow org ah wrong API
165:59 - I want the tension flow jsap I clicked
166:03 - on the wrong place that's those were
166:06 - there version numbers for the current
166:07 - tension flow depth entry flow Jas so I
166:09 - want to go to dense TF layers dense so
166:12 - this is what I'm looking to do and I can
166:14 - see a nice little example of it here
166:17 - this so I'm gonna create a TF layers
166:21 - dets
166:22 - TF oh sorry dot layers dense and then I
166:27 - need a little object which is going to
166:31 - contain all of the configuration
166:33 - information for that dense layer and
166:35 - what are some things I can configure I
166:38 - can give it the number of units
166:40 - that's my hidden nodes which is the
166:45 - hidden nodes I also want to tell it how
166:49 - many things are coming in like what is
166:51 - the input shape so this is the layer I
166:53 - need to tell it about the input shape I
166:55 - forget what that's called somewhere in
166:59 - here alpha input dim would be the input
167:01 - dimensions I guess which would be input
167:05 - Vista input nodes I'm forgetting my this
167:07 - dots as always as always I always forget
167:10 - so there we go what else do I need I
167:14 - think an activation function I
167:16 - definitely need so activation
167:20 - activation now this merits quite a bit
167:23 - of discussion an activation function is
167:26 - is how the data gets processed as it's
167:29 - fed forward so all of these inputs the
167:32 - numbers that are these values come in
167:33 - here they get multiplied by those weight
167:36 - values sum together and pass through an
167:38 - activation function the activation
167:40 - functions job is basically to squash the
167:42 - values to sort of enforce non-linearity
167:44 - to allow for the stuff to go to the next
167:47 - layer and there are all sorts of reasons
167:49 - why you might pick one or the other
167:50 - there's more recent research and it's
167:51 - change over the years but I've talked
167:53 - about this in other videos I'm gonna
167:55 - pick sigmoid as a kind of default
167:57 - activation function that squashes all
167:59 - values between 0 & 1 I'll include some
168:01 - links about sigmoid in the video's
168:03 - description if you're curious so I
168:05 - forget exactly what I do here but I
168:07 - think I can just write sigmoid as a
168:09 - string and somewhere in the
168:11 - documentation there is a list of all the
168:13 - activation functions do I need anything
168:15 - else I think that's good so then I just
168:18 - want to say this dot model dot add layer
168:20 - maybe so TF sequential is what I'm doing
168:23 - here which would be here and O in put
168:28 - shape is probably what I want not input
168:31 - dimensions we'll see I'm noticing that
168:33 - there's input shape so actually I think
168:35 - that's what I want I mean that's
168:36 - certainly what I used previously so
168:38 - input shape and it would be just that
168:42 - number of nodes but inside an array a
168:44 - shape is a way of defining the
168:47 - dimensionality of data so if it's just a
168:51 - list of stuff like a list of numbers
168:53 - it's an array with five things in it so
168:56 - so that's how I define a shape so then I
169:00 - would say model dot add so this dot
169:03 - model dot add the hidden layer now I
169:07 - want to make an output layer which is
169:11 - going to be TF layers also dense and I
169:16 - want to what do i what do I want the
169:20 - units is this dot output nodes and then
169:28 - I actually do not have to define the
169:31 - input shape for this layer
169:33 - because it can be inferred from the
169:36 - previous one so I couldn't infer the
169:39 - number of inputs because from the hidden
169:40 - cuz hidden is first but the last layer
169:43 - here I these outputs I know that I just
169:46 - added this layer if it's dense this is
169:48 - the shape of the input so all I need to
169:49 - do is that and then I also need an
169:51 - activation function soften and I'm gonna
169:56 - I'm gonna make it soft max so soft max
169:59 - is an activation function which takes
170:01 - which like sigmoid squashes all the
170:04 - values to arrange between 0 and 1 but it
170:06 - does something even more
170:08 - it basically enforces that all those
170:10 - values also add up to 1 it basically
170:13 - turns them into probability or
170:15 - confidence scores and all of them add up
170:17 - to 100% or 1.0 and there's more to it
170:20 - than that it's kind of in terms of how
170:23 - the mathematics of work but that's the
170:24 - basic gist of it and that's what I want
170:25 - I want the probability of whether I
170:27 - should jump or not jump so now I should
170:33 - be able to say this dot model dot add
170:37 - output and then if I go back to the
170:40 - documentation I don't need to do this
170:42 - fit stuff but let's call oh do I need to
170:45 - compile it hmm so interestingly enough
170:48 - usually you need to compile you to give
170:49 - a loss function traditional machine
170:51 - learning you're gonna have a loss
170:53 - function an optimization function you're
170:55 - gonna train it with data doing any of
170:57 - that neural evolution remember if you've
170:58 - watched my other videos on ever
170:59 - evolution I'm doing this weird thing I
171:01 - just need a random neural network that's
171:03 - all I need
171:03 - so I don't know if I need that compile
171:05 - step but I'm guessing I kind of do so
171:07 - I'm gonna say this dot compile but I'm
171:09 - just gonna give it an empty object cuz I
171:11 - don't care about those other things so
171:13 - let's try let's this dot model dot
171:15 - compile so now that I have that I should
171:20 - be able to it with my code I'm Kylee
171:22 - getting a little bit further like look
171:23 - at that cannot read property minimize of
171:26 - undefined because I didn't give it any
171:28 - op today let's get rid of the compile
171:29 - let's you might get this to work without
171:30 - this dot model dot compile maybe compile
171:33 - only has to do with the learning process
171:35 - that I'm not using great this stop brain
171:38 - that predict is not a function so now I
171:39 - have the next thing that I need to
171:40 - implement so where is that that's in
171:43 - bird Jas and what is it saying so I'm
171:46 - able to make
171:47 - the neural network and then I am calling
171:51 - predict and I'm giving it an array
171:54 - perfect so what I need to do now in my
171:57 - class here is I'm gonna write a function
171:59 - called predict which will receive an
172:01 - array now what I would essentially be
172:06 - doing is now calling this dot model dot
172:09 - predict with that array only here's the
172:12 - complexity of using tensorflow j s
172:14 - tensorflow doesn't work with traditional
172:17 - JavaScript arrays it works with
172:19 - something called tensors which are
172:20 - multi-dimensional arrays that they're
172:23 - multi-dimensional things collections of
172:26 - numbers that are living in the GPUs
172:29 - memory that's for optimization purposes
172:32 - the operations can happen faster on the
172:35 - GPU which is optimized for a lot of
172:36 - matrix math I don't really need that
172:38 - optimization to be clear because like
172:40 - I'm working with the tiniest thing here
172:42 - but I still need to convert this stuff
172:44 - to tensor so I'm gonna need to say the X
172:48 - is I'm going to call this the inputs are
172:50 - often referred to as X's equals TF
172:53 - tensor and what do I have what's the
172:57 - shape of my array it's one dimensional
172:59 - right it's just an array but the thing
173:02 - is what tensorflow j s expects so this
173:05 - is like my dina it comes in as an array
173:08 - of numbers 1 2 3 4 5 right all of this
173:11 - stuff 1 2 3 heads only 4 but whatever
173:13 - you get the idea there's another one
173:14 - there
173:14 - the thing is tensorflow des is kind of
173:17 - things like you would never be so crazy
173:19 - is's give me just one thing usually
173:21 - you're gonna give me like a thousand
173:22 - rows or two data samples so it's
173:25 - actually looking for a shape that is
173:28 - like this that would have a bunch of
173:29 - these so it's so I just need to take my
173:32 - inputs and put them in a 2d tensor
173:36 - because it's an array of arrays so if I
173:39 - do that tensor 2d X's I think that's all
173:43 - I need to do then I need to call predict
173:45 - with the X's now that's happening
173:48 - synchronously I need to get the data off
173:52 - of oh and this would be wise sorry the
173:56 - Y's would be the result of feeding it
174:00 - forward so that's you
174:01 - exactly this process predictors the
174:02 - function to feed this stuff forward and
174:04 - now I have the Y's I'm gonna do
174:07 - something which is a little bit
174:08 - ill-advised I want to be able to look at
174:10 - those values so right now the Y's are a
174:13 - tensor and that's living on the GPU in
174:16 - order for me to pull it off the GPU to
174:18 - use it I need to call a function called
174:20 - data which is getting the actual data
174:22 - and that's thing that happens
174:23 - asynchronously so I need to deal with a
174:25 - promise or a callback
174:26 - but I'm because I'm working with it to
174:28 - tiny bits event in data here it's gonna
174:29 - be much simpler for me right now at
174:31 - least to get this working to just say
174:34 - basically the outputs equal wise data
174:39 - sync so the data sync function gives me
174:42 - those outputs
174:43 - let's console.log them and let's say
174:47 - return outputs also just so we see
174:49 - what's going on here
174:50 - so I'm now gonna run this neural network
174:53 - tout predict at bird think is not
174:55 - defined hmm what did I miss
174:57 - predict neural network predict where am
175:03 - i bird line 54 this dot brained I
175:08 - predict hmm what did I miss
175:18 - Oh exes is not defined sorry the air is
175:22 - exes is not defined that's weird
175:24 - neural network jazz 10 array exes oh
175:35 - sorry sorry there's a major error in
175:38 - here that you probably all noticed but I
175:40 - didn't I'm taking that array and
175:42 - converting to a tensor so ARR is the
175:44 - array and maybe it would make sense for
175:46 - me to call these inputs I'm taking the
175:50 - inputs as a raw array converting them
175:52 - into a tensor passing them through the
175:54 - model pulling out the outputs and
175:56 - returning it okay let's see how that
175:57 - goes
175:59 - tensor to D requires shape to be revised
176:01 - when values are flat huh
176:03 - Oh guess what this has to be inside an
176:07 - array right because the whole point is
176:09 - that once the 2d thing so it wants that
176:12 - array inside of an array okay so that it
176:16 - I'm tick-tock
176:21 - so that okay stop
176:27 - so that should fix that right oh look
176:31 - I'm getting stuff I'm getting things why
176:34 - aren't I seeing it oh look how slow it
176:36 - is it's so slow so this is sort of like
176:40 - the weird IRA IRA knee of all of this
177:09 - so this is really the irony here I am
177:12 - doing a ton of operations that are
177:15 - copying and removing data from the GPU I
177:19 - and this I really should be doing all of
177:21 - them at once right there's no reason why
177:23 - I couldn't pass all oh no can't I can't
177:26 - do that I have different models
177:27 - nevermind we just
177:43 - so this is kind of ironic in a sense
177:45 - like I'm using a much more powerful
177:47 - JavaScript engine for deep learning
177:50 - that's optimum that does all the
177:51 - operations on the GPU with WebGL to
177:54 - optimize it and yet it runs super slow
177:56 - this is really because I'm a crazy
177:58 - person and kind of doing this in a weird
178:00 - way that attentional jess is not really
178:02 - designed for weight I'm like have all of
178:04 - these different models and I'm copying
178:06 - the data with data sync so there's a
178:07 - couple things I could do number one is
178:09 - let's just for now and I'm off to come
178:12 - back to this or think about how to make
178:13 - this run faster or be more thoughtful
178:14 - and maybe do this stuff asynchronously
178:16 - but what I'm gonna do right now is I am
178:19 - going to just reduce the number of birds
178:21 - to half and I'm also going to do
178:23 - something a little bit silly which I'm
178:25 - going to inset I'm gonna say TF set
178:27 - back-end CPU because actually the amount
178:30 - of data that I'm working with is so
178:32 - small I don't really need to use the GPU
178:35 - I don't need to copy stuff back and
178:36 - forth let's just use the CPU it's
178:38 - perfectly fast enough remember how well
178:40 - it worked when I had my own silly little
178:42 - JavaScript library so let's use the CPU
178:44 - and I think you'll find that now it's
178:47 - still running like kind of slow I have a
178:48 - feeling this console.log is definitely
178:51 - making things kind of unhappy so let's
178:54 - take out that console log and let's
178:57 - refresh and there we go so now it's
178:59 - performing pretty well is it as fast as
179:01 - it was before I don't know could I get
179:02 - back into 500 but it's better ah but now
179:05 - we have a problem
179:06 - copy so copy is not a function because I
179:09 - didn't write a function to copy a neural
179:11 - network so what do I mean by copy and
179:13 - neural network so normally this isn't
179:15 - something you would necessarily do but
179:17 - it is fundamental to neuro evolution and
179:19 - by copying in I need to say like this
179:20 - was a good one let's make a copy of it
179:23 - to keep it and I actually want to copy
179:26 - it not keep a pointer to it because I
179:28 - also want to mutate it and I want to
179:30 - mutate it a bunch of times so I have to
179:32 - figure out what is the way to copy a
179:35 - model in tensorflow j/s and ultimately
179:38 - if you want to try a more the proper way
179:41 - to do this in terms of neuro evolution
179:42 - would not be to just make a copy to go
179:44 - to the next generation but to take two
179:46 - of them and make a new one that's kind
179:49 - of a mixture and when I say mixture I
179:51 - mean mixture of all these weights but
179:53 - I'm just gonna copy it
179:55 - what I need to do is I need to go back
179:57 - to this class again and I need to say
180:00 - copy so if I say copy I could just say a
180:06 - return new neural network and I could
180:09 - just put like input notes hidden nodes
180:11 - output nodes but it wouldn't have the
180:13 - right weights so let's think about this
180:18 - let's do I'm going to say copy model
180:24 - copy equals this create model so I'm
180:31 - creating a model which is the same I and
180:37 - I need to create model with oh it has
180:41 - that stuff so I can call create model
180:43 - that's going to do it with the right
180:44 - input notes in notes out of the notes
180:45 - okay so it's not a copy yet it's another
180:48 - random neural network but really I the
180:50 - architecture is the same so in a sense
180:52 - I've copied the archetype made a new
180:54 - neural network the same architecture now
180:56 - I need to get those weights so luckily
180:58 - for me there is a in TF guess there are
181:01 - two functions called like get weights
181:03 - and set weights so let's take a look at
181:09 - those functions so for example if I go
181:12 - to the console here and I were to say
181:14 - something like can I say let n equal new
181:19 - neural network was it eight five two
181:22 - right now five to eight five eight to so
181:25 - I'm making one of those and so n dot
181:27 - model is that model itself and you can
181:30 - see it's got all that data in there so
181:33 - what I want to do is say n dot model get
181:36 - weights no oh I said mode I want to say
181:41 - end model can I just click here model
181:44 - get weights these are all the weight
181:46 - matrices why are there four shouldn't
181:48 - there just be two well there's four
181:50 - because there are the weights and the
181:54 - bias these one two the weights and the
181:55 - bias these three four so that that is
182:00 - what is here so all I need to do is take
182:03 - these weights and copy them so let's see
182:06 - so I could say
182:08 - constant weights equals this dot model
182:12 - get weights and then I could say model
182:15 - copy each dot set weights weights and
182:24 - then I could say return new neural
182:28 - network with model copy now there's a
182:31 - bit of a problem here that I think I'm
182:33 - gonna have to do but this is pretty
182:36 - decent start right make a model the same
182:38 - architecture get the weights from the
182:40 - other one then put those weights in the
182:42 - new model and then return it I think
182:43 - there's gonna be a big problem here but
182:45 - this is kind of the idea so now if I
182:48 - were to what I need to do here is now
182:53 - I'm making a neural network without
182:54 - giving it the input nodes I need to
182:57 - basically say if a is an instance of TF
183:03 - sequential is that right let's see so if
183:07 - I go back to the console end model
183:10 - instance instance of TF sequential false
183:16 - no TF sequential with a capital true
183:19 - okay so I need to check if it's TF
183:22 - sequential object then this dot model
183:25 - equals a so in other words I have two
183:28 - ways of creating a neural network if I
183:31 - pass the constructor an existing model
183:33 - then I just assign it otherwise I create
183:38 - a new one
183:39 - however I've really always got to keep
183:41 - track of what it's a little this is some
183:43 - redundancy here because the input nodes
183:45 - hidden nodes and output nodes are in the
183:46 - model itself but let's just add another
183:48 - argument here and then I can say also
183:51 - this is awkward but and I could refactor
183:55 - this later so now I'm also going to
183:58 - always require that I also give it the
184:00 - shape basically and so here when I'm
184:03 - making this new neural network with
184:05 - model copy I'm also going to say this
184:07 - dot what is it input nodes this dot
184:14 - hidden nodes this dot output nodes
184:19 - okay so this is me making that new
184:23 - neural network with the models copy and
184:26 - I'm also just giving it the shape also
184:28 - so that you sort of retains that
184:29 - information so now I should be able to
184:32 - go back and we've got a copy function
184:35 - let's speed this up okay great who
184:39 - cannot read property set weights of
184:41 - undefined that's not good
184:47 - where's the copy this got create model
184:56 - huh all right let's look at
185:05 - uh create model doesn't return the model
185:10 - ah okay I've got a little bit of an
185:14 - issue here ah okay I've sort of made a
185:19 - mistake in the way that I've designed
185:20 - this program what I want to say is this
185:23 - stop model equals this create model and
185:25 - I don't actually want to set it here I'm
185:27 - going to just make in the create model
185:30 - function which is where I'm going to
185:32 - make this a variable Const model and so
185:39 - and then I'm gonna say model dot add
185:43 - model dot add and then I'm gonna say
185:45 - return model so this function this could
185:48 - be living somewhere else or a static
185:50 - function or something but it's making
185:51 - the model and it is in setup I'm sorry
185:56 - in the constructor it is creating it and
186:00 - returning it and placing in an instance
186:01 - variable or here it's creating it and
186:04 - returning it and putting in this copy
186:05 - variable so that should work better so
186:09 - let's see great so now I don't have a
186:12 - mutate function no problem no problem
186:15 - this is a way to deal with that bird
186:18 - digest line 33 bird digest line 33 let's
186:26 - just not bother mutate no worries don't
186:30 - mutate let's speed this up let it run
186:37 - for a bit
186:54 - all right let it run for a bit we can
186:57 - sort of see I did it get better kind of
186:59 - but there's only one they're all making
187:01 - the exact same decisions so without me
187:04 - two things are wrong here
187:05 - number one is without mutation I can't
187:07 - get any variety but there's something
187:10 - else that I'm pretty sure is wrong not a
187:12 - 100% sure but I'm pretty sure is wrong
187:14 - so I want to protect myself against this
187:16 - is I haven't really made a copy so I
187:19 - think in the case of my copy function
187:22 - which is here this is the weights as
187:27 - tensors and I am assigning them to the
187:31 - copy but they're all being assigned the
187:33 - same tensor so even though there are
187:34 - multiple models they're all using the
187:37 - same weight table so if I were to mutate
187:39 - them they're all going to mutate in
187:40 - exactly the same way so I need to really
187:43 - make sure I'm copying them and there is
187:45 - a function in tfj s called clone which
187:47 - is to make a new tensor that is a copy
187:49 - of an existing one so I think what I
187:52 - should do is I should say Const wait
187:55 - copies is a new array and then for let I
188:00 - equals 0 I is less than weights index I
188:04 - I plus plus
188:06 - no sorry weights at length so I'm going
188:08 - to iterate over all the weights and I'm
188:11 - gonna say weight copies index I equals
188:14 - weight index I clone so this is a kind
188:19 - of the idea of like sort of deep copying
188:20 - I guess I'm not sure if I'm 100%
188:21 - accurate about that but the idea of
188:23 - actually copying them into a new tensor
188:25 - so it's not the previous one and then I
188:29 - should be able to set the weights to
188:31 - weight copies so this should be this
188:35 - should guarantee that I really got it
188:37 - copied correctly so let's do that I'll
188:40 - run it again speed it up a little bit so
188:44 - it's still converging kind of into it
188:47 - ultimately being just one of them that
188:49 - the one that happened to do the best but
188:51 - it's not doing that because I haven't
188:52 - properly copied it's doing that because
188:54 - there's no mutation and you can see
188:56 - actually that seems to be taking a
188:57 - little longer to get there so I think
189:00 - maybe that copying is better now okay so
189:03 - I do need that mutate function so what
189:06 - do I need
189:06 - where was mutate
189:08 - so I need a function called mutate and
189:10 - it's getting an argument point one which
189:13 - is presumably the mutation rate so the
189:15 - process of mutation in a genetic
189:17 - algorithm is to say look at the genetic
189:19 - information which is basically like all
189:21 - of these weights and biases and one by
189:24 - one examine them and at some probability
189:27 - make it some adjustment make it random
189:29 - change it mutate it so that's what I
189:31 - need to do so it's actually it's more
189:34 - involved than just making a copy of the
189:36 - weights I need to look at every single
189:38 - weight individually and then mutate it
189:40 - ten percent of the time I'm gonna do
189:43 - this but let's see okay so if I go into
189:49 - neural network and I go into I made a
189:54 - copy function now let's look at sorry
189:57 - let's look at mutate so I want to do the
190:01 - same thing the first thing that I want
190:03 - to do is I want to get the weights what
190:12 - I call this this stock model that get
190:14 - weights then I want to maybe have
190:18 - mutated weights is a new just an array
190:29 - so so I get the current weight tables
190:33 - and then a weight tensors sorry and then
190:36 - I'm gonna go through and make mutated
190:38 - weights so let me once again loop over
190:42 - this array and I'm going to say tensor
190:48 - equals weights index I because it's a
190:50 - tensor and then what I want to do I want
190:54 - to get the values so I'm gonna use Data
190:59 - Sync again I want the shape because I'm
191:03 - gonna need that when I convert it back I
191:05 - think I can just do this so I need the
191:07 - tensor which is the data I'm going to
191:11 - need to retain the shape because I need
191:14 - to put it back into a tensor but I want
191:16 - to mutate them I don't think I can
191:17 - mutate the tensor without looking at the
191:19 - values who knows
191:22 - so now I'm gonna go through and I'm
191:24 - gonna say let a equals 0 J so J equals 0
191:28 - J is less than values dot length J plus
191:34 - plus so the actual weight which I'll
191:38 - call W is values index J and what I want
191:42 - to do is say values index J equals a new
191:44 - random weight so I could do something
191:46 - like this right just give it like I
191:49 - actually even need the current weight I
191:53 - could just make a random one right I'm
191:54 - mutating oh but only 10% of the time so
191:57 - this gets a rate so I could say if
191:59 - random 1 is less than that rate then
192:04 - make a new weight I do think this is a
192:09 - case where I might there might be some
192:10 - benefit to rather than picking a totally
192:12 - new weight and I don't know what
192:14 - initialization was used to make the
192:16 - initial random weights that's probably
192:17 - somewhere in tensorflow yes so it might
192:19 - be some operation I could call here but
192:21 - I'm just gonna tweak it so this is why I
192:23 - want to grab that weight and I'm gonna
192:25 - say weight plus and I'm gonna use P
192:28 - fives random Gaussian function which
192:31 - basically gives me a random number
192:32 - that's kind of near to up with a mean of
192:34 - 0 and a standard deviation of 1 so it's
192:37 - just gonna adjust that weight a tiny bit
192:39 - so it's like kind of what you might sort
192:41 - of see with gradient descent dial up
192:43 - dial down but I'm just making a total
192:44 - guess just dial it some direction so
192:47 - it's going to equal that so once that's
192:50 - done right I have I I have my weights I
192:58 - have my weights sorry I'm confused here
193:09 - right
193:12 - this loop is looking at an individual
193:15 - set of weights it might be between
193:17 - inputs and hidden or between hidden and
193:19 - outputs or it might be one of the biases
193:20 - of either of those weights and I have it
193:24 - as a tensor and then have its values now
193:27 - I'm you tainted those values aha
193:29 - I need to make a new tensor new tensor
193:32 - equals TF tensor and give it those
193:36 - values again write the mutated values
193:39 - with the shape so this is what's nice I
193:42 - don't have to I other I don't have to
193:46 - worry about what the original shape was
193:47 - data think is just gonna flatten
193:49 - everything and give me all the numbers
193:50 - pretty sure okay and then what I can do
193:55 - is then mutate those it's flat I can put
193:59 - it back into a tensor with the same
194:00 - shape and it should be back just like it
194:02 - was before I can say mutated weights
194:05 - oh wait a sec yeah mutated weights index
194:13 - I is now that new tensor so I the mutant
194:21 - so I grab the tensor I got its shape I
194:23 - got the values I mutated them I made a
194:26 - new tensor and it's going to go into my
194:27 - new array of mutated weights and then
194:30 - when that's done I can say this dot
194:33 - model dot set weights mutated weights I
194:42 - think this is mutation
194:44 - I can't believe we'll be shocked if I
194:47 - didn't make a mistake you I know I'm no
194:48 - one mistake that I made so there's like
194:50 - a really we there's a thing that and and
194:52 - this is something that thank you to the
194:54 - creators of tensioner float yes thank
194:56 - you sorry
194:57 - there is one mistake here which is that
195:00 - tensor dip sorry which is that data sink
195:03 - is actually not making a copy of the
195:08 - values so I'm still going to be stuck
195:11 - with a lot of things pointing to the
195:13 - same exact data so if I do take one and
195:15 - I'm it's copied for like a bunch all
195:17 - those are gonna get mutated in the same
195:19 - way and I want to have a bunch of
195:20 - different mutations happening in
195:21 - parallel so the fix to this oh let me
195:24 - pull up the discussion of this
195:26 - t fjs github.com Schiffman tensorflow
195:38 - Oh hold on just give me a second to find
195:41 - which one 45 but I'm really close to
195:44 - being done
195:46 - tensorflow Jess examples issues closed
196:16 - I discovered this issue around data sink
196:23 - in this discussion and thank you so much
196:25 - to one of the creators of sensor lo Jas
196:27 - tetany oke Laura who answered my
196:29 - question about this so data sink is
196:33 - mutating I'm mutating the underlying
196:36 - values in the tensor apparently there's
196:38 - an array sink function that I could use
196:39 - instead of data sink that does an actual
196:42 - copy but me I am Sonia Cody drain viewer
196:45 - actually suggested that I just called
196:47 - dot slice which is a JavaScript function
196:49 - for copying the array so this I really
196:51 - really need in there because I really
196:53 - got to make sure that I'm not mutating
196:56 - the same underlying information so I
196:58 - shouldn't add dot slice here and then I
197:01 - think I have this done we're about to
197:04 - find out you know the only way to find
197:07 - out I mean there's other ways to find
197:09 - out I'm sure is to let this run for a
197:11 - while and to sort of see if it gets
197:14 - anywhere so I'll let that do that for a
197:16 - little while
197:28 - so I would say that this worked because
197:32 - there we go I have an agent that learned
197:35 - basically again it's very very simple
197:37 - problem for it to solve but this
197:39 - technique that I've now done there's no
197:41 - reason why it couldn't be applied to a
197:44 - more complex scenario so I now have
197:46 - neuro evolution with tensorflow yes
197:49 - but I'm not finished I would I could do
197:52 - this in the next part but there's a huge
197:54 - problem here I haven't thought at all
197:56 - about memory management and if I do TF
197:59 - memory in the console I have at one
198:04 - twenty eight thousand eight hundred
198:05 - seventy tensors and I'm using all these
198:08 - bytes and if I go sorry if I start from
198:11 - the beginning I have that many tensors
198:12 - and look how it's going up so I'm
198:13 - leaking memory like crazy I'm not
198:17 - cleaning up any of the tensors that I'm
198:19 - using and so the way to do that I don't
198:22 - know why I'm coming over here but it's
198:24 - very important in addition to the get
198:26 - weights and set weights function there
198:28 - are two functions that I really need to
198:30 - be conscientious about when working with
198:33 - tensor flow DHS one is TF dot tidy and
198:36 - this is a function that you can
198:38 - basically give it a call back and any
198:40 - code that you put up in there it'll do
198:42 - the cleanup for you so it's kind of like
198:44 - tension flow Jazz's garbage collection
198:46 - feature it's like just put some code in
198:47 - here and don't worry we'll take care of
198:49 - disposing memory that's not used so this
198:52 - is probably what I'm going to use most
198:53 - of the time but any tensor I could also
198:55 - individually call dispose on when I'm
198:58 - not using it anymore so let me go and
199:00 - find everywhere in my neural network
199:02 - code that I'm using tensors and make
199:05 - sure I'm cleaning up memory that's not
199:06 - being used anymore all right so I've got
199:14 - I'm in my code scrolling scrolling
199:16 - scrolling this should be fine I don't
199:18 - think I need to dispose models maybe I
199:20 - do but here okay oh look at this
199:23 - mutation so I'm sure I'm creating new
199:26 - tensors I'm doing stuff this is
199:28 - definitely a place where I want to say
199:29 - TF tidy and basically it's the nice
199:34 - thing is it's literally as simple as
199:36 - this I just put a
199:39 - everything inside of TF tidy so maybe
199:42 - there's a slightly more optimal a better
199:44 - way of doing this but this should work
199:46 - in predict you know this one's a little
199:49 - easier like I could say like oh I don't
199:50 - need the X's anymore so dispose of those
199:54 - and now once I have the outputs I can
199:58 - dispose of the Y's so I could put manual
200:01 - dispose in here like that's me disposing
200:03 - but I think I probably will also just
200:06 - use TF tidy same exact thing but there's
200:14 - a little something else that I need to
200:15 - do here because this code is returning
200:18 - something I need to return the result of
200:20 - TF tidy so that should be fine I feel
200:23 - like the model stuff is fine this should
200:24 - be all the cleanup that I need let's see
200:26 - a problem okapi oh yeah I guess let's do
200:31 - TF tidy in here also TF tidy let's do
200:39 - this I also need to say return since I'm
200:42 - returning a new model I mean I could put
200:44 - I could put TF tidy in this let's see if
200:47 - I need to let's look at the memory now
200:51 - so there's a thousand tensors that makes
200:53 - sense because I have 250 Birds and
200:58 - there's four tensors for weight matrices
201:01 - that's a thousand so three thousand oh I
201:04 - missed something so every generation I'm
201:07 - not I'm keeping some of the old tensors
201:10 - that I don't need anymore so let's try
201:13 - putting I suppose TF tidy here and also
201:22 - return and let's see what happens
201:26 - oops ah wait mop something undefined
201:31 - what did I mess up
201:32 - TF tidy hmm
201:51 - it's weird let's take this out okay so
202:01 - that causes an error but once they hit
202:05 - the next generation I've got a thousand
202:07 - more oh all right okay that didn't seem
202:15 - to work but I have a better idea I don't
202:18 - know why that didn't work there's
202:19 - probably a very good reason and I will
202:20 - hear from somebody about it but I think
202:23 - I know what I should do where am i
202:25 - copying here oh but I have TF tidy here
202:29 - I was thinking that once I make this new
202:35 - neural network I would call dispose on
202:37 - the existing model hmm where I don't
202:49 - know where I have my memory leak to be
202:53 - honest with you like nothing needs to
202:58 - tidy here because oh wait a second
203:02 - No No
203:09 - [Music]
203:20 - hmm dispose the old generation hmm I
203:30 - mean ultimately what I'm thinking I need
203:32 - to do is say this stop model dot dispose
203:37 - let's just let's just see what happens
203:39 - there
203:41 - 1000 it's already disposed so that makes
203:46 - no sense
203:54 - hmm what am I missing
203:59 - and I couldn't put it here
204:09 - I'm
204:12 - totally lost here this should really be
204:19 - a function outside of the class I'm not
204:30 - disposing the old birds
204:38 - all right hold on those have once a bird
204:40 - hits a pipe you are hittin the those
204:44 - have a model with tensors I hold on that
204:56 - could be yet
205:22 - Update next generation next generation
205:29 - calculate Fitness Birds saved Birds
205:43 - where's calculate Fitness
205:53 - so baby
206:03 - like these
206:11 - like this let's see here
206:22 - Oh oh there we go
206:33 - area that was it okay alright that's it
207:21 - okay after examining this for a bit with
207:23 - a little bit of help from the chat
207:25 - it looks like the issue that I have is
207:27 - that and it's a little bit weird what
207:29 - I'm doing here I have a bunch of
207:30 - different arrays
207:31 - I have birds saved and saved birds so
207:36 - saved Birds is kind of like the previous
207:38 - generation and I make all these new
207:41 - birds for the next generation put them
207:42 - in the birds array but the models the
207:46 - saved bird models still exist so I need
207:49 - to dispose those and so the way I could
207:53 - do that is just find the place where I'm
207:55 - done making the next generation and then
207:57 - iterate over the saved Birds and a way I
207:59 - could do that is I could also like in
208:01 - the bird object right now I could add a
208:03 - function called disposed little silly to
208:06 - do this but why not which just says this
208:09 - dot brain dot dispose and then in the
208:15 - neural network class I now have a
208:17 - function called dispose which I would
208:20 - say this stop model got disposed so that
208:22 - would this is sort of a manual disposal
208:25 - of all of the memory that that
208:28 - particular model is using and then
208:29 - somewhere in the sketch when I call next
208:34 - generation that makes the next
208:36 - generation and then I go on that's in my
208:41 - genetic algorithm which is here so this
208:43 - is making this is making the next
208:45 - generation and then clearing the saved
208:48 - Birds
208:48 - so before I clear the saved Birds I
208:51 - think it's you know I could just use
208:54 - this total value what I can do now is I
208:58 - can say saved Birds index i dot dispose
209:03 - so that should call the dispose function
209:06 - which calls the dispose function which
209:07 - calls the dispose function so now it's
209:11 - I'm looking at a thousand tensors and
209:14 - then let me speed this up so it gets to
209:17 - the next generation faster oh wow it
209:19 - just got like a good one next generation
209:21 - and now still a thousand tensors so this
209:26 - is really complete I mean there's so
209:28 - much more than I could do but this is
209:31 - complete
209:31 - in terms of the idea of neuro evolution
209:34 - with tensorflow chess and this
209:35 - particular flappy bird game alright so
209:38 - what's coming next what could you do
209:40 - what could I do next so one thing is in
209:42 - my previous coding challenge I saved the
209:45 - model to reload later intensive largess
209:47 - has functions for doing that save and
209:50 - load layers model I forgot what the
209:51 - names of the functions are called
209:52 - but they're in there so I could come
209:53 - back and add that to this the other
209:57 - thing would be to apply this idea to
209:59 - different scenarios different games to
210:01 - different environments one of things
210:03 - that I would like to do is work with
210:04 - steering agents whether they're finding
210:06 - food or avoiding predators that would be
210:08 - an interesting thing to try so hopefully
210:10 - I'll come back and do this same idea but
210:13 - with a different environment that maybe
210:15 - has more complexity to it with a less
210:17 - obvious result because I have a feeling
210:18 - that I could have gotten a bird to solve
210:22 - this game with just some if statements
210:23 - like I could probably guess like you
210:25 - should always jump if you're too high
210:26 - well it shouldn't jump if you're higher
210:29 - than where the the pipe opening is and
210:32 - if you're lower you should jump so you
210:34 - know I could write an if statement
210:35 - instead I've used a neural network thank
210:37 - you for watching if you make your own
210:38 - version of this if you have ideas for
210:40 - how to make this better please let me
210:42 - know in the comments and also over at
210:43 - the coding training com you can submit a
210:45 - link to your version of this or running
210:48 - in the browser and I'll take a look at
210:49 - those and hopefully share them in a
210:50 - future video or livestream thanks for
210:52 - watching and good bye alright black hole
211:03 - new revolution stack I did everything I
211:08 - said I was going to do I recorded two
211:09 - discs I'm done for the week
211:11 - there will be no live stream next
211:13 - Wednesday the next time you'll see me is
211:14 - hopefully two weeks from today the way
211:17 - to find out when I'm live streaming is
211:18 - just subscribe don't smash the button
211:22 - just like click it very gently and
211:23 - nicely if this were my subscribe button
211:25 - now we'd do this thank you Lauren Bell
211:31 - you could click that if you want but
211:33 - only if you want you don't want to be
211:35 - notifications are so annoying reduce
211:37 - those in your life but that's why I tend
211:40 - to schedule them
211:42 - either the day of or the day before and
211:44 - so you'll see them pop up in your feet
211:47 - random numbers I think to round out this
211:52 - yeah Joshua Burke in the chat is saying
211:54 - try using this as a base for running
211:56 - your own pong game agents exactly I
211:58 - definitely want to do that and to round
212:04 - out the day to the tune of my flappy
212:10 - bird girl evolved ages six one three
212:14 - eight three one seven two two two five
212:17 - five two three four one eight nine six
212:20 - three nine zero zero six nine three five
212:23 - zero four eight two three seven three
212:26 - four nine eight one five five two zero
212:29 - eight zero two six one six seven five
212:31 - seven two six five five nine seven three
212:37 - two four five four one four three three
212:45 - five three four five two six four seven
212:48 - one nine and four five two six four
212:52 - three two five three three two two one
212:55 - five seven two seven six five six eight
213:00 - nine six one six two five
213:04 - [Music]
213:07 - don't you feel relaxed
213:09 - deep breathing policy gradients minimax
213:15 - reinforcement learning frozen lake cue
213:18 - learning there's too much in this world
213:19 - I can't do it all people I'm trying my
213:22 - best I have to admit I'm a little bit
213:25 - over scheduled this month and I'm very I
213:28 - feel very I'm sort of I think it's good
213:31 - for me not to be to rebuild some
213:34 - strength and catch up on some things but
213:35 - also I'll be out of town so thank you if
213:38 - it's for everyone who supports me
213:40 - whether you're signed just watching
213:42 - signed up to patreon clicking on the
213:45 - brilliant org sponsor link all those
213:48 - things super helpful and kind of
213:49 - motivate me helps me kind of build the
213:52 - resources to do this stuff more and
213:55 - I appreciate it very much so I will see
214:01 - you all two weeks from today
214:04 - stay tuned for edited versions of these
214:06 - videos coming out to watch those because
214:09 - you're watching right now and thank you
214:11 - very much as always I always forget
214:24 - [Music]
214:36 - [Music]
214:45 - [Music]
214:57 - [Music]
215:11 - this stop this top spot
215:15 - never forget to this stop I'm gonna do
215:17 - this this dot this dot this star this
215:20 - star song never forget the Vista but
215:22 - somebody composed that song for me