00:01 - hello here I
00:03 - am so I'm trying I'm moving along here
00:06 - through this journey of trying to
00:08 - program this neural network library
00:10 - again I might suggest skip ahead find
00:14 - some videos where I'm just using the
00:15 - library but I'm I'm doing this I'm
00:17 - exposing this process of a person
00:20 - struggling to make sense of the world
00:22 - but for this video I did actually make
00:24 - some notes um and I want to reference
00:27 - actually a there's a nice um medium post
00:30 - about kind of what linear algebra you
00:32 - need to know for deep learning that I
00:34 - will uh show you on my laptop in a
00:36 - second and and link to it in the video
00:38 - where I read that post this morning and
00:41 - helped me kind of gather my thoughts for
00:42 - this particular set of video so what
00:45 - I've done so far is I've established
00:47 - that we
00:47 - need this
00:50 - idea of linear
00:55 - algebra in order to perform some of the
00:59 - math in the neural network library that
01:01 - I'm building so what I want to do is
01:03 - take a break from the neural network
01:05 - stuff itself and look at the linear
01:07 - algebra stuff in a vacuum and yes
01:10 - finally actually hopefully write some
01:13 - code because I want to talk through the
01:14 - math and implement the math in code in a
01:16 - generic way and then apply that to the
01:18 - neural network we're going to get
01:20 - through this
01:21 - everybody okay so what are the core so I
01:25 - have I I have some props I found
01:30 - my
01:31 - old linear algebra textbooks from 20
01:35 - some plus 25 some amount of years ago so
01:40 - I brought these as
01:41 - props I was reading them this morning
01:43 - but here's the thing this is not a
01:45 - course in linear algebra there's
01:47 - actually some great linear algebra
01:48 - videos on KH Academy um probably there
01:50 - are some other ones out there I will
01:52 - link to additional resources in the
01:53 - description of this video I want to do
01:55 - is cover the aspects of linear algebra
01:58 - that are necessary or relevant to the
02:00 - neural network stuff um and kind of
02:03 - leave out the rest so I'm going to give
02:06 - that an attempt and see how it goes and
02:07 - write code along with it um and you'll
02:10 - let me know how that goes okay so here's
02:12 - the thing there are two key Concepts in
02:15 - linear algebra there's the idea of a
02:17 - vector and there's the idea of a
02:20 - matrix now a vector is actually
02:22 - something that I've spent a lot of time
02:24 - in previous videos in this nature of
02:25 - code playlist talking about the idea of
02:28 - a two-dimensional vector
02:31 - an entity with magnitude and direction
02:34 - in a two-dimensional space we use this
02:36 - Vector for forces and velocity and all
02:38 - sorts of physics simulation all sorts of
02:40 - stuff but ultimately this
02:43 - Vector is just an X and A Y that
02:48 - two-dimensional Vector from and of
02:50 - course could be a z if it were a
02:51 - three-dimensional Vector for all the
02:53 - computer graphics and animation physic
02:54 - simulation stuff I've done in previous
02:57 - videos we could think though about we
02:59 - can we could consider a vector as just
03:01 - an N dimensional list of
03:03 - values and I could make the notation
03:06 - like this and I could say x0 X1 X2 X3 X4
03:11 - X5 so this is a five-dimensional vector
03:15 - there you
03:16 - go so this is the idea of a vector now
03:19 - one thing I should note is that you will
03:21 - see a variety of different kinds of
03:24 - notation um you might
03:27 - see them am I still you might see things
03:30 - written like this XY you might see it
03:33 - written like this XY different textbooks
03:37 - different styles I'm going to use this
03:40 - square bracket notation for the
03:44 - algorithms and examples I'm going to
03:45 - demonstrate in this video and in future
03:47 - videos okay so that's the idea of a
03:49 - vector now if you also
03:52 - recall we can do math with vectors and
03:55 - there are a few different kinds of
03:57 - operations there's the idea of a scalar
04:00 - operation like let's say I have the
04:01 - vector 2 2 three and I multiply that by
04:06 - the number
04:07 - two I could take this scalar value the
04:10 - single value and multiply it by each
04:12 - component of the
04:14 - vector and I would now have 4
04:18 - six there also are operations that are
04:21 - referred to as element
04:25 - wise this is the kind of operation that
04:27 - I did over and over again if I had a
04:29 - velocity vector and a position Vector so
04:31 - if I had a position Vector that was
04:34 - something like you know 2 three and then
04:37 - I had a velocity Vector that was you
04:39 - know
04:40 - -15 I could add element wise add these
04:44 - together so the first element add to the
04:47 - this the the first elements get added
04:49 - together so 2 +1 is 1 the second two
04:55 - elements get added together 3 + 5 is 8
04:59 - so these these are element wise
05:00 - operations
05:02 - now in addition to that there is also
05:06 - something reference referred to as
05:08 - Vector multiplication and there's like
05:10 - the dot product and the cross product
05:13 - there's like the Hadar how do you say
05:14 - that hodaru anyway there's so I don't
05:19 - I'm kind of reminding you of some things
05:21 - and I I have a bunch of videos on the
05:23 - dot
05:24 - product the dot product I use in videos
05:28 - to look at the angle between two vectors
05:30 - there's a pathf finding example we
05:33 - really needed the dot product to figure
05:35 - out how to get a moving agent to follow
05:37 - a path and the way the dot product
05:42 - works is we
05:44 - take two vectors and get a single scalar
05:49 - value so you can see these scalar
05:51 - operations a vector by times a single
05:53 - number we get a vector these element
05:55 - wise operations a vector plus a vector
05:57 - we get a vector the DOT product and the
06:00 - reason why I'm going through this is I'm
06:01 - going to use this again once I get to
06:03 - Matrix Matrix is where the new stuff is
06:06 - the dot product if I
06:10 - have two three uh I just use these same
06:15 - values
06:16 - -15 so the way that the dotproduct works
06:19 - is we actually take the if these were X
06:22 - and Y values we take the x's and
06:24 - multiply them together and the Y's and
06:26 - multiply them together and add them
06:27 - together it's kind of like that waited
06:29 - something that I was doing earlier in
06:31 - the sort of neural network in the
06:33 - perceptron stuff so I would take 2 * -1
06:36 - which is -2 plus 3 * 5 which is 15 and I
06:42 - would get uh 13 so that is the dot
06:46 - product so I could take the next step
06:50 - and I could start to write code for all
06:52 - these operations for vectors but I'm not
06:55 - going to bother with that because
06:57 - ultimately what I need for the neural
06:59 - network library is the Matrix stuff but
07:02 - I starting with the vector stuff because
07:04 - it's all going to translate uh it's it's
07:06 - all going to it's going to be analogous
07:08 - but I should point out that this is all
07:10 - in if you're in p5js for example there's
07:13 - P5 vector. JS the source for the P5 is
07:16 - all on GitHub and you can actually find
07:18 - all of these operations here's the
07:20 - dotproduct function you know if I look
07:22 - for the uh add function here's you know
07:25 - adding two vectors together so you can
07:27 - start to actually go and unpack for
07:29 - these 2D and 3D vectors um how that math
07:32 - works in the source code
07:35 - but now what I want to do is redo this
07:40 - but not for vectors but for
07:45 - matricies so the idea
07:48 - here is what I want to now do is I want
07:51 - to understand well what if I'm storing
07:53 - numbers in a matrix and why would I do
07:56 - that well there are so many reasons
07:58 - pixels live in a matrix data in a
08:01 - spreadsheet is in a matrix the weights
08:04 - of Connections in a neural networks can
08:06 - be in a neural network can be stored in
08:07 - a matrix so there are so many scenarios
08:10 - in programming where the numbers that
08:12 - we're working with are stored in a
08:13 - matrix and we could think of that like a
08:15 - two-dimensional array um that we want to
08:18 - perform these kind of mathematical
08:19 - operations very very often
08:21 - so what is a matrix a matrix instead of
08:25 - a linear list of
08:27 - values is a twod diim I grid of values
08:30 - and I could think of it like this A B C
08:34 - D E F and this would be a 2 by3 Matrix
08:42 - typically we refer to matrix by the
08:44 - number of rows and the number of columns
08:48 - two rows three
08:51 - columns so in that sense we can redo all
08:55 - of these mathematical
08:57 - operations so let's look at these kinds
09:00 - of mathematical operations now with a
09:02 - matrix so I could do a scalar and this
09:05 - should be an a I don't know scalar
09:06 - operation so let's say I have the Matrix
09:10 - 2 uh 3 -4 uh
09:15 - 9 and if I were to multiply that by the
09:19 - number
09:20 - two an scalar operation would just
09:23 - double all of these values so this would
09:25 - give me then the Matrix 4 6
09:30 - 88 okay so let's actually let's pause
09:33 - for a second I'm not really going to
09:35 - pause and let's before we get to these
09:37 - other operations let's start to write
09:39 - some code okay so what I want to do is
09:42 - have a library that allows me to create
09:45 - a matrix of values and then perform a
09:47 - scalar operation let's go write the code
09:49 - for that now I should point
09:51 - out that what I'm doing the nature of
09:54 - what I'm doing is kind of ridiculous
09:56 - because there is a math. JS this is an
10:01 - extensive math library that includes an
10:03 - entire Matrix
10:05 - implementation there is also GPU
10:09 - dos which is a GPU accelerated
10:11 - JavaScript library for doing Matrix
10:13 - operations and you know I'll talk about
10:17 - GPU stuff in a little while later but um
10:20 - there's also I think uh matrix. JS
10:22 - there's P5 as a matrix implementation
10:24 - but um I am going to write my own just
10:28 - to kind of
10:29 - understand how it works and then later
10:32 - as part of this Library I probably want
10:33 - to swap it out to have something more
10:34 - efficient that's going to actually you
10:37 - know opt do these Matrix operations
10:39 - optimally but so let's create a new file
10:42 - I'm going to call it matrix. JS and I'm
10:46 - going to write a Constructor
10:50 - function and I'm going to call that uh
10:53 - Matrix and the Constructor should get a
10:57 - n a certain amount of rows and
10:59 - columns and I should say this do rows
11:02 - equals
11:03 - rows it's been so long since I typed
11:06 - this dot feels good this do calls equals
11:09 - columns okay so the idea being that I
11:12 - want to be able to say VAR m is a new
11:16 - Matrix 3x two something like that right
11:20 - that's the idea here I want to be able
11:21 - to just generate a
11:23 - matrix okay so for example I can do this
11:28 - just here in the console now oh let's
11:30 - actually go to
11:32 - index.html and add in the neural network
11:36 - library and the Matrix library
11:40 - now and I should be able to say varm
11:43 - equals a new Matrix 3 comma 2 and I can
11:47 - see there we go I have a matrix object
11:49 - with three rows and two
11:51 - columns okay
11:55 - now we got to come up with a way of at
11:57 - least initializing the value
11:59 - and this is this is 2x3 and I said 3x
12:02 - two but whatever so let's initialize all
12:05 - the values as zero so how do I do
12:10 - that well
12:13 - ultimately I need to have a variable and
12:16 - maybe I'll just actually call it Matrix
12:19 - I could call it values I don't know what
12:21 - to call it I'm going to call it
12:22 - Matrix equals an
12:26 - array now there are all sorts of
12:29 - sophisticated JavaScript ways you know
12:32 - I'm only ever going to put floating
12:33 - Point numbers in these I can have fixed
12:36 - size to allocate the memory in some
12:38 - optimal way but I'm just going to live
12:40 - in the
12:41 - breeze P this in the most kind an
12:44 - easiest loosest friendliest way and then
12:46 - we can always come back and optimize to
12:48 - use some more efficient and optimal data
12:50 - structures later so what I first want to
12:52 - do again the traditional way to think
12:56 - about a matrix is Rose by columns so I'm
13:00 - going to start with a loop through the
13:02 - number of
13:05 - rows and I'm going to say every
13:09 - single um
13:14 - row is also an
13:18 - array and then I am going to Loop
13:22 - through all of the
13:25 - columns and I have a j here an I here by
13:28 - accident and say then
13:32 - every single row column location is a
13:37 - value and let's just initialize them all
13:40 - at zero
13:42 - whoops so this is me now making a matrix
13:46 - of values everything with zero let's go
13:50 - back to the
13:52 - browser and let's refresh the page and
13:55 - create that Matrix again and I should
13:59 - now see Matrix has three rows and two
14:02 - columns and then it has an
14:05 - array each one of these rows has two
14:08 - values 0 0 0 0 0
14:12 - 0 so this is now we can see the data is
14:15 - actually stored in there so I've got the
14:19 - beginnings of a matrix Library nothing
14:21 - about this is optimal or efficient but I
14:24 - have a library an object that stores the
14:26 - number of rows and the number of columns
14:28 - and creates a two dimensional array fill
14:30 - the
14:31 - zeros okay so now what I'm going to
14:35 - do so we kind of now we have the ability
14:38 - of a library to create this Matrix the
14:41 - next thing that I want to do is add a
14:44 - function that performs a scalar
14:46 - operation so for example let's add a
14:50 - function that's called multiply which is
14:53 - the wording of this is a little bit
14:54 - tricky because ultimately Vector matrix
14:58 - multiplication can mean a lot of
14:59 - different things but just for right now
15:01 - I'm going to write a function matrix.
15:05 - prototype that's part of the Matrix
15:07 - object all Matrix objects I'm going to
15:09 - call it I guess I could call it scale
15:11 - let's just call it scale for right now
15:13 - um equals a function that's going to
15:16 - receive a single value n and what do I
15:20 - want to do I want to I'm going to do
15:23 - this a lot Loop through every single
15:27 - row
15:29 - Loop through every single
15:33 - column and say this do
15:37 - Matrix i j times
15:43 - equals that
15:45 - value let's call I'm going to call this
15:47 - multiply and then I'm going to add
15:49 - quickly add another one for another
15:51 - scalar operation called
15:55 - add and I'm going to uh say plus equals
16:00 - so again this is this idea I've written
16:02 - two functions these are scalar functions
16:04 - I just want to take a single value and
16:06 - multiply every value in the matrix by
16:08 - that value or I want to take a single
16:10 - value and add it to every single value
16:12 - in The Matrix that's what these two
16:13 - functions can do so let's now come back
16:17 - here once again oh I've got a syntax
16:19 - error I guess I have an extra Clos curly
16:24 - bracket so I'm going to create that 3x2
16:27 - Matrix again
16:29 - I'm going to say add
16:31 - five now let's look at it and I should
16:34 - see the values in it should be all fives
16:37 - right now again we're not really seeing
16:39 - the Nuance of this because there's not
16:40 - different values but it started as zeros
16:42 - and then I added fives to it and now I
16:44 - could say m. multiply
16:48 - -3 oops oh I called it
16:52 - multiply and if I look at M again now
16:55 - and I start to look at those values we
16:57 - can see all the values are
17:01 - -5 so what do I have so far I have a
17:05 - simple Matrix implementation that allows
17:09 - me to
17:10 - initialize a grid of numbers by rows and
17:13 - columns and perform scalar operations I
17:17 - can multiply or I can um
17:22 - add so I'm going to pause here and in
17:25 - the next video I'm going to do element
17:28 - wise
17:29 - operations and then we're going to start
17:31 - to look at other Vector multiplication
17:34 - which is really no longer the dot
17:35 - product but we I'll talk about sorry
17:38 - matrix multiplication so I'm going to
17:39 - kind of break these out into separate
17:41 - videos and I'm going to show you some
17:42 - interesting things about building a
17:44 - JavaScript library where I can actually
17:46 - determine what's coming in I can reuse
17:49 - the
17:50 - multiply uh and the add function um to
17:53 - determine am I adding a scalar or am I
17:56 - adding a whole other Matrix so I'm going
17:57 - to get to that in the next video okay
18:03 - [Music]
18:10 - thanks