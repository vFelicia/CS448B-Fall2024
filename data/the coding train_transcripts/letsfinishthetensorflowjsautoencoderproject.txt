00:00 - [Music]
00:09 - [Music]
00:16 - [Music]
00:21 - do
00:23 - [Music]
00:31 - so
00:33 - [Music]
00:42 - [Music]
00:55 - [Music]
01:04 - [Music]
01:11 - [Music]
01:24 - [Music]
01:38 - [Music]
01:49 - [Music]
01:54 - [Music]
01:59 - [Music]
02:06 - [Music]
02:15 - do
02:18 - [Music]
02:36 - [Music]
02:53 - [Music]
03:11 - do
03:31 - [Music]
03:42 - [Music]
03:56 - [Music]
04:09 - do
04:11 - [Music]
04:19 - [Music]
04:25 - check one two hello this is my voice i'm
04:28 - about to get started in approximately
04:31 - two minutes
04:33 - uh if you could if you're in the chat
04:35 - you could let me know that the volume of
04:37 - my voice
04:38 - is coming through and if there's any
04:40 - static or any other issues i should be
04:42 - aware of thank you very much and see you
04:44 - in just a minute or two
04:48 - [Music]
05:23 - [Music]
05:57 - [Music]
06:15 - ugh
06:20 - hello my buttons aren't working properly
06:23 - that's usually the first thing i like to
06:25 - say here on uh
06:27 - when i start a coding trade session good
06:28 - morning
06:30 - happy sunday
06:32 - oh i was all ready to speak and then i
06:34 - pressed the button to bring me live and
06:36 - then i did not show up live and i got
06:39 - completely flustered
06:40 - but
06:41 - i realized actually now that i look at
06:43 - this i was just pressing the wrong
06:44 - button
06:46 - none of this matters let's just give
06:48 - this another try can we please okay
06:51 - going back to here
06:53 - putting the music back on
06:56 - take two everybody
07:01 - [Music]
07:07 - hello good morning happy sunday welcome
07:09 - to the coding train my name is dan i
07:12 - will be your conductor for today's
07:14 - journey
07:16 - and um this train has been going for a
07:19 - very long time it was paused it was
07:21 - stopped in the station for at least a
07:23 - week now
07:24 - uh it but we're we're we're put
07:26 - shoveling the maybe this is this an
07:28 - electric train we had solar panels on
07:30 - the roof i don't know yet
07:32 - um
07:33 - but i'm getting it going again today and
07:35 - i'm going to be returning to this
07:37 - project that i've been building which is
07:39 - uh an auto encoder now if that term auto
07:42 - encoder means nothing to you don't worry
07:44 - i will give a brief kind of
07:47 - five-minute sort of catch-up summary
07:48 - over what i've done in the last couple
07:50 - sessions before before i dive right into
07:52 - the code um but before i even get to the
07:56 - project that i'm going to be building
07:57 - today let me just say hi are you a new
07:59 - viewer i see that i have a new member
08:01 - who just joined this is very exciting
08:03 - this hasn't necessarily happened in a
08:04 - little while it's michael
08:07 - michael
08:09 - thank you for joining
08:11 - the coding train membership program
08:14 - for your membership you will receive uh
08:17 - thanks for me at this very moment
08:19 - because i'm just speaking and i saw your
08:20 - name and i'm talking about your name
08:22 - that's probably not why you joined it
08:23 - shouldn't be why you joined
08:24 - access to some member discord channels
08:27 - for support on your code we'll send you
08:28 - some stickers in the mail all of those
08:30 - things ah but before before
08:34 - i go too far
08:35 - uh we must um dedicate these random
08:38 - numbers that i'm about to read
08:40 - we're just going to start this project
08:41 - over everybody
08:43 - it's been a rough year it's been a rough
08:45 - two years it's been a rough
08:48 - 48-ish years
08:50 - for me actually hasn't been that rough i
08:52 - i i things i i have i have it very good
08:54 - i i can i i cannot complain
08:57 - um
08:58 - but um i have been uh my i'm on a quest
09:02 - uh many quests one of which is to read
09:04 - this entire book a million random digits
09:06 - with 100 000 normal deviates probably if
09:10 - i had just like started doing this when
09:12 - i started making videos i'd be done by
09:14 - now
09:15 - but no i've tried and then i like do a
09:17 - different system then i change the
09:18 - system again we're going to just
09:20 - 2022 it's all twos with a zero
09:24 - it's a new year
09:26 - i
09:28 - we're going to start this book over but
09:29 - for right now
09:31 - we're going to say thank you to michael
09:33 - and reed
09:35 - from page 113
09:38 - row
09:39 - 5620 i'm going to read these digits
09:43 - 51940.44169.83459.8888
09:48 - oh my goodness that's crazy i gotta show
09:51 - this to you this entire book of random
09:53 - numbers
09:54 - it's not an anomaly let's see can i uh
09:56 - there's no light over near to the camera
09:58 - but i'm trying to i don't even remember
10:00 - where it is now here it is look at this
10:01 - look at that sequence
10:03 - is it gonna autofocus on it it's a
10:04 - little dark eight eight eight eight
10:06 - eight eight that's amazing
10:08 - um
10:10 - zero seven seven five two two three two
10:12 - one one two six two six zero zero eight
10:14 - six nine three two nine three six eight
10:17 - nine nine nine five six and uh michael
10:19 - your random number for you your personal
10:21 - number is 995-99956
10:25 - that's page 113 the end of row 5620
10:29 - uh if we can if i can continue to get my
10:32 - act together some of you have received
10:33 - these
10:34 - um many of you have are waiting but um
10:38 - for the members uh your own very own
10:40 - custom uh train whistle with the coding
10:43 - train laser etched on one side and then
10:45 - a random walk pattern generated with the
10:48 - random numbers in this book uh from your
10:51 - own personal position and number uh is
10:54 - um
10:55 - is what i'm offering we're gonna we're
10:56 - gonna be making a lot more of these
10:57 - starting in january
10:59 - and please join the discord everyone you
11:02 - can find out more all of that stuff
11:04 - there
11:05 - and yeah so um
11:12 - what's next
11:16 - ah let me thank today's sponsor
11:18 - brilliant do you like learning do you
11:21 - like interactivity
11:23 - do you like the holiday season
11:26 - and not know what to get somebody uh you
11:29 - could get them a subscription to
11:31 - brilliant so brilliant i'll come back i
11:32 - have a whole bunch of courses in math
11:34 - and science and interactive lessons and
11:36 - computer science so many things that are
11:38 - just in like
11:39 - complete alignment it's like there's
11:40 - another train that's got the words
11:42 - brilliant on it that's just chugging
11:44 - along alongside a parallel track to the
11:46 - coding train
11:48 - so i'll come back i'd like to do
11:50 - i like you know huge thank you to
11:51 - brilliant for sponsoring the coding
11:53 - train and what's wonderful about it is i
11:55 - get to open up brilliant around the
11:56 - middle of the live stream or taking a
11:58 - break and go through a challenge or a
12:00 - lesson in a course i will do that later
12:02 - but you can sign up for free at
12:03 - brilliant.org codingtrain lets them know
12:06 - that you found brilliant from me the
12:08 - coding train i'm not the code am i the
12:10 - coding i don't know
12:11 - that's another discussion for another
12:13 - time no need for the sort of like
12:15 - metaphysical philosophical quandary that
12:17 - we are am i a train am i a human who
12:19 - knows
12:20 - do i have legs
12:22 - yes a little bit stiff today um
12:28 - uh
12:29 - and um yeah oh oh if you want to unlock
12:32 - all the premium stuff and all the
12:33 - courses uh or or you can give it as a
12:35 - gift
12:36 - you will get 20 off
12:38 - the first 200 people to do so from this
12:40 - link all right now
12:43 - what is happening today first of all my
12:45 - glasses are very dirty
12:46 - and i'm going to uh
12:48 - untuck my t-shirt here
12:50 - and clean them off
12:56 - i wore some special clothes for all of
12:57 - you today on a sunday morning i was like
12:59 - let me find my shirt with flowers and my
13:02 - uh cardigan is this a cardigan is that
13:04 - what you call it nice sweater it's cold
13:06 - but i've been running the heat all
13:07 - morning in this garage
13:09 - uh you notice that if you're hearing me
13:11 - and seeing me without interruption the
13:12 - internet is hopefully working here in
13:14 - the garage it is not yet solar-powered
13:18 - um within the next two to six months i
13:21 - will be uh installing i'm not doing this
13:24 - personally but uh solar panels are being
13:26 - installed all on top of this garage
13:28 - where i am hopefully powering all the
13:30 - lights and the computers in here um so
13:33 - i'm excited to
13:34 - sort of see where that leads and talk
13:36 - about that as i go my my um desire to
13:39 - have the coding train you know to the
13:41 - extent of the things that i can control
13:43 - that are in here powered by solar energy
13:46 - uh um and kratos says it has been a
13:48 - while since the last time i've seen his
13:50 - video i think it was before he got his
13:52 - news to new york well
13:54 - boy do i have news for you
13:56 - uh hopefully this is gonna stabilize and
13:58 - i'll be uh broadcasting from here
14:01 - for at least the next
14:03 - year plus probably two years
14:05 - but i am in a new location yet again and
14:08 - mostly i have things going this is what
14:11 - i really want to work on this oh and
14:12 - it's out of focus this um i like to do a
14:15 - lot of diagramming and things in my
14:17 - videos and live streams let's see if i
14:19 - can focus this
14:20 - uh that's hopefully better um but i'm
14:23 - still sort of working on what whiteboard
14:24 - do i want to have how do i want to do
14:26 - diagramming and all of that stuff so
14:28 - coming back over here um
14:32 - all right so let's get going um
14:35 - actually actually before i go into the
14:38 - auto encoder project i i have a bone to
14:41 - pick with you audience
14:44 - i mean it's probably my fault
14:46 - so it's really not on you it's on me
14:49 - but i want to come over here and i want
14:50 - to talk about the fact that i have this
14:53 - video slit scan time displacement effect
14:55 - challenge
14:57 - i believe if you i don't know what
14:59 - happened to the code here on this page
15:01 - uh maybe that's why
15:04 - oh i have a bone to pick with me
15:07 - i've caused my own uh problem here no
15:10 - wonder
15:11 - oh why didn't anybody say anything to me
15:12 - let me let me just do this for a second
15:15 - yeah all right i messed something up
15:17 - here so let's let's see if we can remedy
15:19 - this right now
15:21 - um
15:22 - i think i um i don't know what the issue
15:24 - is and maybe somebody who's watching can
15:26 - do a pull request but let me at least
15:28 - remedy it for you for the year so this
15:29 - my bone that i was going to pick what is
15:32 - where did that expression come from i
15:33 - don't know it sounds kind of i i need a
15:36 - different one
15:37 - i don't like it anymore i want to pick
15:38 - anyone's bones i don't want my bones
15:40 - picked
15:41 - no picking no bones picking please
15:45 - but this is what i wanted to discuss
15:48 - this video came out and i know i'm slow
15:50 - and there hasn't been as much content
15:52 - recently and maybe there's not as many
15:54 - things for you to riff off of but i felt
15:57 - like this slit scan time displacement
15:59 - challenge coding challenge exact set of
16:01 - examples was ripe
16:03 - for creative twisting by you the
16:05 - beautiful passengers of the coding train
16:08 - to make your own special version of it
16:10 - and share back with me this is what this
16:12 - is what i'm here for what i most enjoy
16:15 - about doing the coding train but it
16:16 - seems like there haven't been made any
16:19 - variations first of all i i gotta really
16:21 - work on my language here on the website
16:24 - coming soon based on this coding
16:25 - challenge by the community yet
16:27 - be the first you could be the first and
16:29 - add your own there's a link there that
16:31 - will
16:32 - show you where to add it if you don't
16:33 - know how there's a guide there's a video
16:35 - with me talking about how to do it and
16:37 - even better coming in 2022 there will be
16:39 - a form on the website that you can use
16:41 - probably to just submit um i want to
16:44 - still encourage people to use github and
16:46 - github pull requests as their first
16:47 - foray through the coding train um and to
16:50 - get into that world but um
16:53 - working on some improvements for how um
16:55 - but i i'm realizing now that the code
16:58 - should be on this page
17:00 - and amir hussain says i've just done
17:02 - double pendulum did you submit it please
17:04 - submit it submit it let's see if there's
17:06 - let's see what the most recent
17:08 - community and i uh
17:11 - community contribution time
17:14 - let's see what you the audience have
17:16 - made most recently based on the videos
17:19 - that i have produced here on the coding
17:21 - trade
17:22 - so and then let's find where that code
17:24 - is for that video
17:25 - [Music]
17:28 - i'm gonna go to github.com codingtrain
17:31 - website
17:32 - um oh look pull requests
17:35 - there's some things here
17:37 - a lot old stuff not oh okay i'll have to
17:40 - come look at this but
17:41 - let's look at closed
17:44 - [Music]
17:49 - yeah nothing nothing 14 days ago
17:53 - the last contribution here we go the
17:55 - last contribution from david beale to
17:59 - the diffusion limit again this is on me
18:01 - i just have not been as present
18:04 - and uh
18:06 - in the sort of like
18:08 - ecosystem of the coding train
18:10 - um
18:12 - so that's you know i'm just kind of like
18:14 - make it through this year and and start
18:16 - a new in 2022 but that is my new year's
18:18 - resolution you heard it here first
18:21 - figure out ways
18:22 - to get more people contributing their
18:26 - own versions um you know um
18:28 - is it raphael who does the like creative
18:30 - coding weekly challenge that seems to be
18:32 - very successful i'm sure there's some
18:34 - things i can learn
18:35 - uh
18:36 - there
18:37 - but let's take a look at this one
18:39 - from david
18:40 - beale so um we can just see it here but
18:44 - i um just so you want to if you want to
18:45 - know where it shows up
18:48 - [Music]
18:52 - if i go
18:54 - to here
18:57 - and
18:58 - there it is 3d dla by david beal okay
19:04 - fade out this music let's take a look at
19:06 - this thank you for your submission
19:10 - whoa
19:10 - oh and i love that this is a youtube
19:12 - video
19:13 - cool let's make it full screen wow what
19:16 - did you make this in i would like to
19:18 - know
19:19 - wow that is so cool
19:22 - i love it so um the diffusion limited
19:25 - aggregation uh coding challenge
19:28 - is
19:29 - a simulation of a kind of random motion
19:32 - a brownian motion if you will
19:34 - where which is created by particles
19:37 - entering from outside of a space
19:40 - coming in and when they intersect
19:41 - another particle they're stopped so if
19:44 - you know i i don't know if we can just
19:46 - go back to the beginning of this video
19:47 - to sort of see the big that starting
19:49 - process but you can see it's happening
19:51 - very very fast so each one of these
19:54 - particles it's almost like these
19:55 - branches are coming out and has a very
19:58 - organic
19:59 - um it can have a tree it can create like
20:01 - a tree branching like um pattern but in
20:03 - here i don't know how to characterize
20:05 - this it's very it's almost like um
20:09 - molecular uh in its look so uh thank you
20:12 - for this this is wonderful to see this
20:14 - in 3d there's also something kind of
20:16 - lovely going on color wise here that i
20:18 - can't put my finger on but it seems like
20:20 - there are started as red particles and
20:22 - they're getting more and more blue
20:24 - um
20:25 - you know oh you know i tempted to be
20:27 - like you know
20:28 - just like i just want to make my own
20:30 - version of this i mean i guess i did in
20:32 - some manner but the version i made the
20:34 - example is just 2d
20:36 - and doesn't have this sort of 3d quality
20:39 - to it so wonderful work
20:41 - thank you for this community
20:42 - contribution so i'm hoping um
20:45 - i can kick-start getting more ways for
20:48 - people to share their versions and more
20:50 - ways for me to share them back
20:51 - and i look forward to thinking about
20:53 - ways to do that better in 2022. all
20:57 - right thank you okay i'm going to scan
20:58 - through this just to see where it goes
21:01 - uh
21:03 - whoa oh yeah so it's like zooming out
21:05 - maybe as uh as unchanged colors again
21:08 - this is wild
21:10 - that is a really quite an impressive
21:12 - looking structure
21:14 - um
21:16 - okay
21:17 - um now let's uh close this
21:21 - um
21:22 - just to sort of close the loop on this
21:24 - um
21:25 - if i go here uh you will see this is the
21:28 - actual code from the video
21:30 - and one of the things that i'm doing in
21:32 - this particular example that you didn't
21:34 - see in david's contribution is i'm
21:36 - animating the process of the particles
21:38 - entering and moving randomly and then
21:40 - getting stuck now i'm doing it
21:42 - really fast sped up because
21:45 - uh
21:46 - you know
21:47 - if i were to actually like animate each
21:50 - particle moving like one or two pixels
21:52 - per frame it would take a very long time
21:54 - to build the actual structure oh and i
21:56 - guess i also have some color scheme
21:59 - going on here i say i don't remember
22:00 - what i do in these coding challenges but
22:02 - now i see that color screen scheme is
22:05 - mirrored in the 3d version of it
22:07 - um
22:09 - wonderful i'm just curious here oh it's
22:12 - the iterations probably the iterations
22:15 - is the variable that kind of can i
22:17 - should log in
22:19 - um
22:22 - the iterations is the variable that
22:24 - controls like how many iterations of
22:27 - these particles moving am i skipping
22:30 - so if i went to just like for example
22:33 - one
22:35 - you would see like this is kind of i
22:37 - mean this would be like amazing to watch
22:39 - over an incredibly long period of time
22:41 - but i can only
22:43 - i'm going to talk for a tremendous
22:45 - amount of time and probably not one
22:46 - particle is going to stop and get stuck
22:49 - if i put it at 50
22:52 - we can see things are kind of moving a
22:54 - little bit faster now maybe we would get
22:56 - there but it was i think i had it at a
22:58 - thousand so you know if i
23:01 - if i did it at 100 000 for example oh
23:03 - that's just going to make things now
23:05 - that now i've lost the sort of frame
23:07 - rate of the sketch itself but you can
23:09 - see okay so that's under anyway you get
23:11 - the idea um
23:14 - i'm i'm
23:16 - lost on this tangent let's try ten
23:18 - thousand there we go um and i presumably
23:21 - i think what i would want to do in this
23:22 - case is actually not draw there's not
23:25 - really once i've have this iteration
23:27 - number up so high there's not a
23:29 - tremendous amount of value in drawing
23:31 - the particles moving themselves because
23:34 - ultimately what we're really just seeing
23:36 - is
23:37 - um
23:39 - the um
23:40 - the pattern that's emerging so just out
23:42 - of curiosity if i wanted to change that
23:45 - those are the walkers
23:47 - we could
23:48 - comment this out
23:50 - and i would see
23:52 - now i'm seeing just the sort of
23:54 - diffusion limited aggregation pattern
23:56 - emerging so there's a lot of parameters
23:58 - to play with here
24:00 - i don't want to save this actually
24:01 - because i've kind of messed it i should
24:02 - or i can maybe just do undo all the way
24:04 - back to where it was
24:07 - and hit save but what the thing that i'm
24:09 - just going to hit leave the thing that
24:11 - i'm curious about here is to take a look
24:13 - at source code now
24:14 - my assumption
24:16 - is what david shared here is a video
24:20 - rendering of it so one that's a
24:22 - beautiful way to share documentation of
24:24 - a project because it's very accessible
24:26 - like
24:27 - yes if you have a p5.js sketch that can
24:29 - run in the browser that's just about as
24:31 - accessible in terms of anyone being who
24:33 - happens to have a phone or a computer
24:37 - with a web browser um can just click
24:39 - that link and see it um
24:41 - but i'm assuming here that this is not
24:44 - done with p5.js because then presumably
24:47 - we could see it just running in the
24:48 - browser rather than have a video render
24:50 - of it although it's possible that it's
24:52 - a slow process that rendering it makes
24:54 - more sense anyway let's go i'm assuming
24:56 - this is going to be processing but i'm
24:57 - excited to find out
25:01 - oh no no oh this is i'm so wrong
25:05 - look at this
25:06 - they're just running in the browser
25:08 - so we got all the possibilities oh and
25:10 - and
25:10 - oh and i can control the camera with my
25:12 - mouse okay okay and i can see that it's
25:15 - running at 30 frames per second down
25:16 - here
25:17 - this is amazing uh so now i have to
25:19 - guess that this is i mean this could be
25:21 - the webgl renderer of p5 it looks like
25:23 - there's a lot going on here
25:25 - so and i don't know why the chat is not
25:27 - scrolling for me or maybe just nobody is
25:29 - making any messages in the chat
25:32 - the last message i see is ro doc saying
25:35 - hi
25:36 - um
25:38 - and like discord member chad is
25:40 - completely also dead am i just talking
25:43 - to myself here hopefully people are
25:44 - there
25:45 - so what did i uh sunday maybe sunday
25:47 - morning is not the best time for me to
25:49 - be live streaming but it worked out for
25:50 - me so here i am maybe you're watching
25:51 - this uh as a playback
25:54 - um i'm going to guess that there's
25:56 - something 3js going on here let's look
25:58 - at a view
26:01 - there's a lot of ways i could do this
26:02 - but i'm just going to go to view source
26:03 - here
26:04 - um
26:06 - and
26:09 - logo
26:10 - manifest
26:13 - drop
26:14 - [Music]
26:15 - this is an awkward way okay this is not
26:17 - helping me
26:18 - uh
26:20 - let's do um inspect
26:22 - this is going to be an easier way to
26:24 - look at it
26:26 - and we can see here
26:28 - there are some javascript so this is
26:30 - probably built
26:32 - um let's see let's look here
26:35 - this is probably a sort of built version
26:37 - of this project i'm assuming
26:40 - that this is using
26:43 - 3gs and maybe it's kind of embedded in
26:45 - one of these javascript files here but
26:47 - i don't need to get lost into this right
26:49 - now
26:51 - i can investigate this more later
26:53 - somebody can tell me
26:54 - um i don't know if this is what library
26:57 - this is uh or or what
26:59 - and i could probably click on this and
27:00 - maybe
27:02 - see something more but i assume these
27:03 - are all sort of built in minified files
27:05 - so it's going to be hard to sort of
27:06 - parse through and and find and then i
27:08 - see people saying uh
27:10 - saying hi now in the chat
27:12 - and and minnie jimmy has the same uh
27:15 - reaction that i have by saying sorry i
27:17 - am in awe of the patterns all right
27:21 - all right i've got to get moving here
27:22 - because
27:24 - uh if you've watched any coding train
27:26 - before
27:27 - you'll know that what tends to happen is
27:29 - i it's just a lot of sort of digressions
27:31 - and tangents and sort of
27:34 - going off in arbitrary directions
27:39 - and what i've the thing that i've been
27:40 - enjoying that i've been trying recently
27:42 - just over the last few weeks is picking
27:45 - one project that
27:47 - really requires a a lot of time to sort
27:50 - of dig into and dig through and try to
27:52 - build and debug and iterate and adjust
27:55 - and so on my list for a very long time
27:58 - has been to investigate
28:01 - programming my own auto encoder now not
28:04 - all the way from scratch in the sense
28:05 - that i'm like writing all the neural
28:07 - network code myself but just
28:10 - using a machine learning library like
28:12 - tensorflow.js and i've been doing that
28:14 - over the course of the last live two
28:16 - live streams so i just want to first
28:17 - summarize where i am
28:19 - so far in the project and where i want
28:21 - to go and i also want to address
28:24 - um
28:25 - this pull request that i haven't been
28:26 - able to merge yet i don't know if the
28:28 - chief who submitted this pull request is
28:30 - in the audience right now
28:32 - if you are say hi in the chat um
28:35 - and then also i want to look at this
28:38 - pull request which i did merge
28:40 - and we're going over this so an avaroop
28:42 - question what did you do last time
28:44 - is exactly where i want to be so
28:46 - um let me walk over
28:49 - and i won't be able to see the chat
28:50 - while i'm over there i'm looking to
28:52 - remedy that let me just have a look that
28:54 - looks like the focus is reasonable on
28:56 - there
29:00 - traverse i saw your question about
29:01 - coding challenges i'll try to address
29:03 - that later
29:05 - so
29:06 - the project that i've been building is
29:08 - in some ways like an ancient technology
29:10 - at this point in terms of
29:13 - what is it uh in terms of how
29:15 - synthetic media generative images i just
29:18 - want to see that there's green bars for
29:19 - my audio which there are
29:20 - are created through machine learning now
29:23 - you might have heard of things like
29:24 - again a generative adversarial network
29:27 - you might have heard of style gan or
29:28 - style gan 2 or style game 3 you might
29:31 - have seen this face this person does not
29:32 - exist and this explosion of
29:36 - synthetic
29:38 - cats and dogs and people and cars and
29:41 - all sorts of things that ai models are
29:44 - generating based on a set of training
29:46 - data of real world imagery
29:49 - and there's all sorts of ways they can
29:50 - be fantastical and look very dreamy and
29:53 - artists are making use of this stuff so
29:54 - for me where does learning about how
29:57 - those things work begin well it begins
29:59 - probably in the basics of you know what
30:02 - is a neural network um i do have videos
30:05 - on that but for me in terms of like if
30:08 - if we've got if i'm making this
30:09 - assumption as having sort of gotten
30:11 - through some of the fundamental aspects
30:13 - of the sort of core pieces of
30:15 - neural network-based machine learning
30:18 - the auto-encoder a particular
30:20 - architecture for a neural network is a
30:22 - wonderful starting point to learn about
30:25 - the process by which a model can
30:27 - generate an image and how
30:30 - you you as the sort of artist or the
30:33 - creator or the programmer can manipulate
30:35 - that model to generate images in certain
30:37 - ways um so uh reference most important
30:41 - reference probably for you to watch
30:43 - there's no post production here so i
30:44 - can't just fly this in right now to show
30:46 - you a preview would be the auto encoder
30:48 - video from the youtube channel two
30:50 - minute papers so that's a good two three
30:52 - minute video just you know explaining
30:54 - anything that i'm about to try to do
30:56 - right now in a much better fashion
30:58 - um but the neural network and again my
31:01 - previous sessions i went through this in
31:03 - much more detail i even did a recap of
31:06 - this part in the
31:08 - last session but just to quickly do that
31:10 - again
31:11 - the idea of an auto encoder the starting
31:13 - point of how you think of it as a
31:14 - copying machine an image is the input
31:17 - and we want that same image to come out
31:19 - as the output the trick here is that of
31:21 - course that's a very easy thing to do
31:23 - because we can copy an image i have this
31:25 - many pixels we make a new image and take
31:27 - each pixel and copy it over but what
31:29 - happens if as you're copying the image
31:33 - you're on you're constrained to work
31:35 - with less and less data so in a way
31:37 - you're compressing the image and then
31:39 - decompressing it or encoding it and
31:42 - decoding it what happens is through that
31:45 - process
31:46 - if the neural network
31:48 - learns all these weights
31:50 - the weights are sort of like the make
31:51 - the core sort of like settings the
31:53 - parameters of the neural network itself
31:55 - it learns the weights to copy an image
31:58 - then we could take out the part where
32:00 - the image comes in as input and just ask
32:03 - the neural network to make to make
32:05 - outputs based on what is essentially
32:08 - random inputs
32:10 - or noisy inputs then we're going to
32:12 - generate new images in the style of what
32:14 - we started with that's the idea of an
32:16 - auto encoder and that will lead to ideas
32:18 - like a variational auto encoder and all
32:20 - sorts of other kinds of generative
32:21 - models
32:22 - so
32:26 - where am i i've built this already
32:29 - i think this is where i should go back
32:31 - to my code i have done everything that
32:34 - is in this diagram
32:36 - except for that last part
32:37 - of take off the sort of first half and
32:40 - start to just generate new images that's
32:42 - what i hope
32:43 - and again it's it's not like i've been
32:45 - working on this like i haven't thought
32:47 - about this
32:48 - once when i have thought about it i
32:49 - haven't done anything on this project
32:51 - since the last live stream so i don't
32:53 - know how this is going to go you could
32:56 - go do something else with your sunday
32:57 - and come back and then like watch it on
32:59 - 2x or speed through and just look at the
33:01 - end so that might be advisable but
33:03 - if you're here
33:05 - thank you i appreciate you
33:07 - i'm going to go i'm going to go forward
33:08 - so let's look at the code pieces that
33:10 - exist already
33:13 - um and raj just asks sorry to be alone
33:18 - in a desert first of all
33:20 - nobody i hope nobody watching the coding
33:22 - train the thing that they're coming away
33:23 - from is a feeling of being alone in the
33:25 - desert
33:26 - although i actually have this i've never
33:28 - been to joshua tree and i was looking
33:29 - i'm just i don't know i know why this
33:31 - came up but i was looking at places to
33:33 - go visit joshua tree that's a desert
33:35 - that i could conceivably get to
33:37 - uh i mean i'd have to take an airplane i
33:39 - don't know what we're talking about here
33:40 - i got off track don't feel alone um the
33:43 - the the vibe here
33:46 - the working assumption is that this
33:49 - place is for people who don't know what
33:51 - the thing i'm talking about is and a lot
33:53 - of times i'm just figuring it out myself
33:55 - you should ask of course you know the
33:56 - reality of the situation is i can't
33:58 - every session go back to the very
34:00 - beginning of like what's a variable
34:02 - but you should feel welcome here
34:04 - wherever you are in that journey and
34:06 - there if i've done my job if this is a
34:08 - job correctly i can point you towards
34:10 - resources to find all of the
34:13 - um
34:14 - you know the prerequisites if you will
34:16 - to what i'm working on today so
34:18 - hopefully that explanation helped you a
34:19 - little bit and moby dick is asking would
34:22 - a reverse autoencoder work where you
34:24 - give it more information in the middle
34:26 - so it learns to opposite
34:28 - i don't i don't know i don't know if i
34:30 - fully understand that question if i'm
34:31 - being honest i have to think about this
34:33 - one more it's a fascinating idea and
34:35 - this is this is one of the things that
34:37 - i'm particularly invested and interested
34:38 - in what are the ways that
34:41 - machine learning models that are maybe
34:43 - trained to do a particular kind of task
34:46 - for a real world application can be
34:49 - uh tweaked broken uh
34:52 - done in the sort of like uh turned
34:54 - upside down for creative um and maybe um
34:58 - outputs and hopefully to be sort of
35:00 - critical and investigate um what are
35:02 - some of the sort of
35:04 - issues that the world has and i'm you
35:07 - know being kind of
35:08 - trite about this but uh with the fact
35:10 - that these machine learning models are
35:12 - playing such a sort of fundamental role
35:14 - in our daily lives um
35:17 - odjabi asks do i need to know how
35:20 - tensorflow to follow um it you know so
35:23 - no because my i'm i'm here welcoming you
35:26 - in whether or not you know anything
35:28 - about tensorflow um uh you know
35:31 - and i at least the stuff that i'm gonna
35:32 - do today like a lot of the tensorflow
35:34 - stuff is done already so it won't be the
35:36 - focus so it is
35:38 - um it is a sort of core essential part
35:40 - of what i'm doing right now but i will
35:42 - try to explain things as i go
35:44 - okay um
35:47 - all right lars is asking about
35:49 - generalized ai i don't have uh i don't
35:51 - have an answer for that question around
35:53 - the corner i would say no if i'm
35:55 - guessing but
35:57 - what do i know
36:00 - i'm just here in my garage
36:02 - on a sunny day
36:04 - with a computer trying to make some
36:07 - squares appear out of
36:09 - random numbers
36:11 - all right
36:12 - if you're wondering why i constantly
36:14 - look over here it's because that's where
36:15 - the chat is that's where my monitor is i
36:17 - mean i have it positioned here because
36:18 - then i can sort of
36:20 - gesture at what i'm doing but i feel
36:22 - like sometimes i'm spending too much
36:23 - time live streaming and looking over in
36:24 - this direction
36:26 - okay so um let's look at the pieces of
36:28 - what i have so far and i had the heat
36:31 - running in here all morning to like try
36:33 - to warm it up it is very noisy so i
36:35 - don't run it while i'm streaming but i
36:36 - already feel like it's getting a little
36:37 - bit cold in here so when i take a break
36:39 - i'll crank it up again
36:41 - um
36:43 - it's oil-based heat right now in this
36:44 - garage with like a very old boiler
36:47 - um but i would like to figure out once i
36:50 - have solar panels if i can do some type
36:52 - of like heat pump maybe that'll be
36:54 - quieter i don't know
36:57 - all right so
36:58 - first things first
37:00 - uh i need training data so if we're
37:03 - looking back to this uh this
37:06 - diagram images have to come in right
37:08 - images have to come in what are the
37:09 - what's the training data um it's very
37:11 - sort of
37:12 - rudimentary training data right now it's
37:14 - i have a processing sketch that just
37:16 - draws random squares so i'm going to run
37:18 - it
37:19 - the images it's saving are actually just
37:21 - 28 by 28 pixels because i'm working with
37:23 - very low resolution right now just to
37:25 - have things run fast and sort of work
37:27 - and be easy to deal with um i would like
37:30 - to today start having this generate
37:32 - different kinds of shapes like triangles
37:34 - and circles and squares because i think
37:36 - the sort of ending animation that i'm
37:38 - imagining of sort of like these shapes
37:40 - morphing around in the latent space i'll
37:42 - talk about what that is um would be more
37:44 - interesting so that exists then the next
37:48 - thing that i have which i haven't even
37:50 - opened yet is a node project
37:54 - and the node project is
37:57 - all the code for it is essentially here
37:59 - in index.js
38:01 - and the node project i'm going to talk
38:03 - you through it now i mean if you want to
38:04 - watch like four or five hours of me live
38:06 - streaming building all this you can
38:09 - um
38:11 - the node project is uh architecting this
38:14 - particular uh whoops wrong button this
38:17 - particular um
38:19 - uh neural network architecture
38:21 - i'm sorry to use the same word multiple
38:23 - times uh
38:24 - importing in the training images running
38:27 - the training and then
38:29 - producing output images as well and i i
38:31 - went around in circles with this because
38:33 - i was um you know ultimately i think
38:35 - moving this into the browser will make
38:36 - more sense
38:38 - um
38:40 - but um
38:41 - uh so you can see some things are
38:43 - commenting so i was trying to use like
38:44 - node canvas and different things but i
38:45 - ultimately just using this library
38:47 - called jimp which you can see up here
38:50 - jimp is a library for manipulating
38:53 - images in node
38:54 - so these are the steps we can say i have
38:56 - this like main function
38:58 - where i call build model build model and
39:02 - we'll look at the code in a second
39:03 - creates all of these layers
39:05 - that are in the diagram then i need to
39:07 - load all 550 images i have 500 training
39:11 - images and 50 test images i made a huge
39:13 - mistake which i haven't watched i need
39:15 - to address so this code i'm going to
39:18 - pull in the new code from the pull
39:19 - request in a second so there's a big
39:20 - mistake here
39:22 - but so this code is like slightly wrong
39:25 - but the idea here is the first 500
39:27 - images are the training images and then
39:29 - the next 50 images are the test images
39:32 - so i can train the model and then
39:34 - generate outputs by running the test
39:36 - images through and see how well the
39:38 - model does copying them essentially and
39:41 - so uh i did
39:43 - i forgot that i did this this is great
39:44 - there's some like refactoring there's
39:46 - basically build model load images train
39:48 - test
39:49 - so if we wanted to look at any of these
39:51 - functions i think looking at build model
39:53 - might be interesting to see
39:55 - this is this is the part that i forgot
39:57 - who just asked this like do i need to
39:58 - know tensorflow no but this is going to
40:00 - look kind of a little bit scary to you
40:02 - it looks scary to me and i i sort of
40:04 - know i know ish tensorflow so the idea
40:07 - is i'm making a sequential model
40:10 - a sequential model this is called
40:11 - sequential because the data flows
40:14 - through all these layers in a sequence
40:16 - feed forward left to right and we could
40:18 - draw it any way we want that's arbitrary
40:20 - but it is sequential
40:22 - and then um
40:25 - uh now i need to add the layers so the
40:27 - first layer receives 784 inputs because
40:30 - the images are 28 by 28 that's 784
40:34 - pixels
40:36 - the next layer
40:37 - and basically it takes those pixels and
40:40 - sends the data into 256 nodes and then
40:43 - those 256 nodes send their data into 128
40:47 - that's the encoder so i could actually
40:49 - add a comment here which would be like
40:51 - encoder oh my hands are so cold
40:55 - i'm gonna have to turn the heat on
40:57 - and then decoder
40:59 - what's the temperature outside let me
41:00 - just tell everybody what the temperature
41:02 - outside is where i am
41:04 - uh
41:04 - it's only 40 degrees
41:08 - um and sunny high of 43 today low of 28.
41:11 - this is in fahrenheit of course not of
41:13 - course but
41:15 - of course because i'm an american here
41:17 - who
41:18 - living in the dark ages of
41:21 - measurement systems uh then the decoder
41:24 - is we go back from 128 to 256 and then
41:27 - back to 784 and there's these activation
41:30 - functions and there's the optimizer and
41:32 - the law all these things these are
41:34 - things i've kind of addressed a little
41:35 - bit but you know again this is the
41:37 - territory of other videos i have about
41:41 - um the pieces of the neural network
41:42 - themselves but and then we call this
41:45 - train function where this is interesting
41:47 - normally you're pairing some like if i
41:49 - were training an image classifier i
41:51 - would have the images and the labels so
41:54 - i'd have the training data and the
41:56 - targets
41:57 - but i don't have that because the target
42:00 - of the training data is the training
42:01 - data itself that's the sort of
42:04 - twist here with an auto encoder i'm
42:06 - trying to have data flow in compress it
42:08 - down and the same exact stuff come out
42:10 - so that's really this weird thing it
42:12 - looks like a mistake to me because it
42:13 - should be like x train and y train or x
42:16 - train and y targets
42:18 - but number of epochs is how many times
42:19 - through all the data batch sizes how
42:22 - many data points do i do before i start
42:24 - adjusting some weights et cetera
42:27 - and
42:28 - yeah and there's some stuff about
42:29 - loading the images and i'm using this
42:31 - jimp library so again i don't want to
42:33 - run through all of this but that's the
42:35 - idea so let's try running this right now
42:37 - and see what happens
42:39 - so first thing first oh no let's correct
42:42 - the error so first thing i'm going to do
42:43 - is going to say kit get pull origin main
42:46 - so i've already merged a pull request
42:48 - that came in
42:49 - um
42:51 - and so i merged it on the github website
42:54 - and now this is the command that i can
42:55 - type to receive that image here that
42:57 - that change locally
43:00 - oh i don't know why
43:01 - i'm getting this weird message and i'm
43:03 - also i
43:04 - all right so we have to deal with this
43:07 - two things have gone wrong here one is
43:10 - i guess the way my git is set up on this
43:12 - computer i haven't specified a sort of
43:14 - default way to reconcile so what if
43:17 - you've made changes in more than one
43:19 - place
43:20 - how are those changes reconciled with
43:22 - each other um there are different ways
43:25 - of doing it and i'm not going to get
43:26 - into that right now but i'm going to
43:28 - just i want the default one to just be
43:31 - the one that i'm going to do so i'm
43:32 - going to take this command
43:34 - and type it in
43:36 - now let's call pull origin mean again
43:39 - we're gonna have another issue
43:41 - so it's saying like aha you've made
43:43 - local changes to the following file
43:46 - that would be overwritten because i'm
43:48 - trying to pull in some changes that were
43:50 - made on the github website server itself
43:54 - but i also was messing around with it
43:55 - here so the only change i actually made
43:58 - was just and i can actually see it if i
43:59 - do i think git
44:01 - diff will show me
44:03 - it's just adding these two comments
44:05 - encoder and decoder so i could undo
44:07 - those but
44:11 - what i'm going to do is i'm going to say
44:12 - git
44:13 - add
44:15 - dot
44:16 - git commit
44:17 - i'm going to put a message in i'm
44:20 - adding
44:21 - encoder and
44:23 - decoder comments
44:26 - there we go and then now i should be
44:28 - able to
44:29 - pull the fix
44:32 - no problem it's merging it
44:35 - i'm not going to type in any more
44:36 - information about that and there we go
44:38 - so now that's coming now what was that
44:40 - change
44:41 - let's go take a look
44:45 - uh how does this 40 minutes in this live
44:47 - stream and i've barely gotten anywhere
44:49 - yet i guess that's the hopefully i've
44:51 - been talking a lot in ways that help you
44:52 - understand the world at least
44:55 - focused in on machine learning and
44:57 - javascript and that sort of stuff
44:59 - um
45:00 - and curvers is talking about reducing
45:02 - the latent dimension to something lower
45:04 - from someone yes yes yes my goal
45:06 - actually by the way is to have a browser
45:10 - page with sliders on it where you could
45:11 - manipulate each dimension individually i
45:14 - i i it does not seem realistic but i'm
45:16 - going to get that today i don't think
45:17 - there should be like four parts i really
45:19 - thought i could finish this but that's
45:20 - my goal so having it less so let's look
45:22 - at fixing number one
45:24 - so
45:25 - um and actually we could just look at
45:26 - the issue which maybe um described it
45:28 - better
45:30 - so you're using the same images for
45:32 - training your network and testing it
45:34 - this is due to
45:36 - array.prototype.slicestart returning a
45:37 - copy of the array from the index start
45:39 - to the end and not zero to the start so
45:42 - i had if you what what is this what's
45:44 - happening here i had
45:47 - um this is what i had
45:51 - and i did not realize that slice 500
45:54 - slices out the array from 500 to the end
45:57 - not 0 to 500 which is what i wanted
46:02 - and then
46:03 - now if i just put 500
46:06 - it'll take i don't have to put the end
46:08 - number because it'll take that to the
46:09 - end so that is a huge mistake that i had
46:12 - in the end i don't know to what extent
46:14 - it's going to make that much of a
46:16 - difference because everything i'm doing
46:17 - here is is utterly simplistic and
46:18 - somewhat trivial so so what that i use
46:20 - those 50 images but
46:24 - let's try
46:25 - um running it and i think if you were if
46:28 - you were here last time i was talking
46:30 - about how an auto encoder could be used
46:31 - to de-noise an image and i wasn't
46:33 - getting that to work this is that's
46:35 - probably why i'm not going to go back to
46:36 - that right now because i think that'll
46:37 - send me down
46:38 - you know at least a half an hour of
46:40 - investigation but let's run this again
46:44 - and it's training the model hopefully
46:46 - now off of 500 images not 50
46:50 - and it's going to do a 250 epochs we're
46:52 - seeing the loss go down which the loss
46:55 - is sort of a summary of the error like
46:57 - how well is it currently copying the
46:59 - images
47:07 - uh hi omar i'm reading your message and
47:09 - thank you tom i don't know what the
47:10 - penguins are for but i love penguins
47:13 - i we i had not gotten a loss below 0.1
47:16 - you can see it's really
47:18 - settled so clearly one of the things
47:20 - this we can learn from this is that if
47:23 - the loss is sort of like frozen uh you
47:25 - know it went down to 0.105 but you can
47:28 - see it's not really changing very much
47:31 - at like whatever number of epochs i'm at
47:33 - um so probably training the model
47:36 - for 250 epochs is quite unnecessary but
47:40 - let's let it finish that so after it
47:42 - trains it for those 250 epochs it's then
47:46 - going to
47:47 - generate 50 new images
47:49 - okay great so
47:51 - just let's go look at the directory that
47:54 - i'm in
47:58 - and
48:00 - we can see whoops
48:02 - wait a second
48:04 - where did it load the images from
48:06 - i'm confused well let's just see what's
48:08 - in the output
48:09 - it worked
48:11 - i'm i i'm a little bit confused because
48:15 - where did it load that i don't see the
48:17 - training data actually in the so hold on
48:19 - load
48:22 - data square
48:25 - but there's nothing in this
48:27 - oh no it's there i just don't know why
48:29 - oh yeah it's just the
48:31 - mac os was activated so this is the
48:33 - sorry about that
48:34 - ignore the last minute i was just
48:35 - confused um so this is
48:39 - these are the training images right
48:41 - these are 28 by 28 pixel squares that i
48:44 - generated in processing
48:48 - um
48:49 - and then
48:52 - and i'm getting all sorts of interesting
48:53 - um
48:56 - commentary in the chat so thank you for
48:57 - that i can't it's not possible for me to
48:59 - address all of it as i'm going but i
49:00 - appreciate it and i often do go back and
49:02 - read it afterwards
49:05 - so
49:06 - all right so now what i want to look at
49:07 - just to make sure things are working the
49:09 - way i intended them to is look at the
49:11 - output
49:12 - so these are
49:13 - the generated images now i cannot even
49:16 - discern the difference
49:18 - um in my assumption would be
49:21 - that these are slightly fuzzier like
49:25 - generally speaking my experience with
49:27 - working with an auto encoder is uh the
49:30 - output images are going to have a sort
49:32 - of fuzzier less precise quality to them
49:35 - than the input images but in this case
49:37 - i'm working with such
49:39 - like fixed kinds of images squares
49:42 - um
49:43 - that have of just black and white pixels
49:45 - at such low resolution i'm not sure how
49:47 - we're going to discern the difference so
49:49 - i want to see if i can get this stuff
49:52 - into a place where i can manipulate it
49:55 - so that's what i want to work on i do
49:56 - need to take a break so i wonder if
49:58 - actually that makes sense usually i just
50:00 - keep going and going but maybe i should
50:02 - just take a short break right now if you
50:04 - generate the images as 28 by 28 instead
50:07 - of reducing them the images are sharper
50:10 - i'm not sure what that means mini jimmy
50:14 - um and i'm of the wrong
50:16 - so let's let's let's go let me go a
50:18 - little bit further sort of think about
50:19 - what i'm doing here
50:24 - well
50:28 - um
50:29 - so is there a way
50:32 - this is what i don't know how to do
50:35 - my idea here is that
50:37 - uh and i and i do want to make this
50:41 - like let's actually try this let's let's
50:43 - do a little bit of this
50:45 - let's do it i don't know why i'm let's
50:47 - have the auto encoder go down to
50:51 - 64. i don't know how many layers it
50:53 - makes sense to do what if i just like
50:54 - went to 16 like i want to have 16.
50:57 - that's my goal
50:59 - um
51:01 - could i possibly
51:03 - just go from 128 to 16 is that like a
51:06 - terrible like silly thing to do
51:10 - and then this would go back to 128.
51:12 - should i put more in between i don't
51:14 - know but let's just see what happens if
51:15 - i go down to a really small number
51:18 - and
51:20 - um
51:22 - and then also the number of epochs
51:27 - where is that
51:32 - oh train model that's a parameter i pass
51:35 - in
51:36 - um train model
51:39 - 250 let's just do 100. let me run this
51:42 - again
51:43 - and that while i'm running while it's
51:45 - running i'm going to talk about what it
51:46 - is i don't know how to do
51:49 - so what i'm hoping i can figure out to
51:52 - do
51:55 - is
51:58 - how do i take
52:00 - this neural network architecture
52:03 - and basically
52:05 - make
52:07 - where is it
52:09 - this
52:11 - the input
52:13 - so how do i delete all this and actually
52:15 - add tr add data to produ from predict
52:18 - insert it into here
52:22 - and yes
52:23 - blue tj says i suspect it gets even
52:25 - fuzzier this is what i'm trying to test
52:27 - right now
52:28 - so we got around the same like loss and
52:31 - i could look 1049 these are new images
52:34 - but
52:35 - honestly
52:36 - we can see with 16 no problem i mean
52:38 - it's sort of hard for me to believe that
52:41 - did i like not save the code or
52:42 - something
52:45 - like like like if i change this to two
52:47 - like it really shouldn't work right so
52:49 - let's just make sure that this doesn't
52:52 - work let's change that to two
52:55 - because otherwise maybe something is
52:57 - wrong
53:03 - okay this is good news the loss is not
53:05 - going down
53:12 - i have a lot to say yeah i'm kind of
53:13 - picking the activation functions very
53:15 - arbitrarily i've talked about activation
53:18 - functions in other videos there's relu
53:20 - which is not how you say it but that's
53:22 - how i say it and sigmoid and um
53:26 - so i'm hoping the images that come out
53:28 - are no good here let's see
53:36 - ah they're not so bad they're just
53:42 - uh they're all basically the same
53:45 - it's just like a much bigger fuzzier
53:46 - square it's like only knows how to do
53:48 - one thing so that's great to see
53:50 - um
53:52 - let's try i want to see like what is the
53:53 - minimum can i get it down to eight
53:55 - again i wanted to have more complex
53:58 - imagery so i don't know what the point
54:00 - of getting it down to eight is with this
54:01 - but let's see
54:09 - i recall the loss being at 1.05
54:21 - all right so this looks pretty good with
54:22 - eight there's
54:27 - yeah and blue tj writes exactly what i
54:28 - was thinking there's leaky relu leaky
54:31 - relu and many rectified linear unit is
54:34 - what that stands for i don't know how
54:35 - much that explains anything to anybody
54:37 - but and many others it's quite hard to
54:39 - find the right one and know which one
54:40 - fits in your use case yeah so to be
54:42 - clear my motivation here is exploration
54:46 - and explanation
54:47 - not
54:48 - optimization not speed not efficiency
54:50 - not even producing a meaningful result i
54:54 - want to understand how these systems
54:55 - work and i want to be able to feel like
54:57 - i have some agency in manipulating how
55:00 - they work in and i feel like i do simply
55:03 - by the fact that i can change the total
55:05 - number of neurons at that middle layer
55:08 - the sort of smallest layer and see a
55:10 - very different result means things are
55:12 - working as expected
55:14 - that match the way that i understand how
55:15 - these systems work
55:17 - so you've got to fix the sigmoid
55:20 - um all right let me let me just see here
55:24 - i what i wanted was
55:26 - i know i want sigmoid as the last
55:31 - activation function because i want my
55:33 - values to be to be between zero and one
55:37 - but i don't know if the suggestion here
55:38 - is that i should just try relu all the
55:40 - way through or even don't worry about it
55:43 - just have it i'm just going to leave it
55:44 - as is
55:46 - right now
55:47 - but um i would love to
55:53 - um
55:55 - and kervers is saying that they got an
55:56 - auto encoder to work fine with just two
55:59 - latent dimensions i have two sigmoids i
56:02 - have three sigmoids i don't know i don't
56:04 - understand the comment okay i'm gonna
56:06 - come back to that i the thing that i
56:08 - want to do now
56:10 - is
56:11 - figure out how do i
56:14 - um how do i start
56:17 - from here
56:19 - once the model i is here
56:22 - so maybe what i should do is first save
56:25 - the save and load the model
56:28 - so hopefully this is as easy as
56:33 - let's look on the tfjs documentation
56:36 - i'll take my break after saving and
56:38 - loading
56:42 - layers model safe sequential model is
56:44 - what i'm using
56:46 - well there's no save function here but
56:48 - is this ultimately a layers model
56:49 - because sequential like extends that or
56:51 - something
56:53 - save model dot save i know a local
56:55 - storage is interesting oh but i'm not in
56:57 - the browser so that i do not want to do
57:00 - i mean i could just move this to the
57:02 - browser it's a little bit silly to be
57:03 - honest that i'm doing this in node
57:07 - but let's try this
57:12 - so what happens if i
57:14 - let's forget about testing the model for
57:16 - a moment
57:18 - oops
57:20 - now let's just try
57:24 - save and what if i do
57:26 - like if i give it a directory we'll put
57:28 - it all in there
57:30 - let's just see and let's
57:31 - let's do this for just like 10 epochs
57:34 - just to sort of see
57:35 - so i'm going to try
57:38 - i'll just call it model
57:41 - let's just see if this will save the
57:44 - model in a directory called model
57:53 - i'm just doing 10 epochs
57:55 - okay
57:56 - model is not defined oh my goodness oh
57:58 - my goodness what is wrong with me it is
58:00 - called autoencoder
58:08 - oh i forgot to address the other pull
58:10 - request
58:11 - um could not find any url well so
58:15 - i don't want it to be a url do i just
58:17 - need to have a folder called model
58:20 - will that do it
58:24 - let's see
58:28 - no
58:29 - no
58:30 - this did not work okay
58:32 - um
58:35 - indexeddb
58:37 - downloads my server
58:41 - what about a file
58:45 - does it really not
58:47 - work just to give it a direct
58:57 - talents okay
58:59 - uh
59:01 - all right let's look at the so let's
59:02 - address the pull request which maybe has
59:04 - a solution for it in it
59:06 - so um
59:10 - where where am i going to auto um
59:17 - yeah here we go all right so let's look
59:19 - at this pull request and actually let's
59:20 - just go to this issue
59:23 - so this is incredible what uh the chief
59:26 - has submitted here um
59:29 - i'm just going to read here want to make
59:30 - the code a bit more readable and
59:32 - organize everything in its own class and
59:34 - file
59:35 - yes
59:36 - yes yes so do i
59:38 - i opened a pull request number three for
59:39 - it i added a data source class which can
59:41 - provide training and testing data and
59:42 - there's an interface for it so
59:45 - more data like random mnist arbitrary
59:48 - images blah blah blah
59:50 - more layers divided into an encoder and
59:53 - decoder it can save its state so you
59:54 - don't have to train it every time the
59:56 - image transformer takes an array of
59:58 - normalized pixel images and saves it to
60:00 - disk so there's so much more
60:03 - here in terms of organizing refactoring
60:05 - the code so i didn't feel like i can
60:07 - merge this
60:09 - because
60:10 - um it's too it's like too too good it's
60:14 - like too much of a radical improvement
60:16 - over what i had before that i won't be
60:18 - able to easily continue this process
60:20 - this explanatory process i have so the
60:22 - chief if you're watching
60:25 - i don't know the best
60:27 - one i don't know what to do here with
60:28 - this one is i could wait and eventually
60:30 - merge this in later once the project is
60:32 - totally finished but i would like to
60:34 - have a version that kind of i'd either
60:36 - or maybe i can draw inspiration from
60:38 - this like implement some of these pieces
60:40 - during a live session but i think what
60:42 - might make sense is for this to live
60:45 - um in uh you know in as documented in
60:48 - the readme for this repo linking out and
60:50 - explaining these improvements so that
60:52 - somebody could sort of see the code that
60:54 - i've written in the live streams follow
60:55 - that along and then see how there is a
60:58 - version of it that's just much more
61:00 - thoughtful in terms of how it is
61:01 - organized
61:02 - so let's think about that the thing that
61:04 - i would really like is
61:06 - an excellent readme documenting all of
61:08 - these pieces
61:10 - um expects a file extension maybe
61:13 - a branch would work but um so a pull
61:16 - request with a nice readme that links to
61:18 - the different live streams and kind of
61:19 - like the um
61:21 - the two minute papers video and it kind
61:23 - of has some sample images in it i mean i
61:25 - should be doing that i just haven't had
61:26 - time so if somebody wants to really
61:27 - think about how this whole process could
61:29 - be documented in readme linking to the
61:31 - chief's work and all of that that would
61:32 - be amazing
61:34 - but let's take a look
61:36 - at the actual pull request
61:40 - because maybe we can get some hints for
61:42 - how
61:43 - to save and load the model from the disk
61:46 - because i'm not seeing it obviously in
61:48 - the tensorflow js documentation so let
61:51 - me just look for save
61:54 - this is for saving the images
61:58 - saving the images auto encoder oh
62:01 - so literally i'm doing it right but i
62:03 - just need to put
62:05 - oh and it's
62:07 - oh and it's divided into an encoder and
62:10 - a decoder so that's also
62:13 - a probably a clue to what i actually
62:16 - want to do
62:17 - i have to understand so let's first just
62:19 - get it to save
62:23 - so
62:24 - is it just this
62:28 - file colon slash model
62:32 - with another slash let's try this
62:38 - a little tiny box here
62:40 - yeah
62:41 - i think this might have worked
62:49 - so one thing we can do is we can look at
62:51 - oh i've got it here what am i doing
62:53 - we can see the model files we can see
62:55 - this um
62:58 - the json which is basically a
63:01 - configuration file describing the
63:04 - architecture of the model it's a
63:06 - sequential model here's all the here's
63:08 - all the layers the kind of layer it is
63:10 - the activation function the number of
63:11 - units etc etc so that's great so then
63:16 - let's save a model trained to a hundred
63:18 - epochs
63:22 - and
63:23 - where do i want to do that
63:26 - so go back to 100
63:50 - all right almost 200 we got down to .108
63:53 - of a loss
63:54 - 107.
63:56 - can we get to a six show me a six show
63:58 - me a six before you finish i want to see
64:00 - that six
64:02 - that's fine we got
64:04 - zero point one zero seven
64:07 - now this should be live just to be sure
64:09 - 1101 am yep that's a new model overwrote
64:11 - the previous model by the way this
64:13 - weights.bin file is all of the trained
64:17 - weights
64:18 - so in theory every time i'm saving the
64:19 - model
64:20 - this is not changing at all model.json
64:23 - the weights are what i'm changing so i
64:25 - could have different weights file if i
64:26 - wanted to try different configurations
64:28 - and swap them in and out
64:30 - what are the weights just for any of you
64:31 - who might be kind of just joining right
64:33 - now it is the value the sort of weight
64:37 - of every single connection between any
64:39 - given node in the system and another
64:41 - node uh well the layers are connected
64:44 - sequentially so
64:46 - um
64:47 - you know the first first layers aren't
64:48 - connected to the last layer they're
64:50 - connected through
64:51 - each other all right um all right now
64:55 - in theory then
64:57 - there shouldn't be
64:59 - i should be able to
65:02 - um and it's this is very awkward what
65:04 - i'm doing here
65:07 - but i'm just going to let me just do it
65:09 - this way
65:12 - let me comment out all of this one more
65:15 - time
65:16 - and then
65:18 - let's get test back
65:21 - oh i do have to load the images sorry
65:29 - and let's see can i do
65:32 - auto const auto encoder
65:35 - equals
65:36 - await
65:38 - how do i call load
65:44 - let's just look in our cheat sheet
65:48 - this is terrible i should look in the
65:50 - documentation model.load
65:53 - huh
65:57 - i'm confused all right i'm going to look
65:58 - at let's look at the documentation
66:01 - so where is load
66:03 - save
66:05 - load sync i don't need to load sync
66:13 - load layers model
66:17 - okay that should be it tf
66:19 - load layers model okay
66:25 - and then i should be using the same path
66:29 - but maybe i say
66:30 - model.json
66:32 - here
66:35 - so
66:38 - let's see if this works
66:40 - i'm going to just to be 100 sure i'm
66:42 - going to delete all these outputs that i
66:44 - had previously
66:46 - and now
66:47 - instead of
66:49 - building the model and training the mile
66:51 - i'm just loading the train model from a
66:53 - particular file this is how i'm going to
66:55 - be i'll just move right into the browser
66:57 - because i can um i'll do
66:59 - yeah i mean once i have a saved i'm
67:01 - going to use node just for training the
67:02 - model and then i'll once i've saved it
67:04 - the files will just bring it right into
67:05 - the browser i think i think that makes
67:07 - the most sense to do
67:09 - yeah i was thinking like oh i could set
67:10 - up like a web server and have the
67:12 - browser send like get requests and the
67:14 - the server like generate the images and
67:16 - send it back but that's like a whole lot
67:17 - of unnecessary trouble right now
67:21 - so let's run this
67:24 - okay ah i think this might have worked
67:30 - output
67:31 - yeah 1104 okay we did it
67:35 - yes all right we're in really good shape
67:37 - here
67:38 - um so i'm going to take a short break
67:40 - just so i could turn the heat back on
67:42 - and
67:43 - check out brilliant as a sponsor for a
67:45 - moment but let me just see i saw
67:46 - somebody ask
67:48 - in order to recover the information of
67:49 - the squares you should use relu in the
67:51 - decoder part as activation functions
67:53 - because they are inverse functions the
67:55 - last layer is okay as sigmoid okay that
67:58 - sounds very reasonable to me
68:00 - thank you and k asks what exactly does
68:02 - an auto encoder do um unfortunately so
68:05 - an autoencoder just as like a one sense
68:07 - is a copying machine it's taking inputs
68:09 - and generally trying to generate the
68:11 - same output while compressing the data
68:13 - inside of a neural network there's a lot
68:15 - more to say about that the two-minute
68:17 - papers video on autoencoder and my
68:19 - earlier explanation in today's live
68:20 - stream should give you much more detail
68:23 - but just for anybody who just happened
68:24 - to tune in right now so what's coming
68:27 - next i hope everybody can stick around
68:29 - please stick around
68:30 - i'm going to just take a short break but
68:33 - what's coming next is
68:35 - i'm going to take this trained model and
68:38 - move it into the browser so that i can
68:40 - see
68:41 - the images appear in the browser and
68:44 - animate them which will be very exciting
68:47 - so before i do that i want to thank
68:51 - today's sponsor of the coding train
68:54 - brilliant
68:56 - um
68:57 - i can't emphasize
68:59 - how important it is when you're learning
69:01 - a new concept to be able to try it
69:03 - yourself so me demonstrating stuff in
69:06 - this video i hope is entertaining for
69:07 - you i hope it's turning the wheels in
69:10 - your brain maybe you're even doing it
69:12 - along with me or you're trying it later
69:14 - that's the way to learn but brilliant is
69:17 - all about trying it yourself in spades
69:20 - topics in math in science and computer
69:23 - science anything you can think of there
69:25 - are lessons and challenges and courses
69:28 - and puzzles and all of them are
69:29 - interactive that allows you to try it
69:31 - yourself
69:32 - so um i'm gonna switch back over to the
69:36 - brilliant website itself
69:38 - um you just before i do though that's
69:40 - the url you can actually sign up for
69:42 - free there's a ton of stuff you can do
69:43 - on brilliant for free if you use that
69:45 - link it lets them know you found out
69:46 - about brilliant through the coding train
69:48 - thank you
69:49 - and also that link will give you the
69:52 - opportunity to have a 20 discount on the
69:54 - premium subscription but even better
69:56 - than buying it for yourself let me just
69:59 - quickly mention
70:01 - that uh you'll notice this button up
70:03 - here because i already have them logged
70:04 - in with a premium account this gift
70:07 - premium it is gift giving season and uh
70:10 - it's hard to
70:11 - find things to buy for people it's also
70:13 - i don't know you know this is plastic
70:15 - and packaging and so gifting a premium
70:17 - subscription to brilliant for somebody
70:19 - who loves learning i mean that's what
70:21 - i'm going to be doing for people um uh
70:24 - um you can do that you'll get this
70:26 - through the same link you'll get the 20
70:28 - uh discount that link there so um i
70:31 - can't recommend that enough
70:33 - let's look at this i i was kind of going
70:36 - to go to the logic there's a bunch of
70:37 - courses so i can show you just really
70:39 - quickly like these are what the
70:40 - interactive lessons look like their
70:41 - logic course has been totally redone
70:44 - with lots of new interactivity so you
70:46 - can see like there's a lot of
70:47 - explanation and then interactive things
70:49 - you can do we're talking about neural
70:50 - networks like all these things i'm
70:51 - talking about about weights
70:53 - we can see there's a whole course all
70:55 - about neural networks that you can
70:57 - browse through um it's a great
70:59 - complement
71:00 - um
71:01 - oh and i'm speaking of which daniel
71:03 - montegrano said can you try loss equals
71:05 - mean squared error
71:07 - and if you want to know what mean
71:09 - squared error is and all that stuff i
71:10 - have a feeling that the brilliant course
71:12 - explains that stuff really really well
71:14 - uh so thanks for that chat message so i
71:16 - think what i want to do today
71:19 - is uh i'm kind of again like i didn't
71:22 - have a plan for this so um if i go to
71:24 - courses you can see these are two
71:26 - courses that i would certainly recommend
71:28 - beautiful geometry is personally my
71:29 - favorite right now and then also the
71:31 - logic course we can scroll through and
71:33 - see all of these popular ones
71:35 - recommended for parents and teachers
71:37 - learning paths you know you can you use
71:39 - if you're watching these probably all
71:41 - appeal to you
71:42 - so um
71:44 - but i think today for fun let's try this
71:47 - nine nine plus challenge that i have not
71:49 - looked at
71:52 - sometimes the best way to solve a
71:53 - problem is by just doing something with
71:56 - it uh-huh that's what i've been talking
71:57 - about then slow down and think about
71:59 - what you're doing for example think
72:00 - about what you need to do to solve just
72:01 - one part of the problem here's a warm-up
72:03 - challenge try it yourself
72:05 - drag the tiled numbers up into the plus
72:14 - note that the sum of all the available
72:15 - tiles is zero yet the goal is to make
72:17 - the row sum and columns both positive oh
72:20 - i did not know that
72:22 - uh oh i did
72:24 - wait no oh no no no i didn't because
72:26 - that's negative 1. so i didn't do it
72:27 - right
72:33 - when i first see somebody refused to
72:34 - even try to solve it they glance at it
72:35 - and claim it it's impossible
72:38 - yeah it's impossible
72:39 - i can't do it
72:41 - oh i can put this in the middle
72:43 - well hello
72:52 - no this goes here and this goes here i
72:55 - did it
72:56 - yes
72:57 - [Laughter]
72:59 - if you start by filling the rows sum to
73:01 - one how many different ways are they
73:02 - okay three dwell a little bit so
73:04 - so now it's going to explain
73:06 - 2 goes in the middle
73:09 - yeah this is basically what i did thank
73:11 - you very much
73:13 - your solution might look a little
73:14 - different as long as the 0 and negative
73:15 - 1 are together in the same row or column
73:17 - and the one and negative two are
73:18 - together in the other both sums will be
73:20 - correct
73:21 - so we've shown that it's definitely
73:23 - possible to arrange negative two
73:25 - negative one zero one and two into a
73:26 - plus that's a positive let's take that
73:28 - one step further is it true that if you
73:30 - arrange any five number tiles in a plus
73:32 - and put a positive value in the center
73:35 - the row sum plus the column sum will be
73:37 - larger than the sum of the five tiles
73:40 - can you prove why this is true well that
73:41 - totally makes sense intuitively because
73:43 - you're using the
73:45 - the center tile twice
73:48 - and you're using all the other tiles
73:49 - once
73:51 - so
73:52 - no matter what
73:54 - it's going to be more because you're
73:56 - adding more numbers essentially
73:58 - okay wrap things up here's a bonus
74:00 - challenge that's fair bit more complex
74:02 - than the plus arrangement however it can
74:04 - be solved using the same algebraic
74:05 - strategies to make the puzzle above and
74:06 - today's challenge solvable
74:09 - oh i have to get five five five
74:11 - everywhere well should i try this or
74:13 - should i just let me just move on to the
74:14 - challenge or though maybe i should try
74:15 - this
74:18 - uh
74:20 - i mean
74:23 - if the zero my my intuition is that the
74:26 - zeros and ones should just be in the
74:27 - corner
74:30 - oh but that's going to be
74:34 - the zeros
74:35 - i don't have enough zeros to put in the
74:37 - corner
74:39 - but if i did that
74:42 - right that's five that's five
74:45 - this won't be five
74:48 - oh but now i can do this
74:50 - oh but that's only four
74:53 - all right what am i missing here people
74:58 - we've got everything but this one
75:03 - can i what if i move this
75:05 - here and this what if i put a 2 in the
75:07 - corner
75:11 - oh now i'm confused what number should
75:12 - go in the corner
75:15 - okay hold on again
75:19 - if i put the two here
75:23 - the threes can't be together
75:28 - so the threes always have to be in the
75:36 - how many threes are there just three
75:39 - look at the chat no nobody's solving
75:41 - this for me in the chat
75:44 - oh i have to fit him with the
75:45 - awkwardness of not being able to figure
75:47 - it out
75:48 - okay
75:50 - um what am i missing i should have read
75:51 - all the explanation
75:53 - so
75:58 - so the ways to to make five out of these
76:01 - numbers and only have four numbers are
76:05 - one one one two
76:09 - two two one
76:12 - three two zero zero three two zero zero
76:19 - so
76:21 - is is three in the corner gonna help me
76:25 - or is two in the corner gonna one in the
76:27 - corner are gonna help me more what if i
76:29 - put all the ones in the corners
76:33 - there's only three of each other i'm
76:35 - confused yeah there's hold on reset
76:38 - yeah there's three of each i see
76:41 - definitely want high number in the
76:42 - corner to be used twice yeah
76:46 - okay three
76:48 - hello come on three
76:51 - so if that three is there
76:57 - uh let's put this three here
77:00 - let's think about this
77:02 - then now if where could a two go
77:11 - um with the only other place to put it
77:13 - through i could put a three here
77:15 - all right so let's think about this
77:17 - if the 3 is here
77:19 - if i put 2's here
77:25 - oh i can't put
77:27 - everything has to be a 0.
77:29 - what if i did that
77:34 - oh it can't there's not four zeros so
77:36 - one of these has to be a one
77:42 - then one of these can these can be zeros
77:50 - and then
77:53 - three
77:54 - ah no no no no no so close but no
77:58 - because the 1 is going to mess
77:59 - everything up here
78:04 - you have a total of 18 you want to make
78:06 - it add up to 20. so the tile you need to
78:07 - reuse has to add up to 2.
78:10 - well that's interesting so maybe the
78:12 - ones
78:13 - are what needs to be reused
78:16 - just one one
78:17 - oh hey let's think about this this is
78:19 - the strategy oh this is great
78:22 - 3 times 3 is 9.
78:26 - plus 6 is 15
78:28 - plus 3 is 18
78:30 - but i need to have a total of 20. so a 1
78:34 - being reused is one extra and another
78:37 - one being reused is another extra
78:40 - okay this makes sense this makes sense
78:42 - as a way of following it now then these
78:44 - have to be 0.
78:46 - so then a 3 and a 2 can go here
78:52 - 3 can go here a 3 can go here
78:58 - and then a 1
79:00 - no
79:02 - oh a 3 can go here
79:04 - and a
79:06 - 0. then a one oh i think i did it and a
79:10 - two
79:11 - and a two
79:15 - thank you forever that so that was the
79:17 - logic that was being explained that i
79:18 - like scanned over
79:21 - from first of all by the way these are
79:23 - so fun like if i what i really would
79:25 - like to do is make a p5.js sketch where
79:27 - you can make these puzzles i mean that's
79:30 - um
79:32 - all right
79:33 - oh and uh
79:35 - so i maybe i could have also done this
79:37 - mike on the box says all the corners are
79:39 - zero but one is a two maybe it would
79:41 - also work that way so i i'd love to
79:43 - decide are there two solutions all right
79:46 - so now here's the actual challenge
79:48 - is it possible to arrange five square
79:50 - tiles numbered one two three four five
79:52 - into a plus so the sum of the three tile
79:55 - column and sum of three tile row so we
79:57 - need to add up to 18
80:00 - and these numbers add up to 9
80:03 - 12
80:04 - 14 15. so i need three more no it's not
80:08 - possible i was gonna put this as a poll
80:10 - but i think it's not possible because
80:13 - there's no number i could put in here
80:14 - twice
80:16 - to give me three extra
80:19 - because one gives me one extra two gives
80:21 - me two extra three gives me oh no three
80:23 - gives me three extra yes
80:26 - [Music]
80:28 - three has to go in the center that's
80:30 - totally wrong i don't know what i was
80:32 - thinking there i was thinking three
80:33 - doesn't divide into two like so i can't
80:35 - put a one and a half in the center but
80:37 - no i just need three more did i do that
80:39 - right
80:40 - let's see
80:41 - uh nine i i i you know i usually like to
80:44 - do these with a poll in the chat
80:46 - but there's uh so i could do let's let's
80:49 - just make the poll
80:51 - it possible or not possible while i'm
80:53 - figuring this out i mean i think i
80:54 - hopefully i was right so i'm gonna make
80:56 - the poll possible
80:58 - or not
80:59 - yes or no
81:01 - no no no add another option
81:04 - how do i delete that now
81:08 - no
81:09 - delete okay
81:10 - so there should be a poll that went up
81:12 - into the chat just now
81:14 - it might take a minute to post where you
81:16 - can just give me is it possible or not
81:18 - and i'm going to work it out
81:19 - so we need to add them up to nine
81:22 - wait what
81:30 - i'm so confused eighteen
81:34 - nine
81:38 - how do i do oh no no four okay okay okay
81:41 - the five and the four can't be together
81:43 - obviously
81:44 - that's eight yeah nine okay this one's
81:47 - two
81:48 - why was the other one so much harder for
81:49 - me
81:51 - there we go i've made them hit submit
81:55 - and now we can see the solution
81:58 - which is that 3 the sum of the row and
82:00 - column is 18. the sum of all the tiles
82:03 - is 15. the middle tile is counted twice
82:05 - so the middle tile must be 18 minus 15
82:07 - or 3.
82:09 - and then of course
82:11 - now we just need the desired sum in the
82:12 - row and then the desired sum in the
82:14 - column okay
82:16 - 93 of you said yes you got it right
82:20 - uh um and so uh thank you i've been like
82:24 - is this not fun like this is what i want
82:26 - to do later today with my free time are
82:28 - you like that
82:30 - and i just want to emphasize like um if
82:33 - you like a lot of the algorithmic art
82:35 - stuff or generative art stuff that i do
82:36 - on the channel the beautiful geometry
82:38 - course is really the one for you so
82:40 - thank you brilliant for sponsoring the
82:41 - coding train if you're watching and have
82:43 - a minute right now i turn the heat on
82:46 - uh to sign up at brilliant.org cutting
82:48 - train you could do that for free if
82:49 - you'd like to buy the premium
82:50 - subscription for yourself or gift it to
82:52 - a friend or loved one or anyone um
82:55 - you'll get the first 200 people to do
82:57 - though will get 20 off okay i'm gonna be
82:59 - back in about
83:01 - uh two or three minutes to see if we can
83:04 - get the auto encoder running in the
83:06 - browser so don't go anywhere
83:09 - come back stay with me i'll be back i'm
83:11 - gonna turn the heat on for two or three
83:12 - minutes warm up my hands and i'll be
83:14 - right back
83:16 - [Music]
83:23 - so
83:25 - [Music]
83:34 - [Music]
83:41 - [Music]
83:46 - oh
83:48 - [Music]
84:07 - [Music]
84:20 - [Music]
84:29 - [Music]
84:36 - [Music]
84:49 - [Music]
85:03 - [Music]
85:14 - [Music]
85:19 - [Music]
85:25 - [Music]
85:31 - do
85:35 - [Music]
85:43 - [Music]
86:02 - do
86:18 - [Music]
86:28 - all right i am back just out of
86:30 - curiosity how loud
86:33 - is that hum in the background right now
86:35 - which is the heater going so i'm gonna
86:38 - if it's tolerable i think i'll leave it
86:40 - running for a little bit longer
86:45 - all right everyone
86:47 - so
86:49 - the next thing that i need to do
86:53 - um and i'm keeping an eye on the chat in
86:55 - terms of the volume is i want to just
86:56 - really quickly create a
87:00 - webpage that loads the model and draws
87:03 - the output
87:06 - to a canvas so i'm going to use p5 and
87:09 - tensorflow.js and i believe that at some
87:11 - point there's no reason why i couldn't
87:13 - use ml5 which i would like to but i'm
87:16 - right now i'm not sure if ml5 supports
87:19 - all of the sort of things that i'm doing
87:21 - with tensorflow.js you might be asking
87:23 - like what's ml5 so ml5 is a javascript
87:26 - library
87:27 - that i
87:29 - helped to work on with a lot of
87:30 - wonderful collaborators and people
87:33 - that is a sort of helper layer on top of
87:36 - tensorflow.js to use a lot of
87:37 - pre-trained models and do a lot of stuff
87:39 - and if you want to learn more about ml5
87:42 - if you go to thecodingtrain.com under
87:44 - learning uh ml this the this video
87:47 - series
87:48 - um has just a ton more stuff so at some
87:52 - point
87:53 - my hope would be
87:55 - um
87:58 - it's oddly cut i love all the comments
88:00 - about the sound it's oddly soothing
88:02 - tolerable i love me some calming white
88:04 - noise it's audible but we want you to
88:06 - stay warm so it's all right sounds like
88:08 - a vacuum cleaner all right i'll leave it
88:10 - running for a little bit here
88:11 - one of the reasons why i don't want to
88:13 - run it and let me just vamp for a little
88:15 - bit is that
88:17 - i have this idea
88:19 - that one of the things i want to do with
88:21 - the coding terrain in the new year
88:23 - is make some more kind of
88:26 - video essay like video essay like videos
88:30 - about things like an auto encoder and
88:32 - narrate the process using clips from
88:35 - these live streams so that you could get
88:38 - maybe the sense of how to build the
88:40 - whole project in a 10 to 20 minute video
88:43 - and then if you wanted to of course you
88:45 - could go back and watch all the
88:46 - development during the live streams so
88:48 - i'd have to script that
88:50 - edit that have some animations and
88:52 - things i love your feedback i'm trying
88:53 - to think of like you know
88:55 - i'm on sabbatical for my job at nyu
88:57 - starting in the new year so i'm going to
88:59 - be focusing not full time on the coding
89:01 - train of a lot of other projects and
89:03 - things to work on personally and for
89:06 - creative coding community but
89:08 - i do want to ramp up and at least be
89:10 - doubling my time or tripling my time
89:12 - that i'm currently spending on the
89:13 - coding trade which is very very little
89:15 - so thank you by the way to everyone i
89:17 - don't know how many of you are watching
89:18 - but thank you to all of you who continue
89:20 - to support me through all the ways that
89:21 - you do even when i feel like i'm not
89:24 - doing it enough for good enough so i
89:27 - really appreciate that um
89:30 - okay mike on the box is asking about the
89:32 - cabana i've moved the cabana may come
89:34 - back
89:35 - but right now i'm i'm in a garage which
89:38 - is much bigger than the cabana so
89:41 - uh yeah
89:42 - um okay
89:44 - uh okay so
89:47 - let's go back here okay so what i'm
89:49 - gonna do is
89:52 - let's just go into
89:54 - this project
89:56 - and create a new folder
89:59 - i'm going to call it i'll call i mean at
90:01 - some point i could have this be a full
90:03 - stack web application where the you can
90:06 - send a message to the server to like
90:07 - retrain the model so i'm going to like
90:09 - sort of build it in the way that i might
90:11 - do that so i'm going to call this public
90:13 - and in public i'm going to create
90:15 - index.html
90:18 - and
90:19 - another new file
90:21 - called oops
90:22 - ah what am i doing here
90:25 - don't save
90:27 - don't save so index.html
90:30 - and then i want to create another new
90:32 - file
90:37 - called sketch.js it's in the wrong place
90:42 - i'm sorry you can't see what i'm doing
90:45 - oh my goodness
90:46 - i totally forgot to be recording this
90:48 - whole session
90:50 - so much for that whole speech on what
90:52 - i'm trying to do
90:57 - oh my god i'm the worst
91:00 - i'm the worst
91:02 - well i'm going to start recording it now
91:04 - now i'm recording it so that whole
91:07 - i mean they could still use clips
91:08 - obviously it's being recorded in the
91:09 - sense that when i'm broadcasting it's
91:10 - being recorded but
91:12 - ah
91:17 - okay so much for my grand plan there
91:19 - well still still possible
91:26 - okay
91:27 - um
91:30 - the quickest way for me to
91:32 - let me just get let me just go to the p5
91:34 - web editor
91:36 - this is my html file
91:40 - uh
91:41 - oh whoops that's in the wrong place
91:44 - public yes move
91:48 - and then my sketch file is
91:52 - it's very hard to type when your hands
91:54 - are cold
91:56 - function draw
91:59 - uh
92:07 - what
92:08 - i've got some crazy autofill stuff going
92:10 - on here
92:22 - and
92:23 - um
92:26 - let's just do okay let's move the model
92:29 - into public as well
92:33 - and then when i run the node script
92:36 - to train a model
92:38 - we want this to go into
92:44 - file public but
92:46 - i'm not doing that right now
92:49 - what i'm doing here is
92:52 - i don't need the sound library
92:56 - let's go back to
92:59 - the tensorflow.js documentation
93:07 - no not overview
93:09 - api reference
93:14 - okay maybe overview
93:19 - get started
93:23 - no there's still a nice link there's a
93:24 - nice link to ml5 here that's so lovely
93:28 - um
93:34 - i'm just looking for like the um guide
93:36 - maybe
93:39 - i just want to know what where the
93:41 - script tags i need
93:46 - install
93:50 - but i want tensorflow.js to install ah
93:53 - this is why are things so hard to find
93:56 - is it just me
93:57 - is it me
94:00 - setup
94:02 - there we go i found it it was in an
94:04 - obvious place can i use tfjs 2.0 i hope
94:07 - so
94:09 - why not so let's try this
94:15 - okay so i've got tfjs
94:18 - now
94:20 - what i'm going to do is i'm going to
94:22 - open
94:23 - a separate
94:27 - web server
94:29 - so ultimately again like where i might
94:31 - go with this project is have it all be
94:33 - one application where there is a server
94:36 - that you can like send messages to to
94:38 - like train them retrain the model and do
94:40 - different things and then there's a
94:41 - client that can load the model and do
94:44 - stuff but right now i'm just treating
94:45 - those as separate projects
94:47 - so this is
94:48 - the client
94:50 - and you can see that my
94:54 - p5.js sketch
94:56 - is loading oh style.css i don't need to
94:58 - worry about that
95:00 - so let's
95:04 - i don't know what how this got over here
95:09 - let's get rid of that
95:14 - great
95:15 - so now i have so the goal that i have is
95:17 - to see an output image in that canvas
95:22 - uh
95:24 - yeah sorry everybody about the sound
95:27 - of course now i'm finally recording now
95:30 - is when i have the bad sound and i
95:31 - wasn't recording the whole time when i
95:33 - had the good sound but i just got to get
95:35 - it to warm up a little bit more in here
95:37 - um i don't know
95:39 - this is not something that i really
95:40 - thought about
95:42 - how to
95:44 - once i once i
95:46 - once i solar power this place maybe some
95:48 - electric heaters i can do that i'll be
95:50 - quieter we'll see
95:52 - um
95:56 - okay so now i should be able to
96:01 - have a
96:04 - variable called like auto encoder
96:08 - uh auto encoder equals
96:12 - tf
96:14 - so this should be the same exact code
96:16 - that i'm doing on the server
96:21 - the difference being
96:26 - i shouldn't need the file path anymore
96:29 - and this has to then be an async
96:30 - function
96:33 - and let's do console log
96:36 - auto encoder so let's see if this works
96:41 - well that's a good sign
96:43 - this looks good
96:46 - i feel like it loaded it i got no error
96:48 - and i see an object that looks like a
96:49 - model
96:51 - so now
96:52 - if i go back to the server code
96:55 - and do generate
97:04 - okay
97:05 - x test
97:07 - so now what i want to do
97:09 - is in the draw loop i'm going to just
97:12 - feed at some noise
97:14 - um
97:16 - i'm going to say no loop oh where am i
97:18 - i'm in the web header i don't want to be
97:19 - in the web editor i could be in the web
97:21 - editor but i'm not doing it there
97:23 - um
97:24 - i'm going to say no loop is the font
97:26 - size okay for everybody it's a little
97:28 - smaller than what i usually work with
97:32 - output is auto now x test has to be a
97:35 - tensor
97:37 - so again at some point
97:40 - um
97:43 - where did i make x test
97:45 - images slice so let's think about this
97:48 - what is one image
97:52 - oh i could draw an image
97:56 - okay
97:58 - uh
97:59 - like what if i just make the image a
98:01 - blank array
98:03 - and i know there's a higher order
98:05 - function like that i could use fill
98:08 - and so 784 pixels
98:14 - and if i make that just like a random
98:15 - number i'm just going to feed noise in
98:17 - right now because i'm not sure what else
98:18 - to do
98:20 - um
98:21 - and then
98:23 - uh
98:26 - this would be
98:32 - turn that into a two that image into a
98:34 - 2d tensor
98:37 - and like i only have one
98:39 - so it's just that one image in an array
98:41 - is this
98:43 - right where
98:46 - like
98:50 - images like tensor2d imageslice500 yeah
98:53 - and then
98:55 - and then i should be able to just call
98:56 - predict
99:10 - and then this is an a if this is an
99:12 - async function
99:16 - i get the new image
99:22 - all right let's just try console logging
99:23 - this
99:27 - call this output image
99:34 - so it should just be one and so i'm just
99:36 - doing one image i'm creating a random
99:38 - array of noise
99:40 - i'm turning it into a tensor i'm sending
99:42 - it into the auto encoder i'm getting
99:44 - something back out and just logging it
99:46 - to the console let's see if this works
99:51 - okay good sign
99:53 - why did i do it twice
99:57 - why did i do it three times
99:59 - because i have no loop i wonder if
100:02 - something weird about the async and the
100:03 - no loop let's get rid of draw for a
100:05 - second here
100:08 - and just do this once
100:12 - and let's not log the autoencoder
100:14 - anymore let's run it again
100:17 - okay great once
100:18 - so i got my image now i should be able
100:21 - to and this is very silly what i'm going
100:23 - to do but it's and can i just do this
100:26 - will that work with or do i have to do i
100:28 - probably have to put parentheses around
100:29 - the await
100:33 - so that's the output image okay now what
100:37 - i could do is say load pixels
100:42 - update pixels
100:45 - oh no no no i want to draw it bigger so
100:48 - i'm going to do this this is a little
100:49 - crazy but i'm just going to draw it as a
100:52 - again sorry for all the noise in the
100:53 - background
100:57 - but it's making it possible for me to do
100:59 - this right now
101:03 - um
101:07 - oh i know i need another bracket
101:09 - and then i'm going to say
101:10 - rectangle i
101:13 - i got to fix my vs settings i times 10
101:17 - j times 10
101:19 - 10
101:20 - really square is what i want
101:23 - i'm going to say fill
101:27 - out
101:29 - output
101:30 - image
101:33 - i plus and this should be a j
101:38 - i plus j
101:44 - times the width which is 28. and again
101:48 - i'm hardcod i'm just i'm hardcoding all
101:50 - sorts of stuff
101:56 - um
101:58 - i'm looking at the uh all right
102:00 - everybody let's be nice to each other
102:02 - let's be nice to the fact that i need to
102:03 - run a heater let's be nice to the fact
102:05 - that we're all asking questions and not
102:06 - sure what's going on i'm very confused
102:08 - i'm not explaining everything let's be
102:10 - nice to each other in the chat please um
102:13 - so i'm looking for the pixel that
102:15 - corresponds with the square that i'm
102:17 - going to render which is the x plus the
102:18 - y times the width
102:20 - and then multiply this times 255 now
102:23 - this should probably just be noisiness
102:26 - but let's see
102:30 - uh
102:31 - oh what what import uh
102:34 - just trying to auto import stuff
102:41 - i've never seen so excited to see a
102:43 - square in my life
102:44 - that is insanity
102:48 - oh my goodness
102:54 - i didn't even that's funny
102:56 - i could like basically have the latent
102:58 - space be the beginning
103:00 - wow this is crazy
103:04 - i
103:05 - i weirdly i don't know why
103:08 - but i weirdly want to do this
103:12 - just because i like seeing the full
103:13 - square
103:17 - but also that's silly
103:20 - what i could do let's do this
103:23 - this is so this is like the silliest
103:24 - thing i've ever done in my life that
103:26 - this is what i'm focusing on right now
103:32 - how do you do this
103:36 - is that correct css
103:40 - yeah that's what i i just wanted to do
103:41 - that okay
103:43 - right how did it produce the script
103:45 - monothon asks everything that i'm i'm
103:48 - asking right now in my head how did it
103:50 - produce a square if the input wasn't a
103:52 - square that's cool right so i think the
103:56 - denoising should work now all right
104:01 - you would think right
104:04 - can this model
104:07 - let's do the following
104:08 - let's do an a real input square and a
104:11 - real output
104:13 - so um 280 times two
104:17 - 560 right
104:20 - and then
104:29 - i'm going to do this create graphics or
104:31 - create image
104:34 - uh 28 by 28.
104:37 - um
104:38 - oh no i need to do create graphics
104:41 - oh no this is fine
104:43 - i'm drawing it a square i can it's fine
104:45 - i don't need to put it on a separate
104:55 - background 255 now
104:59 - okay so what i want to do now is have
105:02 - the filter invert 100
105:05 - what i want to do is have an input image
105:07 - and see the output image so let's draw
105:10 - the output image
105:14 - on the other side
105:17 - and now i want to see the input image on
105:19 - this side so the input is so this would
105:23 - be this can be a function
105:27 - a
105:28 - function render
105:31 - sum
105:33 - array
105:34 - image array
105:37 - at some
105:38 - x and y
105:41 - so this would be x
105:43 - x plus
105:44 - that and this is the image array
105:48 - and the width and height i've still got
105:50 - hard coded here in this like scale 10
105:53 - that should be fixed at some point but
105:55 - now what i should be able to do is
105:56 - render
105:59 - output image
106:00 - at 280 comma zero
106:06 - still getting the same thing a little
106:08 - i'm a little bit suspicious of the fact
106:10 - that the
106:11 - square never changes its size
106:16 - oh no no it's different it's different
106:18 - each time just very subtly so okay
106:21 - now
106:22 - there's no reason why i can't say render
106:25 - image zero zero
106:31 - oh this is insane
106:33 - so i could make this like so
106:36 - i want to get to the browsing the latent
106:38 - space part
106:40 - but weirdly i could just turn this into
106:42 - like
106:44 - a pearl and noise field
106:46 - that's like subtly changing over time
106:49 - and see what happens to my output image
106:53 - like i'm not even like the whole point
106:55 - of this is so i can get down to that
106:56 - reduced dimensionality but i can
106:58 - actually play with this input because
106:59 - it's just 784 values
107:02 - this is this is so i'm so excited by
107:05 - this i can't i mean this is like the
107:07 - most basic of the basic of the basic but
107:09 - i'm uh this is just like
107:12 - really unlocking for me um
107:15 - this like sometimes it just feels like
107:17 - total matte and this feels this even
107:19 - feels like magic but it when you see
107:20 - like these really sophisticated
107:22 - generative models but really being able
107:24 - to like all the pieces of everything
107:25 - going on here we have coded and designed
107:28 - yes the actual machine learning math is
107:30 - coming from the underlying tensorflow.js
107:32 - but how we're manipulating this what
107:34 - data we use of total control over
107:37 - so
107:38 - um
107:40 - what i would like to do now is i would
107:42 - like to put this into the draw loop
107:45 - let's just see what happens here
107:48 - if i just put this
107:50 - async function draw
107:54 - like what if i how
107:57 - okay nope
107:59 - what did i mess up
108:04 - oh the auto no
108:08 - can i read properties of undefined
108:10 - reading predict oh this has to be a wait
108:12 - no
108:19 - what am i doing wrong here
108:25 - wait output array render
108:30 - as if oh no now i didn't get an error
108:34 - but i'm not seeing the
108:37 - i think that a i think a sinking draw
108:41 - is a real problem here
108:44 - so let's not async draw
108:47 - let's let draw
108:49 - go
108:51 - ah this is why i don't like doing this
108:55 - in the browser
108:58 - it's got to be the fact that i'm
108:59 - asyncing draw right
109:02 - so what if i just do
109:06 - like my own
109:08 - loop
109:10 - so let's call this
109:12 - input image
109:15 - oh shoot
109:23 - so this will be an async function
109:28 - this in
109:30 - return
109:32 - output image
109:34 - this isn't really no because
109:39 - all right let's make these glo this is a
109:40 - bad idea but let's just make these
109:42 - global
109:47 - so this is
109:50 - uh
109:55 - and then when you get the next image
109:58 - we make a new one
110:15 - hold on
110:20 - what if i do this
110:22 - let's just let's just initialize them
110:26 - this is sort of i don't i don't like
110:27 - what i'm doing but i just want to make
110:29 - sure it works
110:42 - and then let's just
110:46 - i'm just going to fill them randomly
110:53 - and then
110:54 - this just renders both of them okay
111:02 - oh input image index i
111:05 - i i should see just two random images
111:08 - great so i got two random images
111:12 - um
111:15 - yeah that cr what chris is suggesting
111:17 - you could have draw a whatever is latest
111:19 - finished and your asic function called
111:21 - itself recursively is what i'm going to
111:23 - do there also is an array sync function
111:25 - i think where i can make that conversion
111:28 - to data so mike on the box is asking why
111:30 - do i need a weight so the
111:32 - the three the thing with using
111:34 - tensorflow.js is it's doing all the
111:37 - machine learning math on the gpu
111:40 - and there is
111:42 - uh com there i mean i'm using so little
111:44 - data that this is so unnecessary i
111:46 - should send the back set the back end to
111:48 - cpu but
111:49 - you need to uh have any time that you
111:53 - are taking the data out and turning it
111:55 - in and off of the gpu so that i can
111:57 - manipulate it in my code that needs to
111:59 - be an asynchronous function so this
112:02 - return is unnecessary
112:05 - so what i'm going to do
112:09 - is call
112:12 - await next
112:13 - image
112:14 - so
112:16 - let's just see if i can get one new
112:19 - image
112:20 - no image is not defined
112:25 - where am i still using image
112:27 - uh here
112:32 - okay great so i've got one
112:35 - and now
112:37 - i should be able to just call next image
112:39 - now sometimes this will lock up the
112:42 - browser if i don't like give this a
112:44 - little bit of like daylight here like
112:46 - with a set timeout but let's just see
112:50 - okay great no no problem so this is now
112:53 - working i'm just always drawing the
112:55 - latest thing
112:57 - so now again i want to make this a
112:59 - proper latent space but i cannot resist
113:05 - pearl and noising this
113:07 - so we're going to create x
113:10 - off no i'm going to need to use
113:14 - no this will be z off
113:18 - and then
113:19 - the next image is
113:26 - x offset equals zero
113:30 - no let's do this properly
113:34 - let i equal zero i is less than 28. i
113:37 - hate that i have this hard-coded in here
113:38 - i've got to fix that up
113:50 - so we're going to have
113:52 - j is the y offset
113:56 - gonna have an x offset now you might be
113:58 - like what are you even doing right now
114:01 - so i would assume that let's say 2d purl
114:04 - in noise
114:07 - there we go
114:08 - thank you google for referring to me but
114:11 - um
114:12 - so what i'm doing is i'm taking this
114:14 - concept of having two dimensional purlin
114:16 - noise which you can learn more about in
114:18 - this video from
114:20 - five years ago
114:22 - how long have i been at this oh my god
114:26 - and using that as a way of manipulating
114:28 - the input
114:30 - i really should do the denoising
114:32 - but
114:33 - i can't resist this
114:35 - so you may not understand fully but i'm
114:37 - going to say let value equal noise x off
114:41 - y off z off
114:44 - so every j
114:46 - the y off should go up by some
114:48 - incrementation
114:52 - no stop autofilling things for me
114:55 - the
114:57 - x off
115:00 - should also go up by some incrementation
115:02 - value
115:04 - and then also
115:07 - wait i'm missing a curly bracket right
115:10 - next image curly bracket
115:13 - for
115:15 - what did i do wrong here
115:23 - i just
115:32 - oh
115:33 - oh no that's the end there
115:36 - what just happened
115:38 - ah i forgot that this function has more
115:41 - to it okay
115:42 - we're okay
115:45 - there we go
115:46 - and then z off
115:49 - goes up by that incrementation as well
115:54 - we're going to make it a slow increment
115:55 - let's try this for right now
115:59 - and then
116:01 - the input
116:03 - image
116:04 - in
116:05 - i plus j times 28
116:08 - equals that value
116:12 - all right so let's see what happens here
116:18 - oh we've got some weird extra imports
116:20 - again
116:24 - uh syntax error in line 26.
116:28 - that should be an equals
116:33 - so here i am i mean yeah
116:36 - so this uh the z offset incrementation
116:39 - is kind of wildly
116:41 - too high
116:46 - oh wait no why did i oh that's x off
116:51 - i guess i should have a different
116:58 - yeah
116:59 - so this is this sort of like cloudy
117:01 - pearl and noise field that is changing
117:04 - and slowly over time we're seeing late
117:06 - so again
117:08 - i'm gonna really need oh it's 11 54. i
117:10 - have to wrap up uh this is definitely
117:12 - needs
117:13 - uh
117:16 - right michael kempt is pointing out a
117:18 - very good point which is just because
117:19 - pearl and noise only moves slightly does
117:21 - not mean the output squares will follow
117:23 - so i got a little sidetrack whereas i
117:25 - really should just be working with just
117:26 - the decoder
117:28 - but
117:29 - i think i can i i've got to go
117:31 - unfortunately about five minutes because
117:33 - let me just check
117:34 - um
117:36 - okay because my um
117:39 - i gotta get back to my kids
117:40 - for her i could give you all the details
117:42 - about that but that's the that's the
117:44 - summary but um
117:47 - and that's why you're excited for the
117:48 - actual latent space it's more likely to
117:49 - be a smooth but i think i can get
117:51 - something a little bit more exciting
117:53 - here
117:54 - um so what i would like to do
117:56 - well first i would like to test the
117:58 - denoising
118:04 - that's going to send me i really want to
118:05 - test the denoising but
118:08 - the two things i wanted one would be
118:09 - testing the denoising i'm pretty sure
118:11 - the denoising is going to work though
118:13 - because even just like random noise
118:14 - gives me a square so you would think
118:17 - that random noise with a sort of
118:19 - darker
118:20 - high square embedded inside of it would
118:22 - really give me the square but i think
118:24 - what might be more interesting is for me
118:26 - to have an output with much more variety
118:31 - so should i stick i also kind of am
118:33 - tempted to bump up the resolution i
118:35 - think i'll stick with 28 by 28 though
118:38 - and what i'm going to do is this is my
118:42 - data generation
118:44 - so i am going to say first of all i want
118:46 - the
118:48 - size of the images to be
118:50 - have much more variety so let's allow it
118:52 - to go all the way down to 25
118:55 - then let's also say if random
119:01 - is less let's flip a coin
119:03 - and have it either be a square
119:06 - or a circle
119:13 - let's also i mean i think 500 images
119:16 - should i double the number of images
119:19 - just because
119:22 - um
119:24 - just because now i'm doing squares and
119:26 - circles
119:29 - let's see let's so let's try this
119:33 - so now my images are both squares and
119:36 - circles i'd love to introduce triangles
119:38 - in there but i think this will give us
119:40 - something more interesting just to start
119:42 - with
119:43 - because what i want to see with the
119:44 - latent space is the morphing between
119:46 - squares and circles
119:49 - and i i unfortunately the latent space
119:50 - is gonna have to wait till next time
119:52 - although i am planning to live stream
119:53 - this coming friday
119:54 - i could do it tomorrow
119:56 - probably not though tempted to come back
119:58 - tomorrow we'll see
120:02 - so now if i take this data
120:06 - right which should be
120:09 - squares and circles so this is now the
120:12 - new training data
120:15 - and
120:19 - let me just have is the code loading
120:20 - directly from that now i'm going to go
120:22 - back to my training code
120:30 - i could um
120:33 - let's generate whoops ah
120:37 - let's put the training back in
120:46 - ah sorry everybody what is going on i'm
120:48 - so
120:49 - having trouble i'm just going to
120:50 - manually do this
120:58 - so i want to load now 1100 images
121:02 - i want to train
121:04 - train the first 1000
121:07 - and then the rest will be the tests
121:10 - um image loading where are the images
121:13 - being pulled from when i load all images
121:16 - uh so i think i might liked it to go
121:19 - directly into
121:21 - whatever processing has outputted most
121:23 - recently
121:25 - by the way i'm going to turn since i'm
121:26 - wrapping up i'm going to turn the heat
121:28 - off
121:33 - all right
121:35 - it's plenty warm in here and i'm going
121:36 - to be wrapping up soon so i've turned
121:38 - off the heat
121:39 - um
121:40 - so i'm going to grab this
121:42 - i'm sorry to be rushing a little bit
121:44 - here
121:44 - oh and they're all called square that
121:46 - doesn't matter
121:48 - and there's a thousand of them
121:51 - so oops no but that's fine the last one
121:52 - would be 999.
121:55 - wait a sec
121:57 - like i want to get rid of this
122:00 - and
122:03 - what
122:05 - oh i need four i need uh no no it worked
122:08 - no but let me
122:11 - so this should have a four here
122:16 - let me run that again
122:19 - oh actually ah no stop
122:22 - sorry everybody
122:25 - data is a thing okay
122:28 - delete all this
122:32 - the chat has gone quiet again
122:37 - so what i'm learning by the way is which
122:38 - is totally fine is the those of you who
122:40 - are here
122:41 - thank you it's a small audience for this
122:43 - on sunday morning
122:45 - let's generate the data again
122:49 - 1100
122:51 - is that right
122:52 - yeah okay so now
122:54 - and then what i wanted to do is have
122:56 - yeah the images come from oh and
122:59 - this is so silly but it's fine i'm going
123:01 - to leave it as saying square that i do
123:03 - need to change because they're not all
123:05 - squares so i should probably use a more
123:06 - generic term
123:08 - but oh oh oh and then now
123:10 - i should be able to put that in there
123:13 - is there another place where i'm numeral
123:15 - formatting things
123:23 - i don't know what this is
123:25 - is this right this is writing the output
123:26 - but that's fine
123:30 - and so
123:32 - this should go to
123:34 - the actual data from processing so let's
123:36 - see what happens and then
123:40 - we want a thousand and then the 100 for
123:44 - the tests okay
123:46 - so now i should be able to train the new
123:47 - model
123:52 - oops line 21.
123:55 - oh
123:56 - i'm not loading anymore
124:05 - oh this is going to take a while for 100
124:07 - epochs there's a lot more data
124:09 - let's see how the loss goes
124:20 - all right so q who just joined kyu
124:24 - what i'm doing is i have trained an auto
124:27 - encoder
124:30 - to
124:34 - which is a machine learning model
124:36 - to try to reproduce generic images of
124:39 - squares and circles
124:41 - so right now i'm training that model and
124:43 - once it's done i'm going to load a
124:44 - webpage which shows the results of what
124:48 - the model generates when random noise is
124:50 - fed into it
124:51 - there's a lot more pieces to this that
124:53 - i'm
124:55 - sort of missing here
124:57 - at 6 00 p.m
124:59 - yeah
125:01 - um
125:02 - okay we got to 100 okay so now
125:07 - so first of all we have a little we have
125:09 - some test things that i generated just
125:10 - to see
125:12 - so the output
125:14 - folder
125:16 - should now have new oh um i have to look
125:18 - at the noon ones
125:20 - yeah it's like a circle square squirkle
125:23 - is that the term
125:25 - okay great so we're seeing stuff so now
125:27 - in theory
125:28 - if i refresh this page
125:32 - [Laughter]
125:36 - this is so cool
125:38 - you can see this sort of like it's like
125:39 - a latent space browsing
125:42 - but i'm not really doing that yet
125:45 - now
125:47 - could i expand
125:50 - the universe of the inputs
125:53 - like purlin noise is very sort of like
125:55 - limited around the
125:57 - like i'm just curious
125:59 - so this is where i'm going to wrap up
126:00 - today i'm very happy with this result
126:02 - even though clearly i need a part four i
126:05 - need a part four
126:07 - um
126:09 - i would love to like just swap in open
126:11 - simplex noise but one thing i can do
126:14 - very quickly is i can do two times i
126:16 - mean i shouldn't do this
126:22 - but
126:24 - like i'm feeding in like weird negative
126:26 - numbers and stuff that it doesn't know
126:27 - about
126:28 - so just to sort of see
126:34 - this isn't wild
126:38 - um all right let me just go back to
126:40 - i'm not doing this weird thing that i
126:42 - just did here
126:46 - so ah all right
126:48 - oh 1204 okay okay just give me like five
126:50 - more minutes because i just want to see
126:53 - like i want to have a sense of
126:56 - am i capable of doing this at
126:59 - uh double the resolution right now
127:03 - so now unfortunately i've hard coded
127:05 - everything
127:07 - so let's just look for a second in
127:10 - it's like what if i were to
127:15 - uh i don't know about this oh yeah
127:17 - resize everything to
127:21 - so let me just do a little cleanup
127:24 - here just to leave this
127:28 - because i want to leave this in a place
127:29 - where people can play with it so i'm
127:30 - going to delete all the output
127:35 - i'm going to
127:36 - [Music]
127:38 - the model can stay there
127:40 - i'm going to delete the training data
127:45 - i want to just go through and then
127:52 - so let's do 28 times 2
127:54 - which is 56
127:57 - 20 20 plus 20 is 40. 8 plus 8 is 16 56.
128:03 - so let's just try it double
128:07 - um so that's so i'm going to make this
128:08 - training data it's going to be a little
128:10 - bit higher resolution
128:12 - then when i go into
128:14 - [Music]
128:15 - the
128:17 - auto encoder
128:20 - do i have it hard-coded anywhere like
128:22 - 700 yes
128:23 - so now that is that the only place where
128:25 - that's hard-coded there's two places
128:28 - and then is 28 anywhere
128:31 - no
128:32 - okay so i need in this
128:34 - oh here it is so
128:37 - i need to have a constant w equals 56
128:44 - and so this should be
128:45 - w times w
128:51 - this should be w times w
128:54 - and then this should be
128:56 - w times
128:58 - w
128:59 - is there any 28 anywhere
129:01 - w this is w this is w
129:07 - that's just 128
129:09 - and is there any 784 hardcoded anywhere
129:12 - no then i should be able to go back to
129:14 - the sketch
129:15 - and also have i not really
129:20 - this
129:22 - so this should be
129:24 - uh w times w
129:30 - and this is w times w
129:33 - this is w
129:34 - this is w
129:37 - w
129:41 - this is
129:42 - all right so this i have to think about
129:43 - now
129:47 - so
129:48 - then i also have like little w
129:52 - which equals i'm just going to say
129:54 - height
129:55 - divided by
129:57 - the big
129:58 - w because then
130:02 - that is
130:05 - w times w
130:07 - right
130:09 - is how far over
130:11 - this is w
130:12 - w and then this is
130:14 - little w
130:15 - little w
130:18 - little w i think i did this correct so
130:21 - now all i need to do is
130:24 - like if i want to use a higher
130:26 - resolution image this is like whatever
130:27 - that is i just have to change it in two
130:29 - places here well three places the
130:31 - processing sketch the p5 sketch and the
130:34 - node server
130:36 - so i did it already here
130:39 - i didn't actually make it a variable
130:41 - here
130:42 - just to be consistent
130:45 - let's do that again there's there would
130:48 - be
130:48 - you know tying all these together would
130:50 - be better but now i should be able to
130:52 - train the model it's going to take much
130:54 - longer now i don't know how long
130:57 - like that's one epoch
131:00 - so one epoch was a few seconds there so
131:02 - this is going to take a while line 49
131:08 - um so i don't know what line 49 was
131:11 - referring to
131:13 - um
131:15 - i think i got it already i'm assuming
131:18 - if it was in here
131:20 - if it wasn't here
131:24 - thank you missed one
131:27 - thank you for that
131:28 - yeah those variable names ouch yeah this
131:30 - is terrible so pull requests that i'm
131:32 - looking for
131:34 - are cleaning up the variable names love
131:36 - that making a nice readme that sort of
131:39 - explains everything and links to these
131:41 - live streams
131:42 - i would love pull request contributions
131:44 - for that i mean in january i'll get to
131:47 - it myself
131:50 - but
131:51 - i'm at epoch 31 oh boy this is going to
131:53 - take a while
131:56 - but this is
131:58 - this is um this is going to be the end
132:00 - for today i i did not the things that i
132:02 - didn't get to
132:03 - is
132:04 - just lopping off the input so the two
132:08 - the three the things that i wanted to
132:09 - try and this could go into the readme if
132:10 - anyone wants
132:11 - who's keeping notes on any of this
132:13 - nobody my mental notes are i want to see
132:15 - if the denoising works
132:18 - and then
132:19 - then i want to
132:22 - uh also
132:23 - actually work with the proper latent
132:25 - space by feeding the input like i just
132:28 - have eight
132:29 - dimensions and creating sliders to
132:31 - manipulate those
132:34 - that's next on the agenda
132:36 - um
132:38 - and
132:39 - [Music]
132:40 - you know then also trying training like
132:42 - rgb color could i do
132:44 - how high of a resolution can i push it
132:46 - we can see how long this is taking
132:47 - already
132:48 - just for um
132:51 - a hundred epochs but i'm halfway through
132:53 - i don't know this probably doesn't need
132:55 - to train much longer the loss is still
132:57 - going down
133:03 - um thank you for all these chat messages
133:06 - uh
133:06 - um
133:09 - is my discord even working there's
133:11 - nobody nobody putting messages into the
133:13 - discord but um i've got a supporter
133:15 - channel and discord that i keep open
133:16 - during the live streams
133:18 - okay we're at 80 we're getting there
133:20 - this could use some music right
133:26 - all right 82
133:28 - 83 84
133:31 - 55
133:33 - 86
133:35 - 7
133:37 - 88
133:39 - 89
133:41 - 98
133:42 - 51.
133:47 - [Music]
133:54 - seven
133:56 - eight
133:57 - [Music]
133:59 - 100
134:02 - the loss is still going down i could let
134:04 - it train longer
134:06 - okay so now
134:08 - i mean in theory i should just refresh
134:11 - this page and it'll be working at the
134:12 - higher resolution with the new model
134:14 - because everything's pulling from the
134:15 - same
134:16 - directories but how is that how is that
134:18 - possibly going to be true
134:21 - okay
134:23 - yeah
134:24 - working
134:26 - this is wild
134:28 - all right let's move the late let's move
134:30 - oh this is so
134:32 - let's have the numbers move faster
134:38 - so actually let's just do this let's
134:40 - change the incrementation just globally
134:43 - here
134:45 - there we go
134:50 - so i
134:52 - it seems to be just kind of oscillating
134:54 - between a small circle and a big circle
134:57 - um but i think i really need to play oh
134:59 - there we're getting like a square but
135:01 - the purlin noise space is not giving me
135:04 - a tremendous amount of variety actually
135:07 - oh yeah look at that whoa that's cool
135:10 - this is like
135:13 - this is amazing i mean i'm like
135:16 - i you know i'm living like way in the
135:18 - past in terms of like where
135:21 - the current state of machine learning
135:22 - generative models is today
135:24 - but
135:25 - i don't know
135:26 - i just i'm just in love with this
135:28 - weird sort of thing that i've made
135:31 - but um
135:33 - i uh
135:34 - i want to make this go even faster i'm
135:36 - just curious to like
135:39 - let's let's keep pushing this
135:42 - speed of change here
135:45 - yeah what's interesting is how it goes
135:46 - from like small to big through a fade as
135:49 - opposed to actually like having to grow
135:52 - but and then every once in a while it
135:54 - like turns into a square shape
135:57 - um but anyway yeah where are the squares
136:00 - i'm i'm with you michael michael where
136:02 - are the squares
136:04 - um
136:07 - you know one thing that i would do here
136:09 - just out of curiosity
136:11 - is to change from pearl and noise to
136:13 - just randomness again
136:16 - um and sort of see
136:19 - what that gives us
136:22 - ooh whoops oh i'm missing the
136:25 - w times w
136:30 - it really does seem to be
136:32 - that
136:35 - so much more heavily
136:37 - circle making and it's kind of like it's
136:39 - going but i this isn't a proper test
136:43 - because
136:44 - and i'll go gonna go back this isn't a
136:46 - proper test
136:47 - because i'm not actually
136:52 - working with this in a logical way
136:54 - the two things i should be doing are
136:56 - number one
136:57 - if i am actually wanting to see what it
137:00 - does with full in the full input image i
137:03 - should be drawing
137:05 - strange shapes over here and seeing how
137:07 - they match up
137:11 - then i should be actually controlling
137:13 - the latent variables with sliders
137:15 - because i bet you we could find the
137:17 - circle to square
137:20 - that this dimension
137:21 - so this is what unfortunately i mean two
137:23 - hours and 15 minutes is all i can do for
137:26 - today so part four
137:28 - is coming on friday where i want to
137:32 - examine um actually putting in some
137:34 - input images to see if denoising like
137:36 - let's make also some triangles let's
137:38 - make this more sophisticated maybe rgb
137:40 - color could even be added
137:43 - and then working with only the decoder
137:46 - and creating sliders to allow me to
137:48 - manipulate it since you have more input
137:51 - variety you should train longer to
137:53 - recover the shapes properly yeah i also
137:55 - just needed to train this model longer
137:57 - but the initial results are amazing
137:58 - thank you so before i go any further
138:03 - well before i wrap up
138:08 - so what have i changed
138:10 - there's now the public directory that
138:12 - has the model in it and the the p5
138:14 - sketch
138:15 - i've updated the um the node server to
138:18 - train a new model each time
138:20 - and
138:21 - uh the
138:22 - processing sketch um yes hand drawn
138:26 - circle as an input the output would be a
138:27 - perfect circle
138:29 - oh
138:30 - from perlin oh these are such good ideas
138:33 - file them as issues
138:35 - i mean or pull requests to read me but
138:37 - if these ideas i love these ideas i will
138:39 - not remember them
138:41 - so the purlin noise generate landscapes
138:43 - is a really interesting idea the um
138:45 - drawing and then seeing um seeing if we
138:48 - could make a machine learning model take
138:50 - your squiggly circle that you draw and
138:52 - make it a perfect circle i love all
138:54 - these ideas um
138:56 - so um yes
138:58 - let's do all that add them as issues
139:00 - into the github repo
139:02 - um so let me just do git
139:04 - i did that already git add
139:07 - git commit
139:09 - new
139:11 - this is like code for p5 sketch and
139:14 - training
139:16 - and
139:18 - saving slash loading model that's really
139:20 - what i did today
139:23 - git push origin main and you can see
139:25 - that model is you can actually work just
139:27 - with the p5.js sketch now because
139:32 - the model files i r m committing to the
139:34 - repository
139:36 - so uh if i go here autoencoder demo
139:42 - it's very painful to me that there's no
139:44 - readme here
139:45 - but
139:46 - um this is just the p5.js sketch this is
139:49 - the model that i trained most recently
139:51 - i'm just curious how big is this file
139:53 - 6.4 megabytes very reasonable
139:57 - so
139:58 - everyone can play with this to their
140:00 - heart's content
140:01 - those ideas that you have of things i
140:03 - could try next please file them as
140:06 - issues mini jimmy looks like so if you
140:08 - are taking your own
140:10 - you're making your own version of this
140:12 - um
140:14 - and you add things like colors and do
140:16 - like real expanses of the feature set
140:17 - don't pull request that but either file
140:20 - an issue or pull request a link
140:22 - in a readme to your version with um
140:25 - sample images but what i would love pull
140:27 - requests are documentation
140:30 - of what i have so far
140:32 - um any like small
140:34 - any like real bugs or like significant
140:36 - mistakes that are in the code or small
140:39 - clean up things where like the variable
140:40 - names are changed to be a little bit
140:42 - better i would welcome that but anything
140:44 - that's really significantly changing
140:46 - what i have so far i can't merge because
140:48 - i want to have a record of everything in
140:50 - the live streams but you can i could
140:52 - link to it and review it and incorporate
140:55 - those ideas
140:57 - okay thank you everybody
140:59 - uh thank you to brilliant for being the
141:01 - sponsor of today's live stream check out
141:03 - brilliant brilliant.org codingtrain um
141:06 - and uh i will see you all
141:09 - um whoops maybe on well definitely well
141:12 - hopefully
141:13 - hopefully on friday i'm going to
141:14 - continue this i feel like just
141:18 - leaving this here
141:21 - um i wanted to produce some squares
141:26 - no you don't see this this is like uh
141:29 - i was gonna like usually i'm just gonna
141:30 - leave this here
141:32 - as i play all the outro music and see
141:35 - you
141:36 - on uh the next the next live stream uh
141:39 - this auto encoder project has really
141:40 - been uh fascinating to do
141:43 - i have to think about what how do you
141:44 - think about what to do with this next
141:46 - like i could make proper video tutorials
141:48 - of coding the whole thing that are
141:49 - edited through i could make one video
141:51 - that summarizes it i would love your
141:53 - feedback on that like you're maybe the
141:55 - wrong person to be asking because you're
141:56 - watching this right now but a lot of you
141:58 - just are probably tuned in the last 15
142:00 - minutes so what would you want
142:03 - if you weren't able to tune into all the
142:05 - live streams or if you wanted to go back
142:07 - and review parts of the live streams
142:09 - what would you want as
142:11 - something that comes out of this as a
142:13 - video
142:14 - i don't know uh i'm gonna be working on
142:16 - that in january okay um see you all
142:20 - do i have just the laptop button
142:24 - no i don't have a button for that here
142:26 - does this work yeah all right so i've
142:28 - removed myself i'm muting myself
142:32 - and i will see you all next time on the
142:36 - coding train
142:37 - um
142:44 - [Applause]
142:46 - as always i always forget that this dot
142:48 - this
142:59 - [Music]
143:02 - this dot
143:03 - [Music]
143:10 - this dot
147:15 - i'm realizing something
147:16 - so while i'm playing that music i'm
147:18 - realizing that if i had the latent
147:21 - variables like tied to like frequency
147:23 - levels in the music or something then
147:25 - this output would go along with the
147:28 - music so as like the beat goes the
147:31 - circles would like change as the music
147:33 - slo you know like quiets down it would
147:35 - become more static this is also
147:36 - something for me to try for any of you
147:38 - who are adding issues to the repo for
147:40 - things for me to remember next time
147:42 - having the latent variables tied to
147:44 - input sound would be an awesome thing to
147:46 - do
147:49 - that was the invalid syntax i forgot uh
147:52 - there was one other thing here that i
147:54 - think is important that i will use
147:56 - continuously over and over again
147:59 - all sorts of text generation analysis
148:01 - things
148:03 - that i will use continuously over and
148:05 - over again
148:06 - first thing i need to do is yes
148:14 - [Music]
148:20 - kittens and kittens and kittens and
148:21 - kittens kittens and kittens and kittens
148:23 - and kittens kittens and kittens
148:30 - next time
148:36 - bye