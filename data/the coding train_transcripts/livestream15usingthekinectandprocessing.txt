00:00 - I think I'm
00:01 - streaming he everybody welcome good
00:04 - morning I've been having technical
00:05 - difficulties for like the last 20
00:06 - minutes and I think this is actually
00:08 - working oh my God it's working they
00:10 - YouTube changed the way things work good
00:13 - morning welcome this thing is called the
00:15 - coding
00:16 - rainbow uh
00:18 - and I had a whole thing prepared to say
00:22 - that I don't have prepared to say
00:23 - anymore because I just spent 15 minutes
00:24 - trying to make all this stuff work I
00:26 - feel very stressed out but I'm here in
00:28 - New York City at place called ITP at New
00:31 - York University uh Tish School of the
00:33 - Arts and I'm here to talk
00:35 - about I have a prop the Microsoft
00:39 - Connect uh how do you program with this
00:41 - thing how do you do interactive stuff
00:42 - with this thing how do you use this
00:44 - thing with something called processing
00:46 - uh which is running behind me here uh
00:48 - oops I didn't even configure my window
00:50 - or anything so um I people in the chat
00:53 - tell me if you are there uh tell me if
00:56 - you can hear me tell me if you can read
00:58 - this font um
01:01 - tell me if uh you can see me over here I
01:06 - need to test to make sure this
01:07 - whiteboard is working I mean the the
01:09 - Whiteboard is working but if the focus
01:12 - is pretty decent uh I think that's
01:15 - pretty good I'm going to walk over here
01:16 - I've got Periscope live going hi
01:18 - Periscope um so I'm like d triple double
01:22 - streaming something hi I'm talking to
01:24 - Periscope so now I'm on I'm Live on
01:26 - YouTube Periscope so I'm going to put
01:29 - you down so so you could see the
01:31 - URL over
01:33 - here and you can go there
01:37 - uh this is like the most ridiculous
01:39 - thing I've ever
01:41 - done there you go okay so that's where
01:44 - you can go Periscope or you can at least
01:45 - hear the audio so
01:48 - um uh okay everybody can hear me it
01:50 - works like a charm that's great that's
01:53 - exciting to hear um okay so I've got to
01:56 - get
01:57 - started um and I have uh I think I'll be
02:00 - doing this for about an hour or so uh
02:02 - I'm glad to take questions uh the first
02:05 - thing I want to do so I'm kind of going
02:06 - to talk this through first to figure out
02:09 - the kinds of things I'm going to cover
02:11 - um I'll look for any questions or ideas
02:12 - in the chat um and then what I'm going
02:14 - to do as I always do but I'll explain it
02:16 - again is during various parts of this um
02:21 - live stream I'm going to hit a record
02:23 - button to like save a particular chunk
02:26 - as a standalone video Lesson which I
02:28 - will upload to Youtube later so my goal
02:30 - is to have like four or five 10minute
02:32 - video lessons about using the connect
02:34 - and this live stream will be kind of a
02:36 - mess of like trying all sorts of stuff
02:38 - out and in between making those
02:41 - videos um and sometimes I stop and start
02:44 - and redo the redo the same content if I
02:47 - feel like I went in the wrong direction
02:49 - and so you just turn it off if this is
02:51 - like driving you crazy um so I'm
02:54 - checking in the chat hello ah Cardiff
02:56 - again and hello France uh if one thing
02:59 - that's really important if if the audio
03:00 - stops working or if some weird thing
03:02 - happens you can't see me uh please type
03:04 - that in the chat I'm not doing anything
03:05 - with Twitter today so I don't need
03:06 - people to tweet while I'm doing well but
03:09 - you know welcome to um you know let
03:11 - people know this is happening uh it's a
03:13 - holiday tomorrow here in the United
03:14 - States called Thanksgiving NYU is
03:16 - actually closed today but it's a busy
03:18 - active time the end of the semester so
03:20 - um but the reason why I'm doing this
03:22 - actually is because um a lot of students
03:24 - are trying to do projects with the
03:25 - connect around here and I thought this
03:27 - would be
03:28 - helpful we'll see um okay I I'm gonna
03:31 - drink a little water and get set up so I
03:33 - think the first thing that I'm going to
03:34 - do I um first thing I'm going to do is
03:37 - just talk
03:38 - about the connect in general what the
03:42 - different versions of the connect are uh
03:44 - how it works and show you how to install
03:46 - a library in processing that uses the
03:48 - connect open the window for a minute to
03:50 - get some cool air in here lights some
03:52 - get a little bit hot uh so I'm going to
03:54 - just talk about the connect in general
03:55 - and like run some examples to show what
03:58 - it does and then then I am going
04:02 - to uh try to look at a few different
04:05 - scenarios for example
04:08 - um finding the closest thing maybe to
04:12 - the connect maybe finding uh the the top
04:16 - of a human being like where's the top of
04:18 - your head uh I want to look at like
04:21 - taking the depth map and maybe just like
04:24 - dividing it into sections like a grid um
04:28 - somebody had a idea for a project ITP
04:30 - which is to have like the connect
04:32 - pointed at a a sand box and you could
04:34 - manipulate the sand and the height of
04:35 - the sand would play different musical
04:37 - notes so maybe some kind I don't have a
04:38 - Sandbox or and I have the connect in
04:40 - sort of a weird place so I don't know
04:41 - how this is all going to go but I want
04:43 - to try to build a few examples from
04:44 - scratch basically while we're here um
04:48 - okay um great I'm seeing some nice
04:51 - people say hello yes if you're listening
04:54 - to the Periscope audio and the YouTube
04:56 - audio you're in trouble because they're
04:58 - they're definitely going to be out of
04:59 - sync um and that's that so um let me get
05:03 - myself a little bit oriented here uh
05:08 - and I'm going to so here by the way so
05:11 - let me see so let me get this particular
05:14 - example up and running I'm going to hit
05:17 - stop
05:19 - um I need a little bit more room here
05:24 - I'm going to do
05:28 - this interesting I think I actually need
05:30 - this statement in there and I'm going to
05:32 - do
05:34 - this and okay so this is the first thing
05:36 - that I'll just talk about which is that
05:38 - you can get the uh the regular image
05:40 - from the connect the depth image which
05:42 - you can see the darker the color is the
05:45 - closer it is this is um using the
05:47 - connect version two there's the the what
05:49 - the camera is actually seeing the
05:50 - infrared that the cam the camera the
05:52 - sensor the connect whatever you want to
05:53 - call it is seeing and the um this thing
05:57 - called a registered image which aligns
05:59 - the col colors with the
06:01 - depth uh
06:04 - okay uh I think it runs on
06:06 - Linux um I don't know that's a good
06:08 - question I mean I'm so a lot of this
06:11 - work I have to credit Thomas Sanchez
06:14 - lling does anybody know how to pronounce
06:16 - his name let me pull let me pull up uh
06:20 - let me pull up the person I would like
06:21 - to credit for a lot of this work to who
06:23 - helped bring have the library work with
06:25 - the connect version too Thomas
06:28 - Sanchez lling uh here he is a cod codigo
06:33 - generao is his website which I'm
06:36 - probably butchering the um butchering
06:40 - the name so w Works in portfolio of
06:42 - Thomas Sanchez L leling leling if
06:46 - anybody knows how to pronounce that so
06:48 - write it phonetically in the chat
06:50 - otherwise I'll probably mispronounce his
06:51 - name but I do want to thank him uh when
06:53 - I when I start making some of these
06:55 - videos I guess this is a video I'm
06:56 - making right now I'm already thanking
06:57 - him um but he's done a lot of work with
07:00 - the connect and in this part this
07:02 - particular Library so what I should
07:04 - probably bring up here is open connect
07:08 - for processing the uh GitHub
07:13 - page to look at this uh as well
07:19 - as uh sorry let me I'm just getting set
07:23 - here to make this first
07:25 - video uh and um
07:30 - the uh open connect for processing and
07:33 - then this is my page which could use
07:34 - some work but it has
07:37 - some documentation and stuff about it as
07:41 - well okay
07:43 - um yes you can install the connect
07:45 - Library directly from processing and you
07:47 - don't need to install anything else
07:49 - unless you're on Windows maybe you do
07:50 - but you follow the
07:52 - instructions okay uh so I'm getting
07:55 - ready I'm going to make this first uh
07:57 - video I'm going to just drink a little
07:58 - bit of water over here
08:02 - wow I've got 31 people watching that's
08:04 - fantastic
08:08 - um I'm actually just going to send a
08:10 - quick email um to ITP students
08:15 - um
08:18 - because uh hold on a sec because a lot
08:21 - of them were interested in maybe joining
08:23 - so live stream on connect happening now
08:28 - uh okay I'm just sending that out
08:30 - uh okay so I think I'm good to go wow I
08:33 - I just took oh it's eight minutes to get
08:36 - started here but uh I'm going
08:39 - to uh open this up and so in the first
08:44 - video which I'm about to hit record and
08:46 - do the things I'm going to cover are how
08:47 - to install the
08:49 - library
08:51 - um uh what the different kind what the
08:54 - different um versions of the connect are
08:56 - the hardware the different editions and
08:59 - which ones work which ones don't work
09:01 - maybe they all work uh and then the
09:04 - basic functionality of the connect in
09:06 - terms of the pieces of the things the
09:08 - RGB image the infrared image the depth
09:10 - image the raw depth data and um excuse
09:15 - me the uh registered image which is only
09:17 - part of the connect version 2 so that's
09:19 - what I'm going to cover in the first
09:20 - video section and then in the second one
09:22 - I'll probably do some type of
09:24 - visualization of the depth data
09:25 - something like that okay um so it's your
09:27 - last chance to ask a question in the
09:32 - chat oh a lot of you might be interested
09:34 - I just um uh was
09:37 - reminded um that there is something
09:39 - called the key motion or the kimotion or
09:40 - the K motion k i m o t i o n which is a
09:45 - library framework uh for using the
09:47 - connect with um p5js which is another
09:50 - programming environment that I make a
09:51 - lot of video lessons about so don't know
09:52 - if I'm going to get to that today
09:54 - honestly because I haven't had the
09:55 - chance to like really like get it set up
09:56 - and running myself but I definitely you
09:58 - know I imagine this to be a new playlist
10:00 - about the connect I'm going to do raw
10:03 - depth I'm going to do skeleton tracking
10:04 - with the Microsoft SDK I'm going to do
10:07 - using probably this key motion thing for
10:08 - p5js because lots of other people are
10:10 - making stuff and I hope to be able to
10:12 - mention those things and and help people
10:14 - get started with those things as well
10:17 - okay uh here we
10:20 - go in
10:24 - three two one something like that I need
10:27 - like I I need somebody to like be behind
10:29 - the camera going in three
10:33 - two except nobody's there I'm just doing
10:36 - that for
10:37 - myself uh my nose is running but it'll
10:39 - be fine Okay click the mouse mouse goes
10:44 - live
10:49 - and
10:50 - hello okay wait wait wait wait I I like
10:53 - lost track of what I was
10:57 - doing hello this is the first video in a
11:00 - series of videos about using the
11:02 - Microsoft Connect in your own software
11:05 - and the software I'm going to use is
11:07 - this thing called processing uh
11:09 - eventually I will also get to looking at
11:11 - how you might use the Microsoft Connect
11:13 - with p5js in the browser but the first
11:16 - uh this I got to start over too
11:18 - longwinded too
11:19 - long-winded I've been looking too much
11:21 - at my like YouTube analytics and see how
11:24 - like people are watching they whole drop
11:26 - off when I start to ramble at the
11:27 - beginning of a video but I really should
11:29 - care about that I'm way into into my own
11:31 - inside my own head too much I'm just
11:33 - going to make this
11:35 - video hello this is the first video in a
11:38 - series of videos I'm making about the
11:39 - Microsoft Connect this thing so what is
11:43 - this thing how does it work and how do
11:45 - you write your own software that makes
11:46 - use of this thing how can you do all
11:48 - sorts of creative coding projects now
11:50 - there's a lot of different programming
11:52 - languages and environments and
11:53 - Frameworks and libraries for how you
11:54 - might make use the connect um I'm going
11:57 - to use this thing called processing
11:59 - processing 3 the Third Edition version
12:01 - of processing uh which is a Java based
12:04 - programming environment open source uh
12:06 - environment um that there is a connect
12:08 - several different connect libraries for
12:10 - uh eventually I will hope to make a
12:12 - video where I look at p5js which is a
12:14 - JavaScript framework uh for doing
12:16 - creative coding in the browser and how
12:18 - might you get the the stuff from the
12:21 - connect what is this thing called The
12:23 - Connect in the browser itself which I
12:25 - think will be an exciting thing to see
12:27 - as well um but in this first video what
12:29 - I want to do I'm going to get into the
12:31 - code really in the next video and what I
12:32 - want to do in this video is give you an
12:34 - overview so what are the different uh
12:37 - editions of the connect there's a bunch
12:39 - of different ones that you could buy
12:40 - what are the pieces that you need how do
12:42 - you get the library to make use of the
12:44 - connect that sort of stuff and you can
12:45 - see I have a basic example that's
12:47 - running behind me with the connect
12:49 - version two and I will talk through the
12:51 - pieces of this code so first let's think
12:54 - about the different versions of the
12:55 - connect so this is this one here I need
12:58 - reading glass I'm going to this one is
13:00 - the 14 model
13:03 - 1414 this one is the and I'm going to
13:05 - I'm going to come over here and try not
13:07 - to trip over to myself um and I got to
13:10 - grab this uh eraser for a second um so
13:15 - let's make a list here so the the two
13:17 - key pieces of information for you are
13:20 - you need to decide are you using the
13:22 - connect version one or the connect
13:26 - version
13:28 - two I'm probably going to get lots of
13:30 - stuff wrong here that you can write in
13:32 - the comments and I'll put little
13:33 - annotations on the YouTube video that
13:34 - fix them but hopefully I'll get things
13:36 - Loosely right so the original connect
13:39 - version one model 1414 is the one that
13:41 - came out I think it was November
13:44 - 2011 12 somewhere around there I
13:46 - remember the weekend it came out people
13:48 - people were quote unquote hacking it but
13:50 - really just making but by hacking it I
13:51 - mean making open source drivers to to
13:53 - read the data driver being a thing that
13:56 - your computer runs to talk to the
13:58 - hardware device
13:59 - um and so when that came out uh a
14:02 - library I worked on a library called
14:05 - open
14:06 - connect for processing and the reason
14:10 - why it's called Uh open connect is
14:12 - because it's making use of the open
14:15 - connect an open connect an open source
14:18 - uh driver for for uh connecting to the
14:21 - connect which is also known as a lib
14:25 - Free Net so this is sort of the Genesis
14:29 - of all of this um the thing that I built
14:31 - for processing is just a thin layer on
14:33 - top of work that lots and lots of other
14:35 - people did which allows you to get the
14:38 - data from the connect now let's come
14:40 - back to the connect like what is this
14:41 - over here and then I'll get i'll get to
14:43 - the other additions in a second like
14:45 - what is this thing so this is the
14:47 - original connect and you can see here
14:49 - that there are three little circles on
14:51 - here it's like a little nice little
14:53 - friend with three eyeballs and what do
14:55 - each of these eyeballs do so one of them
14:59 - them if we oh camera oh oh shift menu I
15:02 - suck at making these
15:04 - videos okay I'm just I'm going to go
15:06 - anyway okay so this is the connect uh uh
15:09 - um and it has three little eyeballs one
15:12 - of which is an infrared
15:17 - projector so this is this is what the
15:19 - 144 does and I'll talk a little bit
15:21 - about any a different marker here what
15:24 - happens once you get to the connect
15:25 - version two how that works differently
15:27 - um it has an infrared projector which
15:30 - sends out infrared light into the room
15:33 - then it has what I would call you know
15:36 - you could call it a sensor a camera but
15:37 - it has an infrared camera to read the
15:41 - infrared light that's in the in the room
15:43 - what is infrared light it's you know
15:44 - light that's all around us but is
15:46 - invisible somebody with a Physics degree
15:48 - could explain that better but this is
15:50 - blasting out infrared light this
15:52 - infrared camera is reading it so what
15:54 - what is the value of doing this so the
15:56 - interesting thing is the kind of light
15:58 - that it's passing out is actually a
16:00 - whole lot of infrared dots it's
16:02 - projecting a lot of infrared dots into
16:04 - the room that look like this and it's a
16:06 - very specific pattern of dots and the
16:10 - connect itself it knows what that
16:12 - pattern of dots is supposed to look like
16:14 - so if that pattern of dots if I have the
16:16 - connect here it's blasting the infrared
16:18 - light lands on a flat surface the
16:20 - infrared camera that's reading where
16:22 - those dots landed that's seeing those
16:24 - dots reflecting back is going to see
16:26 - like oh it matches exactly the pattern
16:28 - of dots that I know that's a flat
16:30 - surface but if this surface was curved
16:33 - those dots will appear distorted by
16:35 - analyzing that Distortion the connect
16:37 - can recognize what things are closer and
16:40 - what things are further away so the
16:43 - value of this is it uh is often referred
16:45 - to you can think of it as a depth camera
16:47 - or a depth sensor this is what this
16:49 - infrared projector and infrared camera
16:51 - are doing they're measuring the depth in
16:54 - of of each pixel in the room so while a
16:57 - regular web camera says here's a 640x480
17:00 - image each pixel has a red green and
17:02 - blue value and it's beautiful isn't it
17:04 - the colors of the rainbow are there in
17:06 - this image um The Connect is saying I
17:10 - see I don't see RGB what I see is I see
17:14 - a pixel and instead of telling you what
17:15 - color that pixel is I'm going to tell
17:16 - you how far is that pixel away from the
17:19 - sensor and this is incredibly valuable
17:22 - in computer vision you know one of the
17:23 - classic computer vision problems that
17:25 - people try to solve is background
17:27 - removal you know that's why I have
17:29 - this oh green screen oh I have to go
17:31 - underneath this here okay I have an
17:33 - obstacle course in my office I'm going
17:35 - underneath this to turn this camera back
17:36 - on and I'm coming back underneath here I
17:39 - have this hello I have this um I have
17:42 - this green screen here behind me that
17:43 - you can see um and so the the uh camera
17:47 - is saying every Green pixel remove it
17:49 - and put the stuff from the computer
17:50 - behind it but if I had to connect I
17:52 - don't have to say look for the green
17:54 - pixels behind me I could just say look
17:55 - for any pixel that's farther than 2 ft
17:58 - or
17:59 - or some amount of centimeters I'm trying
18:02 - to be a metric I'm trying to be metric I
18:04 - want to be a metric person but I'm not
18:07 - um so uh you could remove you could you
18:09 - could analyze things it makes it really
18:11 - easy to find a human being in the room
18:13 - because a human being has a certain kind
18:14 - of shape it makes it really easy to do
18:16 - quick and dirty 3D scanning there's lots
18:19 - and lots of possibilities of what you
18:21 - can do once you have access to the depth
18:22 - now there was this third little eye here
18:25 - and this by the way is just an RGB
18:28 - camera so one of the things the connect
18:30 - can also do is just see the colors in
18:33 - the room so in addition to having this
18:35 - infrared camera it has an RGB camera now
18:38 - there's a bit of a problem here which is
18:40 - that notice how both of these things are
18:44 - not in the same place so the infrared
18:48 - camera sees the depth of a given pixel
18:50 - at a different place that the RGB camera
18:53 - sees that color so this is an alignment
18:55 - problem a calibration problem where the
18:58 - the color pixels don't necessarily line
19:00 - up exactly with the depth pixels and
19:02 - there are lots of strategies for solving
19:04 - this problem uh and lots of Frameworks
19:07 - and libraries in particular the official
19:09 - Microsoft SDK which has um things baked
19:13 - into it that do this for you but one of
19:14 - the nice things that we'll see once we
19:16 - get to the connect V version two is it
19:19 - has something called a registered image
19:21 - which is an image that aligns the depth
19:25 - pixels with the color pixels okay so
19:27 - this is what the connect does
19:29 - and I really described here what the
19:31 - connect version one does there was also
19:34 - a model 1473 that came out I don't know
19:37 - a year or two later um this one has some
19:40 - problems in particular there's a little
19:41 - bit of a bug uh with currently with
19:43 - running it with the processing Library
19:45 - although it does work kind of only will
19:46 - work every other time can't figure it
19:48 - out for the life of me um so but both of
19:51 - these will work with the library what
19:53 - you need to look for in the library is
19:55 - the version one examples so that's
19:59 - now in between here there was like this
20:01 - connect for
20:02 - Windows and I think this was like a
20:04 - version of The Connect that the
20:05 - Microsoft made to plug into like Windows
20:08 - computers originally this was designed
20:09 - for use with the Xbox for a game for
20:12 - games that you would play by you know
20:14 - dancing I'm kicking my leg by the way if
20:16 - you can't see that um and uh um but you
20:20 - know then Microsoft realized there's I
20:22 - don't know what mic what's in Microsoft
20:24 - has but I'm speculating here but that to
20:26 - make a version that's designed to work
20:28 - with just regular old laptops and
20:30 - computers um I'm not sure if this one
20:32 - works with the processing library but
20:34 - more recently and I I I have this one
20:37 - plugged in and like mounted on the wall
20:38 - over there so I can't hold it up and
20:39 - show it to you the connect version two
20:42 - is a newer and quite significant upgrade
20:45 - from the first connect um and it
20:48 - actually uses a completely different
20:50 - technique it's uses infrared light but
20:52 - it uses a technique called time of
20:53 - flight so it sends the infrared light
20:55 - out measures how long it takes for it to
20:57 - bounce back and that how long that takes
21:00 - uh lets the sensor know how far away
21:02 - things are kind of like a bat maybe does
21:04 - stuff with sound to see I don't know you
21:06 - dolphins do stuff like that but all with
21:08 - sound so with light bouncing it back and
21:10 - forth um the new connect does that and I
21:13 - suppose it's a bit more accurate it's
21:15 - faster uh and uh the RGB camera is also
21:19 - in the new connect is higher resolution
21:21 - okay so that's the basics overview and
21:24 - if I come back over here you can see now
21:27 - now I'm running an example have the
21:29 - connect right over here you can't see it
21:31 - I could I could maybe like turn like
21:33 - kind of like if I hold it up over here
21:35 - can there you go there it is this is the
21:37 - new one I'm G to put it back that felt
21:40 - like a little scary like everything was
21:41 - going to fall over um and you can see
21:43 - now that uh what you're seeing in this
21:46 - particular image is an example of a
21:48 - processing sketch which is rendering all
21:51 - of the pieces of what the library what
21:53 - the connect offers now oh I but I have
21:56 - something more to mention about this but
21:57 - I'll get to that in a second so up top
22:00 - you can see that's just the RGB image so
22:02 - it's like I have a webcam over here I
22:04 - have a webcam over here hi webcam hey
22:07 - that sort of thing right so that's the
22:08 - webcam uh that's that's the RGB camera
22:11 - and it's actually I believe I didn't
22:13 - actually check but it's a it's pretty
22:14 - high resolution image um down below this
22:17 - is the Raw Feed of what the infrared
22:19 - camera is seeing so this is what the
22:21 - infrared camera is seeing and it uses
22:23 - that to extrapolate depth so mostly it
22:25 - just looks like this creepy thing but
22:27 - you can make use of that you can get
22:28 - that image as well um up top up the top
22:32 - right this is what's known as the depth
22:34 - image so the what the connect is
22:36 - measuring is in millimeters it's
22:38 - measuring uh a value between 0 and 4500
22:41 - how far is the thing away from the
22:43 - camera and then often a depth image is
22:46 - used to visualize that data so in this
22:48 - case you can see as I start to go
22:50 - further and further back I get brighter
22:52 - as I start to come closer and closer I
22:54 - get darker so it's mapping the uh theor
22:58 - color of every pixel to how far away it
23:00 - is and you can see just from a
23:02 - standpoint now how much easier that
23:03 - might be to pick out my hand right
23:05 - because my hand is the only thing that
23:07 - has this very very dark color uh as
23:09 - opposed to other things now there is
23:11 - something funny in the back what's up
23:14 - there above oh that's a window I like
23:17 - what's that Black square up there that's
23:18 - a window that's the door you can seeing
23:20 - all sorts of things inside inside this
23:22 - room that you may not have seen before
23:24 - and then down in the bottom right this
23:26 - is the registered image so this is not
23:29 - part of if you use the version one
23:32 - connect with the open connect Library
23:34 - this is not part of that however uh with
23:38 - version two this is the image that
23:40 - aligns all of the RGB values from the
23:43 - webcam with the depth values so if you
23:45 - wanted to hopefully something I might be
23:46 - able to demonstrate at some video is
23:48 - just do background removal where you see
23:50 - only me and I take I get rid of all the
23:52 - pixels that are behind me um that might
23:54 - be something that I could do here with
23:56 - with that particular image oh did the oh
23:58 - the laptop went to sleep come back or
23:59 - wake up okay so uh couple more
24:03 - things so what I want to show you now is
24:05 - how do you get this library to run this
24:07 - like this particular example so a couple
24:10 - things one is here's the I'll put all
24:12 - this in the in the description of the
24:13 - video this is the URL the the uh library
24:16 - is at github.com shiftman open connect
24:19 - for processing you don't need to go to
24:20 - that URL but that's where the source
24:21 - code is there's a little bit of
24:23 - documentation there I want to make give
24:25 - a big thank you to Thomas sanche as
24:28 - lenling I I might not have pronounced
24:30 - his last name correctly he wrote all the
24:32 - code for making this Library work with
24:33 - the connect version two so I worked on
24:35 - the version one a number of years ago
24:37 - and sort of floundered and Thomas came
24:40 - back and revived this and really helped
24:41 - uh over the summer um and there is also
24:44 - I have a little a page that has some
24:46 - additional documentation it's shiffman
24:48 - Donnet p5c connect and you know this is
24:52 - some text that kind of goes through uh
24:54 - the different versions uh and some of
24:56 - these examples as well that I'm going to
24:58 - cover in the videos now in order to get
25:00 - the actual Library itself what you need
25:03 - to do is go to uh one you know first you
25:05 - need to download processing if you don't
25:07 - have that already that's at
25:07 - processing.org then what you'll need to
25:10 - do is once you have processing uh it
25:12 - might look just like this to you
25:14 - something empty you're going to go to
25:16 - sketch import Library add library now
25:20 - you can see that I have already you know
25:21 - I have three libraries here I already
25:23 - have that library but I'm going to
25:24 - pretend that I don't for a second I'm
25:26 - going to go to add Library which opens
25:28 - up up this contributions manager I can
25:30 - type in Connect right here and this is
25:32 - something really quite important now to
25:34 - bring up so there are several different
25:37 - libraries there is by the way something
25:39 - called Simple openni which is an older
25:42 - library openni was an open source
25:44 - platform open source framework for doing
25:47 - skeleton tracking meaning finding the
25:49 - human form where the hands are where the
25:51 - head is which is very very powerful and
25:53 - things that you can do with the connect
25:54 - I'm starting with just the raw depth
25:56 - data um but open and I think was
25:58 - purchased by Apple and then kind of like
26:00 - shut down as an open thing but there are
26:02 - some efforts to revive it and so uh you
26:04 - could Google around and that's something
26:06 - that you could possibly use I'll try to
26:07 - include some links but you can see that
26:08 - it's currently this simple open eye it's
26:10 - no longer compatible with processing
26:12 - three that's why it's gray out connect
26:14 - V2 for processing this is a library that
26:17 - makes use of the Microsoft official SDK
26:20 - and I'm going to demonstrate that using
26:21 - a PC in a later video um this is a key
26:26 - uh this is a really a great thing to use
26:29 - if you want to get all of the magic that
26:31 - Microsoft has spent all this time
26:33 - developing so what the connect just
26:35 - gives you is raw depth data raw RGB data
26:38 - but what the Microsoft SDK does is it
26:41 - pulls that data in and on and it
26:43 - analyzes it and finds where's the human
26:45 - being like what kind of muscle are they
26:47 - making like where is their head like is
26:49 - their hand open or closed and it's so
26:51 - much a sort of a layer of analysis on
26:54 - the raw def data that will give you a
26:55 - ton of information so but for that you
26:58 - do need to use a Windows machine of
26:59 - course there are some strategies for
27:00 - like sending the data from a Windows
27:01 - machine to another machine through like
27:03 - a websocket what's a websocket all sorts
27:05 - of stuff but we'll come to that in a
27:07 - later video um and uh so those would be
27:11 - the two libraries that but the library
27:13 - I'm using today which you know is
27:15 - already installed you can see by the
27:16 - green check mark you would just need to
27:17 - click it and uh click this install
27:20 - button and it would download and install
27:22 - um that this is the library I'm using
27:24 - today it uses open-source drivers it
27:27 - only looks at the raw depth data so this
27:30 - is good for a bunch of different kind of
27:31 - creative applications that I hope to
27:33 - show you in the next set of videos so
27:36 - this was a long rambling 16-minute
27:38 - explanation about the connect that you
27:40 - may or may not have found useful or
27:42 - interesting but I imagine you already
27:44 - turned it off if you didn't and in the
27:46 - next video what I will demonstrate is is
27:48 - just how to write a program that gets
27:50 - that depth image and once it uh I bring
27:53 - that back oh it's not running here get
27:55 - gets that depth image and maybe
27:57 - visualizes that depth image in some way
27:59 - so that's where we'll start and then
28:00 - I'll look at a couple other scenarios
28:01 - along the way as well okay and so thanks
28:04 - for being here and watching and talk to
28:05 - you
28:09 - soon okay everybody
28:13 - uh uh all right did that could people
28:15 - hear me through all that and that worked
28:17 - and everything I don't know what's going
28:19 - I feel like a little lost here um all
28:22 - right I'm looking to see if there are
28:23 - any
28:24 - questions uh um
28:29 - some people are asking things from
28:32 - various place I would like to sing a
28:34 - coding Rainbow theme okay uh uh the
28:38 - white line on his shirt there's a
28:39 - there's a is there something transparent
28:41 - on my shirt oh there's a green it's not
28:44 - white this is a I wore this because this
28:46 - is a shirt that I have that has a
28:47 - rainbow on it and this this line right
28:49 - here is green so it's transparent
28:52 - because the it's picking up the green
28:53 - screen behind me okay um glad that was
28:56 - helpful okay so now what I'm going to
29:00 - do I think maybe what I'm going to do
29:02 - right now you guys is I'm going to try
29:04 - building a little
29:06 - example uh and like the practice and
29:08 - then I'm going to do the video where I
29:10 - build the example again so I'm going to
29:12 - do it now with a little less like
29:15 - personality whatever that means um and
29:17 - you can it's uh ask any questions if you
29:22 - want um so I think the first thing to do
29:25 - would be to actually just look at the
29:28 - depth image and then like take each
29:31 - pixel and map its Z location according
29:34 - to its depth so let me go and grab um ex
29:39 - uh open recent uh this one and I'm going
29:42 - to say
29:46 - um
29:48 - depth dep depth image
29:51 - viz so I'm going to make a sketch that's
29:54 - 640 by
29:56 - 480 uh I'm I'm going to just do
30:00 - this uh so I'm just looking at the depth
30:04 - and I'm going to say p image so I'm I'm
30:07 - I'm going to explain all this when I
30:09 - make the video but I'm just sort of
30:10 - trying out to make see if this this
30:12 - example makes any
30:14 - sense
30:16 - uh and then I'm going to say 4 int xals
30:21 - z x is less than image. width uh
30:25 - x++ for in y = z y is less than image.
30:30 - height y ++ I have a syntax error here
30:34 - uh and then can you guys read this font
30:36 - size okay should I make it
30:38 - bigger uh and
30:40 - then going to take out all this
30:44 - stuff uh and then I'm going to um say
30:50 - int off uh index = x + y * image. width
30:57 - and
30:58 - um color or like uh depth equals uh the
31:06 - brightness of image. pixels at
31:10 - index maybe I'm going to turn off the
31:12 - code
31:13 - completion oh no I want
31:17 - that oh I don't know I'll leave it it's
31:19 - fine uh and um then I'm going to
31:25 - uh I'm going to have a variable called
31:28 - like w is
31:30 - 10 uh oh maybe I call this
31:33 - Skip and that's kind of useful
31:36 - skip uh plus equals Skip and then I'm
31:40 - going to draw I'm just going to draw a
31:42 - rectangle at X comma y uh Skip
31:47 - Skip
31:49 - and I'm going to say fill
31:52 - D and uh I just want to see if this
31:57 - works
32:00 - whoa I'm missing a
32:01 - semicolon uh so I just want I'm just
32:03 - trying to like make it a grid here
32:07 - um what did I miss ah image. load pixels
32:11 - image. load
32:14 - pixels oops I have a capital I
32:17 - there
32:20 - uh oh I totally someone's asking a
32:23 - really good question I totally should
32:26 - have mentioned that in the video you do
32:27 - not need to install any extra drivers or
32:30 - anything it just works um the idea is
32:32 - the library just works um right out of
32:35 - the box yeah so most of the time when
32:37 - you're working with the connect you got
32:37 - to install all this other stuff maybe
32:40 - I'll like I don't know I'll have to put
32:42 - that in an annotation in the video
32:43 - because that was like kind of a big
32:44 - thing that I missed there I should just
32:47 - remake that one but it was too long okay
32:49 - what did I miss here array index bounds
32:51 - array oh X Plus y times width
32:55 - okay okay so you can see great so this
32:58 - is the first thing that I wanted to do
32:59 - which was just and why oh you know what
33:03 - it isn't 640 by 480 what is
33:06 - it
33:08 - uh I forget what's the connect version
33:10 - two with I guess uh it's actually a
33:13 - little bit lower resolution it's uh
33:17 - um
33:21 - uh I forget what it
33:24 - is somebody might know image. width
33:27 - image.
33:31 - height
33:33 - uh come on
33:36 - Console how come I'm not seeing anything
33:38 - in the console don't I have a print line
33:41 - there oh yeah 512 by 424 I forgot about
33:46 - that 512
33:51 - 424 so this is working you can see I'm
33:55 - getting so I just wanted to do something
33:57 - first really quick where I kind of make
33:58 - this grid like lower resolution grid
34:00 - because then what I can do is translate
34:03 - each one of those into 3D based on the
34:06 - brightness and I I'm pretty confident
34:08 - that I can do that in the video so um I
34:13 - think what I'm going to do dare I just
34:15 - delete all this code because I'm going
34:17 - to write it again from scratch in the
34:21 - particular video all right that's what
34:23 - I'm going to
34:24 - do delete okay so I'm going to just make
34:27 - a simp simple video where I look at
34:29 - looping through all the depth pixels and
34:32 - doing something with them uh any
34:34 - questions 512 by 400 thank you thank you
34:37 - for um for pointing out the errors uh
34:40 - wow I've got good I've got a great
34:41 - number of live people today that's
34:43 - wonderful okay
34:46 - so um and then I'll do one where I look
34:51 - at the raw depth data I think so I want
34:55 - to look at the difference between the
34:56 - color data and the Raw depth
34:59 - data um but I think I'll just I'm going
35:02 - to try to do these small little
35:04 - chunks okay here we go um I'm ready let
35:08 - me let me cycle these
35:19 - cameras and um I'm going to
35:25 - erase this diagram I'm over here right
35:27 - now by the way people um erase this cuz
35:31 - I probably need to do a quick pixel
35:34 - diagram uh for this video especially if
35:37 - people haven't worked with pixel
35:38 - processing
35:39 - before and um and now I'm
35:47 - ready okay uh here we go uh got my weird
35:50 - see-through t-shirt I can see the G like
35:53 - like that's like hole in my body it's
35:56 - disturbing okay
35:58 - um the okay so the same exact Library
36:01 - will work with the connect version one
36:03 - as well and the techniques would be the
36:05 - same I just happen to be demonstrating
36:07 - it with the connect version two thinking
36:09 - that that would be a little bit more
36:10 - current okay so
36:14 - um U stop here I I wish there was um
36:17 - okay that's fine
36:20 - and
36:26 - uh okay
36:28 - so I think I can make this a little bit
36:30 - smaller I can minimize the browser here
36:33 - sorry I'm just getting my window all set
36:35 - up uh this one I can close and I'm going
36:38 - to close this and then go open ah come
36:42 - on uh this one
36:47 - great
36:49 - and U make the console a little bit
36:51 - bigger there we go I think we're good
36:53 - what about the font size I feel like it
36:54 - needs to be a little bit bigger it's
36:56 - looking a little smaller to me that's a
36:59 - little bit better right okay um here we
37:09 - go ah the sun is coming sunlight is here
37:12 - today
37:17 - excellent hello in this video I'm going
37:20 - to look at how you can get the depth
37:22 - image from the connect in processing and
37:25 - what you might do with that so this is a
37:27 - very very very first step I have a
37:29 - completely blank sort of like set of
37:31 - code here I just filled a little bit in
37:33 - there in advance but I'm going to write
37:34 - this program from scratch in this video
37:37 - so uh if you didn't watch the
37:42 - prev hello in this video I'm going to
37:45 - look at how you get access to the depth
37:48 - image from the Microsoft Connect in
37:50 - processing and how you write some code
37:52 - to do some stuff with those pixels with
37:54 - that depth image so if you missed the
37:56 - previous video that's where I talked
37:57 - about the connect in general about um
38:01 - how you install the processing Library
38:03 - one thing I did miss which I think is
38:04 - important to mention is that you do not
38:06 - need to install anything else if you're
38:08 - on Mac OS X um so uh the library just uh
38:13 - works it comes with all the libf free
38:15 - neck stuff sort of packaged inside of it
38:17 - uh I believe on Windows there might be
38:19 - one other thing you have to install uh
38:21 - well I should really look this up right
38:22 - now ah crap I'm going to make this I
38:25 - don't want to get this wrong in the
38:26 - video Let's look this up
38:28 - uh here uh connect
38:31 - V2 uh for Windows 8 you have to install
38:35 - some uh this driver um which I'll
38:37 - mention for the V2 okay going do this
38:40 - one more
38:43 - time uh okay here we
38:48 - go hello in this video I'm going to look
38:51 - at how you can uh work with the depth
38:54 - image from the Microsoft Connect in
38:56 - processing I'm going to I need my prop I
38:58 - need my prop I swear this is the last
39:00 - time I'm doing this I just feel like
39:02 - having the prop will be
39:08 - good it's stuck underneath the table
39:12 - help it's funny how I've left my phone
39:15 - on Periscope is still like streaming an
39:17 - index card I don't know if there's
39:19 - anybody there okay uh okay I swear this
39:23 - is the last time I'm making this video
39:25 - now come come some
39:28 - hello I have a prop in this video I'm
39:31 - going to look at how do you use this I'm
39:33 - going to actually look at the code for
39:34 - using this Microsoft Connect in
39:36 - processing using the open connect for
39:38 - processing library now uh one thing I
39:40 - want to mention it that I did not
39:41 - mention in the previous videoos that is
39:43 - if you install the open connect for
39:44 - processing Library you need nothing else
39:46 - whatsoever it just works with the
39:48 - connect there is one exception on
39:50 - Windows 8 with the connect version two
39:52 - you do need to install an extra dri
39:54 - libus I will put that in the description
39:57 - below
39:58 - um but so this is the connect version
40:00 - one model 1414 it would work with this
40:03 - example but I'm going to show you
40:04 - instead I have the connect version two
40:06 - over here and you can see the only code
40:08 - that I filled in so far is having a
40:10 - variable called connect 2 so if you're
40:13 - using the connect version one the only
40:14 - thing you would change this code would
40:16 - work mostly identically um is just say
40:19 - connect uh instead of connect two so
40:21 - it's not connect one and connect two
40:22 - it's just connect and connect two I'm
40:24 - pretty sure about that if I get that
40:26 - wrong somebody will correct me
40:28 - um okay so uh let's look at how you get
40:31 - started so I filled in a little bit of
40:33 - code but the only things that you need
40:35 - really to get started are an import
40:36 - statement at the top that import
40:38 - statement is saying hey I'm here to use
40:39 - this Library uh you need to declare a
40:42 - variable that's variable is going to
40:44 - like hold all the information about this
40:46 - connect that you are using so it's the
40:48 - thing that you're going to create and I
40:49 - create it by saying new connect to this
40:52 - now there is a way to use multiple
40:54 - connects to use a version one and a
40:56 - version two to specify which connect you
40:57 - want to use that's beyond the scope of
41:00 - what I'm doing here in this video I'm
41:02 - only going to look at you just have one
41:04 - connect connected to one connect
41:05 - connected to your computer it's the
41:07 - default one all you need to do is say
41:09 - equals new connect to this so once
41:12 - you've got that going what is the next
41:14 - step well you need to decide what it is
41:16 - you want to do and in this example all I
41:18 - want to do is use the depth image so I'm
41:20 - going to say init depth so the connect
41:25 - uh the connect doesn't the library
41:26 - doesn't start all of the feeds
41:28 - automatically it's not going to start
41:30 - getting the infrared image the raw depth
41:32 - the depth image the video image it's
41:33 - only going to start using what you ask
41:35 - for so in this case I want to say init
41:37 - depth and then I also want to say uh
41:40 - init device which will kind of get
41:43 - things going and by the way this is
41:44 - where if I had multiple devices I could
41:46 - put an argument in there say init device
41:48 - zero one or two that type of thing so
41:51 - once I have that I'm ready to go and I
41:53 - can run this program and we will see
41:57 - nothing nothing on the screen so but a
41:59 - lot of stuff like spit out here which is
42:00 - kind of promising device firmware serial
42:03 - the library is going to like put a lot
42:04 - of stuff in the console which is um some
42:06 - basic information that you can see if
42:08 - it's working it will say like no nothing
42:10 - connected uh if you if you if you don't
42:12 - have it um connected I realized some
42:14 - other things I forgot in the first video
42:16 - but that's okay okay so uh what's the
42:19 - next thing that you want to do so let's
42:20 - just make sure things are working one of
42:22 - the things the connect gives you is that
42:25 - depth image because I said and it depth
42:27 - so in nit depth there are two ways I can
42:29 - look at the depth I can look at the raw
42:32 - depth values with the connect version
42:33 - two these are numbers between 0 and 4500
42:36 - with the connect version one these are
42:38 - numbers between 0 and 248 U these relate
42:41 - to millimeter measurements um but what I
42:43 - want is get depth image and you can see
42:48 - I what I'm you doing here is I'm asking
42:50 - the connect to give me this depth image
42:52 - and store it in a variable called image
42:54 - and now what I can do is just draw that
42:56 - image on the screen to make sure things
42:59 - are working so we can see here and there
43:02 - it is so there is the depth image you
43:04 - can see I've got it and now it's on the
43:05 - screen
43:07 - so this is the goal of the library it's
43:09 - pretty easy to work with in terms of
43:11 - just getting the data so let's think
43:14 - about what you might want to do so I
43:16 - think most almost all of the uh almost
43:22 - everything that you would do where
43:23 - you're working with the raw depth data
43:25 - or with the depth image involves
43:27 - iterating over all the pixels you want
43:29 - to look at all the pixels and see which
43:31 - ones are the ones that are closest you
43:32 - want to look at all the pixels and see
43:34 - what's the highest point of the closest
43:36 - thing or you want to look at all the
43:37 - pixels and say what's the sort of
43:38 - topology of the entire thing so all of
43:41 - those statements I said involved look at
43:43 - all the pixels so before I get to doing
43:45 - anything here let's talk about what it
43:47 - means to look look at all look at all
43:50 - the pixels so this is something that
43:52 - I've covered in some other videos a
43:53 - whole set of videos about just image
43:55 - processing um from you know jpegs pngs
43:58 - webcams that sort of thing you could
44:00 - refer back to those I'll I'll make sure
44:02 - I link to those at this moment in the
44:04 - video um but just to remind you if you
44:07 - have an image whether it's a depth image
44:10 - or an RGB image that image is a grid of
44:15 - pixels and we typically as human beings
44:18 - look at this as a thing that's
44:19 - two-dimensional and it has a bunch of
44:22 - columns and it has a bunch of rows and
44:25 - usually we think of the columns as the X
44:27 - values and the rows as the Y values so
44:29 - you might think of this as like the
44:31 - columns numbered like there's five
44:33 - columns numbered 0 through four and
44:36 - there's uh four columns numbered 0
44:38 - through three and so if I were over here
44:41 - this is pixel 3 comma one so this is how
44:45 - uh I think of pixels and images and this
44:48 - is the this image over here this depth
44:51 - image is a big grid of pixels columns
44:53 - and rows the thing that you have to
44:55 - remember when working with stuff like
44:57 - this is that the computer is actually
45:00 - storing all of those depth values all of
45:03 - those brightness depth values in this
45:05 - singular onedimensional array 0 1 2 3 4
45:10 - 5 6 7 8 9
45:12 - Etc and those numbers correspond like
45:15 - this the counting goes across comes down
45:17 - here uh comes down here comes down
45:23 - here so you can see I've got 20 pixels
45:26 - because I've got a five 5 by 4 grid 5 *
45:28 - 4 is 20 the pixels are numbers 0 through
45:30 - 19 so what we need is a methodology for
45:34 - if we're thinking of the XY how do I
45:36 - convert that to the location that's in
45:38 - this onedimensional array the index into
45:40 - that onedimensional array and the
45:42 - formula for doing that is x + y * width
45:46 - and you can see how that works because
45:48 - if I look at this column index two over
45:50 - here 2 + 5 is 7 7 + 5 is 12 12 + 5 is 17
45:55 - so the width to finds those numbers as
45:58 - they go sort of down row by row by row
46:00 - so if I say 3 + 1 * 5 that's 3 + 5 which
46:05 - is 8 and you can see that's eight right
46:07 - here so this is the formula that you're
46:09 - going to have to get used to because
46:11 - what I'm going to add is Loops I'm going
46:14 - to say Loop through every column and
46:16 - loop through every row row to look at
46:18 - every spot in this depth array so if I
46:21 - come back over here we can now add that
46:23 - to our code so for example I can say
46:26 - right here
46:28 - for every X from zero to and I'm going
46:31 - to say image.
46:32 - width uh not I and I'm going to say four
46:37 - every
46:42 - Y and again if this this idea of a
46:45 - nested Loop is confusing to you I would
46:47 - refer back to some previous videos about
46:48 - image processing but what we can see
46:51 - what I would like you to see here is how
46:53 - this is the loop to say I want to look
46:55 - at every single depth pixel so it could
46:58 - be I want to search for the closest one
47:00 - or I want to search for the for the the
47:03 - furthest away one right or I want to
47:05 - just visualize every pixel in
47:07 - three-dimensional space so for every X
47:09 - from zero to the width for every y from
47:12 - zero to the height and now what I could
47:14 - do is say what is that index how to
47:17 - apply that formula now x + y * image.
47:23 - width and then the color is is the color
47:27 - that's in that pixel even though it's a
47:29 - depth value it's turned into a grayscale
47:31 - color is the image. pixels at that index
47:35 - so this is now a loop that you will see
47:37 - in just about all the examples I intend
47:39 - to make today where I'm looking at every
47:41 - single Pixel and finding its index into
47:44 - the depth the the into that depth image
47:47 - and pulling out the color that's there
47:49 - so what might I do with that I could
47:52 - make a point in three-dimensional space
47:54 - Let's do let's okay let's do something
47:56 - thing here let's turn what we're seeing
47:58 - on the screen let me run this let's turn
48:01 - this into a lower resolution grid so
48:04 - let's look what I'm going to change this
48:06 - program to do right now is just look at
48:07 - every 10 pixels or every 20 pixels and
48:10 - draw a rectangle with that particular uh
48:12 - color there so let's do that real quick
48:15 - and I'm going to say so what one thing
48:17 - I'm going to do is I'm going to change
48:18 - this to uh brightness I'm just going to
48:20 - look at
48:21 - the um I'm going to look at the
48:23 - brightness of that pixel which is just a
48:25 - single value between 0 and
48:27 - 255 and I want to draw a rectangle at XY
48:31 - now I'm going up by one pixel so what I
48:34 - want to do and you'll see this in some
48:35 - of my examples is I want to introduce a
48:37 - variable called Skip and I'll say skip
48:40 - equals 20 because that's how many pixels
48:42 - I'm going to skip instead of looking at
48:44 - every single Pixel right now I'm going
48:45 - to look at every 20 pixels um and EV
48:49 - then I'm going to draw a rectangle at
48:51 - every 20 pixels and I'm going to fill
48:53 - that rectangle with that particular
48:55 - color so if we run this we should see
48:57 - exactly what I had before but just it's
48:59 - much lower resolution so that you can
49:01 - see I'm still looking at all of the
49:04 - pixels finding its color uh uh from the
49:08 - from the pixel array and then drawing a
49:10 - rectangle of some size arbitary size 20
49:13 - at that spot so you can see as I move
49:15 - around in front of the connect you can
49:17 - see my hands here and you can start to
49:18 - see like ah this is the kind of thing
49:21 - that computer visionwise it might be
49:23 - easy to pick out my hands as the sort of
49:25 - singular blobs
50:26 - the rectangle but by through a
50:28 - translation because ultimately I want to
50:30 - translate along the three-dimensional
50:31 - axis so I use push Matrix and pop Matrix
50:34 - to save and restore um that
50:36 - transformation State these might be
50:38 - Concepts that are unfamiliar to you I
50:39 - will refer you to a different video
50:42 - about Transformations but you can see I
50:43 - have the same exact thing here so
50:45 - instead of drawing the rectangle at XY
50:47 - I've now translated to XY and drawn the
50:49 - rectangle at 0 why am I doing this
50:52 - because now I could add something I
50:54 - could add a z here so the first thing I
50:57 - might try is just say okay well what is
50:58 - this Z let's make this Z equal to
51:02 - brightness and you can see here what do
51:05 - we got we've got as I uh it's kind of
51:08 - hard to see but you can see some uh some
51:11 - rectangles are further in front than
51:14 - other ones that are further away so the
51:16 - brighter ones are closer and the darker
51:18 - ones are further back this isn't really
51:21 - this isn't really doing me any good
51:23 - because actually I think what might make
51:24 - more sense is to have the Clos closer
51:26 - ones be more forward and the further
51:29 - ones way be more behind so I want to
51:32 - essentially position all these
51:33 - rectangles about where they actually are
51:35 - in physical space and so to do that I
51:38 - might do the map use the map function
51:39 - right because we know the brightness has
51:41 - a range between 0 and 255 but what I
51:44 - want is to now have a z value this zv
51:48 - value that's coming out of the screen I
51:49 - want things that are dark to appear
51:52 - close and things that are bright to
51:53 - appear far away so maybe I'll have the
51:56 - things that are
53:16 - [Music]
53:56 - looking at their brightness value and
53:58 - mapping it now the truth of the matter
53:59 - is if if I was really doing this what I
54:02 - probably would want to do is actually
54:03 - just look at that raw depth data if I'm
54:05 - trying to visualize the data in 3D this
54:08 - is not exactly the quote unquote correct
54:10 - way of doing it so that's what I'm going
54:11 - to show you in the next video how
54:13 - instead of using the depth image how you
54:15 - might make use of the raw depth data
54:17 - those numbers which are between zero and
54:19 - 4500 okay thanks for watching and I'll
54:22 - maybe see you in the next
54:25 - video
54:29 - okay uh okay
54:35 - um um so is the is it in the in Connect
54:40 - I'm seeing some in the chat I wonder if
54:42 - with the connect version one it's not in
54:43 - it device which is something that I'm
54:45 - learning right now let's go let me open
54:47 - up one of the examples for The Connect
54:50 - version
54:51 - one
54:55 - uh yeah I don't think you actually need
54:57 - the init device for The Connect version
55:00 - one I'm looking at the example right now
55:02 - the the init depth and init video stuff
55:05 - just turns it
55:06 - on um so I think you don't need that
55:09 - function um let me
55:12 - open
55:15 - that uh I'm looking in the chat to see
55:19 - if there are any more the depth range is
55:21 - different I believe between the two
55:23 - models I believe the second version has
55:26 - like a longer depth
55:28 - range um
55:30 - yeah uh okay so that wasn't my best
55:35 - work uh okay
55:38 - so I'm trying to
55:45 - think I'm going to trying to think of
55:47 - what would be most useful to do
55:51 - next um I said I was going to look at
55:53 - the raw depth
55:54 - data um so I think will and then maybe
55:57 - with the raw depth data I'm going to do
55:59 - a thresholding thing where I'm going to
56:03 - uh only show you pixels between certain
56:06 - distances and in that sense I'm going to
56:09 - get just the human form I wonder if I
56:13 - should do that in um Advance who's
56:19 - coming to get me
56:21 - Victor
56:23 - um okay uh
56:28 - I'm trying to
56:29 - think of what else I might be
56:33 - missing
56:34 - [Music]
56:37 - um
56:42 - uh
56:44 - uh yeah okay
56:47 - um all right um okay sorry everybody I'm
56:51 - I'm spaced out for a second everybody
56:53 - doing okay Sirens oh yes the sirens are
56:55 - coming to get me thank you uh okay
56:59 - so let's go on to the next
57:04 - topic what I'm going to do is open
57:08 - recent so I think I'm just gonna not
57:11 - going to build this one from scratch
57:13 - this one I have ready in advance which
57:15 - is just doing the point Cloud why did
57:18 - this break had this working a second ago
57:22 - um oh something's already running that's
57:25 - why um
57:29 - um yeah so this is a more accurate way
57:32 - of doing the
57:35 - um the the thing that I did in the
57:37 - previous one um so I think I will show
57:42 - this example which uses the raw depth
57:44 - data and then I'm going to use that to
57:48 - um to do some sort of thresholding as
57:51 - well so I will change this into
57:53 - something else uh
57:59 - okay I think my live stream is like way
58:01 - behind
58:03 - me
58:04 - um like 10 minutes
58:07 - behind um but who knows
58:12 - okay I better get on to the next
58:16 - topic
58:19 - uh so let me close this
58:25 - one okay
58:34 - um okay Point
58:43 - Cloud
58:49 - uh
58:55 - uh
58:56 - sorry everybody I'm just getting this
59:01 - ready that's
59:04 - funny because the X and the
59:23 - Y
59:25 - okay
59:34 - hold on I'm doing something
59:43 - here
59:46 - okay okay this is going to do and I'm
59:50 - going to have that go a lot
59:52 - slower okay sorry I'm ready for the next
59:55 - video
59:58 - let me cycle the
60:07 - cameras and drink a little water my
60:11 - phone battery must have died by
60:15 - now let me see where
60:20 - the okay here we go
60:23 - everybody
60:25 - um
60:30 - s over I need a little I need a little
60:32 - energy boost here should have gotten
60:34 - more coffee this
60:45 - morning
60:48 - okay hello in this video I want to look
60:51 - at look I want
60:54 - to hello in this video but that hello
60:58 - was like a little bit
61:00 - creepy hello in this video I plan and
61:04 - hope and I'm excited to look at the raw
61:08 - depth data meaning not the depth image
61:11 - not the depth values um converted to a
61:14 - grayscale image but actually the raw
61:16 - depth data that's coming out of the
61:17 - connect itself so again with the version
61:19 - two connect you're getting numbers
61:21 - between 0 and 4500 with the version one
61:23 - connect you're getting numbers between 0
61:25 - and 2 48 and to demonstrate this what I
61:28 - have over here is a simple processing
61:31 - sketch that's drawing a whole lot of
61:34 - dots on a plane in three-dimensional
61:36 - space and that plane is rotating rather
61:38 - slowly so what I want to do is and this
61:41 - is what's known as a point Cloud I want
61:43 - to take every point on this plane and
61:46 - give it its actual physical
61:49 - reals space no wait wait wait let me say
61:52 - that again okay the connect is seeing
61:54 - all these points I am all these points
61:56 - in a room and the connect is seeing me
62:00 - and I want to move these points around
62:01 - but this is like the weirdest thing I've
62:03 - ever had to explain and it's like the
62:05 - it's like totally simple and it would
62:06 - just make sense if I just showed it to
62:07 - you yet I insist on trying to explain it
62:09 - in this weird way but I want to take all
62:12 - the points that the connects are seeing
62:13 - in this physical three-dimensional space
62:15 - where I am and I want to move these
62:18 - virtual dots which are on the screen in
62:20 - this virtual 3D space and that's known
62:23 - as a point Cloud this is how you might
62:25 - start to build a 3D model of what the
62:27 - connect is seeing in the space so the
62:30 - the the the key difference here uh so
62:33 - one thing that I had before in the
62:34 - previous video is we were looking at
62:36 - this pixel-based image right this idea
62:39 - of each image each pixel of the depth
62:41 - image has a value between 0 and 255 and
62:45 - it's a brightness value based on how far
62:46 - or close it is now the information is
62:49 - stored in exactly the same way inside of
62:52 - this a big array um but uh instead the
62:56 - numbers are between 0 and 4500 so how do
62:58 - we work with these numbers so let's come
63:00 - over here and uh going to do a couple
63:03 - things in this video but this first
63:05 - point Cloud example I mostly have the
63:07 - code already so you can see here that
63:11 - what I'm doing is looping through the
63:13 - connects width and height again I'm
63:15 - skipping because I don't need to do
63:18 - every single point I don't need to do
63:20 - all the points just to visually get this
63:22 - effect um and then I'm finding the
63:24 - offset off set into that array so x + y
63:29 - * connect to.wi so that's how I'm going
63:32 - to look up into that big array of all
63:34 - those depth values now what is that
63:36 - array that array is called is I get that
63:40 - array by saying connect 2 dot get raw
63:42 - depth so when I said get depth image
63:45 - that gives me a p image object with
63:47 - pixel values all in it now I just get a
63:48 - big integer array again those integers
63:50 - are between zero and 4500 so they're in
63:53 - that array and I can say
63:56 - the depth is uh I already use the depth
64:01 - is the offset into that array now
64:04 - there's something else going on now in
64:07 - this function what it's doing is there's
64:09 - a function here called depth to point
64:11 - Cloud position xyd X is the pixel X Y is
64:15 - the pixel y d is the depth that the
64:18 - connect is seeing there's sort of
64:20 - there's a strange thing that's happening
64:22 - which is that the pixel we we look at
64:25 - all these these
64:26 - uh pixels in a grid and we get this raw
64:29 - depth value but the connect itself um
64:32 - there's some math involved in how that
64:34 - can actually converted to real
64:36 - measurements in physical space like
64:38 - where is the actual X where's the actual
64:40 - y based on like how the camera is seeing
64:42 - it so in order to do that this
64:45 - particular example has just this
64:47 - function which essentially you want to
64:48 - download these examples and copy this
64:50 - verbatim um but this function is using
64:53 - all of these kind of uh par parameters
64:56 - that are built into the hardware itself
64:58 - so these are like a whole set of numbers
65:00 - and values that are just part of the
65:01 - connect calibration and you kind of
65:04 - multiply and divide by these numbers and
65:06 - you get the actual value of where it is
65:07 - in space sort of an interesting problem
65:09 - I would love to like go through it at
65:10 - some point but right now I'm sort of
65:12 - inclined to sort of skip it and say the
65:14 - interesting thing is what you're getting
65:16 - is if you give the raw depth value the
65:18 - pixel X and the pixel Y and use that
65:20 - function you're going to get the X Y and
65:23 - depth values in millimeters back of
65:25 - where those things are in physical space
65:28 - so I don't want to in fact draw the this
65:30 - is what you're seeing in this particular
65:32 - visualization right now is just all of
65:36 - these pixels at their exact XY and XY
65:40 - value with a zero depth so what I want
65:43 - to do is change this program to say this
65:45 - actual physical point this P Vector the
65:47 - P Vector is an object that has an x a y
65:49 - and a z i want to draw the vertex at
65:51 - point dox point doy and now point
65:57 - point doz and in order to make this a
65:59 - little bit better I'm going to skip
66:00 - fewer pixels I'm going to skip only four
66:02 - and I'm going to run this again and now
66:04 - you'll
66:05 - see here I am this is the point Cloud
66:08 - this is me in three-dimensional space so
66:10 - if I zoom in on this you can start to
66:12 - see like what's going on this over here
66:14 - by the way is the wall it's funny how I
66:16 - can like put my hands on the wall it's
66:18 - almost as if I'm distorting the wall but
66:19 - really what I'm doing is I'm casting a
66:21 - shadow um so it's a little bit strange
66:23 - to see this view of me and my connect I
66:25 - could like no I would give myself a hug
66:28 - that's a little bit weird too I was like
66:29 - punching is weird hugging anything that
66:30 - you do I don't know just scratch all
66:32 - that but you can see here this is now a
66:35 - visualization in three-dimensional space
66:37 - you could connect these points with
66:38 - lines you could color them there's a way
66:40 - of actually getting the RGB values and
66:43 - so you could see like the colors that
66:44 - are on my shirt on these points as well
66:47 - this is a road you could go down and I
66:50 - find this road to be particularly
66:51 - interesting but what uh and uh you can
66:54 - see that I'm I'm using just a simple y
66:56 - rotation so now I'm kind of like
66:58 - spinning around this image which is now
66:59 - gone off screen um but if I zoom back in
67:02 - you can sort of see it's over there um
67:05 - so this is kind of the start of sort of
67:08 - thinking of like what can you do with
67:09 - these raw depth values I think what
67:12 - would be a useful demonstration now is
67:15 - to look at how might I actually pick out
67:17 - just me so you can visually see just me
67:19 - but there's a sort of Nest there's like
67:21 - all this stuff over here there's this
67:23 - over here um there's actually like this
67:25 - pole over here that's being picked up by
67:27 - the connect so what I you know what if I
67:29 - just wanted to like even only get my
67:31 - hand right here what I want to do is try
67:32 - to calibrate a threshold so what if I
67:35 - want the connect only to see the
67:36 - connect's over here remember so it's
67:38 - it's to the left of me I don't know what
67:40 - what side that is you're viewing but
67:42 - what if I want to say only look at the
67:43 - pixels in between here and here and that
67:46 - would conceivably get my hand right how
67:48 - would I do that how would I look only
67:50 - look at the pixels between a certain
67:52 - minimum and a certain maximum let's look
67:54 - at that so one thing I'm going to do is
67:56 - I'm going to save this as um I know what
68:00 - to call this min max
68:02 - threshold um and I'm going to get rid of
68:05 - all this 3D stuff for right
68:07 - now uh because I'm not going to do this
68:10 - with you could do this with visualizing
68:11 - the point Cloud still but I'm going to
68:13 - do this with
68:14 - just
68:16 - uh and I'm going to look at all the
68:19 - pixels so I want to do
68:22 - x++ and Y ++ and somebody remind me
68:25 - what's the size 4
68:27 - 512 484 is that right I don't know if
68:31 - that's right um and so hopefully that's
68:33 - right and then what I want to
68:36 - do is I don't need end shape I don't
68:40 - need I don't need begin shape I don't
68:42 - need any of this stuff what I want to do
68:44 - again and I don't need this depth to
68:46 - point Cloud thing I'm taking all of that
68:48 - out because what I want to do right now
68:51 - is just go through this double nested
68:56 - Loop and look at every depth value 0 and
68:59 - 4500 but I only want to like count the
69:01 - ones that are between 200 and 400 or
69:04 - between 500 and 800 what is that what's
69:06 - that minimum and what's that maximum
69:09 - threshold okay let's make this happen so
69:12 - the first thing that I should do
69:13 - probably is uh I would like to make
69:16 - myself just to be able to see this I'm
69:17 - going to make myself an
69:19 - image and I'm going to create a blank
69:22 - image which is the
69:24 - same as the width and height of the
69:27 - connect uh and it's an RGB image so this
69:32 - is a function in processing create image
69:34 - that just makes a blank image and then
69:37 - uh whoops and then what I'm going to do
69:40 - right now is I am going to in here I'm
69:44 - going to right here I'm going to say
69:46 - image. load pixels because I want to
69:49 - operate I need to operate on the pixels
69:51 - of that image I'm going to set pixels in
69:52 - that image based on the raw depth and
69:55 - the end I'm going to need to say image.
69:57 - update
69:59 - pixels and I'm also then going to want
70:02 - to draw that
70:04 - image so just to make sure that things
70:06 - are working what I'm going to do is
70:08 - right here inside sorry this is where
70:11 - all of the important code needs to
70:13 - happen right now it needs to happen
70:15 - right here inside this double Loop right
70:17 - for every X for every y I want to set a
70:20 - pixel in the image image. pixels index
70:23 - offset equals and I'm I'm just going to
70:25 - set it to be you know some color right
70:29 - now some purplish color and run this and
70:32 - we should see that that's working U okay
70:35 - so you can see this purplish color I
70:36 - clearly got the size of the window wrong
70:38 - let me just let me just get that for you
70:40 - guys really quick so if I go back and
70:43 - look at my RGB depth test um ah this
70:46 - isn't telling me Oh actually you know
70:47 - what let's just be smart about this um I
70:50 - want to just know what those values are
70:52 - I'm going to print out I'm going to
70:54 - print out the the the depth width and
70:57 - the depth height really quickly uh we
71:00 - can look in the console 512 424 I knew I
71:03 - had some was close so let me just get
71:06 - that right now and I I don't need this
71:07 - much of the console here and I can get
71:09 - back to the important part of the code
71:10 - we can run this we can see okay purple
71:13 - so I have now filled every pixel on the
71:15 - screen with purple but what I want to do
71:18 - is fill every pixel on the screen based
71:20 - on the depth so for example what if I
71:23 - were to just say if d is greater than
71:26 - 300 and D is less than
71:34 - 1500 image. pixels offset uh is that
71:41 - otherwise image. pixels offset is
71:44 - black so what I'm doing is I'm saying
71:47 - only if the only if the distance is
71:50 - between 300 and 1500 let me see a purple
71:52 - color otherwise let me see a black color
71:55 - and when I run this we should see oh my
71:57 - God I can't believe what I guessed I'm
71:59 - like a genius here I somehow guessed a
72:02 - pretty reasonable uh threshold so you
72:04 - can see here that now what I've done and
72:07 - now you see like all computer vision
72:09 - problems Melt Away in a way like uh what
72:12 - I could do now is like it's so easy to
72:14 - find the I mean not easy but it's much
72:16 - easier now to find the Contours I have
72:18 - this problem of this wall over here so
72:21 - how do I get rid of this wall well first
72:22 - of all the real way that I get rid of
72:24 - that wall is by not doing my connect
72:26 - stuff right next to a wall so
72:28 - unfortunately this is like a bad I need
72:30 - a better setup I think for doing these
72:31 - videos which someday maybe I will find
72:33 - but what I want to do let's at least see
72:35 - if I can get the hands so one thing
72:38 - you'll notice here is that the hands go
72:40 - away once you're about a foot and a half
72:42 - from the connect so what I really want
72:44 - is between about I don't know between
72:46 - zero and maybe like 500 so there's
72:48 - probably a better way for me to
72:50 - calibrate this than just randomly
72:52 - picking numbers but let's give this a
72:54 - try you can see nothing nothing nothing
72:56 - nothing nothing nothing nothing nothing
72:57 - nothing oh that didn't do much any good
73:00 - so so let's uh uh so I you know I whoops
73:03 - that's not going to do me any good
73:04 - either uh let's do between like 200 and
73:06 - a th000 nothing you can see uh like
73:09 - right but if I come in theit so you can
73:10 - see here how like I'm able to pick out
73:12 - only my
73:13 - hand uh again I've got this problem with
73:16 - the wall so I'm going to do something
73:18 - about that in a second uh to maybe try
73:20 - to like just like not look at the pixels
73:22 - on this side of the window I guess um
73:24 - but you can see how you I'm starting to
73:26 - find this idea of a minimum and a
73:28 - maximum threshold and really I should
73:29 - make these variables so I'm going to say
73:32 - A Min thresh is 200 and Max
73:37 - thresh is 1,000 and you know I might as
73:40 - well make these floats because what
73:42 - could be also useful I think the way to
73:44 - I could calibrate this right here's a
73:46 - great way I could calibrate this so in
73:48 - between the minimum threshold and the
73:50 - maximum threshold what I might do is up
73:53 - here I might say Min threshold equals
73:57 - map the mouse's x value which goes
74:00 - between zero and width to between 0 and
74:06 - 4500 uh and the maximum threshold I'm
74:09 - going to do Y which between 0 and height
74:12 - 0 and 4500 and then I'm just going to
74:14 - print out those values I could draw them
74:15 - on the screen which would probably be
74:17 - let's draw them on the screen so then
74:19 - down here I'm going to just fill 255
74:22 - text size uh 32 two uh text Min thresh
74:28 - plus oh I got to use um double quotes
74:31 - Max thresh you know 10 comma 64 so here
74:35 - we should see on the
74:37 - screen these values so now what I need
74:40 - to do is figure out like what's a good
74:43 - uh whoops wait X is going between I'm
74:46 - doing I'm lost what I'm doing something
74:48 - is wrong here uh Mouse X between oh this
74:52 - is Max thresh yeah that's a problem uh
74:55 - okay so now you can see I'm able to like
74:57 - calibrate the minimum
75:00 - threshold and let's calibrate the
75:02 - maximum threshold like how far back am I
75:04 - seeing but the minimum needs to be
75:06 - higher and then I don't want to see too
75:08 - far back so there we go so this I feel
75:11 - like is good if I'm getting my hand
75:13 - right now it's between about 480 and
75:16 - 827 so let's like only if I'm standing
75:19 - right here of course but you know you
75:20 - could design an interactive exhibit
75:22 - where you put some footprints on the
75:23 - floor and the person has to stand there
75:25 - so I'm now going to keep my hand boy
75:27 - this is a long video I'm at 15 minutes
75:28 - I'm going to keep my hand around here
75:30 - I'm going to make the minimum and
75:31 - maximum 480 and 830 so now I can comment
75:34 - these lines of code out and I'm going to
75:37 - say uh 480 and
75:42 - 830 and I'm going to run this
75:45 - again and we can see I'm kind of I'm
75:47 - getting my hand like really I'm getting
75:49 - a pretty good tracking of my hand so one
75:52 - thing that I'm going to do now of course
75:54 - which I think would be useful is try to
75:56 - get rid of this wall over here so you
75:58 - know the wall is a bit of a problem but
76:00 - I can kind of uh do a little bit of a
76:01 - cheat here I think which is also to say
76:05 - if
76:06 - and and X is greater than I don't know
76:09 - what how many pixels do you think that
76:11 - was that was probably about uh 75
76:15 - pixels so uh maybe it's a little bit
76:17 - more so I'm just like not allowing me to
76:19 - measure anything that's like 100 pixels
76:22 - over so you can see I kind of got rid of
76:23 - that wall and now I have my hand so this
76:25 - is great you can see like this really
76:27 - nice clean outline of my hand because
76:30 - this is my other hand coming in it's not
76:32 - inside until it gets there right it's
76:34 - outside of that maximum threshold and
76:36 - now it's inside of that minimum
76:37 - threshold it's funny how it like oh no
76:40 - my arm is coming in so of course if my
76:41 - whole body comes in now you can see my
76:43 - whole body is here which is another
76:45 - thing that I want to look at so um you
76:47 - can see how this minimum and maximum
76:49 - threshold is working pretty well so I
76:51 - think this is this wraps up this video
76:53 - I'm going to continue this exact example
76:55 - you could try this on your own as an
76:56 - exercise before you get to the next
76:58 - video how would I actually just find the
77:00 - center of my hand so I could control a
77:02 - processing sketch Now by moving my hand
77:04 - around or moving this hand around or
77:06 - what if I do both hands so how would I
77:08 - do that this is I feel like I'm like I'm
77:10 - some sort of like magic person here um
77:12 - so that's what I'm going to look at in
77:13 - the next video how do I find the center
77:15 - of my hand and control something else
77:17 - like a little like snake that's moving
77:19 - around the screen or make a particle
77:20 - system come out of my hand we'll look at
77:22 - that in the next video and another thing
77:24 - I want to look at is how would I find
77:25 - the top of my head so if I'm the human
77:28 - being here how do I know if I'm bending
77:30 - down or standing up okay so we'll look
77:32 - at that in the next video thanks for
77:34 - sticking with me here I think this is
77:35 - actually starting to come together
77:39 - okay all right chat is anybody
77:43 - there um okay how is the hand Edge drawn
77:47 - in black
77:49 - um okay 424 you guys are telling me in
77:52 - the chat you're so nice uh boy the the
77:56 - live stream is like way behind me I
77:58 - think oh no I've DVR I'm I'm like I'm
78:01 - behind okay I don't need to sorry I'm
78:04 - how's everybody
78:06 - doing uh I got to refresh this page
78:09 - that's my problem oh no I just need to
78:11 - be here ah no wonder I'm in the wrong
78:15 - place uh sorry everybody um I gotta
78:18 - close this come back here there is 23
78:22 - people
78:23 - watching um uh hi Sean uh welcome
78:28 - everyone I'm about to do in the next
78:30 - video I'm going to demonstrate how to
78:31 - find the center of my hand so and then
78:33 - I'll make a particle system come out of
78:34 - it which I think will be loads of fun
78:36 - for every all the family it's a family
78:40 - holiday family edition of the coding
78:42 - rainbow today and Thanksgiving uh I'm
78:44 - going to drink a little water
78:45 - here
78:48 - um I got to cycle the
78:53 - cameras
79:01 - okay
79:03 - um so I'm just about ready I'm seeing if
79:06 - there's um somebody asked when do you
79:08 - think you can upload the videos uh I
79:10 - will most likely upload the videos uh by
79:12 - the end of the day today tonight um or
79:14 - certainly tomorrow morning guess I'm
79:17 - going to do it as soon as I can uh and
79:19 - if they're not there you can always twe
79:21 - but this will always be there um this
79:23 - will automatically be archived and on
79:25 - YouTube this like a long thing but the
79:27 - so far I've made two three videos
79:29 - they're each about 15 minutes those will
79:31 - be uploaded
79:32 - tonight I don't so many Sean's asking if
79:34 - anyone ordered me pizza yet first of all
79:36 - I don't eat dairy so don't order me a
79:38 - pizza a little like you know vegan tofu
79:42 - quinoa salad things is like more in my
79:45 - speed um but don't order me any food I'm
79:47 - fine I ate a big breakfast I'm feeling
79:49 - good I got to probably this Thanksgiving
79:52 - thing is going to happen tomorrow and
79:53 - I'm going to have to eat this like giant
79:54 - meal
79:56 - uh so don't worry about me I'm fine
80:01 - uh um okay uh what was I going to say I
80:05 - don't
80:05 - remember I think I'm ready for the next
80:08 - video okay so in this next one what I'm
80:11 - going to do is look at how to find the
80:12 - center of my hand right we did this
80:14 - thresholding here and now I'm going to
80:16 - find the center of my hand and let me
80:18 - get a particle system example open it's
80:21 - probably overkill for me to bring that
80:23 - in but it's uh I'm let's let's do it
80:25 - it's totally worth
80:27 - it uh so I'm g go under topics simulate
80:31 - a simple particle system I'm going to
80:33 - change something here really
80:37 - quick about this particular
80:39 - example
80:42 - um uh I really wish I didn't make the
80:45 - example the way that I made it
80:50 - uh
80:52 - uh yeah what did I oh add particle
80:56 - H shf
81:03 - man okay let's see if this works okay so
81:06 - I'm going to make this these particles
81:08 - come out of my hand as I move that's
81:10 - going to be fantastic okay that's going
81:13 - to be the next example yeah yeah read
81:16 - only read only shme only okay so I'm
81:20 - going to go back to minmax threshold and
81:23 - here we go I'm going to hit run here uh
81:27 - and I'm ready to do this
81:29 - video uh thanks for sticking around both
81:32 - XP goodbye Cardiff
81:34 - England uh Wales which is part of the UK
81:38 - and whatever I my geography is off sorry
81:41 - okay here we go ready uh did I cycle the
81:43 - cameras did any remember if I did that I
81:44 - don't remember so I'm going to do
81:48 - that uh let's see oh I'm running low on
81:52 - battery for the microphones but I think
81:55 - I've got a full bar and I've got three
81:57 - bars on the one in my pocket so it
81:58 - should be
81:59 - okay try to keep an eye on that and over
82:03 - here if I stand about here that's where
82:05 - the hands are okay great okay here we
82:09 - go in three I'm going to close
82:13 - this in
82:16 - three I have to press the button there's
82:18 - nobody here to press the button but
82:20 - me hello um in this video I'm going to
82:23 - demonstrate some really basic basic hand
82:25 - tracking with the with the connect and
82:27 - I'm going to make a particle system come
82:28 - out of my hand that's what we're going
82:30 - to look at in this particular video so
82:32 - in the previous video what I did is
82:34 - create this sketch where I calibrated a
82:36 - minimum threshold and a maximum
82:38 - threshold so I'm only looking at depth
82:40 - pixels between those values so if I
82:42 - stand exactly here and move my hand
82:44 - around I can you can kind of see a
82:45 - pretty clean outline of my hand of
82:47 - course this breaks down if I stand too
82:49 - close or if I stand too far away but you
82:52 - know and so I should mention that
82:53 - ultimately this type of of hand tracking
82:55 - might be better suited for the official
82:57 - Microsoft SDK and I'll get to that
82:59 - eventually using a PC and different uh
83:03 - uh processing connect library but I
83:04 - think it's still nice to see these
83:06 - examples of how you can do this stuff
83:07 - with the raw depth okay so let's look at
83:10 - how you might do this so this is where
83:12 - we are we're looking for all pixels that
83:14 - are in between a minimum threshold and a
83:16 - maximum threshold so how might I find
83:19 - the center of all of those pixels right
83:22 - here in the center of my hand well the
83:24 - way that you find the center of
83:26 - something off sometimes called the
83:27 - centroid if you want to sound like
83:28 - you're from the future let's look at the
83:31 - centroid um is by finding the average
83:34 - location so let's say we have a
83:36 - collection of pixels you know that are
83:40 - Loosely this is some strange like
83:41 - three-fingered hand right these are all
83:44 - the pixels we care about we can plainly
83:47 - see that this is the scent about around
83:49 - the center but how would I find out the
83:51 - average well let's say you just had
83:54 - these X values this is the x value zero
83:57 - three uh you know 4 8 12 to find the
84:02 - average of some numbers add them all
84:04 - together and then divide by the total 0
84:07 - + 3 + 4+ 8 + 12 divided by 1 2 3 4 five
84:11 - divid five is the average so if we add
84:14 - up all add all x's and we add all y's
84:21 - and we divide by total pixel
84:25 - not the total pixels in the entire image
84:27 - just the pixels that we've picked out
84:29 - that are in between this minimum and
84:30 - maximum threshold then we'll find the
84:33 - center of that area of pixels so let's
84:35 - look at that how do we inside that Loop
84:37 - add up all the X's add up all the Y's
84:39 - divide by the total number of pixels
84:41 - it's actually a pretty simple thing to
84:43 - do this might be the shortest video I've
84:44 - ever made um I'm going to start I need
84:47 - some value to keep track of the the sum
84:50 - of all the X pixels so I'll add that in
84:53 - then I need another variable to keep
84:55 - track of uh summing up all the Y pixels
85:00 - so I'll add that in then what I also
85:03 - need is a just a total pixels zero now
85:07 - I'm making all these floats because I
85:09 - think it's going to be a bit more
85:10 - accurate to use floating Point math
85:12 - doesn't really matter they're they're
85:14 - technically the they're integers there's
85:15 - no like pixel 3.21 but it's a little
85:18 - simpler to work with floats so this
85:20 - value is where I'm going to add up all
85:21 - the X's this value is we're going to add
85:23 - up all the Y's this is going to be the
85:24 - total number of pixels remember that's
85:26 - not a fixed number like depending on
85:28 - where my hand is how many pixels is it
85:29 - picking up that's um that's going to be
85:32 - the total once I have that I can divide
85:34 - some X by total some y by total and
85:35 - that's going to be average X and average
85:37 - y so let's look at that so right here
85:41 - these are the pixels that count right
85:43 - these pixels right here are the ones
85:45 - that are pink those are the ones that
85:46 - are between the minimum maximum
85:47 - threshold that X is greater than 100 was
85:49 - just to get rid of the wall that's over
85:51 - here because the wall is 100 pixels and
85:53 - over um so in order to do that now I'm
85:56 - going to say right in here I'm going to
85:59 - say sum X Plus equal x sum y plus equal
86:04 - y like I'm literally just adding up all
86:06 - the X's adding up all the Y's and then
86:08 - total pixels plus plus so for every
86:11 - single Pixel just add one I need to add
86:13 - up the X values for the X the Y values
86:15 - for the Y and then figure out how many
86:16 - pixels are there and then at the end
86:19 - what do I got I've I don't need to um
86:23 - draw this text on the screen anymore
86:25 - what do I need to say I need to say the
86:27 - average X right the average X is the sum
86:29 - x divided by the total
86:31 - pixels the average Y is some y divided
86:36 - by total pixels and then now why don't I
86:39 - just draw let's make this a different
86:43 - color why don't I draw an ellipse at
86:45 - average X average Y and 100 um I don't
86:50 - know what what size should that ellipse
86:51 - be 64 by 64 so let's run this
87:54 - con that says add particle Mouse X Mouse
87:57 - y right so it's just as easy now as
88:00 - bringing all this particle system code
88:02 - over and saying instead of adding the
88:04 - particles at Mouse X Mouse y add them at
88:07 - average X average
88:09 - y so uh let's see if we can make that
88:11 - happen I'm going to bring I'm going to
88:13 - do a quick little I should have probably
88:15 - do like the cooking show thing where I
88:17 - have an now coming out of the oven I
88:18 - already pre-made this but I'm just going
88:20 - to copy paste everything over real
88:22 - quickly I'm going to bring the particle
88:24 - system
88:25 - object I'm going to put this in my setup
88:28 - over
88:29 - here and I'm going to put this stuff in
88:33 - draw and at the end here and then what
88:37 - do I need I need all this particle code
88:40 - so I don't actually need this camera
88:42 - prams tab for this example
88:45 - uh oh hold on uh uh hand tracking sort
88:50 - of particles I don't know what to call
88:52 - this uh I'm going to get rid of this uh
88:56 - tab C camera
88:58 - prams uh and then I'm going to add a new
89:01 - tab I really shouldn't be doing this in
89:03 - the
89:03 - video I think I crashed processing hold
89:06 - on no everything's fine I'm gonna add a
89:08 - new tab called this was not this was not
89:11 - good you fast forward fast forward a
89:12 - minute I'm gonna move the particle
89:14 - system over that was the particle
89:16 - class and I'm GNA duke it doesn't matter
89:19 - I'm to move the particle over just
89:20 - imagine that I did that correctly I'm
89:22 - going to run this which we can see right
89:25 - the particles the the circle is
89:26 - following my hand the particles are
89:28 - following the mouse how do I make those
89:30 - do the same exact thing now all I need
89:33 - to do is say make the particles not at
89:35 - the mouse but at average X average Y and
89:38 - you know what let's let's actually
89:41 - add about 10 particles per frame to make
89:44 - it kind of make more particles and let's
89:47 - run this and we can see now as I put my
89:49 - hand here I can like control where the
89:52 - particle I can make this like fiery
89:53 - thing come out of my it's not fiery but
89:56 - come out of my hand so you can see I'm
89:58 - now using my hand to control particles
90:00 - coming out I can do my dance and it you
90:03 - know works with anything like I can I
90:05 - can have part like this stuff like
90:07 - emanating from my it's like alien and
90:10 - like bursting out or something I don't
90:12 - this is all getting a little bit weird
90:13 - but you can see I can I can strike this
90:15 - pose and uh it's running kind of slow
90:18 - because I'm drawing like so many circles
90:20 - on the screen um it was a little bit
90:22 - unnecessary to like do that much but
90:25 - you can see anyway so I can make the
90:26 - particles move faster you can you can
90:27 - get where this is going here so this is
90:29 - one example of what you can do by having
90:32 - a kind of specific setup knowing where
90:34 - all the pixels are thresholding them
90:36 - finding the center of something um this
90:38 - is what you can do now let me say a
90:40 - couple more things before I go into the
90:42 - next scenario number one uh um and let's
90:46 - um let's turn the particles off for a
90:48 - second number one is we have this issue
90:51 - of one hand two hands the thing in the
90:55 - center on the one hand this is kind of
90:57 - cool I'm like I am a
91:00 - magician levitating a ball around I I
91:04 - forgot that I was making a video for a
91:06 - second on one hand that's sort of an
91:08 - effect on its own feature not a bug type
91:10 - thing on the other hand you might
91:11 - actually want to have a circle for each
91:14 - hand and in that sense you need to
91:16 - employ a more sophisticated blob
91:18 - detection mechanism for example you
91:20 - don't want just the average of all of
91:21 - the pixels you want the average of a
91:23 - bunch of pixels but don't include pixels
91:25 - that are over a certain distance
91:27 - threshold from other ones so this is
91:29 - something that I could potentially
91:30 - demonstrate in a future video in this
91:31 - series I'd be happy to add one in but
91:33 - also in this case one thing you can do
91:35 - if you have this very clean image you
91:37 - can pass it to a library that might do
91:40 - that type of edge detection blob
91:42 - detection Contour detection for you and
91:44 - there's two libraries I'll try to link
91:45 - to them in the description that I might
91:46 - recommend one is called blob detection
91:49 - does kind of what you're thinking
91:51 - another library is called open CV which
91:53 - has a lot of computer vision
91:54 - functionality built to it but one of the
91:56 - things in it is blob detection so maybe
91:58 - I'll try to like show that at a certain
91:59 - point but you can see the basic idea
92:01 - here is still just working even without
92:03 - uh an extra sophisticated layer of
92:05 - looking for separate chunks um okay
92:07 - thanks for watching this I think in the
92:09 - next video I have two more that I
92:10 - intended to do today although it is 1210
92:13 - I wanted to see if I could look at for
92:14 - the top like how do you find the highest
92:16 - pixel um or Theo you know closest pixel
92:19 - is something you could also find but I
92:21 - think highest might be interesting
92:22 - because uh somebody here at ITP has a
92:24 - project that she's working on which is
92:26 - uh having somebody move up and down so I
92:28 - think that's a useful demonstration and
92:29 - then also maybe looking back at that
92:31 - grid again um but averaging all of the
92:34 - depth points within cells of a grid okay
92:36 - that's what I intend to make next I'm G
92:38 - to hit stop on the record button uh come
92:41 - on wake
92:43 - up okay
92:46 - everyone
92:48 - uh all right
92:50 - [Music]
92:51 - everyone yeah I see some are chatting
92:54 - about me in the Stream it is true
92:57 - actually I didn't actually code start
92:59 - programming until 2001 I was 27 years
93:03 - old 2001 you can figure out how old I am
93:05 - now I did take some programming classes
93:08 - in middle school middle uh Assembly
93:10 - Language and basic uh I also took an
93:13 - evening C++ Course once because I
93:15 - thought it might be interesting in
93:16 - programming and I was like this didn't
93:17 - like it uh but then I think being in a
93:19 - creative environment like ITP I got kind
93:21 - of obsessed with it so that is true
93:25 - uh um okay so uh I forgot when my I have
93:29 - to check when my office hours are
93:32 - because I have to go soon unfortunately
93:34 - I have to grab something to eat before
93:35 - let me just I'm looking this up right
93:38 - now uh they start at uh shiffman
93:43 - shiffman shiffman where's shiffman uh at
93:46 - one I I'm not going to give the time
93:49 - okay yeah 120 I need to take a break
93:52 - obviously to eat something between them
93:53 - so so I think I could manage a little
93:56 - bit more because I want to do I think I
93:58 - could try to do these two examples real
94:00 - quick um so let's look at the
94:04 - um yeah there's a problem where I need
94:07 - to file the open CV is not showing up in
94:10 - processing 3 but it actually works in
94:11 - processing 3 it probably just needs a
94:12 - few little fixes um uh I I would love to
94:16 - I uh Greg Borstein who did a tremendous
94:18 - amount of work creating this Library um
94:21 - I should look at it and see if I can uh
94:22 - just put a pull request quickly on
94:24 - GitHub to or to make sure that it shows
94:26 - up uh in processing 3 because it does
94:28 - work in processing 3 there's probably
94:29 - just a few little things that need to be
94:31 - fixed um okay I'm going to I'm going to
94:35 - get a little more water I'm going out
94:36 - into the hallway and I'll be right back
94:52 - okay
94:58 - are you watching this from here okay you
95:00 - were
95:01 - sorry thanks
95:07 - Sean okay okay I'm back everybody uh I'm
95:12 - going to just get a little cool air in
95:14 - here for a
95:16 - second um I'm going
95:19 - to turn off and on the cameras Oh I have
95:23 - to go around this
95:31 - side
95:33 - okay
95:36 - uh let's see here I'm over here I'm
95:39 - going to erase so the next video that
95:41 - I'm going to make here oh wow there's
95:43 - quite a glare from the sunshine over
95:45 - here wonder if I write over here if you
95:47 - can't see it yeah you can't see that
95:49 - very well so I'll just be conscientious
95:51 - of that I I just can't bear to like
95:54 - black out the window in this room it's I
95:56 - did that last year and it's like
95:57 - miserable to be in here so much rather
95:59 - have the sun infecting me uh let's see
96:02 - okay this is pretty good um okay so in
96:04 - this next video the next thing that I'm
96:06 - going to do is look for the closest
96:08 - point or the top of someone's head uh
96:12 - the highest point that type of thing um
96:14 - which is a kind of common algorithm in
96:15 - computer vision that you need uh uh oh
96:19 - yeah right there was a hot mic again uh
96:23 - and um okay and I'm going to um um here
96:27 - we go I got to close the
96:29 - window I'm going to try to I'm going to
96:31 - try to do this by the way for 15 more
96:34 - minutes I don't know if I can get
96:36 - through both of these topics in 15 more
96:38 - minutes
96:41 - um and then I have to
96:43 - go uh I guess I've been doing this for 1
96:46 - hour and 36 minutes so
96:48 - far okay here we go uh water's here and
96:54 - getting myself ready I I cycled the
96:57 - cameras didn't I just do that right I
97:00 - can't remember do it
97:04 - again I'm going to check the battery is
97:07 - at one bar still so my mic shouldn't go
97:09 - out in the middle of
97:12 - this
97:18 - okay hello um in this video I'm going to
97:21 - look at how you might using the connect
97:23 - fine the closest thing in the room or
97:25 - the highest thing in the room um this
97:28 - type of algorithm is kind of common in a
97:30 - lot of computer vision applications I
97:32 - think which involves
97:38 - similar hi um in this video I want to
97:41 - look at an algorithm that lets you do
97:42 - the kinds of things like find the
97:44 - closest thing in the room or find I'm
97:47 - doing all sorts of like Vogue poses find
97:49 - the highest thing in the room I don't
97:51 - know why I need to do that for the
97:52 - highest thing but whatever um or uh and
97:56 - this is a similar type of algorithm if
97:57 - you've ever looked at like a color
97:59 - tracking algorithm find the brightest
98:01 - thing or find the most red thing in the
98:03 - room I like to refer to this as like the
98:05 - world record algorithm which means like
98:07 - I've got to look at every single Pixel
98:09 - and keep track of which pixel is the
98:11 - record holder and hold on to that record
98:13 - holder the closest thing the highest
98:14 - thing the most red thing and when I get
98:16 - to the end have that XY coordinate that
98:18 - I can use for something else so a lot of
98:21 - things that you might do with the raw
98:22 - depth data of the connect could involve
98:24 - this like if you know the person is
98:25 - always standing like this in a fencing
98:28 - pose what is where is their hand because
98:30 - their hand is always the closest thing
98:32 - or if you want to determine if a person
98:34 - is moving up and down how do you find
98:36 - the top of their head what's the highest
98:37 - thing within a given threshold so let me
98:40 - uh go over to the Whiteboard for a
98:41 - second to just talk in generally
98:43 - speaking about how this kind of
98:44 - algorithm works and then we'll go and
98:47 - implement it in a couple different
98:48 - scenarios okay so as with just about
98:52 - everything that involves IM and pixels
98:54 - or depth points you've got this grid
98:57 - right and the grid has a bunch of x's
98:59 - and a bunch of y's and there's always
99:01 - this Loop all the examples have this for
99:04 - every X for every I look at every pixel
99:08 - now I've got some glare here so
99:10 - hopefully you're going to be able to see
99:10 - what I'm writing but I was to to say
99:12 - shout at me just shout at your computer
99:14 - screen or wherever you're watching this
99:16 - and I will hopefully hear you someday um
99:18 - if you can't read what I'm about to
99:20 - write but uh but so the way that this
99:22 - works is you need to find the record
99:24 - holder so what let's say we wanted to
99:27 - find the um uh the closest thing so
99:32 - remember the depth values are between 0
99:35 - and
99:37 - 4500 so we could start by saying the
99:40 - initial record right the world record
99:43 - for the closest thing would be 4500
99:46 - because that's the furthest back so any
99:49 - pixel that beats 4500 is the is by
99:51 - definition the new record holder
99:54 - so we have to say something like if I
99:56 - have the current depth in a variable I
99:59 - need to say if that depth is less than
100:03 - the
100:04 - record then the record is now that depth
100:09 - so this is the core algorithm for every
100:11 - pixel is the first one beating the
100:13 - record it is that's the record holder is
100:15 - the next one beating that record no is
100:17 - the next one beating that record no is
100:18 - the next one beating that record yes
100:20 - okay that's the record holder and while
100:22 - we're doing this we could also keep
100:23 - track of you know the record X and the
100:26 - record y so if we went every time we get
100:29 - that new record we store that X and Y so
100:31 - that by the time we get to the end of
100:33 - this Loop in those variables are the X
100:36 - and Y that win this record so let's look
100:39 - at how we might do that um and I will
100:43 - come over here and let's look at let's
100:46 - do um okay let me save this I kind of
100:49 - want to do the closest thing this what
100:51 - we talked about but you'll see that it's
100:53 - not going to work in the most perfect
100:54 - way but let me save this as uh a closest
101:00 - uh
101:01 - thing and I'm going to um I just want to
101:04 - delete the particle system tabs which
101:07 - are no longer
101:08 - relevant uh oops don't delete that tab
101:11 - ah I think I made a mistake earlier and
101:14 - I'm going to get rid of all this
101:15 - particle system stuff sorry I should
101:16 - have done this before I started
101:18 - recording this but it's too late now um
101:20 - we can get rid of all this particle
101:22 - system stuff and and I'm going to get
101:24 - rid of the average thing that was
101:25 - interesting that we were doing in the
101:26 - previous video um and even such I'm
101:30 - going to keep this I'm going to keep
101:31 - this thresholding in here because I
101:34 - think that's maybe a little bit useful
101:36 - um to kind of keep at the moment
101:38 - actually you know what I'm going to take
101:39 - that thresholding out but I'm going to
101:42 - keep this x is greater than
101:44 - 100 and uh what I would like to do
101:50 - is H too much too much going on that I
101:53 - didn't think to do in advance it's okay
101:55 - everything's fine just you know Talk
101:57 - Amongst yourselves for a minute or fast
101:59 - forward like 30 seconds in this video
102:01 - and I will be at the point so I just
102:03 - want to take out all this stuff let's
102:05 - keep the
102:06 - um uh and uh yeah this is
102:11 - fine uh what I ah I know what I need to
102:14 - do everything's
102:16 - fine uh I'm going to draw I don't need
102:18 - this image
102:20 - anymore uh right what I'm going to do is
102:24 - what I want to have access to to look at
102:26 - sorry everybody is the um the raw depth
102:30 - image I'm not sorry the depth image as
102:32 - well so I'm going to call this the D
102:34 - image equals connect
102:37 - to.get depth uh
102:40 - image so that way I can draw that image
102:43 - on the
102:45 - screen and so let's just make sure this
102:47 - is now working so you can see okay I've
102:50 - got the depth image on the screen so
102:51 - what I want to do now is look look for
102:54 - the pixel that is the closest okay and
102:57 - we've got a bit of a problem here
102:58 - because some of these there's a window
103:00 - back there and it's going to give me
103:01 - some weird zero values so I think this
103:04 - this might not work oh and I should have
103:05 - kept the
103:06 - thresholding crap I should really you
103:08 - know what I'm GNA I'm going to hit stop
103:11 - on the recorder for a second and I'm
103:13 - going to just uh Stitch these Stitch
103:15 - This Together from when I move from over
103:16 - here over here ah crap I I wasn't
103:19 - thinking straight there okay I'm pausing
103:21 - for a
103:22 - second uh all right um so let let me let
103:26 - me figure this out
103:29 - here closest let's just see how this
103:31 - works I'm going to build this I'm going
103:33 - to pause the video I don't I I should
103:34 - have checked this in advance I'm going
103:36 - to close this so what I'm doing now I'm
103:38 - going to come back and record again in a
103:40 - second what I'm doing here is and I can
103:43 - delete all this stuff I'm need that
103:46 - threshold again in a second what I'm
103:48 - doing here is um looking for okay okay
103:53 - so I need the uh record is
103:58 - 4500 and the record X is zero and the
104:02 - record y uh record Y is zero and I'm
104:08 - going to
104:09 - say
104:11 - uh if D is less than record then record
104:15 - equals D Record xal X record yal
104:20 - Y and I need to close curly bracket and
104:23 - then at the end of all this looping I
104:26 - can say
104:28 - uh draw an ellipse at record X record y
104:32 - that is some size that's kind of big uh
104:36 - and let's see how this
104:38 - goes okay so you can see the problem is
104:42 - that it's always in the top
104:43 - left U it's a good thing so what I
104:46 - should probably okay so one thing that I
104:48 - was going to do right is Skip
104:51 - uh skip these
104:55 - pixels uh let's try
104:58 - this and let's see can I get it to be
105:01 - something problem is there's too much
105:03 - glare and reflection back there so I
105:05 - should do the top I should just do oh I
105:08 - I as I got over here something became
105:10 - closer than what's back there my
105:14 - head oh yeah I'm kind of able to get
105:17 - this to work if I come really close but
105:20 - not it doesn't work so great because I
105:21 - really should be there we go why is it
105:24 - if I move I must have messed something
105:27 - up record yals y record xals x no that's
105:31 - right um what I probably I probably
105:34 - should do the top of the head thing why
105:36 - is it not it's interesting how so I
105:39 - think this is a bad demonstration I um
105:42 - which is a mostly because of the setup I
105:44 - have here like if I had if I had the
105:46 - connect over here and had this flat wall
105:47 - behind me it would work pretty well um I
105:50 - could look for the thing that's closest
105:52 - within a minimum Max maximum threshold
105:54 - which is probably I should have kept
105:55 - that um but I think what I might do is
105:57 - put the threshold back in and look for
105:59 - the I should put the threshold back in
106:01 - so let me bring that back uh I still
106:05 - have that here so I want to say
106:10 - if uh so let's bring the threshold back
106:12 - in
106:14 - if so I only want to consider stuff
106:17 - that's if D is greater than Min
106:20 - thresh and D is less than Max thresh
106:25 - and
106:27 - um X is greater than 100 I think is what
106:30 - I had then then I can look for the
106:35 - record uh
106:39 - thresh so this should right now this is
106:43 - working you can see how much it jumps
106:44 - around but you can see it works with
106:46 - anything that's within that threshold
106:48 - that's closest which right now if I bend
106:50 - down is also my head but course as I
106:53 - move out of the threshold so you can see
106:55 - how like unstable this is but I think
106:57 - that could sort of do the demonstration
106:59 - I actually want now also to have that
107:01 - image back
107:02 - now uh which is that I should say
107:07 - um uh what I should be doing
107:11 - is uh I think this would be hold on I
107:15 - you're kind all to
107:18 - stay uh set the initial record to the
107:21 - highest possible didn't I do that um so
107:24 - what I want to do is put that that
107:26 - um the uh image back in too so uh image
107:31 - that load pixels so I'm going to say
107:36 - um
107:38 - uh image
107:41 - dot here let me turn off I'm going to
107:43 - turn off the code completion uh else
107:46 - else uh image.
107:49 - pixels uh
107:52 - offset equals D image.
107:55 - pixels
107:58 - offset and I'm going to here say uh
108:04 - image. pixels offset
108:08 - equals uh color uh 2550
108:12 - 150 and then uh this should be a
108:16 - different
108:17 - color uh so I oh and then I need to draw
108:20 - that image
108:22 - also
108:25 - let's see up
108:27 - whoa hello connect that is the weirdest
108:30 - thing I've ever
108:32 - seen what just happened
108:35 - there whoa what is going on oh some
108:38 - other imag is
108:41 - there whoa what is going on oh I didn't
108:44 - say image. update
108:46 - pixels must be
108:49 - why there we go so I should see like
108:53 - when the stuff is within the threshold
108:55 - I'm finding the closest thing within the
108:57 - threshold um which might be like my
109:02 - elbow uh that sort of thing maybe that
109:06 - minimum threshold should be actually
109:08 - like lower anyway um okay so sorry okay
109:13 - I'm gonna I'm going to I'm gonna start
109:16 - this over and I'm going to start it I'm
109:19 - going to take this
109:21 - out and I'm going to
109:24 - take this out this is the stuff that I'm
109:26 - going to add
109:27 - in and I'm going to take this out so now
109:32 - what it should
109:33 - be I've just got something where it's
109:35 - showing the only the threshold of pixels
109:38 - but also all the rest of them and then I
109:40 - I really want to do the top of the head
109:42 - thing because I think that might
109:43 - actually work much more accurately um to
109:46 - find the highest pixel that's within the
109:48 - threshold but I'll do the closest and
109:50 - then the top why not right
109:53 - okay um so I now have to pretend where
109:57 - was I I was over here and I was talking
110:01 - about this stuff and then I finished and
110:04 - went over to the computer to talk about
110:06 - something else so I'm going to do that
110:13 - again shoot this is going to be this is
110:17 - definitely going to be uh whoops this is
110:19 - definitely going to be
110:21 - um come back come back this is
110:24 - definitely going to be it for today once
110:25 - I get through these two examples because
110:27 - I really I'm I'm like sort of late now
110:29 - we have 45 minutes till my first
110:31 - appointment I need to eat something in
110:32 - between so but I I want to I want to get
110:34 - through this so to have this done okay
110:37 - so here we go I think I can do this now
110:40 - um with this particular
110:43 - example uh so I'm gonna have to like cut
110:45 - this somehow I I I hate it when I do
110:48 - editing this is I'm not really going to
110:50 - do editing I'm just going to splice
110:51 - these things together
110:54 - and I'm going to uh pretend okay so I'm
110:57 - going to walk into the scene over
111:01 - here I'm afraid am I recording this I am
111:04 - yes
111:05 - okay okay so to demonstrate this example
111:08 - now what I have is I've I've adjusted
111:10 - this example a little bit and what it's
111:13 - doing now is it's showing you both the
111:15 - depth image as well as coloring
111:18 - particular pixels of that depth image
111:20 - this pink color that are within this
111:21 - threshold so now I need to figure out
111:24 - what pixel in that threshold is perhaps
111:27 - a record holder of some sort of record
111:29 - so we'll look at the closest thing and
111:31 - also the highest thing and I'm pretty
111:32 - sure the closest thing is going to not
111:34 - work that well but the highest thing I'm
111:36 - hoping is going to work pretty well so
111:38 - let's do the thing that's not going to
111:39 - work as well first um and let's just
111:41 - look at a little bit of what's changed
111:43 - in the code just to to show you so first
111:45 - of all I'm looking at the depth image as
111:46 - well and then what I'm doing is if the
111:50 - pixel if this um depth value is in the
111:52 - the threshold I'm setting that
111:54 - particular color to this pink value if
111:57 - or purple value I don't know what color
111:59 - it is I can't tell uh if it's not um
112:03 - then I'm just pulling the color value
112:04 - from the depth image itself then
112:06 - updating the pixels and drawing the
112:07 - depth image so that is why you are
112:09 - seeing this particular result it's
112:12 - essentially what I had earlier in the
112:14 - previous examples with just also adding
112:16 - in those depth pixels instead of black
112:18 - so now we need to figure out this way of
112:21 - a getting a record holder so the first
112:23 - thing we need to do is say what at the
112:25 - beginning what's the record distance I'm
112:27 - looking for the thing that's closest so
112:30 - the thing that's closest the record to
112:32 - start would be something really really
112:33 - high so the record would be 4500 that's
112:36 - as far as it as something is possible to
112:38 - be from the connect then I need the
112:40 - record X which will be at zero and the
112:42 - record Y which will be at zero so I want
112:44 - to test every pixel X and Y if it beats
112:47 - the record if it does beat the record
112:49 - set RX to that new X and set r y to New
112:53 - Y and then draw a circle at that record
112:55 - value at the end so right here I'm going
112:57 - to check only inside the threshold you
113:00 - know in a different scenario where I had
113:02 - the connect in like an open space and a
113:04 - and a sort of flat wall and people just
113:06 - came into the middle I don't wouldn't
113:08 - really need to do this thresholding
113:09 - thing because I but there's so much
113:10 - stuff in this room there's a desk
113:12 - there's a computer there's a wall that
113:13 - it's not so I think using the threshold
113:15 - here helps it be a little bit more
113:17 - accurate so I can say if that distance
113:20 - is less than the record then the new
113:22 - record is that particular distance right
113:24 - for every single Pixel does that pixel
113:26 - beat the record if it does I've got a
113:28 - new record and if it beats the record
113:31 - then I need to save that particular X
113:34 - and Y in RX and r y so all we need to do
113:37 - this kind of record algorithm is a
113:38 - starting record a starting RX and r y
113:41 - and then every time we beat that record
113:43 - save those two values and then at the
113:47 - end I can draw a circle at RX and r y
113:52 - and I'll just make that Circle uh White
113:55 - uh so it kind of we pick it up and we
113:56 - can see now okay now first of all you
113:58 - can see that circle is just jumping
114:00 - around that's because first of all
114:02 - there's very little there's like stray
114:03 - pixels that are that are making it in
114:05 - the threshold so now you can see that
114:07 - it's kind of working now you can see
114:09 - that white circle is following my hand
114:11 - now notice this is much less accurate
114:12 - than what I did before with a sort of
114:14 - average section of pixels um mostly
114:17 - because anytime you're looking for a
114:18 - single Pixel it's not such a great thing
114:20 - I kind of want to find a group of pixels
114:22 - that are like beating that record but
114:24 - that aside you can see the basic idea is
114:26 - working but it's really like if I come
114:28 - and stand in here like there's a lot of
114:30 - me that's in the threshold but my head
114:33 - as I'm bending over is closer so you can
114:35 - see if I move my hands out they're a
114:37 - little bit closer if my shoulder comes
114:39 - in my shoulder is the closest thing so
114:41 - you can see it's jumping around a lot
114:43 - but it's always finding the particular
114:45 - pixel that is closest it's just sort of
114:47 - demonstrating the idea but let's change
114:49 - it now let's have it find I'm going to
114:51 - stand here to
115:52 - I've beaten that record so record equals
115:55 - that y value save this save the X and
115:58 - the Y and then draw it so the same exact
116:00 - idea I'm just changing what the test is
116:02 - like the height is the yv value if it's
116:04 - less than that record so now we'll run
116:07 - this and we can see it's picking up a
116:09 - lot of noise but if I come in and bend
116:12 - down so there's too many pixels up top
116:15 - you can see that it's flickering there's
116:16 - too many pixels up top that are pulling
116:18 - up some sort of value so I'm going to
116:20 - try to do like a little bit of a hack
116:21 - here again we're going to say and I'm
116:24 - say let's skip uh let's skip the first
116:27 - like 50
116:29 - pixels I'm only going to look and let's
116:31 - see if this helps there we go so now you
116:34 - can see I'm getting the top of my head
116:36 - pretty accurately if I move my hand up
116:38 - here I'm getting the top of my hand so
116:40 - if I had a particular uh project that
116:43 - wanted to have something move based on
116:45 - whether I'm moving up and down this is
116:46 - good I'm going do some X squats here um
116:49 - you can see that this works so you know
116:51 - I had to sort of like Cal and do some
116:53 - goofy things but you can see this is a
116:55 - very simple way of just finding the top
116:56 - so like people always get obsessed with
116:58 - like finger tracking like let me find
117:00 - the finger but you can see how accurate
117:02 - this is I'm just getting like the tip of
117:03 - my finger now there's no finger tracking
117:05 - here just like if I go like this it's
117:06 - getting the top of my elbow but if you
117:08 - tell people to stand like this and wave
117:09 - their finger you can see how like kind
117:11 - of super accurate that tracking is just
117:13 - from looking this is like the simplest
117:15 - thing ever I'm just looking for the top
117:18 - pixel inside this threshold so hopefully
117:20 - this shows you a few types of things you
117:22 - can can do uh we've seen a range of
117:24 - things of just sort of visualizing the
117:25 - 3D data from like looking for
117:27 - thresholding it in between for tracking
117:29 - the the height of something the average
117:31 - location um this is where I'm finishing
117:34 - this video set today um but there will
117:36 - be some more ones I guess who knows when
117:38 - you're watching this the more ones might
117:40 - already exist the more ones and you'll
117:41 - see them in the next video okay so
117:43 - thanks for watching uh this how oh yeah
117:46 - right uh and I will uh talk to you soon
117:48 - okay
117:51 - goodbye
117:53 - all right everybody um so that's it for
117:56 - today um and uh so if you have any
118:00 - questions I can take questions for like
118:02 - maybe five minutes it's 12:36 and I'm
118:05 - going to go in about five minutes um and
118:10 - uh I can take questions and um then I'll
118:14 - go sorry my brain is like totally fried
118:17 - this has been an hour and 58 minutes
118:19 - that I've been on this live stream um so
118:22 - I'll give it a minute to see if anybody
118:23 - wants to ask
118:25 - anything
118:29 - uh uh
118:31 - whoops um see if anybody
118:36 - is
118:38 - um okay
118:41 - uh any important info
118:44 - here
118:50 - um uh okay let's see if anybody ask any
118:53 - questions uh any tips on using more than
118:56 - one connect uh what you want to do if
118:58 - you want to use more than one connect is
119:00 - uh go look at the examples uh in the
119:03 - examples I'm going to come back up here
119:05 - under contributed exam uh oh oh no no
119:09 - contributed libraries under open connect
119:11 - um so this one here multiconnect version
119:15 - this one is showing you actually how to
119:16 - use more than one connect and even a
119:17 - connect version one and a connect
119:19 - version two in the same sketch and here
119:21 - under connect one multiconnect and here
119:23 - in Connect for multiconnect 2 so for
119:26 - example if I just come to multiconnect 2
119:28 - you can see here um that you can create
119:32 - uh two different connect objects and
119:34 - then init them as init device zero and
119:36 - init device one which will make them
119:38 - separate so you can actually everything
119:39 - works exactly the same way it's pretty
119:41 - simple to be able to do that
119:44 - yeah uh what is the update rate of
119:46 - connect depth data I'm pretty sure it's
119:48 - 60 frames per second but kind of I don't
119:51 - actually know uh I bet you if you Google
119:53 - that there'll be an answer on stack
119:54 - Overflow or something I would love to
119:55 - know the answer to that for sure I I I
119:57 - seem to remember hearing 60 frames per
119:59 - second I don't know that the first
120:01 - version one connect was that but I think
120:02 - the new one is um
120:05 - okay oh yes sorry so okay great so I
120:08 - this is technically how you could have
120:10 - more than one connect hooked up to your
120:11 - computer but you do have certain issues
120:13 - with like you point them at each other
120:15 - the infrared light starts to interfere
120:16 - with each other so trial and error is
120:18 - your best friend here sometimes it just
120:20 - seems to work anyway sometimes it can be
120:21 - a problem if you have a lot of the
120:22 - sunlight it can interfere you can't put
120:24 - a mirror in the room because the mirror
120:25 - is can to reflect all the light so
120:27 - there's a lot of issues around that but
120:29 - um you know for the most part you can
120:32 - have two connects you know if they're
120:34 - pointed in different directions and the
120:35 - infrared stuff doesn't cross they'll
120:37 - definitely work if they do cross I feel
120:39 - like with the new version too they seem
120:40 - to like operate on different frequencies
120:42 - or something and it kind of still works
120:44 - anyway but i'm to be honest I I haven't
120:46 - you know done a lot of stuff with the
120:48 - connect I'm kind of just trying to teach
120:50 - it from like making examples but I
120:52 - haven't with the new connect I haven't
120:53 - really like made a lot of projects with
120:55 - it
120:57 - um okay 2 hours is generally my limit uh
121:00 - I hope next week I've got a real
121:02 - schedule problem but I hope to be back
121:04 - to do at least one day next week but it
121:06 - might not happen but I'm going to be
121:08 - doing these uh in January I might even
121:10 - do these live streams twice a week I'm
121:12 - hoping and then in February I'm going to
121:13 - be doing them a lot is my plan so um so
121:18 - but uh keep in touch ask questions over
121:20 - Twitter put uh comments and questions
121:22 - the YouTube videos is super helpful
121:24 - especially if I mention something that I
121:25 - forgot to put in the description or I
121:26 - could put an annotation in that corrects
121:29 - something that's great so please keep in
121:31 - touch let me know hope this is helpful
121:33 - and I will see you guys soon I'm going
121:35 - to hit stop on this stream