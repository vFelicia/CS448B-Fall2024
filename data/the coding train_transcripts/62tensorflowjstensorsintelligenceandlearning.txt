00:00 - hello I'm back to for another video
00:03 - where I'm going to look at the core API
00:06 - of tensorflow jazz and in my
00:08 - introductory video I totally forgot to
00:10 - mention and link to this particular
00:13 - announcement video machine learning in
00:15 - JavaScript from the tensorflow dev
00:17 - summit where Nikhil for at and Daniel
00:20 - smilk off the creators of tension flow
00:22 - thas talked about the project and you
00:25 - should watch that because it'll give you
00:26 - a lot more background and also that show
00:28 - interesting demos and other things that
00:30 - people are working on with it ok so I
00:32 - wanted to mention that now okay so if
00:36 - you didn't watch my previous video which
00:38 - is kind of an overview of the landscape
00:39 - of all the pieces around working with
00:42 - machine learning in JavaScript you could
00:45 - go watch that or you could just be right
00:46 - here because what I'm gonna do in this
00:47 - video is I'm just gonna go to this API
00:49 - reference and in this API reference what
00:52 - I want to do is talk about the basic
00:56 - building blocks of tensorflow dot J's
00:58 - now here's a thing again I just want to
01:00 - mention I just want to mention that you
01:02 - don't have to be here right now anywhere
01:05 - else in the world than watching this
01:06 - video ultimately I'm going to start
01:08 - using something called the layers API
01:13 - which is built on top which is part of
01:16 - tensorflow Jas
01:18 - so there's court enter flow Jas
01:24 - ultimately I'm gonna for projects that
01:27 - I'm gonna make I'm too used to the
01:28 - layers API which is a higher level
01:30 - abstraction and then even I'm going
01:32 - inverse like down is higher level
01:35 - eventually I'm also going to use
01:36 - something called ml 5 which is a project
01:40 - being developed here at New York
01:41 - University which is a JavaScript library
01:43 - separate project from tensorflow TS but
01:45 - uses tensorflow digest behind the scenes
01:47 - to do some to show demonstrations of
01:50 - common machine learning tasks like image
01:52 - classification poetry generation and and
01:56 - things like that ok so but for me for my
02:00 - own sanity I would like to learn the
02:02 - basics of the core API of tensorflow yes
02:05 - and I think it's useful as foundational
02:08 - knowledge for moving along and looking
02:10 - at
02:10 - there's other stuff but if you just want
02:12 - to get to like getting your webcam and
02:15 - trying to classify the images that are
02:17 - in your webcam you can you could find
02:18 - some videos that aren't made yet but
02:19 - they will be made maybe I don't know
02:21 - this is very confusing I'm gonna make
02:23 - something within they'll finally be
02:24 - getting to that okay
02:27 - core API what is the core core core
02:31 - building block of everything in
02:33 - tensorflow
02:34 - it is something called a tensor and I
02:37 - talked about this in my previous video
02:39 - but just to recap we have this idea of a
02:42 - scalar which is a single number we have
02:45 - this idea of a vector which is a
02:48 - one-dimensional list of numbers and we
02:50 - have this idea of a matrix which is
02:52 - really a two-dimensional grid of numbers
02:55 - a tensor is a sort of more generic term
02:59 - that refers to any n-dimensional thing
03:03 - of numbers and also the operations
03:06 - associated with those things like matrix
03:09 - multiplication and so this idea of this
03:11 - idea of a tensor being this building but
03:14 - it's a thing you can make and perform
03:16 - the common mathematical operation it's
03:18 - actually quite similar to in p5 if you
03:21 - watch my p5.js tutorials I use this
03:23 - create vector function so this create
03:26 - vector function is making a vector and
03:29 - actually a three to two or three
03:31 - dimensional vector so it's always just
03:32 - like an XY inventory it's always just an
03:35 - X or Y and sometimes a Z and so then you
03:39 - can make these create vectors and you
03:40 - can get their magnitudes and normalize
03:42 - them two common mathematical operations
03:44 - the tensor is exactly the same thing so
03:46 - if we now go and look at the at the API
03:51 - here we can see here it is TF tensor so
03:54 - how do we even make a tensor let's just
03:57 - make a tensor so first of all I have
03:59 - some code I have some code not very
04:02 - little code I have a single file called
04:04 - sketched out JavaScript and you would
04:06 - think like okay let me just go and take
04:08 - this and let me just put it in here I'm
04:11 - gonna hit save then I'm gonna go back to
04:13 - the browser I'm gonna hit refresh and
04:15 - uncaught reference error TF is not
04:17 - defined so why is TF not defined well
04:19 - it's not defined because I need to
04:21 - import to tensorflow das life
04:24 - so a way that I can do that I'm actually
04:27 - just going to Google I'm sure it's like
04:28 - in an obvious place but tensorflow je s
04:31 - CDN and oh it's actually right here on
04:35 - the homepage right here this is what I'm
04:38 - looking for I'm gonna grab this bit of
04:42 - code right here because what I want to
04:44 - do is reference the tensile ojs library
04:47 - file via a CDN a CDN is a content
04:49 - delivery network I could download the
04:51 - library include potential ojs javascript
04:54 - file in my project it's a little easier
04:57 - for me right now just to go into
04:58 - index.html you can see I'm actually
05:00 - referencing P 5 and P 5 Dom libraries of
05:05 - CDNs I don't know that I've been
05:06 - actually to use the P 5 library in this
05:07 - video but I can just add one more here
05:11 - and now I have tensorflow 2's imported
05:18 - as part of my project and I'm gonna go
05:20 - over here I'm gonna hit refresh and look
05:23 - at that
05:23 - ha ha it's our first tensor we made a
05:27 - ten-story beta tensor
05:29 - ok so I've made my first tensor now one
05:33 - of the things you'll notice if I go to
05:34 - the tensor flow documentation whoops is
05:37 - that in addition to just TF tensor and
05:40 - there's also by the way oh look at this
05:42 - I need to talk about shape and datatype
05:44 - but just for the moment I want to just
05:46 - look there also is this o TF scalar
05:48 - we're gonna talk about that
05:49 - TF tensor 1d 2d okay so here's the thing
05:54 - this funk this idea of a tensor TF
05:57 - tensor is a generic concept that will
06:00 - work for any n-dimensional tensor but if
06:04 - you're working with tensor flow Jas you
06:06 - want it to the extent possible use the
06:09 - functions that specify something about
06:11 - the shape so what do I mean by shape oh
06:13 - boy so here's something a really
06:17 - important concept a shape this shape
06:21 - refers to the dimensions of the tensor
06:26 - so for example we might this right here
06:30 - this has a shape that's 2 by 2 I
06:37 - could write this this now has a shape
06:43 - because you always say the rows first
06:45 - with matrix this is two rows by three
06:49 - columns two by three so one thing that's
06:52 - important when creating tensors is to
06:55 - also specify the shape like why does
06:57 - this even matter well we're just kind of
06:58 - in the low-level land here just to get a
07:00 - sense of how these things are the reason
07:01 - why this matters for example imagine if
07:04 - what I'm ultimately going to do is feed
07:07 - in image data into a neural network for
07:10 - some tasks like image classification
07:12 - well I want and and what I have are lots
07:15 - of images maybe all those images are 28
07:18 - by 28 pixels so my shape is going to be
07:23 - 28 comma 28 and let's say that I
07:27 - actually have a hundred of them I have a
07:28 - hundred 28 by 28 images this is exactly
07:31 - what I'm going to have for the doodle
07:32 - classifier example that I'll make at
07:33 - some point then the shape of all of the
07:36 - data is 100 comma 28 28 because I have
07:41 - 28 by 28 images and I have a hundred of
07:44 - them so this is a really sort of
07:47 - important piece this idea of the shape
07:49 - is a really important piece of defining
07:51 - a tensor so let's take a look at that
07:53 - real quick so let's come back and let's
07:55 - go back to here and let's just do this
07:57 - in the console so I'm gonna say by the
07:59 - way one thing I didn't I mean I guess I
08:03 - could keep doing this in my code let's
08:05 - keep doing in my code so I have a record
08:06 - of it so um one thing I didn't mention
08:09 - by the way is why am I saying TF tensor
08:12 - and first of all I'm gonna write this in
08:15 - a different way I'm going to say
08:16 - constant nums let me call it data data
08:21 - equals let's write this out like this
08:25 - and then data dot print so let's look at
08:30 - this so one thing that's a key here that
08:32 - I'm using the the way of declaring a
08:35 - variable called Const for constant which
08:38 - means I can't reassign this object and
08:41 - so this is what you're gonna commonly
08:45 - see in the tensor flow to tutorials I
08:48 - could say let data
08:51 - in a sense I'm using consequence I'm
08:53 - protecting myself from reassigning the
08:55 - variable data to something else later so
08:58 - I'm gonna say Const data then data dot
09:00 - print we'll go back here and we'll see
09:02 - there's the tensor now incidentally what
09:04 - if I say console dot log data so the
09:08 - tensor that print function is a helper
09:11 - function in there to let you sort of see
09:13 - just the information the data that's in
09:15 - the tensor but if I actually say console
09:17 - dot log data what you're actually gonna
09:20 - see is well look at this whole thing so
09:21 - a tensor itself is actually this complex
09:24 - object so this is useful for us to be
09:27 - able to see those are a properties of it
09:28 - but most of the time we just want to
09:30 - look at the data so another thing that I
09:33 - can do here is I could say console dot
09:35 - log data to string so data dot print
09:38 - just takes the string version of the
09:40 - tensor and puts it into the console so
09:41 - if I do this hit refresh we can see
09:43 - there's that tensor as well okay now
09:46 - here's the thing what if what I want to
09:50 - do is this these are pixel values oh
09:53 - let's actually say these are pixel
09:55 - values like 0 0 127 255 and what I want
10:02 - is for these pixel values to be a 2 by 2
10:05 - image to represent a 2 by 2 image so I
10:08 - want to create now I want to create the
10:10 - tensor with a 2 by 2 shape so now let's
10:16 - look at what we see in the console now
10:18 - that I've defined a shape look at that
10:21 - we can see that it's basically a 2
10:24 - dimensional array and what I could do is
10:28 - what's interesting about this let's say
10:29 - I had two of these images so now there's
10:32 - eight values and we'll make these like
10:35 - totally different numbers now what would
10:39 - happen if I try to turn eight numbers
10:42 - into a two by two a tensor a two by two
10:45 - tensor look at this I'm getting an error
10:50 - so this by the way this is an error
10:53 - you're probably going to see throughout
10:54 - your life if you go down this road now
10:57 - not exactly this error but constructing
11:00 - tensor of shape for should match the
11:02 - length of values eight so this means
11:04 - like hey you gave me
11:04 - eight values but you're trying to make a
11:06 - sense of a Tencent that only has four
11:08 - values I can't do that and this is
11:10 - actually quite a common error
11:11 - I was trying to work on a doodle
11:13 - classifier with tensorflow Jess earlier
11:15 - this week and I kept getting all these
11:17 - errors because I was trying to train my
11:19 - dataset
11:20 - what didn't match the size of what the
11:22 - machine learning model expected so we're
11:24 - getting a little baby steps into that
11:25 - this idea of if I'm preparing data as a
11:28 - big of I'm loading it from a file a
11:30 - spreadsheet and I have a big list of
11:32 - numbers I better have the right amount
11:34 - of numbers to put it in the right size
11:36 - tensor and so this can now be corrected
11:38 - in the code because I can say well
11:40 - actually what I want and it's awkward
11:43 - that all these numbers are just two but
11:45 - hopefully you're following me here is I
11:46 - want to have two by two and I want two
11:50 - of them so now if I add the shape is
11:53 - really and let's well I'm gonna give
11:56 - leave it as an exercise to you try to
11:58 - redo this but use like a three by five
12:01 - and so now I'm actually do that myself
12:05 - I'm gonna hit refresh you can see there
12:07 - we go there's my essentially this is the
12:09 - shape now it's two by two by two okay so
12:13 - let's do a couple more things here let's
12:15 - say console dot log a data just so I can
12:19 - see now so what I have here is that's
12:22 - the sort of pretty version of the data
12:24 - there it is those are all my numbers now
12:27 - shaped into these arrays now also here
12:30 - look at this I can see that the shape is
12:32 - two by two by two the size is eight
12:35 - meaning there's eight total numbers the
12:38 - type this is something I haven't talked
12:39 - about type is important I'm putting
12:41 - floating-point numbers in there so this
12:43 - that's the default type for example this
12:46 - could be 1 27 point 5 and if I'd run
12:49 - this again we're gonna see one twenty
12:51 - seven point five is in there however I
12:53 - could have changed the type two if we go
12:58 - look at the documentation int 32 so for
13:02 - example I could say you know what I want
13:05 - to be more I don't need to have
13:06 - floating-point numbers so I could change
13:08 - the data type to in 32 and that's just
13:11 - one more argument for me to add here in
13:13 - 32 now let me run this again
13:18 - and you could see it actually worked
13:20 - fine it didn't complain that I tried to
13:22 - give it a floating-point number but it
13:24 - just took off the decimal place and my
13:26 - assumption here is it's not going to
13:27 - round it like if I make this one twenty
13:29 - seven point nine ninety-nine we're still
13:31 - going to see 127 there it's always going
13:33 - to floor that value meaning taking take
13:36 - off the decimal place so we can see now
13:38 - in making a tensor we have three
13:41 - important properties essentially we have
13:43 - the values these are the numbers that
13:46 - are going to go in the tensor we have
13:49 - the shape which is defining the
13:52 - dimensionality of the arrays of data
13:55 - basically and then we also have D type
13:58 - or data type which is saying what goes
14:01 - in that tensor and the only
14:03 - possibilities are floats intz or boolean
14:08 - z'
14:08 - so you can imagine just like if you know
14:11 - you only need integers you're gonna save
14:13 - some memory or some GP yunus by using
14:16 - integers instead of floats so this is
14:18 - what it means to make a tensor so I want
14:20 - to do two more things before I move on
14:22 - for the next video we'll start to look
14:23 - at some operations on mathematical
14:25 - operations on these tensors and and and
14:27 - also I need to talk about the difference
14:31 - between numbers so let's let's make an
14:52 - array well I'm gonna I'm gonna be a
14:57 - human who uses the constant at values is
15:02 - an array and I'm gonna just say I equals
15:05 - 0 I is less than 15 I plus plus I'm
15:08 - going to make up some pretend data and
15:10 - I'm going to use p5 random function I
15:12 - could say math dot random if I wasn't
15:14 - using p5 between 0 and 100 and then what
15:21 - I want to do is and then I'm gonna then
15:23 - I'm going to make a shape and I'm gonna
15:25 - say the shape is 5 by 3 then I'm going
15:30 - to say Const
15:32 - equals TF tensor with the values and the
15:38 - shape so this is perhaps a bit more like
15:41 - how you might want to do it right
15:43 - for example I load this is me loading in
15:46 - a lot of data from a spreadsheet or from
15:47 - another API or loading image files and
15:49 - converting them to pixels there's
15:51 - actually from pixels function in tension
15:53 - flow digest that will just take pixel
15:54 - data and turn it into a tensor but so
15:56 - basically so so I have 15 numbers I set
16:01 - the shape and now I have this tensor and
16:04 - now we're gonna look at it down here
16:06 - let's take a look and see if this worked
16:10 - so now we can see now there's a little
16:12 - bit awkward to look at because of all
16:13 - there we go
16:14 - look at this it is 5 by 3 5 rows 3
16:19 - columns so this is working this is good
16:22 - now what happens if I were to have 30
16:25 - numbers I get that error but again this
16:32 - could be 2 by 5 by 3 and now you can see
16:37 - I have two chunks of 5 by 3 data so now
16:40 - at least we're able to see how this kind
16:43 - of shape stuff works and if I wanted to
16:45 - I could also add back in int 32 because
16:49 - maybe what I want are just integers and
16:51 - you can see it looks a little nicer
16:52 - there now here's the thing all this time
16:55 - I have been using just a generic tensor
16:59 - TF tensor but if we look at the API and
17:03 - this is the last thing that I wanted to
17:04 - point out here if we look at the API
17:06 - what you'll actually see is first of all
17:08 - a scalar so this is rank of 0 meaning a
17:12 - single number rank 0 there's a idea of a
17:15 - ranking here tensorflow 1d is Rank 1
17:19 - that means a vector tensor flute atf
17:23 - tensor 2d is a matrix that means a
17:26 - matrix and 3 so even though you can just
17:29 - use TF tensor it's going to make your
17:33 - code more readable and you're gonna
17:34 - protect yourself for more errors if you
17:37 - use in here the actual if you actually
17:41 - specify the rank that you intend so for
17:43 - example if I just go back to the
17:46 - Sol for a second and I hit clear I could
17:50 - say scaler for so this now num dot print
17:55 - is just a tensor with a single number
17:59 - that's scaler now again I could have
18:01 - said num T equals TF tensor for and then
18:07 - I could say num T dot print this is
18:10 - exactly the same right
18:11 - TF tensor for or TF scalar but I've have
18:15 - possibly more legible readable code by
18:18 - saying TF dot scaler so now if I go back
18:21 - and look here even though I'm also just
18:24 - using the generic TF tensor this is
18:27 - really a rank three tensor a three
18:30 - dimensional tensor so to make my code
18:34 - more readable what I want to do is and
18:37 - and also to protect myself from errors
18:40 - what I want to do is come here and use
18:43 - TF tensor 3d so again if I know I'm just
18:46 - making a one dimensional vector I'm
18:48 - gonna want to use tensor dot 1d if I'm
18:51 - just making a single number
18:52 - TF dot scalar 1d so I'm just gonna
18:55 - change that here TF dot tensor 3d I am
18:59 - now going to go back to the sketch I'm
19:02 - gonna hit refresh and we can see there
19:04 - it is here is my tensor which is 5 2 by
19:09 - 5 by 3 okay so this I think this
19:12 - concludes this particular video tutorial
19:15 - where all I have done is show you what
19:18 - is it what is it tensor how do I make a
19:20 - tensor what is shape and what is data
19:23 - type now that I have this building block
19:26 - finished in the next video I need to
19:28 - actually talk about something these
19:30 - tensors are some are known as spooky
19:33 - music immutable whoo spooky whatever I'm
19:36 - not gonna bother this music they're
19:38 - immutable I cannot change the value so
19:40 - there is something called TF variable in
19:42 - the distinction between TF tensor and TF
19:44 - variable is important and I probably
19:46 - want to look at reshaping tensors
19:48 - although as well as I want to look at
19:53 - the operations so what does it mean to
19:55 - multiply tensors add stuff to tensor
19:57 - square tensors what are the kinds of
19:59 - operations mathematical operations just
20:01 - like there are a whole bunch of
20:03 - mathematical operations with a p5 Ector
20:06 - what are some of the mathematical
20:07 - operations where the tensile ojs tensor
20:09 - ok so that's what will be coming in the
20:11 - next couple videos
20:16 - [Music]
20:19 - you