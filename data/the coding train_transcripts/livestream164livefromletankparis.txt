00:00 - I'm gonna hit this button here and then
00:03 - I think I don't know what this is not
00:10 - something I've done before so let's see
00:13 - in a second we should see this this
00:15 - appear here yeah that looks promising
00:19 - okay all right all right let me just ask
00:28 - now if people in the live chat can hear
00:33 - me and then I'm going to then I'm gonna
00:39 - close this yeah this is gonna go on
00:45 - forever all right all right hi hi hi hi
00:49 - hi hi hi hi hi hi I just want someone to
00:52 - say the sounds works okay okay so I'm
00:56 - gonna close this so so from this moment
00:59 - on my focus is now on you the the the
01:03 - the people who are physically here in
01:05 - this room
01:06 - I just wanted to turn that on and so I
01:08 - don't know if anybody if there's if
01:10 - anybody is has that live stream like in
01:15 - the background on their machine and
01:16 - there's some like really important
01:18 - question or well tons of people saying
01:19 - like it stopped you could let me know
01:21 - but I'm gonna not pay attention because
01:24 - this is a rare and unique opportunity to
01:25 - be physically with people in real life
01:28 - so so hello welcome I guess it's a few
01:32 - minutes early but now I might as well
01:35 - start my name is Dan Shipman thank you
01:38 - so much to grow Paris and litang for
01:42 - having me here this is like a real honor
01:44 - to get to be able to be here in Paris
01:46 - and do a workshop and meet people who I
01:50 - have correspondent with online or maybe
01:52 - met before
01:54 - and yes I'm thrilled to be here
01:58 - so I most people are probably familiar
01:59 - with me someone because that's probably
02:02 - how you found out about this but in case
02:04 - we've just just as a matter of quick
02:06 - introduction what I do actually
02:09 - full-time is teach at a program in New
02:12 - York called ITP I'll just pull up the
02:14 - website real quick this is a two-year
02:17 - graduate program at Tisch School of the
02:18 - Arts and actually that's why I'm here in
02:21 - France as NYU has a study abroad program
02:23 - at NYU Paris and I'm visiting that for
02:26 - most of this week and so in addition to
02:30 - this I have this YouTube channel where I
02:33 - make coding tutorials that's where most
02:36 - people find me yeah oh they can't see my
02:41 - face oh because I fight go like this
02:44 - alright so sorry to the live viewers I'm
02:48 - this is this is just the webcam I'm
02:50 - gonna be moving around a lot but I'll
02:52 - give you a moment of looking at you but
02:53 - otherwise it's gonna be it's gonna be
02:55 - hit or miss so but and so the other
03:00 - things that I work on I said I think are
03:01 - important to mention which are related
03:04 - to what I'm going to show today is I
03:06 - helped to I don't know what the right
03:09 - term is administer run manage
03:12 - participate in something called the
03:14 - processing foundation and the processing
03:16 - foundation and say it's a United States
03:18 - charity a non-profit company that
03:21 - maintains a bunch of open source
03:23 - software toolkits for the Arts
03:25 - processing p5.js if you don't have a p5
03:31 - sticker I didn't bring any processing
03:35 - stickers I didn't have any important bit
03:37 - but but if you want to see one Simon
03:39 - here has one so so so so one of the
03:44 - things that so so pressing foundation
03:47 - has does a lot of in community and
03:49 - education initiatives one project in
03:51 - particular that I want to mention is
03:53 - that I just did called p5 something that
03:56 - I started working on a little over a
03:59 - year ago is a project called ml 5 and
04:02 - this is an open source library and the 5
04:06 - is an homage did I use a
04:08 - maybe slightly I won't I did I do have
04:13 - like high school American high school
04:15 - level French which is very bad
04:17 - we'll see if I can see how much courage
04:20 - I have any of my French but so the five
04:24 - is an homage to p5 but this project is
04:27 - funded actually through a grant from
04:28 - Google which comes from the team that
04:32 - created something called tensorflow Jas
04:35 - so I'm just giving you that as
04:37 - background for what I want to do in the
04:39 - workshop today what I want to attempt to
04:42 - do in the workshop today is build a
04:44 - simple image classification engine in
04:47 - javascript in the browser using the p5
04:51 - web editor so you know so so let's let
04:56 - me think here for a second so if you
04:58 - Eddie all of you are welcome to be here
05:01 - no matter what your background and skill
05:02 - level is I imagine that some of you this
05:04 - might be kind of beginner 4 and some of
05:06 - you might maybe have just started
05:08 - programming there might be some stuff
05:09 - that's very new and confusing so I'll
05:11 - try to manage that as best as I can but
05:13 - you could certainly ask questions and
05:15 - maybe also as a small community here we
05:17 - can help each other for those of you who
05:19 - have a lot experience with this so if
05:21 - you're but if you're new to programming
05:22 - or to JavaScript then I would suggest
05:24 - using the p5 web editor I'll mention a
05:28 - link you'll need to go to in a second
05:30 - but if you're experienced with web
05:32 - development in JavaScript you don't you
05:34 - could be following along and doing the
05:36 - coding through whatever editor system
05:39 - build environment that you so desire but
05:43 - but you'll need to have the things that
05:46 - you'll need if you're in the p5 web
05:48 - editor will all get packaged there for
05:50 - you if you're not you're going to need
05:51 - to have the p5 libraries and you can get
05:55 - those through a CDN link which which is
05:59 - which is here so you just go to the p5
06:03 - web editor and open up the index.html
06:04 - file you'll find these so it's some
06:07 - point if anybody's like really stuck and
06:09 - can't find p5 let me know and I'll try
06:12 - to oh I'm definitely gonna like pause
06:14 - and take breaks so my goal is to spend
06:16 - about an hour it's one o'clock now kind
06:20 - of talking about
06:22 - what how image classification works in
06:24 - ml 5 and a particular algorithm called
06:27 - KN n which stands for K nearest neighbor
06:30 - and try to build up something and then
06:33 - hopefully if that goes well then we can
06:36 - just hang out here for the second hour
06:38 - and people can try to make something
06:40 - with it maybe towards the end you could
06:42 - share a couple things that are or just
06:43 - you know so this can this will start
06:46 - very presentational but I'm happy for
06:48 - this to move towards being more just
06:51 - hanging out and working on stuff all
06:53 - right ok so and let me just let me just
07:00 - show an important link here so if right
07:04 - here github.com slash Schiffman slash
07:07 - the tank workshop this is where i at
07:11 - least so far put all the links of the
07:14 - things that are relevant and I will I
07:17 - will go over this in more detail in a
07:19 - second but this this is probably the
07:22 - most important link for you web editor
07:24 - template because the thing that I want
07:26 - to mention is that Here I am in the web
07:30 - editor over on the top left up there if
07:32 - I click this little arrow shape you'll
07:35 - see in here it says ml5 Minjae s so I
07:40 - have built a version of the ml5 library
07:43 - just for this workshop with some new
07:46 - features that don't exist in the
07:47 - published version of ml5 so if you were
07:50 - to be using the published version of ml5
07:52 - the stuff that i've got to try to code
07:54 - today won't work so on so that's
07:57 - important and if you aren't used so
08:00 - you'll need you'll start here and then
08:02 - the first thing you can do is just to
08:03 - save or duplicate I think so if you if
08:07 - you want to use the P 5 web editor and
08:09 - you have it before I would take the time
08:11 - right now just to go to editor type
08:13 - p5.js Dorgan sign up for an account
08:14 - because and then you can go to this link
08:19 - and click on web editor template but I'm
08:21 - gonna I'm gonna be showing you a whole
08:23 - bunch of demos and things before I
08:25 - actually start writing code but I just
08:26 - wanted in case people are trying to
08:28 - figure out to get set up yeah
08:34 - yes so I usually do this is a good good
08:37 - question on that Simon has asked so here
08:39 - in settings there are there's a there's
08:42 - a few different views and usually I use
08:44 - this high contrast mode I didn't use it
08:46 - because it just wasn't set to it
08:50 - actually on my laptop but also I think
08:51 - I'm gonna have a bunch of text that
08:53 - would this gray background might end up
08:54 - looking a little weird so let's put it
08:56 - back here to this okay all right anybody
09:00 - have any like just sort of general
09:02 - questions or logistical questions in
09:04 - terms of like how to be set up before we
09:07 - start oh and then there's the Wi-Fi over
09:09 - here which is I won't broadcast the
09:13 - secret Wi-Fi what could possibly go
09:22 - wrong with me saying but the Wi-Fi
09:24 - password is but that seems like it seems
09:26 - like I shouldn't okay alright so I think
09:33 - what I'm gonna start with actually is
09:35 - this website called teachable machine
09:37 - how many of you have seen this a couple
09:40 - of people so so teachable machine is a
09:44 - project that was made by Google Creative
09:47 - Lab and a bunch in collaboration with a
09:49 - bunch of different research teams at
09:51 - Google and it was this came out like
09:53 - quite a while ago before the official
09:55 - JavaScript tensorflow was launched and
09:58 - it demonstrates something to me like
10:02 - this is a really amazing demonstration
10:04 - of what is very recent
10:07 - only recently possible to do in a web
10:09 - browser so I'm gonna skip the tutorial
10:11 - and just run this to show this to you so
10:14 - the idea of a teachable machine so just
10:17 - you know spoiler alert my goal is to
10:19 - actually basically build a version of
10:21 - this in the P 5 web editor it will have
10:23 - none of the bells and whistles that
10:25 - you're seeing here in terms of design
10:27 - and you know thoughtful interaction but
10:31 - but it will have the functionality it
10:33 - will allow you to create an interactive
10:36 - system in the browser that might be
10:37 - different than a way you've thought
10:38 - about it previously so just to show you
10:40 - the way this works I
10:42 - I think I practiced this with my code
10:45 - example earlier so let's see so what I'm
10:47 - gonna do here is I'm gonna basically
10:49 - teach this machine to learn three
10:53 - different what are often referred to as
10:54 - classes or you can call them labels
10:57 - three kinds of images so one image is
11:00 - just gonna be me
11:01 - that'll be green so I'm holding this
11:04 - down so it's just learning like if I
11:05 - just move around here this is I'm giving
11:07 - it lots of examples of me in the web
11:09 - browser okay
11:11 - sorry not in the web browser me just me
11:13 - and the camera now I'm gonna step away
11:16 - and I'm gonna do I'm gonna train it just
11:19 - on with nothing yes yes so if you yeah
11:29 - you're right if you watch the tutorial
11:31 - will walk you through this and so the
11:32 - last thing I'm gonna train it with is
11:34 - with me holding this book that I found
11:35 - here called blog story so okay so now
11:40 - that I've done this I've now trained
11:42 - this system and you can see what I'm
11:44 - sitting here it's confidence and
11:46 - actually only when I'm looking straight
11:47 - ahead its confidence is 99 percent that
11:51 - it that's me the green category the
11:54 - green label if I walk away we should see
12:03 - that it became confident in purple if I
12:06 - sit back down we're back to green and
12:08 - then now if I hold the book it's orange
12:12 - and what time is pointing out is right
12:14 - so this is also showing you like it's
12:16 - gonna display a different gift based on
12:19 - which category you can also do sound so
12:22 - it's playing birds
12:24 - combo spreads okay so um so this is the
12:35 - idea this is the idea of on top of how
12:40 - the sort of like process of image
12:42 - classification works that you're
12:44 - teaching the computer you're saying
12:46 - here's a lot of examples of images of
12:48 - cats here's a lot of examples an image
12:51 - of the dogs the computer in theory is
12:53 - going to learn from that and then you
12:55 - can present it with new images and it
12:56 - will make an appropriate guess so but
12:59 - there's something that's that I'm not
13:01 - telling you which is super important so
13:04 - this is um this is working only because
13:07 - it is building on top of something
13:11 - that's already already been trained on
13:14 - millions and millions of images so this
13:16 - is a process known as transfer learning
13:18 - so there any of any questions about like
13:21 - just I'm gonna switch over to some
13:23 - slides that are gonna kind of like pull
13:25 - go underneath the hood of this a little
13:26 - bit more but before I move away from
13:29 - here okay so let me just close this
13:32 - window and I'm going to sew the this by
13:36 - the way so one thing that I want to
13:37 - mention is you name she who is a
13:41 - colleague at NYU at ITP she taught a
13:45 - course this past semester called machine
13:48 - learning for the web and it's basically
13:50 - it's a seven week course that goes
13:52 - through some the basics of machine
13:54 - learning and different kinds of
13:55 - algorithms and models so here's a bunch
13:57 - of and so basically what I'm attempting
13:59 - to do in this workshop is what's here in
14:01 - week two but there's lots of other
14:03 - features of the ml5 library that
14:07 - tensorflow library that might be things
14:10 - you would want to look into later and i
14:13 - forgot to include i really didn't want
14:16 - to have to pull
14:17 - my need to have a link to this make sure
14:21 - my volume is off oops
14:24 - okay so let me just also wanted to
14:28 - mention so this particular playlist also
14:40 - goes through and I realized people who
14:43 - are maybe watching this live I'm
14:44 - stepping away so I guess I could swivel
14:46 - this so this particular playlist which
14:52 - is actually in some ways somewhat of a
14:54 - prerequisite so I'm kind of gonna gloss
14:57 - over some of the stuff that is in some
14:59 - of these videos but certainly if you
15:01 - want to after today go back and dive a
15:04 - little more deeply into some this stuff
15:05 - this is some material that you could
15:06 - look at and the thing that's different
15:08 - the thing I want to point out what I
15:10 - what I'm doing in this workshop today is
15:13 - almost exactly what's in video four and
15:17 - five but I'm going to use a different
15:19 - algorithm for number five called KNN
15:22 - this is a recent feature of the ml5
15:24 - library that you name she who taught
15:27 - that class added to the library itself
15:28 - so as we go through maybe I'll come back
15:32 - and try to distinguish those a bit more
15:34 - but that just wants it like sort of et
15:36 - this context okay so I'm gonna go to
15:39 - yuning's presentation and use some of
15:42 - that to kind of talk through to talk
15:45 - through how some how this actually works
15:49 - so where's I present okay and thank you
15:53 - to you name for allowing me to use a
15:56 - basic presentation so ml5 library comes
16:00 - with something called a pre trained
16:03 - model a pre trained model is a machine
16:05 - learning model that somebody has already
16:07 - spent the time to train to recognize
16:10 - images and the particular model that
16:12 - that that ml5 comes with is is called
16:16 - mobile net so mobile net of you can see
16:21 - this is what mobile net does it
16:22 - basically looks at an image and then it
16:24 - says like oh it's a Robin
16:26 - confident 99% so weirdly mobile net so
16:31 - mobile dad is kind of amazing in that
16:32 - it's this machine learning model that
16:34 - you could just immediately have access
16:35 - to and we could actually I'm gonna I'm
16:39 - gonna go to ml5 jazz org I'm gonna go to
16:42 - examples I'm gonna quickly click on
16:46 - video classification so this is an
16:48 - example now of mobile Matt trying to
16:51 - classify the images in this video and
16:54 - you can see let's see if we can get this
16:56 - maybe sunscreened sun-blocker
16:59 - almost fit book and then it bookstore at
17:01 - one point let's see bottle of water
17:03 - maybe your glass water bottle water
17:05 - bottles so and we look at these
17:07 - sunglasses bowtie usually it says yeah
17:10 - so this is the thing michigan machine
17:16 - learning models are only as good as the
17:19 - data set with which they were trained
17:30 - yeah thinks it's a meat cleaver so so so
17:36 - one of the so let me go back to this
17:39 - presentation here so let me find this so
17:44 - mobile net was trained on a particular
17:47 - image data set called
17:48 - image net and and basically this is like
17:52 - a image data set that was made just for
17:55 - researchers to experiment with not
17:58 - necessarily for practical real world use
18:01 - and it has a incredible amount of plant
18:06 - elements in it it has like a whole bunch
18:09 - of different like sport sport things you
18:11 - can see it's it's it has six 1603
18:14 - pictures of the dog so what but what the
18:19 - what the mobile net model which was
18:21 - trained on this database and I'm gonna
18:22 - go to here real quick to show you
18:29 - something
18:33 - it only knows
18:37 - about these 1,000 things so you could
18:41 - see like this is what's so crazy a lot
18:43 - like machine learning off it feels like
18:45 - magic oh it's like this really smart
18:47 - amazing system that can recognize
18:49 - anything and in fact it's really good
18:52 - this particular model can recognize a
18:54 - variety of species of lizards and
18:56 - reptiles apparently but it can't
18:59 - recognize a person so so that's one
19:02 - thing that's important
19:03 - while it's useful and fun to play with
19:05 - and it's a nice demonstration of the
19:08 - idea of image classification it's not
19:11 - necessarily going to be really useful
19:15 - for you to use with your own project
19:16 - unless what you happen to do is you want
19:19 - a project about rare bird species then
19:22 - maybe the mobile net model will by
19:23 - accident be very useful to you
19:25 - but what it actually does one of the
19:30 - things yes so this is the list of the
19:31 - classes so there is something however
19:37 - you probably don't realistically have
19:40 - access to a database of 50 million
19:42 - images so let's say what you want to do
19:44 - is recognize that the example that
19:46 - meaning has made and that I'm gonna do
19:48 - something with this like
19:49 - rock-paper-scissors the game which I
19:51 - learned today is Pierre Foy sees oh I
19:55 - would have said wash we're by the way
19:59 - okay so yeah so rock paper scissors so
20:03 - you would like if you wanted to train a
20:06 - machine learning model to recognize you
20:07 - making the rock gesture or the paper
20:09 - gesture or the scissors gesture mobile
20:11 - net is not going to do that because it's
20:13 - not able it doesn't know anything about
20:14 - images of people's hand gestures but
20:17 - there is a process called transfer
20:18 - learning which it's defined here is use
20:20 - the knowledge gained while sovereign one
20:22 - problem in applying it to a different
20:24 - but related problem and what what what
20:29 - mobile net actually does the math behind
20:31 - mobile net is when it looks at a cat
20:36 - image what it actually does is creates a
20:39 - graph of probabilities and you can see
20:41 - these are all one thousand things it
20:43 - knows about and ended up here with this
20:46 - very high probability that it is like
20:48 - you know number 288 or 280 the class ID
20:52 - is 285 the Egyptian cat so this is what
20:56 - this is the end result of the machine
20:59 - learning and this actually by the way
21:01 - comes from this really nice observable
21:03 - notebook that I like I'll click on in a
21:05 - moment also by McKeel or at who's one of
21:08 - the creators of on the development team
21:11 - of 10 attention flow - s so this is the
21:14 - mat this is what the machine learning
21:15 - model actually outputs an array of
21:17 - probabilities but if you were to on
21:22 - again this isn't going to be this
21:23 - workshop I'm not gonna I'm gonna kind of
21:25 - like hand wave the aspects of how neural
21:27 - networks work but if I were to a neural
21:29 - network in one way to describe it is
21:33 - right if if the image is the input and
21:37 - the very last thing that comes out is a
21:41 - list of probabilities which I'm showing
21:43 - you right here there are actually a
21:45 - whole bunch of steps in between and one
21:48 - of those steps which is the last step
21:51 - right before the probability is known as
21:54 - the like logits activation so this is
21:57 - basically the unnormalized predictions
22:01 - vector which sounds like a very fancy
22:02 - word but basically this is this is
22:07 - basically looking at almost like a
22:09 - rating of a numeric rating for how
22:12 - likely a particular image is any one of
22:15 - these categories and you can see that
22:19 - you see these high spikes but what what
22:23 - this gets turned into in the mobile net
22:25 - model is something much simpler because
22:27 - all you want is kind of like a medium
22:28 - specification is the answer which one is
22:30 - the most likely so soft my max is a
22:33 - mathematical function that basically
22:34 - just watches everything and leaves the
22:36 - highest ones but this is actually a it's
22:43 - like this numeric
22:45 - image this is what's known as like a
22:46 - feature vector in other words the image
22:49 - which is maybe 250 I know what the
22:51 - dimensions are let's say it's 256 by 256
22:54 - pixels has that's how many numbers whoa
22:59 - could go I think I should know this math
23:01 - but I'm in front of a live audience so
23:04 - that's 65,000 pixels and if they're RGB
23:08 - suddenly we have like one hundred ninety
23:11 - six thousand numbers so 196,000 numbers
23:17 - okay what did I do wrong
23:19 - by the way this is like actually what
23:21 - happens in right there so there's
23:37 - infinitely more possibilities that's
23:39 - that's right so there's there's 256
23:41 - Siamese right there's 256 to the third
23:43 - power possible grayscale values I could
23:47 - say but but yeah RGB well aren't you
23:51 - being right
23:52 - but oh yeah yeah there's 256 x 256 spots
23:56 - pixels and each each spot has 256 to the
24:01 - third power possible yes but the point
24:07 - what I'm saying is whatever whatever the
24:09 - actual map is which I could get exploit
24:11 - lead from but thankfully Simon's 0
24:13 - correct me this is a much this is a lot
24:16 - less information this is like a thousand
24:18 - numbers and so the what what the what
24:22 - the neural network actually learns to do
24:25 - even though it boils all these pixels
24:36 - [Music]
24:38 - yes so so this particular this
24:42 - particular like this particular array is
24:45 - known as the features so what we can
24:48 - then do and there's here's some more
24:53 - examples so let me let's look at some of
24:55 - these
24:58 - okay so what we can then do is we can
25:03 - make use of the fact that mobile net is
25:05 - very good at taking any image and making
25:09 - it into an array of numbers and then
25:12 - what can we do with that so the reason
25:15 - why I'm also using this term called
25:16 - vector I'll write this over here so I
25:21 - usually when I think of a vector I think
25:24 - of like an arrow
25:25 - it's a and what that this is a vector in
25:29 - two-dimensional space
25:32 - yes and it has an x and y component but
25:37 - as Simon is saying you can have a vector
25:38 - in three dimensional space which should
25:40 - I have XYZ component the truth of the
25:44 - matter is mathematically speaking even
25:46 - though our brains aren't really able to
25:48 - visualize past three dimensions in an
25:51 - easy way this list of numbers is
25:54 - basically a vector in 1000 ameno space
26:01 - yes exactly
26:03 - a plain list of numbers so if I set you
26:07 - on this on this white board over here
26:10 - and I know I guess I will make some
26:13 - small effort to turn this this way you
26:16 - know this point here is it more similar
26:21 - to this point or this point you might to
26:25 - ative lee say this point because it's a
26:28 - closer distance so we can see that and
26:32 - we could also we could say this is often
26:35 - I think that an example I gave in some
26:36 - of the videos is if we thought of think
26:38 - of RGB color if we filled this room with
26:41 - red green and blue colors on when like
26:44 - this accent was the amount of red this
26:46 - axis was the amount of green and then
26:49 - this axis was the amount of blue similar
26:51 - colors would be near each other so
26:53 - looking at how data appears near to
26:57 - other data in space
26:59 - is a measurement of
27:01 - molarity so if I were to basically look
27:04 - these two are probably pretty near each
27:07 - other in a thousand dimensional space
27:08 - right and this is what we can this is so
27:12 - the process of transfer learning is
27:14 - basically use mobile net to get and a
27:19 - thousand a thousand numbers from an
27:21 - image and then find your nearest K
27:30 - nearest neighbor King nearest nearest
27:32 - which basically is a way of saying okay
27:36 - which category is something just
27:41 - something a member of based on its
27:44 - proximity to other entities in that same
27:47 - space so we go all the way back to that
27:50 - teachable machines just for a second now
27:55 - if I go all the way back to here what
27:57 - I'm basically saying is here's a whole
28:00 - lot of examples of me in a thousand
28:03 - dimensional space here's a whole bunch
28:05 - of examples of nobody in a thousand
28:09 - dimensional space and now here's a new
28:11 - image look is it closer to images that
28:15 - it's already knows about of me in the
28:18 - picture or with me not in the picture
28:20 - and this new image is closer to all of
28:22 - those but I'm not if I were to like try
28:25 - to compare every single pixel color I
28:27 - might be able to sort of get something
28:28 - like this to work but it would run super
28:30 - slow and it wouldn't be very accurate
28:32 - but the fact that mobile net already
28:34 - knows so much about what the mean the
28:37 - meaningful parts of images and turns it
28:39 - into this thousand dimensional array
28:41 - that we can basically take forget about
28:44 - this probabilities we basically get rid
28:47 - of that last layer about with the
28:49 - natural labels and just use the features
28:51 - of an image to try to match any new
28:53 - image with previous images I don't know
28:56 - if that made any sense at all
29:01 - anybody have questions yeah right so
29:11 - sorry
29:11 - this technique yes so sorry so I kind of
29:18 - I'm jumped I'm jumping around here quite
29:20 - a bit certainly but this technique the
29:23 - the mobile debt model is just a digital
29:27 - file with a lot of like information
29:28 - numbers in it and that's a thing that
29:31 - you could use in Python in the browser
29:34 - and then so the concept of transfer
29:38 - learning can be applied in any
29:40 - programming language with a lot of
29:41 - different machine learning libraries or
29:42 - from scratch if you have you know a few
29:44 - years to like write every every bit of
29:46 - the algorithm yourself but what I'm
29:48 - gonna show you is the quotes and what's
29:50 - what's the reason why this is exciting
29:53 - at least to me is the fact that this is
29:56 - a way to get a image classification
30:00 - system working in real time in the
30:02 - browser which prior to this prior to the
30:06 - JavaScript tensorflow version and a lot
30:08 - of these models like Bobo met be made
30:10 - JavaScript compatible would be things
30:12 - that you would need more powerful
30:13 - computers or lots more training time to
30:15 - be able to do okay so let's see what so
30:21 - let me show you actually a really nice
30:23 - example of how this is can be applied
30:29 - and so this is one of the tensorflow j/s
30:31 - examples and I'm just gonna click on it
30:34 - here so let's see this is yes allow use
30:38 - of camera okay so I'm gonna make this a
30:41 - little bit bigger this is basically a
30:44 - project that someone made apologies that
30:47 - I don't know the name of it but this is
30:49 - one of the official attention flow Janus
30:51 - examples where what I could do now is I
30:53 - can say okay let's say I need pac-man is
30:58 - for controls so what I could do it's
31:00 - basically create a physical controller
31:02 - from myself to to control the game of
31:06 - pac-man if I train a train a set of
31:10 - images for both right left up and
31:12 - so I'm gonna just say that me just
31:17 - looking here regularly is is this so I'm
31:19 - gonna click here this is this is for
31:21 - moving up I'm moving to the right is
31:28 - hold this book for moving to the left
31:32 - that's gonna be impossible to remember
31:33 - and and I'll just leave for moving down
31:39 - so now in theory I'm gonna hit this now
31:43 - something that's really important I
31:48 - don't know you might not have noticed
31:50 - this but when I was when I was showing
31:54 - you teachable machine
31:56 - there was no button that said train I
31:58 - just added the images and then it
32:01 - started guessing but here in this system
32:03 - there's a button said that says train so
32:05 - there's actually two different ways of
32:07 - approaching this st. there's more than
32:09 - two but in terms of the examples that
32:11 - are in the ml5 library and that you'll
32:14 - find the tension flow j/s there are two
32:16 - distinct ways of approaching this
32:17 - problem this is using a slightly
32:19 - different one this is using the method
32:21 - that's actually in the video tutorials
32:23 - that I made and now I'm showing you this
32:24 - other method called K&N look things up
32:27 - like pause for a minute or two and try
32:29 - to distinguish those more clearly but
32:30 - for now I'm just gonna mention those are
32:31 - two different things so I'm gonna hit
32:32 - train so it's training lost by the way
32:37 - is a keyword that you'll see in machine
32:39 - learning quite a bit it's also called
32:42 - cost and the fact that it's zero is
32:45 - probably not actually true it's probably
32:47 - point zero zero zero zero that's a bunch
32:49 - more zeros before it gets to some actual
32:50 - numbers but on it's the amount of error
32:53 - so it's been training and how does it
32:55 - know the amount of error well it's
32:57 - trains itself with all these images
33:00 - knowing which ones are right left up and
33:02 - down and then it almost is like well
33:04 - even though I know the answers I could
33:06 - also try to guess the answers so then it
33:08 - looks at those images again trying to
33:10 - guess but the answers are and sees it it
33:12 - guesses the correct answers if it if it
33:14 - didn't get a single one wrong it's would
33:17 - be 100% correct mean it's air
33:18 - would be zero okay so now I'm gonna
33:22 - click play and we're gonna see if I can
33:23 - play this where would I want to go to
33:26 - the left first maybe oh yeah wait hasn't
33:31 - started yet
33:32 - left okay up up okay wait I wanna go
33:37 - right down there we go so you got the
33:43 - idea I'm not sure this is a left oh so
33:48 - okay so the point of this and another
33:51 - project that I will mention which is in
33:56 - this presentation towards the end is oh
34:00 - this is the post meta stuff which I'm
34:02 - going to talk about is this is by and ni
34:06 - TP our researcher named alejandro called
34:09 - pong ml I won't play this through right
34:12 - now but this is a similar idea where he
34:14 - trained a teachable machine for certain
34:18 - gestures to move pong paddles up and
34:20 - down so this is a pretty you know
34:22 - there's hopefully your ID your brains
34:25 - are filling with ideas beyond just like
34:27 - oh I could train this to be a like a
34:28 - weird gestural controller for a simple
34:30 - 2d game but this is a nice way of sort
34:32 - of demonstrating what is the sort of
34:35 - creative possibilities of what you can
34:37 - do with this kind of transfer learning
34:39 - technique and this so there's the other
34:42 - thing I think is interesting to mention
34:44 - here is that you'll notice that like I
34:46 - just trained this right now so in theory
34:51 - a couple things one is I could I could
34:53 - save all of these training images and
34:57 - the resulting model and then load it
35:00 - again like if i refresh this page all
35:03 - that all that work is gone but I'm what
35:07 - I'm going to show you when I get to the
35:08 - examples you can actually save that and
35:09 - load it again later but even though you
35:11 - can do that which is more typical of
35:13 - machine learning systems what's exciting
35:15 - about this is you could imagine building
35:16 - like an interactive like museum exhibit
35:19 - kind of interactive kiosk where it's
35:20 - just continually being people are
35:22 - continually training it all day or all
35:25 - night or all
35:26 - whatever however long ago usually okay
35:30 - so let me see what did I what did I miss
35:33 - here so let's see what else is in
35:36 - innings presentation that I wanted to
35:40 - yeah so I've got I bet I'm gonna talk
35:42 - about Poe's net but I you know I want to
35:44 - be conscientious about the time here so
35:47 - let me look here and see if there's
35:50 - anything important here that we missed
35:51 - so this is more for the code stuff that
35:54 - I'll come by these are some of those
35:55 - examples okay
35:56 - and actually let me just briefly show
35:57 - you
35:59 - oops this is Nikhil's observable
36:03 - observable is a system for creating kind
36:07 - of like interactive JavaScript notebooks
36:09 - it's one way of describing it's built by
36:11 - a bunch of people but I think started by
36:13 - Mike Bostock who's the creator of a
36:15 - JavaScript library called d3 and so
36:17 - Nikhil this is how you would basically
36:21 - create a teep the teachable machine demo
36:24 - with tensorflow j/s and i'm hopefully
36:27 - going to show you an even easier way of
36:29 - doing it with ml5 but the reason why I
36:31 - wanted to bring this up here is this is
36:33 - a nice also demonstration of calcaneus
36:35 - NeighborWorks again we're in two
36:37 - dimensions here and you can see it's
36:40 - trying to guess is my mouse mouse part
36:43 - of the blue I guess that's kind of blue
36:46 - purple who knows blue group or red group
36:48 - and basically yeah the reason why the
36:52 - algorithm is called K nearest neighbors
36:54 - is it classifies it according to a
36:56 - coding system that's okay I just stepped
37:02 - on this everything's fine it classifies
37:04 - it according to a voting system so in
37:07 - other words for this new point it's
37:09 - looking for its K nearest neighbor K
37:12 - being 3 2 of its nearest neighbors are
37:15 - read-only one of its nearest neighbor is
37:17 - blue therefore it is more likely to be
37:19 - of the category red it is more likely a
37:22 - cat than a dog but you can see that this
37:25 - is the kind of algorithm if I first I
37:27 - could add this which is showing you like
37:28 - actually where is that decision boundary
37:30 - that's every any point in space that's
37:33 - on this side is going to be classified
37:35 - as
37:36 - this red category and then you could
37:38 - also see how this works if we change
37:39 - like K so you can see here it's you can
37:44 - see that here it's got one two three
37:46 - four five six six times closest to that
37:50 - are red and three so this is a
37:54 - particular algorithm that's a classic
37:56 - machine learning algorithm K nearest
37:57 - neighbor that can be computed very very
38:00 - quickly which which makes it powerful
38:02 - and it actually the oh look at this I
38:06 - didn't even notice this you could change
38:07 - this to three classes so now we can see
38:09 - how its category how its categorizing
38:11 - based on three different clothes three
38:13 - different classes okay so a couple
38:17 - things so let me quickly let me close a
38:21 - bunch of these windows that I don't
38:24 - necessarily need open anymore
38:25 - because we're gonna start writing the
38:27 - code for it you can follow along but
38:29 - before I do that here we go
38:36 - let me whoa oh boy there's already lots
38:40 - of links here Thank You Alka who is
38:43 - watching the live stream and I gave
38:44 - right permissions on this repo who added
38:46 - it done some fantastic okay so what I
38:50 - want to just show you is are these two
38:51 - examples real quickly so this is if you
38:55 - go to this one that says KNN image
38:57 - example this is basically a fully
39:00 - working
39:02 - [Music]
39:04 - KNN image classification example in the
39:07 - p5 web editor I'm gonna go back to a
39:10 - blank a blank sketch and put the pieces
39:13 - together step by step because I think
39:15 - that'll be more most helpful while
39:17 - falling but if at a good point you just
39:19 - wanna go and use this this is the sort
39:22 - of working version of it and has a few
39:24 - certainly it's not as sophisticated as
39:26 - teachable machines but has more dollars
39:29 - and whistles so I'm just gonna mention
39:31 - that that's there but the other thing
39:33 - that I was like what what's interesting
39:35 - about the can and algorithm is even
39:38 - though I'm talking about okay well we
39:40 - get those photo logits
39:43 - from mobile net that vector of a
39:46 - thousand numbers
39:49 - there's lots of other kinds of data that
39:51 - comes as an array of numbers so this the
39:55 - ML 5kn classifier object can take any
39:59 - arbitrary input so for example another
40:03 - example that I want to show you which I
40:05 - don't think we'll have time to code the
40:07 - whole thing but I will show it to you is
40:10 - this pose net example so what this
40:14 - example is doing this is using a machine
40:17 - learning model called pose net which
40:19 - basically makes a guess as to where and
40:23 - this is really designed this is not
40:24 - designed to this is designed to be used
40:26 - with like more of a full-body view so
40:29 - attempt to see if I can make that happen
40:33 - but you can see what pose net does is it
40:35 - can it looks at any 2d image with a
40:38 - person if I'm yes right if I turn to the
40:44 - side it tries to make its best guess but
40:47 - it's most accurate with a well-lit full
40:50 - body image so what it's doing is it's
40:55 - basically making a big list of x and y
40:57 - values here's the X Y value for the left
41:00 - hand the right hand the right elbow the
41:02 - right shoulder it kind of has this
41:04 - skeleton and nodes about so what this is
41:06 - doing go back to it's actually will work
41:10 - even as I can basically say like oh let
41:12 - me make two categories here let me say
41:16 - that these are a bunch of examples of me
41:20 - with my head to the right and here's a
41:23 - bunch of examples of be to my head with
41:26 - the left and now you should see 100% be
41:32 - 100% a oh and goodbye I don't know what
41:38 - just happened there
41:39 - I was weird you know why that just
41:45 - decided to completely die but I'll do it
41:48 - again left I think I took the other way
41:52 - before and so you can see it's able so
42:00 - so this this is not using even though
42:02 - the image is there the can and
42:04 - classifier is not trying to categorize
42:07 - the image input at all it's trying to
42:10 - categorize the results of the pose net
42:12 - model which are XY positions of the body
42:15 - and then so you could imagine using this
42:18 - with an application to choreography or
42:22 - and/or gesture in a more robust way than
42:27 - the image classification example work I
42:29 - don't know why this decides to just like
42:31 - die after every few a little bit that's
42:35 - the I think the live workshop disease
42:38 - that like live demo itis I think it's
42:43 - called I don't know why that decided to
42:44 - stop working okay so that's the sort of
42:48 - like story of all of the pieces yes so
42:54 - I'm keeping an eye on the time thank you
42:56 - Simon so what I want to do now is I want
42:59 - to start a bit from scratch and so if
43:02 - you want to follow along you would go
43:05 - here to this link web editor templates
43:08 - and you should see that it says the tank
43:14 - template by coding train and then what
43:17 - you're gonna want to do is you have to
43:18 - be logged in I'm already logged in as
43:20 - coding train but what you would want to
43:22 - do is then save or I'm gonna do
43:25 - duplicate and then what you would see is
43:28 - the tank template copy by your username
43:31 - so I'm gonna give everybody a minute to
43:33 - see if they can get to the point where
43:36 - they have a copy of this and if you want
43:38 - to work offline you could also just do
43:42 - file download in old
43:44 - all the libraries and everything and can
43:46 - use a different text editor so I'm just
43:48 - going to give everybody a minute or two
43:49 - to see if you can get set up with the
43:51 - web editor at this particular normally I
43:58 - would start a workshop of just like oh
44:00 - just start a blank sketch but the reason
44:03 - why I can't do that here is you need a
44:05 - copy of this because it has this special
44:07 - version of the ml5 library as part of it
44:10 - so you can check in this left-hand
44:12 - column to make sure you see Emma five
44:14 - minutes
44:24 - you've gotten working you can help your
44:26 - diesel
44:53 - [Music]
45:09 - the live the live audience to Larry I'm
45:12 - tempted to check I don't let's just I'm
45:16 - just gonna check real quick on the live
45:18 - audience do I have any I see people are
45:26 - tweeting about this workshop that's
45:28 - great let's go to live stream know
45:45 - there's like a lot of people watching
45:47 - this that's crazy okay okay okay so the
45:57 - tank template the template copy okay
46:04 - okay I'm going to move on in a minute
46:09 - you know like 30 seconds to a minute
46:11 - anybody stuck and won't want to ask okay
46:16 - if you're too shy poke the person next
46:18 - to you get them to help you
46:20 - we're all we're all nice helpful people
46:22 - here I can see smiling faces okay okay
46:27 - so so I don't know how far like I mean
46:31 - you certainly we have a fair amount of
46:34 - time we want to leave some time for
46:37 - people to just try to play around with
46:39 - it a bit on their own so I'll try to get
46:40 - as far but this as I can
46:42 - in the next half an hour and then we can
46:45 - always fall back on the sort of pre-made
46:47 - example and really you can just kind of
46:49 - give that a try but so so I'm gonna you
46:52 - can follow along I am going to the first
46:55 - thing that I want to add is just the
46:56 - video live video so I'm gonna create a
47:00 - variable called video and then I'm gonna
47:03 - say video equals create capture did you
47:07 - know I think that's what it is let me
47:10 - run this so if you've never used the p5
47:13 - web editor before it's really just this
47:15 - is the text editor where you can write
47:17 - JavaScript and you can stop and restart
47:19 - your program with these stop and play
47:21 - buttons you can also click this auto
47:23 - refresh and it'll update
47:25 - it'll rerun the sketch as you're typing
47:27 - but I'm going to keep that offer right
47:28 - now yes yes now you see me next to me
47:37 - probably okay so now we have the video
47:41 - now one thing I want to do is I actually
47:43 - just want to I want to make this smaller
47:48 - and I want to just I think it's gonna be
47:50 - this is not really important for the
47:52 - machine learning aspect but I just want
47:54 - to take this video and draw it on the
47:56 - canvas my drawing canvas which p5 is
47:59 - through my default setup to work with
48:02 - and so I am going to say image video 0 0
48:10 - I'm gonna change the videos size to 320
48:14 - 240 so now you can see
48:18 - the video is in two places so three
48:22 - times so now I'm gonna say video dot
48:24 - hide and so now I just have the video so
48:28 - this is just a few bits of code to just
48:31 - get the video drawing in the canvas okay
48:37 - now can people see this font size okay
48:43 - okay so I'm just gonna try to pause but
48:47 - I'm gonna move fairly quickly through
48:48 - the stuff you should all just wave your
48:50 - arms flail your arms and me to slow down
48:52 - if you need a general question okay so
48:57 - now now the next piece that we need is
48:59 - we need to have this thing called the
49:00 - ml5 feature extractor so I'm gonna call
49:05 - this feature I just call a feature
49:09 - extractor to call it so I'm gonna say
49:12 - feature extractor equals ml v dot
49:16 - feature extractor then so the feature
49:20 - extractor an image but he knows how to
49:36 - do that based on a pre-existing model
49:38 - that pre-existing model is mobile net so
49:43 - I'm gonna and in theory we could apply
49:46 - this same technique to non-mobile other
49:50 - models but ml5 really only said at the
49:52 - moment only supports mobile net maybe
49:53 - one or two other models and then I'm
49:55 - also gonna give it a callback model
49:58 - ready so this is the kind of thing this
50:00 - by the way requires an internet
50:02 - connection I mean it already requires an
50:04 - internet connection to be using the P 5
50:05 - web admin record but even if you if you
50:08 - weren't using the P 5 web editor
50:10 - it's got to load the mobile net model
50:12 - from the cloud it's possible to download
50:14 - that and have that locally but that's
50:15 - not a thing by default that it does so
50:18 - I'm gonna say console dot log model
50:21 - ready so now if I run this again you can
50:27 - see but down here in the console if you
50:29 - see that at the bottom it now says
50:31 - already so I've created the video and I
50:35 - have made a feature extractor so I have
50:40 - video which is the source of my images
50:42 - and by the way you don't have you can do
50:45 - this with you know JPEG PNG image files
50:49 - you don't have to do this with live
50:51 - video that's just the way I'm
50:52 - demonstrating it in sort of like live
50:54 - interactive sense okay so now what I'm
50:59 - gonna do is I'm gonna add a function
51:00 - called mousepressed probably I'm gonna
51:04 - need some buttons at some point but this
51:05 - will be fine right now and I'm just
51:07 - gonna show you something there is a
51:09 - method feature which is feature
51:13 - extractor dot infer I think this is all
51:19 - I need to write so what this function
51:20 - does I could I might have this wrong I'm
51:23 - about to look this up what this function
51:24 - does is it says give me that list of
51:28 - thousand numbers from an image and that
51:32 - image is the video and I'm gonna say I'm
51:35 - gonna put that in an array called inputs
51:38 - and then I'm going to just do something
51:41 - called inputs I'm gonna say inputs print
51:43 - and Alex want to make sure this works
51:45 - and then I'll explain again what's going
51:46 - on so this is me just testing the model
51:49 - is loaded what I want to do is when i
51:51 - press the mouse i should see here in the
51:54 - console a list of a thousand numbers if
51:57 - that happens then things are working
51:59 - there we go I don't see all the numbers
52:02 - but I see some numbers so this is very
52:09 - important cannot move on if you don't
52:11 - have this stuff working so you should be
52:14 - able to see the video create the feature
52:18 - extractor object and then infer that's
52:21 - that I by the way I'm not a 1 percent
52:22 - sure infer is the best name for this
52:24 - function so if anybody has any ideas
52:26 - about that you can join the ml 5
52:28 - open-source project this ml 5 and
52:29 - finally get up issues saying I have an
52:31 - idea for the name of the infer function
52:33 - might be good but the idea is to do
52:35 - inference to infer the essence of
52:38 - to take that energy give me my list of
52:41 - 1000 numbers so the weird thing is
52:43 - though how come I didn't just say like
52:45 - console dot log inputs so this is like
52:51 - you know if this were like a longer
52:54 - course about machine learning we'd have
52:55 - done a lot of steps leading up to this
52:58 - point but I'm just gonna kind of give
52:59 - you the quick details here if I click
53:02 - look at this whoa look at this is
53:04 - disposed in internal shape d-type size
53:09 - so what this thing actually is now I
53:13 - meant to have both of these print out
53:17 - even though I'm describing to you let me
53:22 - just get this back what I'm describing
53:25 - to you that the logit is just like yeah
53:33 - how does it what's the first correct
53:34 - pronunciation but I'm describing inputs
53:39 - as well I meant to
53:44 - I meant to I'm going to attribute that's
53:47 - a jet lag so this array of numbers isn't
53:58 - to plain JavaScript array of numbers
53:59 - it's a special kind of object called a
54:02 - tensor and by the way that's why
54:05 - tensorflow
54:06 - is called tensorflow the idea of a
54:10 - tensor is a it's a fancy word for an
54:14 - array of numbers but of any dimension so
54:18 - it could be you know a multi-dimensional
54:21 - array a two-dimensional matrix a
54:27 - 3-dimensional array it's tensors this is
54:29 - a generic term and so the library tensor
54:32 - flow is named for that because that's
54:33 - the sort of core building block of
54:35 - machine learning systems right even
54:37 - though we think of like oh it's
54:38 - generating code like while in creative
54:41 - machine learning
54:42 - this machine learning algorithms
54:43 - generating poetry or it's classifying an
54:45 - image these are just the sort of human
54:48 - dressing we put all around the system
54:51 - but the inputs and outputs of a machine
54:53 - learning system are always numbers
54:56 - tensors so what the feature extractor
54:59 - does is it gives you this object called
55:01 - the tensor now if I wanted to look at it
55:03 - as a plain array I could say values
55:07 - equals logits dot I'm gonna use a
55:10 - function called data sync data sync is
55:13 - like a function in that's part of
55:15 - tensorflow j/s that will actually pull
55:20 - the values out of the tensor and put
55:22 - them in a regular array and now if I
55:27 - click here we can see there we go we got
55:29 - an array that has a thousand numbers in
55:34 - it so I could look at it this way if I
55:35 - want but I actually that's just for
55:38 - demonstration purposes I want it as a
55:43 - tensor because the next thing that I'm
55:46 - going to do is I'm going to take that
55:49 - tensor and add it to the K and a k-9
55:53 - classifier right so what I need now is
55:58 - I'm going to make one more variable
56:00 - called KN n I'm going to say K and N
56:05 - equals ml 5 I'm totally digging this up
56:08 - classifier I should look at the
56:11 - documentation or my other example let's
56:14 - just look at this example yeah ml 5
56:17 - cannon classifier I got that right ok
56:19 - make a make a cannon classifier and then
56:23 - what I could do is I could say KN n add
56:26 - example these particular logits
56:30 - are a cat
56:34 - legit it's legit too legit to quit
56:38 - okay no G wha sorry that's the fact
56:44 - okay so let's I don't know I don't know
56:47 - if I got this 100% right but let's see
56:49 - if this works let's see if police I
56:50 - don't get it here so now I'm saying like
56:52 - I if I'm here here's some examples of a
56:55 - cat I'm not getting any error so all I
56:57 - can do is assume that it's working now
56:59 - let's let's do this in a sort of awful
57:02 - way I'm gonna change this to keep rest
57:05 - I'm gonna say if key equals C I'm gonna
57:11 - get the logits out otherwise if else if
57:17 - whoops key equals this is where the
57:21 - YouTube live chat will complain that I'm
57:23 - not using a switch statement thank you
57:26 - equals D then add an example of a dog
57:33 - and let's books let me put some print
57:39 - statements in here console.log cat
57:42 - example added so again I'm doing it this
57:46 - way to skip over the complexity of
57:49 - making a nice interface just to
57:53 - demonstrate the idea so now the idea
57:55 - here is that I can say hey any time I
57:58 - press a key on the keyboard I want you
58:01 - to extract that list of a thousand
58:04 - numbers associated with this image and
58:07 - then I want to tell my KNN system that
58:10 - this is a cat or it's a dog so if I and
58:16 - by the way I might have to click over
58:17 - here first to give this area focus to
58:20 - register the key events so now I should
58:22 - be able to say no so let's try this
58:31 - console dot log key this was happening
58:39 - the other day with the web editor and
58:40 - then I assumed no this is not this
58:45 - didn't just happen
58:47 - whoa oh my goodness yeah this is the
58:51 - demo itis again look at this what oh I
58:56 - mean the whoa
58:58 - the template Oh weird this is my code
59:02 - but it's like oh yeah this is fine there
59:04 - it is I don't know why it disappeared
59:05 - weird but you should know that the p5
59:08 - web editor is a you know a relatively
59:11 - new project it's pretty amazing but it I
59:14 - have note there have been some recent
59:16 - bugs with it all right sorry I mean yeah
59:19 - I don't know why that wasn't working
59:21 - before and now it is hopefully you don't
59:23 - you lose you're good by the way if you
59:26 - if you're feeling nervous which I am in
59:29 - a constant state of you can always just
59:32 - do something like you know copy paste
59:35 - your code every once awhile until like a
59:37 - text file somewhere in case you're
59:39 - worried that's the web the web editor is
59:41 - gonna eat your homework okay so okay so
59:45 - this is working I don't know why it
59:46 - wasn't before oh okay let me start it
59:50 - over so we can see that now it's adding
59:53 - some examples of cats adding some
59:58 - examples of dogs
60:02 - [Music]
60:11 - I can't alright there's a cat here this
60:18 - is my favorite sticker by the way but I
60:19 - can't firstly don't have any of those
60:23 - okay so so sorry let me so this is where
60:28 - we are so far so the idea the idea here
60:32 - is that we have loaded the video we have
60:36 - created and let me see if I can get more
60:38 - of the code in case people are still
60:41 - following along we lower this here so
60:46 - this is almost all of the code I can't
60:50 - get it all on to the screen but they
60:53 - we're creating the video we're creating
60:56 - a feature extractor let me move this
60:59 - over then we are also creating a
61:05 - classifier so the feature extractor gets
61:08 - numbers from an image the classifier
61:10 - associates those numbers with a
61:12 - particular category and I just made up a
61:14 - cat and dog as a kind of classic machine
61:17 - learning example of distinguishing cats
61:19 - and dogs okay so I'm gonna I'm gonna
61:25 - just pause for another minute to see if
61:26 - people get caught up here and then we're
61:34 - almost ready for like the last piece of
61:37 - this I really think this is actually
61:39 - quickly there's not a lot to this if you
61:42 - don't build a whole interface anybody
61:48 - have any questions they want to ask
61:49 - about what's I've coded so far any
61:52 - questions
61:53 - p5 JavaScript ml five machine learning
61:57 - everything's fair game
62:04 - yes so I will I will get to the Sagan so
62:08 - that's the so but what's left for me to
62:11 - do the next thing what the things that
62:13 - are left for me to do is number one to
62:15 - actually make it make a guess right I've
62:17 - got to have a guess and then number two
62:20 - I want to show you how to save your
62:24 - training set and then I realize there's
62:27 - still this there's still this question
62:50 - of vs. but I I want to talk about the
63:06 - difference between classifier and the
63:10 - technique that I used in the video
63:12 - series which are for the same result to
63:15 - train your own image classifier with
63:17 - built on top of mobile net but they're
63:19 - both slightly different and I kind of
63:22 - like the KNN technique better for a
63:25 - couple reasons so I want to make sure I
63:29 - talk about that at the end before I
63:33 - finish okay
63:36 - any other questions alright so now what
63:39 - I'm going to do with my terrible no
63:42 - interface system is I'm gonna add the
63:44 - mouse pressed function back oh boy does
63:48 - processing actually know what you know
63:49 - what I'm gonna do ah oh jet lag jet lag
63:53 - okay
63:55 - actually what I'm gonna do I'm gonna
63:56 - have it always guess that'll be let's
63:59 - let me do mouse press first I think we I
64:01 - want it to always guess but let me just
64:03 - have it guess with a mouse press right
64:05 - now so for it to guess the first thing
64:09 - we need to do is take when you I was
64:12 - about to say do the opposite of training
64:13 - but it's not the opposite at all
64:14 - it's
64:15 - same first step this is by the way
64:17 - training so we should in in machine
64:21 - learning we talked about training and we
64:25 - also talked about prediction aka like
64:29 - inference maybe there's other words for
64:32 - this guessing so for training we say
64:39 - give me the numbers that are from that
64:40 - image and then training I'm saying this
64:43 - is called supervised learning I am the
64:45 - supervisor this particular set number is
64:48 - associated with this prediction is
64:53 - saying well I don't know what it is what
64:56 - I want you to do is now say KNN classify
65:02 - those that array of numbers and then
65:05 - this I need a callback and I'm gonna
65:10 - call this function and again I'm using
65:11 - kind of old-style es5 JavaScript which
65:15 - hopefully doesn't mean anything to you
65:16 - because who wants to fill our minds with
65:18 - all this like es5 or es6 yes 8 well this
65:21 - is there a 7 I don't know if maybe we
65:23 - skip 7 okay yes Thank You Simon
65:30 - not many new features right so it was ok
65:33 - if we just talk about es6 in the essay
65:44 - ok so but yeah I'm writing my JavaScript
65:49 - to be sort of long-winded and
65:50 - beginner-friendly
65:51 - but just for those of you who might be
65:54 - watching the live stream are here you
65:57 - can use dot this will return a promise
66:00 - you can say can classify then or you can
66:04 - use the arrow syntax this JavaScript
66:06 - there's always a thousand different ways
66:08 - to do the same thing but in the simplest
66:10 - sense what I'm saying is get that num
66:13 - numbers from the video please classify
66:17 - that for me and when you're done make
66:20 - this event
66:21 - function run this callback got results
66:23 - you just print out the results to the
66:26 - console so now in theory if I run this
66:33 - again and here here but first I'm gonna
66:37 - neurotically paste all the code into
66:40 - here just so if it all goes away okay so
66:46 - now I'm going to uh I'm a my a cat or a
66:49 - dog I'll be a cat for today I am a cat
66:52 - it's not working Cat Cat Cat Cat Cat Cat
66:56 - Cat Cat Cat Cat Cat then I will show it
67:01 - this book which is a dog we give it a
67:05 - bunch of examples of dogs and now for
67:09 - the grand a very anticlimactic if this
67:13 - doesn't work I'm gonna just click the
67:14 - mouse and it should say cats
67:21 - alright let's so what did I get wrong so
67:23 - this is what's when this has changed a
67:25 - little bit let me look at the ya know so
67:30 - there should have been an error I knew
67:31 - there this error whatever so if I
67:32 - haven't given it any examples when I
67:35 - clicked a mouse
67:35 - it's definitely gonna give me an error
67:37 - because I haven't given anything to
67:38 - train we could handle that error in a
67:39 - more elegant way so let's let's uh let's
67:46 - let's look at let's go look at the
67:51 - working example oh boy this is has
67:53 - changed again
67:54 - alka is working working very hard here
67:57 - okay let's go look at this code and find
68:01 - classify feature extractor yeah that's
68:06 - fine infer video Oh features that's a
68:09 - nice way this is by the way I want to
68:11 - rename my variable because that a I feel
68:14 - awkward Lee can't pronounce logits or
68:18 - load Jets and features is kind of a nice
68:21 - word because those are that that's what
68:24 - when you hear this oh what are the
68:25 - features of the image and machine
68:27 - learning speak that just means what's
68:29 - the boil down numeric essence of that
68:31 - image into that so let me change that so
68:33 - this looks
68:34 - let's let me go this is the working exam
68:38 - this is this is the working example - if
68:41 - anybody sees anything Oh interesting
68:46 - well yeah so you know where it's okay
68:50 - hold on infer classifier features got
68:54 - results oh I know it's a problem is
68:57 - classic error oh boy
69:00 - I just err I make every single time
69:02 - nobody's caught it yet in that I just
69:04 - caught it I mean it I didn't show it to
69:08 - you so I just realized what it is it is
69:10 - because I come from a world of
69:14 - programming JavaScript and weird
69:16 - incorrect beginner-friendly ways that's
69:18 - not very standard so this is how p5
69:20 - would work like if you if you've looked
69:22 - at in the p5 functions like load image
69:24 - or load JSON there's typically a
69:26 - callback and the arguments of that
69:28 - callback is the stuff you want it's the
69:31 - answer it's the result it's the JSON
69:33 - file it's the image this is a most most
69:35 - JavaScript libraries are written with
69:37 - something called error first callbacks
69:41 - meaning the callback always has more
69:45 - than one argument and the error is
69:47 - always first and the reason why people
69:50 - who know more about actual JavaScript
69:52 - programming than I do think this is
69:53 - important is because this guarantees
69:56 - that you handle your errors right if
69:58 - because called if error came afterwards
70:02 - this is just a design pattern it's not a
70:04 - requirement of writing if this were the
70:07 - way ml5 were implemented where the
70:10 - results come in first but if there's an
70:11 - error it comes in second that means I
70:13 - could optionally ignore the error and
70:15 - this is not a good practice in terms of
70:18 - writing real software that needs to be
70:20 - out in the world with millions of users
70:21 - in the sort of like hey we're here at
70:23 - the tank in Paris messing around with p5
70:26 - you know we don't handle our errors so
70:29 - well life will go on but so it actually
70:31 - the error was undefined it was working
70:33 - so so if I wanted to be a little bit
70:36 - more thoughtful about this I would say
70:37 - if error console dot error error and I
70:43 - said console dot log but you can
70:44 - actually say console dot error else
70:48 - console dot log results so this this
70:52 - should fix it and actually this should
70:54 - give us on UPS and again the mysterious
71:00 - that your code disappears for no reason
71:03 - error okay so one thing I want to do is
71:09 - I'm just gonna click oh whoa do we do we
71:13 - maybe figure out what cat for you oh
71:15 - thank you so you could use it so to be
71:19 - interesting as an exercise would be
71:20 - great to try to make this program but
71:23 - use like images you take on your phone
71:25 - as opposed to like from the webcam all
71:28 - right why is that's really weird
71:31 - does anybody yeah okay hold on let's
71:37 - sanity check here stop play what's going
71:47 - on there's no okay that's the this is
71:54 - correct this is what I was expecting to
71:56 - see there is no example in any class huh
72:01 - okay let's let's this is this is loads
72:04 - of fun this never happens when I
72:08 - livestream ever I never have run into
72:11 - errors or problems oh boy well where am
72:16 - I
72:16 - save open let me get my code back
72:25 - I'm Savin in both I'm just gonna let it
72:28 - okay let it rest
72:30 - somebody needs to like let it rest for a
72:31 - minute yeah let's comment out the mouse
72:38 - press function for a second
72:46 - okay click over here and I can add my
72:50 - cat my dog examples okay let's put this
72:53 - back save let it rest for a minute okay
73:04 - click over here okay
73:06 - whoa it's so weird is any other people
73:12 - having this happen to them it's working
73:30 - for for you let me go back here let me
73:36 - okay so let me do something just out of
73:38 - curiosity let's change this to like else
73:43 - if key equals spacebar let me try doing
73:48 - this oh yeah it's so great so what I'm
73:55 - gonna do now yeah but that's gonna
73:57 - happen up here in the got result
73:59 - callback so what I'm going to do just
74:02 - maybe I don't know something weird was
74:03 - going on with the mouse press
74:05 - interaction for so let me see if this
74:10 - works here by just making it based on
74:14 - the spacebar I mean a global
74:17 - mousepressed event is never really a
74:18 - good idea anyway so so let me add some
74:22 - cat examples I'll just step out a frame
74:27 - to add some dog examples and now I hit
74:31 - the spacebar okay
74:34 - it's a cat okay so I don't know what was
74:35 - going on with that weird mouse press
74:37 - thing let me step out of frame dog there
74:45 - we go yay I don't know if you people can
74:47 - see the bottom of the console here but
74:52 - by the way what's useful about this I'm
74:54 - going to click in here is well
74:59 - by the way it also will even when it
75:02 - says the label that it is cat that's
75:05 - giving you the answer that you want but
75:08 - it also is giving will give you its
75:10 - confidence is bilingual in this case
75:13 - there's only two categories but data is
75:16 - so simple it's there's very few examples
75:20 - so it really like this just means it
75:23 - matched it matched the image the new
75:27 - image 100% to only cat images right we
75:35 - can see confidence is by label no so I
75:40 - think it's just like the sort of like
75:42 - smallness of the data set here okay now
75:50 - okay so let's let's add a few things to
75:52 - this to make this a little better what
75:57 - I'm going to do here is I'm going to
76:00 - create a paragraph element a called
76:07 - label P label paragraph label paragraph
76:14 - equals create P no training data yet so
76:23 - now when I run this it's going to say
76:26 - here let me make that larger just so
76:29 - it's label P style I don't know who
76:34 - knows CSS in this room font size don't
76:38 - eat you let's see if that's right there
76:42 - we go so I'm just putting a paragraph
76:45 - element on the page that says no
76:47 - training data yet because there's no
76:49 - training do you would prefer Helvetica
76:56 - okay I'm gonna go with excitement
76:58 - suggestions here Helvetica
77:03 - oh that's beautiful now thank you
77:06 - okay okay so now what I want to do is
77:11 - the first time the first time it has an
77:20 - example we're trying to think about this
77:23 - so one of the things you can get let me
77:27 - just show you something here
77:28 - this by the way unfortunately the
77:29 - console in the p5 web editor isn't
77:32 - interactive so I'm going to actually
77:34 - open up the chrome console for a second
77:37 - just to show you just to test out an
77:39 - idea and I have to switch it to I have
77:42 - to also go here to switch it to like
77:44 - canvas frame so that I can use so if I
77:47 - can look at the KNN variable and I could
77:49 - say KN um classes it's not in Canon it's
77:54 - in the feature extractor Nam classes
77:57 - yeah I think we should change this
77:59 - because the classes the categories
78:01 - aren't really part of part of the
78:07 - feature extractor oh no no no no KN hold
78:11 - on class example count that's what I'm
78:18 - looking for sorry I basically just want
78:21 - to find out what variable class example
78:27 - count where was that
78:39 - you know that's weird
78:41 - let's go along here but hold on let me
78:45 - look at my let me look at my example
78:47 - because this is the thing that's in the
78:49 - example num get numb labels that's what
78:52 - I'm looking for
78:53 - there's a function yeah okay so what I'm
78:56 - looking for here did I close that by
79:00 - accident I certainly did and go back
79:06 - what I want to do is what I want to say
79:09 - is I'm gonna create a variable I'm gonna
79:12 - create a variable star training start
79:21 - training or like I've tried to think of
79:26 - a name for this variable but it
79:28 - basically what I need to do is I don't
79:30 - want to start guessing until I've
79:33 - trained it on the first class so I'm
79:36 - going to basically say start it I'm just
79:39 - gonna say started is false so here in
79:47 - key press the first time I'm gonna say
79:50 - if K and n get number get numb labels is
79:56 - not equal to 0 and you haven't started
80:00 - already then start it equals true and
80:04 - you can start classifying so this is a
80:09 - little awkward
80:10 - I'm sure somebody here can think of a
80:12 - better way a different way of doing this
80:13 - but basically I want to start this
80:16 - process of classifying and I want to
80:18 - classify continuously so as long as
80:21 - there's at least one label meaning I've
80:23 - at least given it a cat or a dog [ __ ]
80:26 - and I haven't already started then I
80:30 - want to say that I've started this is
80:32 - just the first time I classify and so
80:35 - why am I getting why am I seeing errors
80:37 - here unmatched oh right like I lost uh
80:42 - end bracket by accident okay
80:46 - so now let's make sure this works no
80:51 - training data yet so I could press a lot
80:54 - of keys but if I don't prep but until I
80:57 - press the C I have to click over here
81:00 - first compress a lot of keys until I
81:03 - press the C then you can see it
81:06 - classified it as a cap right so we added
81:09 - the image and then it immediately
81:10 - started classifying but just did it once
81:12 - and what I want to do is when it gets
81:16 - the result I want to say the result dot
81:22 - label label P dot HTML results dot label
81:28 - I want to put that I want to get the
81:32 - actual label and put it right there
81:34 - where it says no training data yet and
81:36 - that HTML function will say take that
81:39 - label and add it to the content of the
81:41 - label paragraph so let's just do this
81:44 - one more time no training day I'm gonna
81:47 - press D click over here and press D and
81:51 - it put dog there because it thinks it's
81:53 - only got one training image no matter
81:55 - what it looks at it's always gonna be a
81:56 - dog right so now here's the magic thing
82:00 - what I can then do is once it's done
82:07 - that I can have it do it again
82:17 - so this is like recursive in the sense
82:20 - that it's gonna call classify which will
82:23 - make this callback happen it'll get the
82:25 - results and then immediately call
82:27 - classify again and make the callback
82:29 - happen again so this is just gonna and
82:31 - now we might see something slow down or
82:33 - happen you might see some problems with
82:35 - this I don't know yet try to do it this
82:38 - way I know what the example does
82:39 - sometimes it's nice to put a little like
82:41 - breathing room so I can't wait a couple
82:43 - of milliseconds and then call it but
82:44 - let's just see how this works so now no
82:49 - training data yet and I'm gonna I'm
82:52 - gonna start with C for a cat it's a cat
82:56 - it's a cat it's a cat now I'm gonna give
82:59 - it some more examples of cats I'm gonna
83:02 - move out of frame give it some more
83:04 - examples of dogs and now it should be
83:07 - there we go
83:08 - continuously continuously guessing this
83:20 - worked all right there's a lot of code
83:23 - here now I'm just gonna pause for a
83:25 - second so you might have questions or
83:26 - people might want to see certain parts
83:28 - tell me to scroll to a certain spot
83:30 - there's a certain spot need to see and
83:34 - again this is not the though way of
83:37 - doing this this is my like let me just
83:39 - in the short workshop time that we have
83:42 - today kind of like patch a bunch of
83:44 - these like pieces of functionality
83:45 - together the the actual example is a bit
83:48 - more thoughtful has some buttons it has
83:51 - some comments in the codes variable
83:53 - naming but this is the idea right the
83:55 - idea is I just need to give it and by
83:58 - the way I could create like ten
83:59 - different categories now these
84:01 - categories could be things that the user
84:02 - makes up like I could actually put a
84:05 - text box here and with a button and have
84:08 - the user enter in a label and hit submit
84:11 - so if you can have an infinite amount of
84:14 - labels I'm using by the way the word
84:15 - label category and class interchangeably
84:19 - the technical term is probably
84:21 - class 4a classification but I like the
84:25 - word label English is a little
84:27 - friendlier I know what you would say
84:28 - French just that's just the word
84:34 - category bad French accent okay any
84:40 - questions okay I definitely want to show
84:47 - about saving see so let's a whoops let's
84:58 - let me add stop here let me I'll add
85:03 - another key press s because this is the
85:07 - best way to interact with this and I'm
85:10 - it's called kmn save cats and I'm just
85:14 - gonna cats dogs dogs so nice thing is
85:18 - saving is literally as simple as just
85:22 - calling this function called fate
85:26 - so let's we're gonna train our super
85:29 - awesome model here Cat Cat Cat Cat Cat
85:35 - Cat Cat oh no sorry to click over here
85:36 - first cut cut cut cut cut cut got that
85:38 - got that dog dog dog hug ok is it
85:46 - working I'm a cat I'm the dog and the
85:49 - cat now I'm gonna press s look at this
85:55 - automatically to the downloads is a file
85:58 - called cats dogs JSON so you'll notice
86:01 - here that I didn't specify the dot JSON
86:04 - extension but it is adding it to the
86:06 - file automatically if you're not
86:09 - familiar JSON JSON is a file format
86:12 - JavaScript object notation is a way of
86:15 - storing data with JavaScript syntax
86:17 - spacer plate so I am now going to open
86:22 - that file up let's open it in like
86:24 - visual studio code so we can look at it
86:29 - just
86:30 - so we can see like look what is actually
86:35 - in this photo it's all of those numbers
86:38 - this is what a K&N model is it's just a
86:42 - list of all of the examples all of the
86:45 - examples and there are a thousand
86:46 - numbers or associations if I save here
86:51 - another another nice way of looking at
86:53 - this actually is she just look at it in
86:56 - the browser cuz my browser has should
86:58 - have no it doesn't have a hold on this
87:05 - is worth doing for sure even installed I
87:08 - don't know I don't know why I don't have
87:09 - a surprise that I don't already have
87:13 - this extension
87:18 - oh yeah maybe yeah anyway but you can
87:24 - see we don't me I just was gonna try to
87:26 - show you them but this this it's sort of
87:28 - crazy you would think like this is what
87:30 - it's actually doing it's just a file
87:32 - with all the numbers of it that's
87:34 - exactly what it is and but if you think
87:37 - about it we deal with files with lots of
87:39 - numbers we already talked about earlier
87:42 - how many numbers are part of an image
87:44 - right and so right and we can see here
87:51 - that a by the way ignore this other file
87:54 - that happens to be on my computer it's
87:55 - it's not even a megabyte it's 969
87:58 - kilobytes just this one file so this is
88:03 - something that's quite reasonable for it
88:05 - to do all right now what if what I
88:09 - wanted to do is I wanted to load that
88:12 - model when the program starts
88:29 - so I'm good yes so images could easily
88:40 - an image file could easily have
88:41 - trillions and numbers in it because it's
88:43 - that many pixels each with in RGB so
88:45 - actually just having like 100 example
88:48 - images each with a thousand numbers
88:49 - right right alright so there's one last
88:59 - step here which is to load the json file
89:03 - i hear people like talking amongst
89:06 - themselves which is awesome this means
89:07 - like you've already moved on to maybe
89:08 - trying something alright but but but
89:10 - does anybody have any questions are
89:11 - really stuck like i can't believe that
89:14 - everybody has this working perfectly but
89:18 - the nice thing is you can you know I
89:21 - will put this URL or alko will do it
89:23 - before I get to it you can actually just
89:26 - go in addition to the actual example the
89:28 - full example this URL is also one that
89:31 - you go to just get this code immediately
89:33 - okay so the next thing that I want to do
89:36 - is I'm gonna say K and N Load so what I
89:41 - could do is in the setup function right
89:43 - what I could actually do is have it load
89:46 - that file so but that file needs to be
89:50 - part of my p5 sketch so I'm gonna go
89:55 - here under add file then I'm gonna go
89:58 - whoops then I'm going to grab cats dogs
90:02 - JSON and upload it so you can see now my
90:08 - project has sketched out JS which is my
90:13 - JavaScript code in the excitation which
90:15 - is the HTML code it has that version the
90:17 - ml 5 library and then now it has cats
90:20 - dogs JSON so what I could do now also
90:24 - when the program starts is have it load
90:28 - cats oh I don't know what the I think I
90:32 - supposed to do it like this cats dogs
90:34 - JSON I always forget I think I'm in
90:37 - JavaScript the standard way to say
90:40 - something is in the local directory
90:42 - is this we're gonna find out if this
90:46 - works then I could give that a call back
90:49 - I'm just gonna say KNN loaded and I'm
90:56 - gonna another function function cane and
90:58 - loaded and then here also by the way I
91:02 - could say now cuz I started is true and
91:06 - I could start classifying immediately I
91:11 - know I that's what I always thought too
91:14 - and then there's some weird that's let's
91:16 - see if it works this way I want it to
91:18 - work this way let's try it this way so
91:21 - I'm pretty sure oops
91:25 - I know why it just went away cats dogs
91:28 - json k and n loaded and then i'm gonna
91:38 - have that again okay and then loaded i
91:44 - this bothers me that it's capital so i'm
91:46 - gonna make it lower case for no reason
91:48 - other than my own neuroticism
91:52 - and then i also could say here started
91:56 - equals true and get the classification
92:01 - process started by calling classify
92:06 - alright let's see let's see if it loads
92:08 - up Oh guess what
92:17 - interesting okay first of all let's
92:20 - double check to make sure that load is
92:21 - actually the right it might be right
92:27 - also I might have to wait for a mobile
92:29 - net to load before I can load it but
92:31 - let's let's see I shouldn't have to do
92:33 - let's look at this example code just to
92:36 - see because it's
92:43 - load my K&N is the name of the function
92:45 - in the example it does have it here
92:50 - update yeah so let's try that so I think
92:54 - this is a little bit of weirdness that I
92:57 - think we have to iron out cats dogs JSON
93:01 - let's try this oh whoops
93:08 - why is this year that's bad this was
93:11 - supposed to go here no wonder I I put
93:14 - this in the wrong place okay okay ready
93:22 - ah there's been a problem loading the
93:25 - file that's good sign I mean it's not a
93:27 - good sign but okay I wonder if oh whoops
93:34 - no no no I need to get I need to call
93:37 - infer forgot that I by the way usually
93:41 - if I'm like live-streaming
93:42 - once I get past the two-hour mark my
93:44 - brain sort of shut down and just
93:46 - continuously make mistakes and
93:47 - apparently I think that I mean I
93:49 - probably don't like a half an hour but
93:50 - definitely hitting it now okay so I need
93:53 - the features I need to classify
93:55 - something so and I should probably put
93:59 - that in its own function like start
94:00 - classification but let's let's try this
94:08 - here we go
94:11 - there we go cat dodge okay so now I've
94:16 - loaded the month this is by the way now
94:19 - he's finished completely finished
94:21 - version of what I wanted to show you
94:23 - let's review
94:24 - let's I would have just like you're
94:26 - probably trying to catch up and get this
94:28 - word you all by the way I actually
94:37 - something's really important to show you
94:42 - so okay so what are the steps okay hold
94:47 - on one second sign okay the steps are
94:51 - load mobile net that's the first step
94:58 - the second step is create K&N classifier
95:06 - okay
95:07 - that's here now there is an optional
95:09 - third step which is load previous
95:17 - training data cuz I can continue to
95:21 - train by the way is these stuff these
95:24 - aren't mutually exclusive
95:25 - I could start with no training images
95:27 - and add training images or I could load
95:29 - training data and add more to do but so
95:33 - this is really like optional I put it in
95:34 - parentheses which is load the previous
95:38 - so that's what we're seeing here so let
95:40 - me put comments in here right this is
95:42 - really I mean I'm skipping create video
95:45 - but load mobile net this is step 1 step
95:54 - 2 create K&N classifier and then this is
96:03 - optional load pre load existing or like
96:09 - existing training data optional
96:15 - okay so then the other steps in no
96:21 - particular order our ad example
96:32 - this adds new training data so that's
96:36 - what's happening down here add new
96:42 - training data and then and that is so
96:57 - this step for now if you stop and start
97:06 - again unless you file and so by the way
97:11 - this is the awkwardness of saving the
97:14 - file having to go to your downloads
97:16 - directory and then having a copy and
97:18 - paste it back uploaded back ep5 web
97:20 - editor is is a problem that exists only
97:23 - because we are doing client-side
97:26 - programming only but if we were writing
97:29 - say like a node.js server or wrote our
97:32 - own server we could have the file save
97:35 - as the programs running and reload
97:38 - automatically but with just clients I'm
97:40 - not writing our own server code we can't
97:43 - manage the [ __ ] file system for user
97:47 - and where the sort of where the creator
97:50 - of the coop I sketch and the user but so
97:51 - that our only option is to is to to run
97:55 - all the training downloaded to our
97:57 - Downloads directory and then manually
97:59 - copy the file into the sketch but that's
98:01 - perfectly reasonable if what you want to
98:03 - do is like calibrate a model for an
98:06 - installation you just you might what I
98:08 - might recommend is actually two separate
98:10 - schedules one that's like doing all the
98:13 - training and saving the file on another
98:15 - sketch that just like runs the model or
98:17 - unless you drink something that's but
98:19 - right right oh you could think yes
98:22 - there's no reason why what's in that
98:24 - model that JSON file is just did I could
98:26 - easily go to like a database as a
98:27 - service like firebase and there's so
98:30 - many what you can put it in a Google
98:31 - sheet if you wanted to there's so many
98:33 - ways you can save the K&M do okay so
98:39 - what I want to do want to show you here
98:40 - is let's see if this is actually still
98:42 - working
98:43 - cat dog oh let me finish shouting the
98:50 - comments sorry
98:51 - so forest training data and then five is
98:57 - classified which is here and also here
99:05 - and that's the last step now I want to
99:12 - show you something
99:13 - let's start oh let's run this and cat
99:19 - dog it's still working I'm gonna swivel
99:22 - this around maybe nobody wants to be on
99:24 - camera
99:25 - I'll swivel it this way okay I'll just
99:27 - swivel it over here okay now if I go out
99:33 - of the frame actually getting it it so
99:38 - amazingly this is still working but what
99:41 - I wanted to point out to you is that
99:46 - interesting it's like one of the things
99:49 - that's easy to what I'm attempting to
99:51 - point out to you now is that I basically
99:53 - could break it by turning moving what
99:55 - the cameras seeing is the background
99:57 - because what you have to remember is
99:58 - it's not just it's not actually learning
100:01 - what I look like in particular it's just
100:04 - learning what I look like and what the
100:06 - background looks like and then comparing
100:08 - new images to either of those so if I
100:11 - have a new background then it might
100:15 - suddenly the results are going to be
100:16 - different now that the thing is the
100:18 - mission the thing is it actually is kind
100:20 - of still working anyway because it's
100:21 - always trying to make a best guess and
100:24 - guess what me standing in front of this
100:27 - background is more similar to just a
100:31 - background that you know same thing with
100:38 - this here so it's similar enough you
100:40 - know was trained with about this behind
100:42 - me
100:46 - yeah and we could look at the the
100:48 - confidence - yeah we could put that we
100:50 - could output that now would be a useful
100:51 - thing to output but this is something
100:54 - that's important to remember that you
100:58 - know if you start trying to train it on
100:59 - objects like the what the background is
101:03 - also plays a pretty significant role the
101:06 - other thing is mobile net like if if I
101:11 - were to let's let's actually let me not
101:15 - load the I want to show you one more
101:18 - thing I'm not going to load the existing
101:20 - one and I'm going to do something yeah I
101:33 - really do
101:36 - okay so good erase this
101:42 - [Music]
101:45 - no you'll you'll see what I'm gonna do
101:47 - here we go I'm gonna draw a cat okay
101:55 - and now this is my cat I'm giving it a
102:02 - bunch of yeah I should move it a little
102:06 - bit I should move this a little bit this
102:10 - is a very flawed demonstration now I'm
102:15 - gonna erase this and I'm going to draw
102:19 - oh boy yeah okay wait for assignment
102:35 - this by the way I what I'm trying to
102:38 - show you something that's not gonna work
102:40 - at all
102:40 - that's pretty good here Simon
102:47 - I will finish your your dear dog for you
102:49 - so just tell just to make it somewhat
102:51 - different this is probably like looking
102:53 - more like a monkey or something but this
102:56 - is going to be the dog
103:05 - so now all right look you can see it's
103:16 - like
103:25 - let's start with the cat right that the
103:31 - point is this not you know that one of
103:33 - these is only two it's got a 50% chance
103:36 - of getting it right I think I gave it a
103:38 - lot more cat images still a cat but the
103:50 - point is that's like a weird frog the
103:54 - point of what I'm saying is mobile net
103:56 - because we're doing what I'm trying what
103:58 - I'm the point of that took way too long
104:00 - for the point I'm trying to demonstrate
104:01 - but the point that I'm trying to
104:03 - demonstrate is that mobile net was
104:05 - trained on photographic imagery it
104:07 - wasn't so it actually just thinks every
104:10 - drawing is basically a drawing now it
104:13 - probably thinks it's a webpage drawing I
104:15 - don't know what what what the features
104:17 - it's not gonna be able to extract unique
104:19 - features for different line drawings
104:21 - those all look like the same category to
104:23 - it so that's not gonna work
104:25 - but photographic imagery that's full of
104:27 - color and shape and like things that we
104:29 - see in the real world it's gonna be able
104:31 - to somewhat distinguish that in a way
104:33 - that's meaningful so if you wanted you
104:36 - know there's a bunch of projects like
104:38 - gene Kogan's doodle classifier is a you
104:41 - know like this is not a magical solution
104:44 - that works for everything and so this
104:47 - particular project which recognizes
104:50 - drawings is not using transfer learning
104:54 - at Canon and mobile net it's actually
104:55 - training an entire model of some
104:57 - scratch-off of a massive database of
105:00 - drawings I've used these a lot if you
105:01 - have seen the videos the quick draw
105:03 - dataset so that's what that's one thing
105:06 - that I wanted to mention is that like we
105:08 - are we are we have the our ability to do
105:13 - this and let me let me load it back to
105:16 - something that was kind of like working
105:19 - our ability to have this work is limited
105:23 - by the kind of data that I show it and
105:28 - I'll show you another just to show you
105:30 - the the let's just to go to this
105:34 - particularly this the example that you
105:37 - need me
105:38 - let's try to actually I think
105:40 - rock-paper-scissors won't actually work
105:42 - super well so let's try this so I'm
105:44 - gonna put my hand this is rock I'm gonna
105:49 - give it a lot of rock examples I'm gonna
105:51 - move my hand all the way around to still
105:52 - like give it lots of examples now paper
105:56 - try to make this fairly distinguished
106:01 - paper and then scissors start predicting
106:13 - okay Rock you can see that it's getting
106:18 - it wrong a lot of times paper Wow really
106:20 - got it it's really good at doing paper
106:22 - scissors so maybe I yeah maybe I need
106:29 - more training data but the thing is the
106:31 - quality of these images is kind of the
106:34 - same it's sort of like you know the
106:36 - dural network ends up seeing like these
106:37 - this blob of a person with their hands
106:39 - somewhere kind of thick I mean it's not
106:41 - it doesn't think in those terms it's all
106:43 - just numbers but the difference what
106:46 - those logits are what the features are
106:48 - between this and this are probably not
106:50 - super significant so it's good yeah
106:57 - yeah yes yes it's fine - fine that's
107:01 - actually that so that would be a fun
107:02 - project to make would actually be like a
107:03 - thing that just plays against people
107:05 - always always wins and certainly this
107:08 - would probably fail if I were to move
107:11 - the fail it'd be much worse if I remove
107:13 - the computer over to there and have
107:15 - people with different hand sizes and
107:18 - skin colors work with the system so
107:20 - there's so many inherent limitations to
107:24 - what we think of as like you know robots
107:26 - are gonna take over and we'll all beat
107:27 - them and we've got a ways to go because
107:29 - it really is can't play it can't beat us
107:31 - at rock-paper-scissors okay I'm gonna go
107:39 - back to you I mean I'm gonna try to feel
107:40 - somewhat successful by going back to
107:42 - this example and stepping out see it's a
107:44 - volume
108:10 - it turns out
108:15 - [Music]
108:23 - [Music]
108:40 - all right cute yes 6 5 256 256 the 5th
108:55 - power
108:55 - that's all right
109:24 - all right so that's actually right
109:35 - because there's pixels and nurse how
109:39 - many pixels are there 256 oh that's the
110:02 - total number of
110:37 - if this is another well then actually I
110:43 - I just got a raise this to the power no
110:52 - this is just times yeah right so
111:04 - basically they're pixels there but then
111:07 - if you that's multiplied by another 256
111:15 - squared because right because I can't we
111:26 - did that Simon will you make will you
111:29 - make a video on this when you get back
111:30 - home
111:57 - that's the size it's actually really
112:09 - phenomenal because we don't think about
112:11 - the scale of the possibility of we you
112:14 - know we work with images so often and if
112:16 - this seems so sort of like crazy how
112:18 - many possibilities are our boxes
112:20 - the scale of these numbers are just
112:21 - unimaginable I can't even like think in
112:24 - those sizes like if we were actually
112:26 - writing that number out yeah you would
112:28 - need you need like a fancies calculator
112:51 - right much smaller that's the world of
112:57 - every possible image that you could ever
112:59 - make in the entire universe it's just
113:01 - one of those is a much smaller
113:14 - the size of the image there's me about
113:17 - this many bits it's actually much more
113:19 - why because actually there is it's
113:23 - something called a compression outward
113:26 - yeah the idea is that yeah me being that
113:30 - one pixels
113:38 - or berries kind of similar to and so and
113:42 - so you only really have some core color
113:45 - right and so basically and so that
113:49 - compresses the image right and in a way
113:52 - the feature extractor is something like
113:55 - a compressor because it's taking the
113:57 - larger image and converting it down into
113:59 - a thousand numbers and in fact you know
114:02 - JPEG of all these JPEG compression other
114:04 - compression on recension to like find
114:07 - smaller amounts but then when you go to
114:09 - redisplay the image
114:11 - it's decompressing it so you can see all
114:13 - those pixels you you wouldn't really be
114:15 - able to can't the neural network doesn't
114:17 - really work so nicely in Reverse but
114:19 - when you see all of those kinds of
114:21 - things that people are publishing about
114:23 - like neural networks that are so
114:27 - dreaming or generating images in a way
114:29 - that is the backwards process so
114:33 - thing that we started with if you take
114:35 - you take the full image when you boil it
114:37 - down to a thousand numbers
114:39 - well could you run that algorithm in
114:40 - Reverse start with some random amount
114:42 - random set of numbers and get and get
114:46 - the image out of that and that's the
114:48 - best it's like a decompression and
114:50 - that's what when you see a look of
114:51 - knobbies fancy for fancy videos that
114:54 - people are neural networks are dreaming
114:55 - and walking through the Big Dance paid
114:58 - space we've seen yourself a big Dan
114:59 - model types of general networks I mean I
115:03 - skipped up a hundred thousand pound
115:05 - steps in between what we're doing today
115:07 - and that
115:19 - well we're seeing you know do I you know
115:21 - I think we could we could probably go on
115:23 - with this discussion for a very very
115:24 - long time because it's an interesting
115:25 - question like are we seeing because but
115:28 - but in essence we have to view all of
115:31 - them we are you're right that we are
115:32 - seeing the compressed image but there's
115:34 - still a full pixel being drawn for every
115:36 - location but but but but it is a good
115:39 - point and I think we could argue it for
115:41 - a long time right because it can't find
115:53 - [Music]
116:07 - you know most machine learning about
116:10 - something I was working with recently is
116:12 - called the universal sentence encoder
116:14 - when you hear that what is that what
116:18 - could that possibly mean
116:19 - well the universal sense encoder is a
116:21 - particular machine learning model that
116:24 - takes a string of text and converts that
116:28 - into numbers so you could actually
116:30 - figure out what keeps trying to boil
116:32 - down the essence of what that text is
116:33 - into a set of numbers and so then you
116:36 - could do things like say like oh are
116:38 - these two sentences similar because you
116:41 - can always measure the similarity of
116:43 - numbers by distance by distance in some
116:47 - dimensional space so this is this
116:49 - process is you're absolutely right music
116:51 - sound images text anything that's data
116:55 - that we can that we can turn into data
116:58 - that we can turn into numbers we can
117:00 - pass it through a machine learning
117:01 - system to detect features this again
117:04 - this isn't magic the universal sense
117:07 - encoder only exists because you know
117:10 - some researchers most likely at Google
117:12 - happen to be able to train this model on
117:16 - some massive amount of text
117:21 - yes yes right
117:32 - oh the summary exactly yeah
117:42 - you mention things we passed you yes so
117:55 - this is a hidden really now there are
117:57 - there are countless variations on all of
118:00 - these different techniques and
118:02 - algorithms but at its core this is the
118:05 - idea of a shape if you if you start to
118:09 - read into it like more of a
118:10 - documentation attention flow that day
118:12 - asset tend to flower other machine
118:13 - learning models you'll you'll see this
118:16 - idea of a shape so for example image
118:20 - classification we're taking this image
118:23 - the webcam image is 320 by 240 and
118:27 - sending it into mobile net well I don't
118:30 - remember what it is exactly but mobile
118:32 - net actually only accepts input data
118:35 - that is I can't remember with its but
118:38 - it's some weird dimension like this to
118:40 - 24 by 24 so I don't remember whether
118:43 - it's p ml 5 or 10 to flow digest but
118:46 - somewhere before it's actually passed in
118:48 - there that images video size so the
118:51 - other way a sort of standard typical
118:55 - neural network system works and this is
118:57 - different than a neural network that's
119:00 - recurrent that's designed for sequential
119:02 - data which is a different discussion is
119:04 - the inputs are fixed so weird things
119:09 - happen like with with that like a
119:12 - sentence like a sentence is some
119:14 - arbitrary number of words so how is that
119:18 - boiled down into a fixed amount well
119:22 - read the paper let me know how they did
119:25 - that but it's typically done there's
119:27 - like each word is probably looked up in
119:31 - a dictionary and then assigned some
119:33 - other number that's then repackaged in
119:34 - another array there's you know elaborate
119:38 - techniques for like fitting the data
119:40 - into
119:42 - particular sub dimensions but that is
119:44 - different than if you've heard of
119:46 - something this is also an ml five it's
119:48 - called a recurrent neural network which
119:51 - is a neural network that's trained on
119:54 - sequences or can generate sequences
119:56 - that's really useful for data that is a
119:59 - of not fixed dimension what I mean by
120:01 - that is just I mean this is you know
120:06 - certainly merits more than two minutes
120:08 - of discussion but if we have the image
120:11 - classification example right where it
120:14 - has some fixed number of inputs one two
120:16 - three four five six seven eight so this
120:19 - is like a four by two image you don't
120:22 - eat pixel values that goes in and gives
120:25 - us you know cat or dog so any any
120:29 - arbitrary image would have to be resized
120:31 - to this very tiny dimension before going
120:33 - into this particular system the current
120:36 - network a classic example is like you
120:39 - know a lot of comma
120:41 - my name is the way I would curl now
120:45 - recurrent neural network works is it
120:50 - feeds in one character at a time so H
120:54 - the input is a single character and the
120:57 - output the idea is trying to guess the
120:59 - next element of the sequence and then
121:03 - that is fed back in recursively so it's
121:08 - able to do something one element at a
121:11 - time so you can basically train it by
121:14 - saying like hey I'm going to give you an
121:17 - H you're supposed to get an e mixed it's
121:19 - going to make a guess which is probably
121:21 - to be incorrect it's gonna tweak its
121:23 - dials and then it's gonna feed the e
121:25 - back in and then it's gonna say okay
121:27 - one minute you're supposed to get an L
121:29 - next so it's gonna train itself based on
121:31 - the sequence and then it can generate
121:33 - things one at a time and so examples of
121:35 - this that I've done have videos about a
121:37 - site recently like a model sketch RNN
121:40 - cuz a drawing is a sequence so it can
121:42 - try to predict where you're gonna go
121:43 - next based on the drawing path so an
121:45 - infinite amount of possibilities here
121:48 - yes
121:50 - yes yes so this is a great question and
121:58 - so you the short answer is no who get in
122:01 - the sense that ml5 is dependent entirely
122:05 - dependent on tensorflow j/s and the work
122:10 - that the tent villages team did is very
122:13 - to make it work is very specific to
122:16 - javascript the browser and WebGL so
122:19 - what's kind of missing from this
122:21 - discussion is all of this can happen now
122:23 - in the browser at very efficiently
122:26 - because of WebGL which is using your
122:29 - computer's graphics card to do all these
122:31 - matrix math calculations that you know
122:34 - graphics cards were designed to do all
122:36 - those calculations to surrender graphics
122:38 - but turns out those same kind of
122:40 - calculations the field of linear algebra
122:42 - matrix math that drives a lot of
122:44 - computer graphics also drives these
122:45 - machine learning algorithms so their
122:47 - implementation is entirely an ml 5 is
122:52 - entirely like focused on JavaScript and
122:54 - WebGL that said it would be technically
122:58 - possible to make a port of ml 5 to
123:04 - processing by building on top of Java
123:07 - bindings for reg regular tensorflow so
123:10 - the original tensorflow library is is is
123:12 - C++ as written in C++ most people
123:15 - interact with it through a language
123:17 - called Python because that's you know
123:20 - the sort of language of the data science
123:21 - world and so you're kind of you can
123:24 - control tensor flow from Python
123:26 - basically execute tensor flow machine
123:28 - learning
123:30 - operations from Python you can also do
123:33 - those from Java and pretty sure it's
123:35 - just this is like not a thing that a lot
123:37 - of people know how to do Java bindings
123:40 - tensorflow and look at this install
123:45 - tensorflow for java so in theory you
123:48 - could make you could make a you could
123:51 - sort of wrap tensor flow and put some
123:53 - niceties around it in processing the
123:56 - same way that but no one has done that
124:00 - anybody if anybody wants to do that
124:03 - something a message on Twitter or
124:04 - something I'll be there I'm just gonna
124:06 - like cheer the whole time you know it's
124:09 - it's there more you know it's it's a
124:11 - weird sort of thing cuz I don't I don't
124:12 - I don't have a good world I don't have I
124:16 - think an accurate worldview in the sense
124:19 - that if you I think people are using
124:20 - Java and Java is used in industry and in
124:24 - education a huge amount but in the world
124:29 - that I kind of walked through this
124:31 - creative coding education art school
124:35 - there's so many more people now invested
124:38 - in learning JavaScript than contributing
124:40 - to JavaScript so I think it's it's
124:42 - harder to find contributors to
124:46 - processing Java than it is to JavaScript
124:49 - libraries these days from but I don't
124:51 - know if that's really true in a sort
124:53 - global sense or just in the sort of
124:54 - small little circles that I operated I'm
124:57 - not reaching out to the right people or
124:59 - communities other questions yes Simon
125:07 - one more question from Simon or is this
125:09 - more you are you're gonna talk to us
125:10 - about how many pixels are any image
125:12 - again because this is writer you really
125:16 - should make a video about that so let me
125:29 - pause you for a second because I want I
125:31 - want to hear about this but I think also
125:33 - we're reaching the time where maybe if
125:35 - people want if we want to like break out
125:36 - and like just hang out here for a little
125:38 - bit trying to work with these examples
125:39 - and we can also have like some side
125:41 - discussions so hold that saw for like
125:43 - one more minute can you do that Simon
125:44 - okay so what what I want to do is let so
125:50 - let me just stop here with this let me
125:52 - let me stop here with this example so
125:55 - I'm going to if it isn't already what
125:58 - I'll do in a moment is I'll take this
126:00 - URL and put it as a link right here
126:03 - maybe it's here already working progress
126:06 - sketch look it's there already and so
126:08 - you know I'm certainly I'm gonna be
126:10 - hanging out here for at least another
126:11 - hour I don't I don't know
126:12 - you know this was like a a free event I
126:15 - don't I don't know what time's with the
126:16 - tank closes down but you ought you're
126:18 - all obviously welcome to lead held
126:21 - captive here um but what I would be
126:23 - interesting to me is if people can take
126:26 - this example and play with it whether
126:28 - that's just like trying to train their
126:30 - own model with some objects you find
126:31 - running around whether you want to hook
126:33 - it into something else you've already
126:34 - been working on people want to hang out
126:36 - here for another hour or so and work on
126:38 - stuff I can float around and answer some
126:41 - questions if you didn't get a sticker
126:49 - stickers I know there's some treats that
126:52 - home-baked and also some that care about
126:54 - from a vegan place nearby
126:56 - so so we can just hang out here for
126:59 - another hour and work on stuff okay
127:06 - so I'm for that purpose I'm gonna shut
127:09 - down the live stream and then Simon I'm
127:14 - gonna start with you to hear about this
127:15 - thing that you want to tell me but first
127:16 - let me shut down the livestream and then
127:18 - so and then what is the we'll make this
127:20 - an official moment how do I do this okay
127:22 - I'm gonna go here yeah we're like
127:27 - they're there let's check in on the
127:29 - livestream for a second okay uh Java
127:33 - seems good okay okay stop streaming okay
127:38 - this has been longer than an hour and a
127:40 - half that time is not accurate okay all
127:42 - right I'm feeling very nervous about
127:43 - clicking this button okay goodbye
127:45 - everybody watching this live if we make
127:47 - maybe what we'll do also before I get
127:49 - kick stop there and what we'll do is if
127:52 - people make stuff from today maybe we
127:54 - can come up with a way of aggregating
127:56 - that and I know certainly that just
127:59 - having people add links to things you
128:01 - made from that github readme would be a
128:02 - start but certainly if people have other
128:04 - ideas hashtag the tank the coding tank
128:08 - is that like a thing like a tank is like
128:10 - a train how do you think how do you say
128:12 - never mind okay I'll get my French
128:14 - lessons later okay I mean it stop
128:15 - streaming thank you