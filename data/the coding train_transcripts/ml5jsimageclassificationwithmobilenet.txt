00:00 - [BELL RINGING]
00:00 - Hello.
00:01 - Welcome to the first code
tutorial that I am ever making.
00:05 - I did make this kind of
long-winded, rambling
00:08 - introduction to what ML5 library
is itself, but in this video,
00:11 - I'm actually going to
make a code example that
00:13 - does image classification.
00:15 - So this is going to be
our "hello world," "hello
00:18 - to machine learning,"
first start.
00:21 - It's one of the easiest
things you can do with the ML5
00:23 - library, and it involves--
00:25 - this is very key--
00:27 - a pre-trained model.
00:28 - So this is not where
everyone starts in tutorials
00:32 - about machine learning.
00:33 - A lot of tutorials
about machine learning
00:34 - start with, like I said
in the previous video,
00:36 - linear regression and the
math and training this.
00:39 - And we're just going to
use a pre-trained model.
00:41 - Somebody else made
a machine learning
00:43 - model that knows how to
recognize the contents
00:46 - of images, and ML5--
00:48 - they open-sourced it,
and ML5 is providing
00:50 - us access to it
within JavaScript
00:52 - to use with the p5 library.
00:54 - So I'm going to write
the code for this
00:55 - and talk about how it works,
but let's first actually--
00:57 - if you just even want to just
play around with this model
01:00 - to start with, you could do
this right here on the ML5 home
01:02 - page.
01:03 - So right here, you can
see this image of a macaw.
01:06 - And guess what?
01:06 - The MobileNet model labeled
this image as a macaw
01:09 - with a confidence of 98.79%.
01:14 - Oh, this must be the best,
smartest machine learning model
01:17 - ever.
01:17 - It's like magic.
01:18 - It just knows everything.
01:19 - And in fact, I can
grab this toucan
01:21 - and I can drag it in
here, and look at this.
01:23 - It's a toucan with a
conference of 99.99%.
01:28 - This is so smart.
01:29 - So smart.
01:29 - I can't believe the
MobileNet model is amazing.
01:31 - Now let's get this
puffin in here.
01:33 - It's got to know
what a puffin is.
01:34 - Look at this.
01:35 - The MobileNet labeled
this as an oystercatcher,
01:39 - and its confidence
is kind of low.
01:41 - Huh.
01:42 - So what's going on here?
01:43 - Why is it not saying puffin?
01:45 - That's clearly a puffin.
01:47 - Well, first of all, guess what?
01:49 - A pre-trained model for
image classification--
01:53 - forget about accuracy-- has
a fixed number of even things
01:58 - in the world it knows about.
02:00 - And one of the things that's
really important if you're
02:02 - working with something
like a pre-trained model
02:04 - is actually to know
what's in that set.
02:06 - Now, it's not the most
easy thing to find.
02:10 - But right here on
the ML5 GitHub,
02:12 - there's actually this
page of JavaScript code
02:15 - that shows all the things that
the MobileNet model happens
02:20 - to know about.
02:20 - In fact, there
are 1,000 classes.
02:23 - And you could see this is crazy.
02:25 - It knows about a beagle and a
bloodhound and a black and--
02:27 - and a English foxhound.
02:29 - It's trained to know
obscure dog breeds.
02:33 - But if I look for puffin,
it's nowhere to be found.
02:38 - Oystercatcher,
however, is in there.
02:40 - And if I were to look-- like,
what does an oystercatcher
02:42 - look like?
02:45 - It kind of makes sense.
02:47 - That's the thing it knows
about that's closest to puffin.
02:50 - So if your project
is all about puffins,
02:54 - you're not out of luck.
02:55 - And I will show you ways to
train with your own data,
02:59 - to retrain a pre-trained model.
03:00 - But right now, we're
at this starting point.
03:02 - So birds aside-- it happens
you know a lot about birds.
03:06 - It happens you know
a lot about dogs.
03:08 - But let's just say, for
the sake of argument,
03:11 - I'm going to now give it
this coding train logo.
03:13 - It thinks that's a wall clock,
and it has a low confidence.
03:16 - And that-- I don't know,
maybe because of what's
03:19 - here, the flat nature of it.
03:22 - I can give it an
image of myself.
03:24 - It thinks I'm a snorkel,
which strangely is probably
03:27 - quite accurate.
03:28 - I'm kind of snorkel-like
in more ways than one.
03:31 - But whatever.
03:32 - Maybe that's too weird.
03:33 - But the point is, it actually
knows nothing about people,
03:37 - and it knows nothing
about a lot of things
03:39 - that exist in our world.
03:41 - Who made these decisions?
03:43 - What's in the pre--
03:44 - why are these classes
written this way?
03:46 - And what was it
even trained with?
03:47 - So first-- so let's
talk about for
03:49 - a second supervised learning.
03:51 - What is supervised learning?
03:52 - So image classification.
03:53 - What's happening with
image classification?
03:55 - So the stage that we're
going to do in our code,
03:58 - we're really just going to
do the prediction stage.
04:02 - So the prediction stage-- we
have this pre-trained MobileNet
04:05 - model.
04:07 - The model expects some input,
and it expects that input
04:12 - to be an image.
04:14 - So that's the
input to the model.
04:16 - Then the model
generates an output,
04:18 - and that output is
a list of labels--
04:21 - cat, dog, puffin, et cetera--
and confidence scores--
04:28 - 98%.
04:31 - Well, I guess the--
04:32 - do the scores all
add up to 100%?
04:34 - I think they should.
04:36 - 90%.
04:37 - 6%.
04:38 - 2%.
04:40 - Et cetera.
04:41 - So this is the stage
that we're doing.
04:43 - But how did we even--
04:45 - how do we get to the point where
we could do this ourselves?
04:48 - So somebody had to do
this with a process known
04:51 - as supervised learning.
04:54 - I'm going to write this down
here-- supervised learning.
04:57 - So supervised learning
involves a data set.
05:03 - And this is often
referred to as a
05:05 - labeled data set,
meaning-- you could
05:07 - think of it as a
spreadsheet, a table,
05:10 - a table of images and labels.
05:16 - Essentially, there's
two columns here.
05:18 - One column is a lot
of examples of inputs,
05:21 - and the other column is a
lot of examples of outputs.
05:24 - So I might have cat.jpeg.
05:27 - Oh, and that's a cat.
05:29 - And then I might
have kitten.jpeg,
05:32 - and that's also a cat.
05:33 - And then I have puffin.jpeg,
and that's a puffin.
05:38 - So the idea here is that there
is this existing training
05:42 - data set.
05:42 - This is a training data set.
05:46 - The data set is used to
train the MobileNet model.
05:50 - It just says over and over
again, here's this image,
05:54 - here's its label.
05:54 - Here's this image.
05:55 - Here's this label.
05:56 - And the process
of how that works
05:58 - involves looking at the error.
06:01 - The model tries to make a guess.
06:03 - Does it get it wrong?
06:04 - Since it knows the
right answer, it
06:05 - can change its
settings to try to get
06:07 - the right answer the next time.
06:08 - This is the process.
06:09 - Once that finishes,
usually the model
06:12 - is tested with some
other images that
06:15 - weren't used in
the training set,
06:16 - and then a paper is written
about it, it's published.
06:19 - Or it might be something
that a company owns and keeps
06:24 - closed down and doesn't
provide access to.
06:26 - It uses it in their own
proprietary software.
06:28 - MobileNet is one that is public.
06:31 - So the important
question for us to ask,
06:33 - if we're going to use
this pre-trained model
06:36 - and we're going to start trying
to understand why it's giving
06:39 - us certain results and
what is it good at,
06:40 - what is it not good
at, is we need to know,
06:42 - what was that training set?
06:44 - In this case, the
training set is a database
06:49 - of images called ImageNet.
06:51 - We can come back
to the computer.
06:54 - Sorry.
06:54 - Whoops.
06:56 - We can look at the
ImageNet website.
07:00 - And look at this.
07:01 - ImageNet is a database of
almost 15 million images.
07:05 - And that seems
pretty good, right?
07:07 - A machine learning
system, for it
07:09 - to do a good job in the
supervised learning process,
07:12 - it needs a lot of data.
07:13 - If we just have 10
images, it's not
07:15 - going to be able
to do very much.
07:16 - There's some tricky things we
can do that I'll show you later
07:19 - with small data sets,
but in general, we
07:21 - need a large data set.
07:22 - So that seems like a good thing.
07:23 - But one thing you
have to realize--
07:25 - what are the motivations
of this data set?
07:26 - Where are the
images coming from?
07:28 - Well, most of the--
07:31 - this data set was really
put together for research
07:35 - into image classification.
07:37 - And in order to
do that, it needs
07:39 - to use, well, images that
are in the public domain,
07:42 - that it can get access to.
07:43 - And frankly, almost all of--
07:46 - it's very likely that if you
do a Google search for any
07:49 - of these-- so any of the--
07:51 - let me just do this
really quickly.
07:52 - So I go back to the labels.
07:53 - Let's look for king penguin.
07:56 - So I'm going to do a
search for king penguin.
07:58 - I'm going to go to Images.
08:00 - I'm going to grab this image.
08:02 - I'm going to do Save Image As.
08:04 - I'm going to save it to
the desktop as Penguin.
08:07 - I mean to go back to ML5.
08:09 - And then I'm going
to go here and say--
08:12 - Look, 100%.
08:13 - Do you know why it's 100%?
08:15 - I am almost sure that
that image is in--
08:18 - I mean, I'm not sure about
this, but go and look.
08:20 - That's probably in ImageNet.
08:22 - So a lot of these things that
come up in the first search
08:25 - result that are in the
public domain for Wikipedia,
08:27 - they're actually in
that image database.
08:30 - So it's going to work
really well with something
08:32 - like that versus the
image of a puffin that's
08:34 - not in the database.
08:35 - Doesn't even know
what a puffin--
08:36 - So maybe if we could find
an image of a penguin that's
08:38 - not in the database,
ImageNet database,
08:41 - it probably would
guess it as a penguin.
08:42 - But we wouldn't necessarily
see that much of a confidence.
08:45 - Maybe if we had a zoomed-out
picture with a lot more
08:48 - background noise--
08:49 - something that you could
try that's super interesting
08:51 - is to just download this image
and draw over it or change
08:54 - a couple of pixels.
08:55 - What happens to the image
classification afterwards?
08:57 - All these things you could try.
08:58 - And better yet, you can try
them by writing your own code.
09:02 - So I think it's time--
09:03 - I've rambled on and
on for long enough
09:06 - about what this model is.
09:07 - The last thing I'll
mention is, if you really
09:09 - want to dive deeply into
the MobileNet model,
09:11 - there is a whole paper
written about it.
09:12 - There's a GitHub repository.
09:13 - I'll link to all that stuff.
09:15 - I encourage you to
research this stuff
09:17 - and to think about it, to ask
questions, and to be critical.
09:20 - What are the motivations
behind the creation of a model?
09:23 - What data was used
in that model?
09:25 - And where might you want
to use it or not use it?
09:30 - So all that aside,
let's actually
09:32 - write some code to
use the model now.
09:35 - We're ready to write the code.
09:36 - Now, what I'm starting
with is one JavaScript file
09:40 - with a little bit of code in it.
09:41 - Again, I mentioned I'm
using the p5 library.
09:43 - The p5 library supports
a setup function
09:46 - which executes when
the web page loads.
09:48 - createCanvas makes a canvas.
09:50 - And now I color the
background with the color 0,
09:53 - which is black.
09:54 - And if I go into
the browser, I am
09:56 - able to see the
results of this code
09:59 - because I also happen to be
running a local server using
10:02 - a node server package.
10:05 - Now, there are so many
ways that you can run a web
10:09 - page that's running JavaScript.
10:10 - And you could use CodePen or
OpenProcessing or something new
10:15 - that's going to be
coming out soon,
10:16 - which is a p5 editor
that you could use online
10:18 - that, when it comes
out, I'll link
10:19 - to it in the video description.
10:21 - But for right now,
I'm going to use
10:23 - my workflow of
having my own text
10:24 - editor on my computer and the p5
libraries imported in the HTML
10:31 - file.
10:32 - So here's the HTML file.
10:33 - The only thing it's doing
right now as it's referencing
10:36 - the p5 library and something
called the p5.dom library
10:39 - which I need for some of
the things I want to do.
10:41 - And then also, of
course, my own sketch.js.
10:44 - I have a video where I go
through my entire workflow
10:48 - in more detailed steps.
10:49 - I will also link to that
this video's description.
10:52 - Now that that's
settled, though, I
10:53 - can actually start to use ML5.
10:55 - So how do I use ML5?
10:57 - So right here, I'm
on the ML5 homepage.
10:58 - The first place I
should go is just
11:00 - click on this big
Get Started button.
11:01 - So I'm going to click on that.
11:03 - And I totally clicked
around to the wrong place.
11:07 - Let's try that again.
11:08 - I'm going to click on
the Get Started button.
11:11 - And I'm going to
go right down here,
11:12 - and I'm going to look at this.
11:13 - This is what I need.
11:15 - Now, I can download the ML5
JavaScript library file itself
11:20 - and include it on my computer.
11:21 - And I might want to do that
if I'm going to work offline.
11:24 - But I prefer to just reference
this particular URL in a script
11:29 - tag.
11:29 - And this is-- at the
time of this recording,
11:32 - this is the current version
of the ML5 library--
11:35 - 0.1.1.
11:36 - Now, by the time you're watching
this, it might be like 7.8.6.
11:40 - And if that's the
case, this video
11:42 - probably means absolutely
nothing whatsoever.
11:45 - But if it's relatively
close to that version,
11:47 - hopefully this video is
still helpful to you.
11:50 - I will not make my
joke about your brain
11:52 - being inside of the
gelatinous thawing machine
11:54 - thing in this video.
11:56 - I've made it too many times.
11:58 - It's not even a--
it's not even funny.
12:00 - So I'm going to
put that in here.
12:02 - I'm just going to go
back to my web page,
12:04 - and I'm going to refresh.
12:05 - It's still working.
12:07 - Good.
12:08 - So now we have the
ML5 library imported.
12:10 - We can start calling
ML5 functions.
12:12 - So one thing I might actually
do is just go back to the ML5
12:16 - website-- oops, sorry--
12:17 - which is here, and
click on Examples.
12:20 - And I could go down to
Image Classification,
12:22 - and then I could start
looking at this code
12:25 - and copy-pasting some stuff.
12:27 - I'm going to type it out.
12:28 - And I have some of
this in my head,
12:29 - so I can just type it out.
12:31 - But more importantly, probably--
12:33 - there are these examples which
you can use to get started,
12:36 - but I might also
suggest just having
12:38 - the web page open
to the reference
12:40 - page for a particular feature.
12:41 - So again, I want
to have videos that
12:43 - go through all of
these features,
12:45 - but let's go through the
Image Classifier one.
12:47 - I'm going to click on that.
12:50 - So now, this is
the documentation.
12:52 - There's a little bit
of an example here,
12:54 - and there's some information
about the syntax.
12:56 - And if I get confused, I
can refer back to that.
12:59 - But since I know some of
this having done this before,
13:02 - I'm going to just start writing
directly into sketch.js itself.
13:07 - So the first thing
that I need to do
13:09 - is I need to create an
image classifier itself.
13:12 - So I'm going to make
a variable, and I'm
13:14 - going to call it classifier.
13:16 - And actually, you know what?
13:17 - I'm going to call it mobilenet
because I want to remind myself
13:20 - that this is not
magic, that this
13:22 - is using a very specific
pre-trained model called
13:24 - MobileNet.
13:25 - So I'm going to call
my variable mobilenet.
13:26 - Then I'm going to say mobilenet
equals ml5.imageClassifer.
13:33 - So this is a function
that generates
13:34 - an image classification object.
13:36 - It's going to be stored in
that variable mobilenet.
13:39 - And now it needs some arguments.
13:41 - So what goes in there?
13:42 - Now, the truth of
the matter is, there
13:46 - might be a variety of
things you can put in there.
13:48 - At the time of this
recording, there's
13:50 - really only one option,
which is the MobileNet model.
13:54 - So I'm telling ML5 that I want
to make an image classifier,
13:57 - and the first
argument I'm giving it
13:59 - as a string with the
name of the model.
14:02 - Now, in theory, as ML5 supports
additional pre-trained model,
14:06 - I might get to type something
in here, like UnicornClassifier.
14:10 - Maybe it classifies all
different kinds of unicorns.
14:14 - MobileNet.
14:14 - And then I need something
else really important.
14:16 - I need a callback.
14:19 - Deep breath, deep breath,
deep breath, deep breath.
14:22 - So I've got to
stop for a second.
14:24 - Oi.
14:26 - The ML5 library
supports callbacks,
14:27 - which is what I'm going to
use in these video tutorials,
14:30 - and something called promises.
14:32 - If you don't know what
a JavaScript promise is,
14:34 - I will refer you to my playlist
about JavaScript promises,
14:37 - and you might look at
some of the documentation.
14:40 - But if you're
someone who already
14:41 - uses JavaScript promises,
it's another way
14:43 - of handling asynchronous
events that's
14:45 - slightly different but
very similar to callbacks.
14:47 - That's something you can
go and do on your own,
14:50 - or I'll make some
videos about that too.
14:52 - But right now, I'm going to
use the callback methodology.
14:54 - So the idea here as I type
in the name of a function.
14:57 - I could also put an
anonymous function
14:59 - in there called model ready.
15:01 - And I'm going to write--
15:02 - I'm just going to
put that function
15:04 - up here in the global
space because that's
15:06 - going to be very simple.
15:08 - And I'm just going to say
console.log, "Model is ready!"
15:15 - So the idea here is I am now
creating an image classifier
15:18 - with a MobileNet model.
15:19 - It's going to take some time
for it to load that model.
15:21 - This is not a small thing.
15:22 - Now, it's called MobileNet
because it's actually
15:24 - a tiny model that can
even run on mobile phones.
15:27 - So this code would work well
even in a mobile browser.
15:31 - But even the tiniest
model is something
15:34 - that's got some size to it.
15:35 - It's going to take a
little while to load.
15:37 - So let's go see how long.
15:39 - I go over here, into here.
15:41 - I'm going to hit Refresh.
15:42 - [WHISTLING]
15:45 - Model is Ready.
15:46 - So I don't know-- that
was a few seconds.
15:48 - You can see-- now, one thing
that's interesting-- where
15:50 - did it load the model from?
15:52 - Does the ML5 library have
a copy of it loaded--
15:55 - actually, no.
15:56 - So one thing that's
important here is a lot
15:59 - of the pre-trained models--
16:00 - this is going to be
different, but a lot
16:02 - of the pre-trained models that
you might make use of in ML5
16:05 - are actually loaded
from the cloud,
16:07 - meaning some underground
bunker of servers
16:10 - where the model file is stored.
16:13 - And I believe it's coming
from a Google server.
16:17 - So if you're not
connected to the internet,
16:20 - this example won't even run.
16:21 - At some point, it would be
nice to support ways of running
16:24 - MobileNet model offline.
16:25 - It is certainly
technically possible.
16:26 - But the ML5 library--
not all of the examples,
16:29 - but this example in particular
requires you to be online.
16:33 - So the model is ready.
16:34 - So now what can I do?
16:36 - I can classify an image.
16:39 - This is fun for me.
16:41 - All right.
16:42 - So let's see.
16:44 - I already have in
this directory a bunch
16:47 - of those images that I
was experimenting with.
16:49 - Let's start by using the
puffin, since that's one
16:51 - that we worked with earlier.
16:53 - Personally, I like
to use in my examples
16:56 - stuff that doesn't work because
it leads you to ask questions.
17:01 - If stuff just
works, it can start
17:03 - to feel like magic and you can--
17:05 - it's important to
think about why stuff
17:07 - and how stuff is working.
17:09 - So what I'm going
to do in setup,
17:11 - I'm going to make a
variable called puffin.
17:14 - Puffing.
17:14 - Puffin.
17:15 - And I'm going to say,
puffin equals createImg.
17:19 - Now, this is a particular
function in the p5 library.
17:23 - This is now-- like createCanvase
is p5, createIMG is p5.
17:27 - This makes a dom element, an
image element on the web page
17:32 - that is that image.
17:34 - So if I were to reload this
page, you're going to see--
17:37 - OK.
17:37 - Ah, it's in the
directory images,
17:40 - so I need to include that there.
17:41 - You're going to see
there it is down there.
17:43 - Now, I can do things, like
if I wanted to have this all
17:45 - happen in my canvas, I
could say puffin.hide,
17:49 - and then I can actually
say image, puffin.
17:52 - And this won't work, but it'll
be interesting to think why
17:55 - for a second.
17:56 - And I want to draw the
puffin into canvas.
17:58 - The reason why it didn't
work is, once again, things
18:02 - don't happen in JavaScript
instantaneously.
18:04 - So it's going to take some
time to create that image.
18:08 - I'm going to-- I could give that
a callback called imageReady.
18:12 - A lot of this stuff is
unnecessary to the example
18:14 - I'm building, but just
to demonstrate the idea.
18:17 - And then, now I'm going to
draw the image into the canvas.
18:21 - Ah, but that image is really a
big size, so I could resize it.
18:25 - Or I could just force it to
be the size of the canvas.
18:28 - And there we go.
18:29 - So I now have a p5 canvas
displaying my puffin image,
18:32 - and the model is ready.
18:34 - So now, once the model
is ready, what can I do?
18:38 - I can classify the image.
18:40 - I can try to ask
MobileNet what's in it.
18:42 - And the way I do that is with
a function called predict.
18:46 - So you'll see different
names for different functions
18:48 - in the ML5 library.
18:49 - Predict will come up often.
18:51 - It might change to classify by
the time you watch this video,
18:54 - but I think it's called predict
right now, this version of ML5.
18:58 - I'm going to say
mobilenet.predict puffin,
19:04 - meaning I want
MobileNet to give me
19:06 - a prediction of what it thinks
the content of the puffin image
19:10 - is.
19:11 - And then, guess what?
19:12 - That takes some time.
19:13 - It doesn't happen
instantaneously.
19:14 - So I need yet again
another callback.
19:17 - And I'm going to give it a
callback called gotResults.
19:19 - And again, I could do
this with a promise
19:21 - if that's something that
you're more comfortable with,
19:23 - but I'm going to
do with a callback.
19:25 - And then I'm going to write
this function called gotResults.
19:28 - And now, if you've
used p5 before,
19:31 - this is very
similar to loadJSON.
19:33 - Oh, I want to load the
data from this JSON file.
19:39 - And then, you usually
have an argument
19:41 - to the callback which
has the stuff in it.
19:43 - The stuff that you want
fills that argument.
19:46 - But here's something.
19:48 - ML5 works with error
first callbacks.
19:50 - This is a JavaScript
pattern where,
19:52 - when you write the
callback, you always
19:55 - must include as
the first argument
19:58 - an error argument,
an error variable,
20:01 - meaning the library is forcing
you to check for errors.
20:04 - So in this case, I might
want to say something like,
20:06 - if (error)--
20:08 - whoops, not a new promise--
20:11 - console-- and by the way,
I could say console.log,
20:13 - but I can actually say
console.error(error).
20:15 - And then otherwise,
console.log(results).
20:19 - So this is a little bit
of extra error handling,
20:21 - if something went wrong
in the prediction process,
20:24 - hopefully I would
see that there.
20:25 - Otherwise, I'm going
to see the results.
20:30 - Let's see if this works.
20:35 - Model is Ready.
20:36 - Model is Ready.
20:38 - And then-- oh, look at this.
20:40 - [MUSIC PLAYING]
20:42 - And here we go.
20:44 - Oystercatcher.
20:45 - And we can see this
probability is--
20:48 - that is crazy.
20:49 - So this is really
interesting to me.
20:51 - This got 75%.
20:53 - Then it also thought
it was albatross
20:55 - and drake, different
probabilities.
20:57 - Now why-- 5%, 11%.
21:00 - Why-- why is this
different than what
21:02 - I got with the oystercatcher
in the home page of ML5JS?
21:07 - I don't know the answer to that.
21:09 - I will have to think about that.
21:11 - It's a different probability.
21:12 - But nonetheless, I'm getting
a pretty similar result.
21:14 - It might have to do with
versions of something,
21:16 - and that the home page is
running a different version
21:18 - of something.
21:19 - But we can see this is the idea.
21:20 - Now what I could what do is
I could go and I could say,
21:24 - all right, let me get
the label is results.
21:29 - This, by the way, is an array
with three objects in it.
21:33 - So I could say, I want to get
the first object, index 0.
21:38 - And I want to get the class
name, object 0 dot classname.
21:43 - That's the label.
21:44 - And then I'm just
going to draw--
21:46 - I'm going to say
fill(0) textSize(100)--
21:51 - no, starts with (64).
21:53 - I don't know.
21:53 - And then I going
to say text(label).
21:58 - And I'll say 10, and like
height minus 50 or something.
22:02 - I don't know.
22:04 - I'm just putting it arbitrarily
somewhere on the page,
22:07 - on the canvas.
22:08 - So let's run this again.
22:09 - We can see Model Loaded.
22:13 - And then it says
oystercatcher right there.
22:15 - How thrilling.
22:16 - We have now run the MobileNet
model, gotten a prediction
22:20 - for our image, and there it is.
22:21 - Of course, I could
also do something
22:23 - like create a dom
element for the label.
22:27 - I could also get the probability
by saying equals results(0).--
22:35 - and what was it called?
22:37 - className probability is
the other probability.
22:42 - And I don't know if
I spelled that right.
22:43 - And I could create two dom
elements using createP.
22:49 - And we could run
this one more time.
22:52 - And now we're going to
see that stuff down here.
22:55 - It's very, very small.
22:56 - Probability is not defined.
22:58 - Probability.
23:01 - Probability.
23:02 - Oh, prob.
23:04 - I named my variable prob
because I got a lot of probs.
23:12 - So we can see here
there's the probability.
23:14 - So this is the basics.
23:16 - Now you see you could
actually just go and use
23:18 - this in a project right now.
23:20 - I have a couple
of ideas for you.
23:22 - Number one is make
a little interface,
23:24 - try different images.
23:25 - Can you make one
where you can actually
23:26 - drag and drop your own image
like it does on the ML5 home
23:28 - page?
23:29 - Could you make something
where you draw on the canvas
23:31 - and it's trying to classify
what you're drawing?
23:34 - Another thing you could try is--
23:35 - can you get it to classify
what the web canvas is seeing?
23:38 - And guess what?
23:39 - That's what I'm going
to do in the next video.
23:41 - So there are so many more
things you could do with this,
23:43 - but this is the basic idea.
23:45 - Try your own version
of this experiment.
23:46 - Play around.
23:47 - Try a lot of different images.
23:48 - But in the next video, I
am going to basically take
23:51 - this exact example but hook
it up to the live webcam feed,
23:55 - and we can see it
classify images
23:56 - from the webcam in real time.
23:58 - All right.
24:01 - I'm doing this as a
Livestream right now.
24:03 - If you're watching this
recorded, it's recorded.
24:05 - But I'm going to check
to see any questions,
24:06 - and I'll answer those also at
the beginning the next video.
24:08 - See you soon.
24:09 - [BELL RINGING]
24:10 - [MUSIC PLAYING]