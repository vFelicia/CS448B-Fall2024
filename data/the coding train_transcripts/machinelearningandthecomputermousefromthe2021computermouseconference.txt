00:06 - [Music]
00:24 - sorry where'd you go
00:31 - [Music]
00:38 - [Music]
00:52 - hello computer mouse conference
00:54 - attendees
00:55 - maybe some viewers from the coding train
00:57 - i don't know
00:58 - why are you watching this video i'm
01:00 - gonna try something new
01:01 - i would like to invite the computer
01:04 - mouse to be with me out here
01:05 - in the garden with my desktop i just
01:08 - realized i forgot my train whistle
01:10 - but let's take a trip you and me and
01:12 - explore what it means to learn
01:14 - with the mouse so where do i want to
01:16 - begin
01:17 - 40 years ago a man named douglas
01:20 - engelbart created what he called
01:21 - the xy position indicator for a display
01:24 - system
01:25 - or more commonly as we know it today the
01:28 - computer
01:29 - mouse he presented it in what is
01:31 - famously known as
01:32 - the mother of all demos and so much of
01:34 - what we take for granted today
01:36 - every time we interface with technology
01:38 - can be traced back to this original demo
01:40 - perhaps a little bit less known was that
01:42 - a few weeks before engelbart's mouse was
01:44 - demoed to the public
01:45 - the german company telefunken presented
01:48 - the first
01:49 - official device that displaced a cursor
01:52 - on a monitor this invention was called a
01:54 - roll hugo
01:55 - i'm not sure if i'm pronouncing that
01:57 - correctly but that directly translates
01:59 - to rolling ball and it is just the
02:02 - cutest
02:03 - most delightful rolling ball i have ever
02:05 - seen over the decades the mouse has
02:07 - changed fundamentally in terms of its
02:09 - design
02:09 - in terms of how we the human beings here
02:12 - in the world
02:13 - use the mouse and interface with our
02:15 - computers and here i find myself today
02:17 - at an actual conference all about the
02:20 - computer mouse
02:21 - itself thank you so much mn ashley for
02:24 - inviting me i'm really thrilled
02:25 - to try to do something a little bit out
02:27 - of my comfort zone here
02:29 - i have a bunch of demos to show but
02:31 - ultimately
02:32 - i want to take the question presented
02:36 - by the computer mouse conference itself
02:37 - the fundamental question of computer
02:39 - mouse scholarship
02:40 - and explore it what is it exactly that
02:42 - the mouse sees
02:44 - and how does that shape what humans
02:49 - come on see come on
02:53 - [Music]
02:56 - come on come on
03:08 - [Music]
03:11 - i want to begin this journey with the
03:14 - image
03:14 - of a mouse itself you might have seen in
03:17 - the news or on social media lots of
03:18 - examples of this blank does not exist
03:21 - or perhaps this ai dreams about cats
03:24 - and it'll haunt your nightmares and you
03:26 - might be wondering should you be worried
03:28 - i mean i'm a little bit scared i have
03:30 - of nightmares i don't want to have
03:31 - nightmares this blank does not exist
03:33 - typically refers to the concept of
03:35 - synthetic media and
03:37 - there are lots of different kinds of
03:38 - techniques to generate imagery
03:40 - but what is grabbing all the headlines
03:42 - today what you're
03:43 - often hearing about is something called
03:46 - a gan
03:46 - or generative adversarial network a gan
03:50 - is a system of
03:50 - two neural networks one is known as the
03:53 - generator the other is the discriminator
03:55 - the generator is just making images
03:57 - generate images images images images
03:59 - maybe it's trying
04:00 - to create images of mice
04:03 - the discriminator's job is to look at an
04:05 - image made by the generator and compare
04:07 - it to a lineup of images of
04:09 - real mice this is the training data set
04:11 - actual photographs of mice
04:13 - from the real world only that
04:14 - discriminator doesn't know which is
04:16 - which
04:17 - it's got to make a determination if it
04:19 - can guess correctly which one is the
04:20 - fake
04:21 - the generator has to go back and try
04:23 - again and it tries again
04:24 - and back and forth this is the a in gan
04:27 - adversarial these two networks are
04:30 - pitted together against each other
04:32 - in a game of cat and mouse if you will
04:35 - early gans produced fuzzy low resolution
04:38 - images ones that aren't very realistic
04:40 - into the human eye are quite
04:42 - distinguishable from real images however
04:45 - over the years these synthetic images
04:47 - have become
04:47 - more and more photorealistic in december
04:50 - 2018
04:52 - nvidia researchers released something
04:53 - called stylegan a novel technique for
04:56 - generated images with finer control over
04:58 - the style of the image itself
05:00 - in 2020 further improvements were made
05:03 - to this model known as
05:04 - stylegan 2. and this is where i find a
05:07 - really big challenge
05:08 - i can't help but get really excited by
05:10 - this technology and think about
05:12 - the possibilities that sort of like
05:14 - magic output of these pre-trained models
05:16 - and what doors
05:17 - they might open when placed in the hands
05:19 - of artists creative people
05:20 - people like who i'm imagining are
05:22 - watching this video right now
05:24 - however it is absolutely critical that
05:26 - my
05:27 - enthusiastic sharing of how to generate
05:29 - your own synthetic images
05:30 - be tempered with a really serious look
05:33 - at the harmful
05:34 - unintended and sometimes rather
05:36 - unfortunately intended
05:38 - consequences of this kind of technology
05:41 - machine learning models are making
05:42 - decisions for us impacting
05:44 - our daily lives all the time there are
05:46 - countless examples of deeply ingrained
05:48 - biases of harm that's being caused
05:50 - this harm disproportionately affects
05:53 - communities of color
05:54 - and other misrepresented identities
05:57 - synthetic media is being used on a
05:58 - regular basis to spread misinformation
06:00 - so here's just one
06:02 - example of a generated twitter profile
06:04 - pictures of fictional amazon workers
06:07 - who love working at amazon and this was
06:10 - used as an
06:11 - attempt to prevent the unionization of
06:13 - workers
06:14 - still there is beauty to be found and
06:16 - much to be learned by these ai dreams
06:19 - as evidenced by a global diverse array
06:21 - of artists and activists making
06:23 - thoughtful impactful work with the new
06:24 - technology
06:25 - these synthetic artifacts can help us to
06:28 - dream and see the small beauties of life
06:31 - take as an example helena sarin's leaves
06:34 - which showcase intricate outputs of a
06:36 - model trained on the colorful leaves
06:37 - fallen in her
06:38 - backyard others like dr nettress r
06:41 - gaskins use a related technique called
06:43 - style transfer
06:44 - to generate portraiture drawing
06:46 - inspiration from other
06:48 - generative techniques and treating the
06:49 - imagery with neural networks
06:51 - these are beautiful examples but ai
06:53 - dreams are
06:54 - often just so ridiculous that they can
06:56 - also bring laughter and levity to our
06:59 - day
06:59 - take for example this foot does not
07:01 - exist by the collective mschf
07:04 - as well as bivalent friends created by
07:06 - golon levin
07:07 - and ling donghuang so who am i to just
07:10 - make some absurd style gan mice
07:12 - i don't know but it's my hope that if i
07:14 - share this technique with you the
07:15 - creative and beautiful people of the
07:17 - world
07:17 - you can educate others spread awareness
07:20 - share your artistic vision and affect
07:21 - positive change
07:23 - so here's how i trained my own stylegan
07:25 - mice to simulate the machine
07:26 - dreaming of the computer mouse and to be
07:29 - clear there's no
07:30 - actual dreaming going on here machine
07:32 - learning these ai dreams really boil
07:34 - down
07:34 - to just numbers and spreadsheets and
07:36 - those spreadsheets being you know
07:37 - multiplied together
07:38 - a lot of times i began by first
07:40 - collecting a data set of mouse imagery
07:42 - so i scraped from flickr i scraped from
07:44 - google images
07:45 - and honestly i just i took a lot of
07:47 - pictures of mice
07:48 - i've been buying some off ebay making a
07:50 - collection and just taking lots of
07:51 - pictures of them from multiple angles
07:53 - using runway ml i uploaded the entire
07:56 - data sets of their servers and started
07:58 - the training process
07:59 - runway makes this process of training a
08:01 - stylegan model easy so first it's got a
08:03 - cloud
08:04 - server that just has all the
08:05 - configurations set up for you so all of
08:07 - the time that you might
08:08 - be configuring your environment and
08:10 - setting settings and trying to like
08:12 - get your machine learning gpu system to
08:15 - not
08:15 - throw an error runway handles all of
08:17 - that for you but even
08:19 - better than that runway has a set of
08:21 - base models from which to train
08:23 - so it would be you need a much larger
08:25 - data set and much more time
08:26 - to train a style gain model from scratch
08:28 - but in this case i started from one
08:30 - trained on objects mostly cars and so
08:32 - without starting from nothing
08:33 - i've got my synthetic mice in no time
08:36 - really just about an hour
08:37 - once the training is complete i can
08:39 - execute the model in runway itself and
08:41 - browse what is known as the latent space
08:43 - so the latent space refers to the
08:45 - universe of all
08:47 - possible dreams the model might have
08:49 - about these mice
08:50 - it's essentially a really really really
08:52 - big graph in many many dimensions
08:55 - when you see a dreamlike sequence of
08:56 - morphing synthetic imagery what you are
08:58 - really seeing is a walk
09:00 - through that latent space anna ridler's
09:03 - mosaic virus
09:04 - is a wonderful example of a walk through
09:06 - a latent space of beautiful flowers
09:08 - what's interesting is how you choose to
09:10 - make that walk and in anna riddler's
09:12 - piece
09:12 - that walk is directed by the price of
09:14 - bitcoin runway ml also has a feature
09:17 - where you can host the model that you've
09:18 - trained so once i've hosted it
09:20 - i can then write my own program to
09:22 - request images
09:23 - and i can make the walk happen however i
09:25 - want what i chose to do is program a
09:27 - node server that would request these
09:28 - images and then a processing sketch
09:30 - that would ask the node server to
09:32 - request the images and the reason why i
09:34 - wanted to use processing
09:35 - is i love this algorithm called open
09:37 - simplex noise
09:38 - it's a wonderful way to smoothly
09:40 - navigate the latent space
09:42 - and by calculating the noise in
09:44 - processing sending the results to node
09:46 - node getting the image from the server
09:48 - then back to processing
09:49 - i'm able to render what i'm about to
09:51 - present to you my
09:53 - short film entitled computer mouse
09:56 - dreams and uh just in case you know i
09:59 - did throw in a couple
10:00 - real mice in there so hopefully this is
10:02 - not gonna haunt your nightmares
10:05 - [Music]
10:14 - [Music]
10:16 - sorry
10:22 - [Music]
10:25 - and there we have it cat versus mouse
10:27 - score one for the mouse
10:28 - but i think i might have jumped ahead
10:30 - maybe done this out of order here i am
10:32 - using generative adversarial networks
10:34 - two neural networks pitted
10:36 - against each other in a fiery battle to
10:38 - generate synthetic mice
10:39 - let's take a step back what is machine
10:42 - learning what is a neural network and
10:44 - can the computer mouse help us to
10:47 - understand the answer to these questions
11:02 - gloria
11:03 - [Music]
11:06 - come here
11:15 - [Music]
11:26 - kyle mcdonald in his 2018 kik festival
11:29 - talk weird
11:30 - intelligence defines machine learning as
11:33 - programming with examples not
11:36 - instructions
11:37 - so what does this mean exactly
11:39 - programming with instructions
11:40 - is like me attempting to explain and
11:43 - provide instructions
11:44 - to my children on how to do something
11:47 - code works the same way
11:48 - only it requires a highly formal and
11:50 - very specific syntax
11:52 - and generally speaking code tends to
11:55 - listen to me
11:56 - here's a beginner example from my
11:57 - tutorials on conditional logic this is
11:59 - something that you learn
12:01 - in the first couple weeks of learning to
12:03 - code
12:04 - if the mouse's x position is on the
12:07 - right hand side
12:08 - of the canvas or greater than 200 pixels
12:11 - draw a red background else or otherwise
12:14 - if it's on the left hand side
12:16 - less than 200 pixels draw a blue
12:18 - background
12:19 - programming by example works differently
12:22 - instead of you
12:23 - the programmer writing the explicit
12:24 - instructions you show
12:26 - examples to the machine itself and say
12:29 - hey
12:29 - why don't you based on these examples
12:31 - learn what those instructions should be
12:33 - to reproduce what i'm showing you but i
12:35 - can't just show the machine something
12:38 - in the case of machine learning what i
12:40 - really mean is
12:41 - take a data set of examples of inputs
12:45 - paired with outputs
12:46 - and feed those into a particular
12:48 - algorithm so that
12:49 - the machine learning system can learn
12:51 - the instructions to reproduce
12:54 - those same outputs with those inputs a
12:56 - collection
12:57 - of example inputs and outputs is what is
13:00 - known as a training data set
13:02 - and probably one of the most famous
13:04 - well-known training data sets for
13:05 - machine learning
13:06 - is something called mnist or modified
13:09 - national institute of standards and
13:11 - technology database
13:12 - a large database of handwritten digits
13:14 - that is commonly used
13:15 - for training various i don't have the
13:18 - next page training various image
13:20 - processing systems
13:22 - personally i'm a fan of a twist on that
13:24 - there's a data set called
13:25 - fashion mnist which is an alternative
13:27 - database it has 60 thousand example
13:29 - images of
13:30 - shirts and pants shoes and more all
13:32 - paired with a label so if i want to
13:34 - demonstrate image classification i can
13:36 - show
13:36 - a machine learning system here's all of
13:38 - these fashion mnist examples
13:40 - here's what their labels are now could
13:42 - you go look at some real clothes
13:43 - and correctly classify them but what is
13:46 - the algorithm that we're giving these
13:47 - examples
13:48 - to while there are many machine learning
13:50 - algorithms and sometimes these are
13:51 - called recipes
13:52 - the n in stylegan stands for network or
13:56 - more specifically artificial neural
13:58 - network
13:58 - a computational model based on the brain
14:01 - and probably
14:02 - what is the most popular machine
14:03 - learning recipe being used in today's
14:06 - modern so-called ai systems
14:09 - oh i got it that was really good back to
14:12 - the mouse interaction
14:13 - i've written code very specific
14:16 - instructions for the computer to follow
14:18 - could i reproduce this exact same result
14:21 - but instead of explicitly writing the
14:23 - instructions just create a data set
14:25 - examples
14:25 - of what are some points that happen to
14:27 - be on the left hand side of the canvas
14:29 - versus on the right hand side of the
14:30 - canvas i love this example because it's
14:33 - kind of ridiculous it's very silly and
14:35 - trivial i'm asking a big
14:36 - fancy neural network to learn one of the
14:38 - most basic things
14:39 - that a beginner coder learns how to do
14:42 - when learning to program
14:44 - i find this to be a great entry point
14:46 - into machine learning i can demonstrate
14:47 - the entire machine learning pipeline
14:49 - see it from start to finish with
14:50 - something so obvious that it's very easy
14:52 - to test the results and understand all
14:54 - the pieces of what's going on
14:55 - and figure out whether or not it's
14:57 - working so let's put this into practice
14:59 - i'll use the ml5.js library built on top
15:01 - of google's open source
15:02 - machine learning library tensorflow.js
15:05 - it has a neural network object
15:06 - ready to go first step is to collect
15:09 - training data
15:10 - i can write a quick p5.js sketch that
15:12 - collects data through mouse clicks
15:14 - click on the right hand side of the
15:15 - canvas a bunch of times then on the left
15:17 - hand side
15:18 - all the while making sure to pair those
15:21 - clicks with the correct label
15:23 - now it's time for me to configure the
15:25 - ml5.js neural network
15:27 - i just have two inputs the x and y value
15:29 - of each click and i should note i don't
15:31 - actually even need
15:32 - the y value so that would be another
15:34 - version of this that
15:35 - doesn't bother to use the y and one
15:37 - output a classification
15:39 - that has two discrete possibilities left
15:41 - or right
15:42 - next i call the train function and this
15:45 - is what is known
15:46 - as supervised learning the neural
15:48 - network for each
15:49 - data point makes a guess left or right
15:52 - if it makes the correct guess it doesn't
15:54 - have to do anything just move on to the
15:55 - next point
15:56 - if it makes an incorrect guess there's
15:58 - an error and it can go back inside of
16:00 - itself
16:00 - and just all of its weights and
16:02 - parameters and various internal
16:04 - mechanics
16:04 - to try to get the correct answer the
16:06 - next time over and over
16:08 - again we go many many times with the
16:10 - data every time i send all the data the
16:13 - training data through the neural network
16:14 - that is one epoch the amount of times
16:17 - the neural network has gotten things
16:19 - right or wrong that's all summarized in
16:21 - what's known as a loss function
16:23 - the lower the total loss the fewer the
16:25 - mistakes the loss is going down
16:27 - during your training things are working
16:29 - as planned
16:30 - once the model is trained i can go back
16:32 - to that original
16:33 - if statement take it out and replace it
16:36 - with
16:37 - sending the xy position into a neural
16:39 - network and
16:40 - getting the output from that neural
16:41 - network same exact thing this time
16:43 - neural network classification the fun
16:45 - thing about this is i can start to play
16:47 - with all
16:47 - different kinds of delineations i don't
16:49 - have to just look at left versus right
16:51 - maybe i look at a circle maybe i have
16:52 - sort of like a fuzzy collection of
16:54 - points
16:54 - and ultimately the question i want to
16:56 - ask of you is
16:57 - could you reproduce every single mouse
17:00 - interaction we take
17:01 - for granted that is generally programmed
17:04 - with instructions
17:05 - with machine learning and neural
17:07 - networks so this is the example i use in
17:09 - my introduction to machine learning for
17:10 - the arts course
17:11 - in my video tutorial series about ml5.js
17:14 - i hope that it's helpful i'd be curious
17:15 - to hear your feedback
17:17 - on how how you imagine teaching machine
17:19 - learning
17:20 - uh with thinking about programming with
17:22 - instructions and programming with
17:23 - examples
17:24 - and i also want to give a big thank you
17:26 - to dr rebecca freebrink
17:27 - her work um building the wekinator
17:29 - project another tool for machine
17:31 - learning and
17:32 - all of her examples of interactive
17:33 - machine learning for design systems
17:35 - was a huge inspiration for these
17:38 - examples and the ml5.js project itself
17:47 - [Music]
17:58 - gloria
18:01 - [Music]
18:05 - now that i've demonstrated how the
18:07 - machine can dream
18:08 - about the mouse how the machine can be
18:10 - trained by data from the mouse
18:13 - i want to explore what can the mouse
18:15 - teach us about ourselves the human
18:17 - beings
18:18 - and how we use the machine physical
18:20 - objects show
18:21 - signs of use over time wear on a piece
18:23 - of clothing
18:24 - or a desire path cutting through a patch
18:26 - of grass whatever the landscape design
18:29 - says about how to get from point a to
18:30 - point b we're going to go the most
18:32 - useful and direct way
18:34 - technology shows this kind of wear in
18:36 - hardware f1 keys are sometimes removed
18:39 - command keys are worn down similarly
18:42 - faded patterns on a mouse pad
18:44 - can give indications on how the mouse
18:46 - itself moves
18:47 - where can we see this where left by our
18:50 - digital
18:51 - presence the mouse is an extension of
18:53 - the self in the digital space which is
18:55 - easy to forget
18:56 - char styles in her sketch nails doesn't
18:58 - let you forget this as you
18:59 - physically grimace and wince scratching
19:02 - the mouse as nails across the screen
19:04 - which has now become a chalkboard in
19:07 - maya man's can i go
19:08 - where you go maya frees us from the
19:10 - limitations of the mouse as
19:12 - agent of the body and the whole body is
19:14 - able to act
19:15 - and move freely in the digital space in
19:18 - do not
19:19 - touch by the amsterdam-based studio
19:20 - moniker real-time cursor movements of
19:23 - hundreds of users
19:24 - are collaged into an interactive
19:27 - crowd-sourced music video
19:28 - a collaborative symphony of pointers i
19:32 - began
19:32 - my own exploration of these ideas by
19:34 - writing a processing sketch to collect
19:36 - mouse data
19:37 - over long periods of time i was teaching
19:39 - writing emails
19:40 - endless and endless and endless zoom
19:43 - meetings
19:44 - creative coding libraries like
19:46 - processing and p5.js they have built
19:48 - into them
19:49 - mouse x and mouse y variables but you
19:52 - can't actually use these variables they
19:54 - limit you
19:54 - to the pixels of your graphics display
19:57 - window or canvas themselves
19:59 - processing in case you didn't know is
20:01 - built however on top of the java
20:03 - programming language and you have access
20:06 - to all that there is to do
20:08 - with java itself and one of java's
20:10 - classes it's part of the awt package or
20:13 - abstract window toolkit can both track
20:17 - and control mouse movements in real time
20:21 - across any use of the operating system
20:24 - or any application whatsoever
20:26 - so i wrote some code to collect and save
20:28 - all of my mouse pointer positions
20:30 - into a csv file csv stands for comma
20:33 - separated values it's a very standard
20:35 - data format that you can easily reload
20:37 - into all sorts of other things like a
20:39 - spreadsheet you can then take this data
20:40 - and visualize it in a myriad of ways
20:42 - time lapse animations heat maps i tried
20:45 - a few different ones
20:47 - with all of these mouse movements saved
20:49 - i could also use them as training data i
20:51 - can analyze the probability of any
20:53 - moment of the mouse going up down left
20:55 - right
20:55 - and replay a sequence based on those
20:57 - probabilities with something known as a
20:59 - markov chain
21:00 - i could feed this data into something
21:01 - called a recurrent neural network
21:03 - a kind of neural network that's very
21:05 - well suited for sequential data
21:07 - time series text music
21:10 - vector paths there's a well-known
21:12 - machine learning model called sketch rnn
21:14 - that was trained off of the google
21:15 - quickdraw data set to generate
21:18 - doodles of all sorts of different types
21:20 - of things and i can take the results
21:22 - of that recurrent neural network trained
21:24 - off of my mouse movements
21:25 - to take a nap and let it just take over
21:28 - and control my computer now i didn't
21:29 - include
21:30 - mouse clicks in here well although i
21:32 - could have this way i
21:34 - just you know i'm safe and i'm not going
21:35 - to end up you know who knows what
21:36 - nefarious
21:37 - business the sort of dream version of my
21:39 - recurrent neural network mouse
21:41 - controller might get itself
21:42 - up to thank you so much for spending
21:44 - your time with me at the 2021 computer
21:46 - mouse conference for indulging me in
21:48 - this experiment i have learned a lot
21:50 - about what it means to
21:52 - operate a camera frankly to try to work
21:55 - with a script
21:56 - and i've really enjoyed having the
21:57 - opportunity to sort of put this set of
21:59 - demos uh together for you
22:01 - um i've made all the example code from
22:04 - this video available for you it's at
22:06 - thecodingtrain.com mouse learning
22:09 - and i hope that you find some
22:10 - inspiration to explore dreaming
22:12 - learning and teaching with a computer
22:14 - mouse and that you will
22:16 - share it with me thank you to emma and
22:18 - ashley and everyone who helped put
22:20 - together the computer mouse conference
22:22 - and i will see you sometime later
22:26 - that's my ending
22:32 - gloria come here how did i do it
22:35 - yes no no no no yes help me
22:40 - [Music]
22:51 - come in go come on come in yeah
22:55 - [Music]
23:06 - okay
23:11 - [Music]
23:45 - you