{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\felic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\felic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\felic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\felic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries to navigate within directories\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# the usual suspects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "\n",
    "# NLP pre-processing from nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# let's make pre-processing more efficient\n",
    "## batch processing\n",
    "from typing import List\n",
    "## parallel processing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "# Jupyter-specific imports\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline \n",
    "\n",
    "# Suppress warnings (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_url</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>video_length</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>transcript_filename</th>\n",
       "      <th>Tier (1, 2, or 3)</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Girls Code</td>\n",
       "      <td>Have You Ever Thought About Working at Google?...</td>\n",
       "      <td>https://www.youtube.com/watch?v=ahQQpYG0Lhk</td>\n",
       "      <td>4/26/24</td>\n",
       "      <td>6:26</td>\n",
       "      <td>199330</td>\n",
       "      <td>5625</td>\n",
       "      <td>4</td>\n",
       "      <td>haveyoueverthoughtaboutworkingatgoogleepisode8...</td>\n",
       "      <td>1</td>\n",
       "      <td>hello everyone and welcome back to codal along...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black Girls Code</td>\n",
       "      <td>Tutorial 4: How to Code Animated Art In JavaSc...</td>\n",
       "      <td>https://www.youtube.com/watch?v=I49CXUIXvM8</td>\n",
       "      <td>4/28/23</td>\n",
       "      <td>11:18</td>\n",
       "      <td>84000</td>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "      <td>tutorial4howtocodeanimatedartinjavascriptcodea...</td>\n",
       "      <td>1</td>\n",
       "      <td>what's up for the encoders welcome back to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black Girls Code</td>\n",
       "      <td>CODE Along: Win $2500!</td>\n",
       "      <td>https://www.youtube.com/watch?v=fZKyNSH2mmM</td>\n",
       "      <td>8/25/23</td>\n",
       "      <td>2:19</td>\n",
       "      <td>139194</td>\n",
       "      <td>344</td>\n",
       "      <td>18</td>\n",
       "      <td>codealongwin2500.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>hey what's up everyone I'm Cheyenne and I'm yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black Girls Code</td>\n",
       "      <td>Don't Know What Career to Choose? Actress and ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=ohceCkLK8Wo</td>\n",
       "      <td>8/21/23</td>\n",
       "      <td>0:44</td>\n",
       "      <td>1143</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>dontknowwhatcareertochooseactressandgamerellab...</td>\n",
       "      <td>1</td>\n",
       "      <td>this question means so much to me because when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Girls Code</td>\n",
       "      <td>Watch Actress Ella Balinska Recap Her Career i...</td>\n",
       "      <td>https://www.youtube.com/watch?v=jAYK6vJbhxU</td>\n",
       "      <td>8/19/23</td>\n",
       "      <td>0:48</td>\n",
       "      <td>3493</td>\n",
       "      <td>117</td>\n",
       "      <td>10</td>\n",
       "      <td>watchactressellabalinskarecaphercareerin60seco...</td>\n",
       "      <td>1</td>\n",
       "      <td>60 seconds okay so I started off uh with a cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel_name                                        video_title  \\\n",
       "0  Black Girls Code  Have You Ever Thought About Working at Google?...   \n",
       "1  Black Girls Code  Tutorial 4: How to Code Animated Art In JavaSc...   \n",
       "2  Black Girls Code                             CODE Along: Win $2500!   \n",
       "3  Black Girls Code  Don't Know What Career to Choose? Actress and ...   \n",
       "4  Black Girls Code  Watch Actress Ella Balinska Recap Her Career i...   \n",
       "\n",
       "                                     video_url publish_date video_length  \\\n",
       "0  https://www.youtube.com/watch?v=ahQQpYG0Lhk      4/26/24         6:26   \n",
       "1  https://www.youtube.com/watch?v=I49CXUIXvM8      4/28/23        11:18   \n",
       "2  https://www.youtube.com/watch?v=fZKyNSH2mmM      8/25/23         2:19   \n",
       "3  https://www.youtube.com/watch?v=ohceCkLK8Wo      8/21/23         0:44   \n",
       "4  https://www.youtube.com/watch?v=jAYK6vJbhxU      8/19/23         0:48   \n",
       "\n",
       "    views  likes  comments                                transcript_filename  \\\n",
       "0  199330   5625         4  haveyoueverthoughtaboutworkingatgoogleepisode8...   \n",
       "1   84000    179         8  tutorial4howtocodeanimatedartinjavascriptcodea...   \n",
       "2  139194    344        18                               codealongwin2500.txt   \n",
       "3    1143     40         2  dontknowwhatcareertochooseactressandgamerellab...   \n",
       "4    3493    117        10  watchactressellabalinskarecaphercareerin60seco...   \n",
       "\n",
       "   Tier (1, 2, or 3)                                            content  \n",
       "0                  1  hello everyone and welcome back to codal along...  \n",
       "1                  1  what's up for the encoders welcome back to the...  \n",
       "2                  1  hey what's up everyone I'm Cheyenne and I'm yo...  \n",
       "3                  1  this question means so much to me because when...  \n",
       "4                  1  60 seconds okay so I started off uh with a cou...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata_transcript = pd.read_csv('metadata_transcript.csv')\n",
    "df_metadata_transcript.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processing\n",
    "We employ different methods to pre-process the text before using NLP to analyze it:\n",
    "- Lowercasing ---> seems like we've done this!\n",
    "- Tokenization, as a pre-processing step for Term Frequency Distributions\n",
    "- Remove Stop Words!\n",
    "- Remove leftover contraction tokens (\"'s\", \"'m\", etc...)\n",
    "- Lemmatization, to simplify tokens further by removing plurals and such\n",
    "\n",
    "Takes a long time to run... \n",
    "- VF Record: 3m 43.8s, 11/28/24 11:52pm WOW WHAT HAPPENED HERE WHY IS IT BETTER\n",
    "- VF Longest Run: 12m 27.6s, 11/14/24 10:15am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: ['channel_name', 'video_title', 'video_url', 'publish_date', 'video_length', 'views', 'likes', 'comments', 'transcript_filename', 'Tier (1, 2, or 3)', 'content', 'preprocessed_content']\n",
      "\n",
      "First few rows of content and preprocessed content:\n",
      "                                             content  \\\n",
      "0  hello everyone and welcome back to codal along...   \n",
      "1  what's up for the encoders welcome back to the...   \n",
      "2  hey what's up everyone I'm Cheyenne and I'm yo...   \n",
      "3  this question means so much to me because when...   \n",
      "4  60 seconds okay so I started off uh with a cou...   \n",
      "\n",
      "                                preprocessed_content  \n",
      "0  [hello, everyone, welcome, back, codal, along,...  \n",
      "1  [whats, encoders, welcome, back, fourth, final...  \n",
      "2  [hey, whats, everyone, im, cheyenne, im, resid...  \n",
      "3  [question, mean, much, whenever, anything, mak...  \n",
      "4  [second, started, couple, writer, pass, tv, sh...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define custom filler words\n",
    "custom_fillers = {\n",
    "    'uh', 'um', 'na', 'like', 'actually', 'basically', 'literally',\n",
    "    'you know', 'i mean', 'sort of', 'kind of', 'yeah', 'okay',\n",
    "    'right', 'well', 'so', 'just', 'going', 'oh', 'ah', 'gon'\n",
    "} # i just add onto this when i see something repetitive or weird\n",
    "# Pre-compute lowercase stop words and unwanted tokens\n",
    "stop_words_lower = {word.lower() for word in stop_words}\n",
    "all_filtered_words = stop_words_lower.union(custom_fillers)\n",
    "unwanted_tokens = {\"'s\", \"'m\", \"'re\", \"'ve\", \"'d\", \"'ll\", \"n't\"}\n",
    "all_filtered_words.update(unwanted_tokens)\n",
    "\n",
    "def optimized_preprocess_text(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Combine operations\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(token.lower())\n",
    "        for token in word_tokenize(text)\n",
    "        if token.lower() not in all_filtered_words\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the 'content' column\n",
    "df_metadata_transcript['preprocessed_content'] = df_metadata_transcript['content'].apply(optimized_preprocess_text)\n",
    "\n",
    "# Verify columns are preserved\n",
    "print(\"Columns in DataFrame:\", df_metadata_transcript.columns.tolist())\n",
    "print(\"\\nFirst few rows of content and preprocessed content:\")\n",
    "print(df_metadata_transcript[['content', 'preprocessed_content']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Summary Statistics per YouTube Channel, per YouTube Video. Specifically, we'll get the Total Words & Unique Words across all dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus-Level Statistics:\n",
      "--------------------------------------------------\n",
      "total_words: 36,516,986\n",
      "unique_words: 128,028\n",
      "total_videos: 16,206\n",
      "total_channels: 65\n",
      "\n",
      "Updated DataFrame with word statistics:\n",
      "                                         video_title      channel_name  \\\n",
      "0  Have You Ever Thought About Working at Google?...  Black Girls Code   \n",
      "1  Tutorial 4: How to Code Animated Art In JavaSc...  Black Girls Code   \n",
      "2                             CODE Along: Win $2500!  Black Girls Code   \n",
      "3  Don't Know What Career to Choose? Actress and ...  Black Girls Code   \n",
      "4  Watch Actress Ella Balinska Recap Her Career i...  Black Girls Code   \n",
      "\n",
      "   total_words  unique_words  \n",
      "0          546           281  \n",
      "1          711           271  \n",
      "2          209           152  \n",
      "3           61            53  \n",
      "4           64            56  \n",
      "\n",
      "Per Channel Statistics:\n",
      "                          total_words  unique_words  video_count\n",
      "freeCodeCamp.org             15671181         78140         1600\n",
      "The Coding Train              3113668         34093         1137\n",
      "Clever Programmer             2894526         28720          762\n",
      "ProgrammingKnowledge          2038172         16917         1586\n",
      "Tech With Tim                 1643448         17628          936\n",
      "...                               ...           ...          ...\n",
      "Coding with Mat                  4199           844            5\n",
      "The BlackFemale Engineer         2760           745            2\n",
      "Codingal Education                794           281            1\n",
      "Kids Coding Club                  314           154            1\n",
      "Computer World Kids               271            24            9\n",
      "\n",
      "[65 rows x 3 columns]\n",
      "\n",
      "Summary Statistics:\n",
      "\n",
      "Video Level:\n",
      "         total_words  unique_words\n",
      "count   16206.000000  16206.000000\n",
      "mean     2251.935950    409.261878\n",
      "std      6773.723888    466.660802\n",
      "min         0.000000      0.000000\n",
      "25%       385.000000    155.000000\n",
      "50%       740.000000    258.000000\n",
      "75%      1530.000000    460.000000\n",
      "max    289046.000000   7835.000000\n",
      "\n",
      "Channel Level:\n",
      "        total_words  unique_words  video_count\n",
      "count  6.500000e+01     65.000000    65.000000\n",
      "mean   5.617998e+05   7148.107692   249.323077\n",
      "std    1.999985e+06  11014.886317   372.747238\n",
      "min    2.710000e+02     24.000000     1.000000\n",
      "25%    1.641600e+04   1547.000000    32.000000\n",
      "50%    9.415400e+04   4201.000000   108.000000\n",
      "75%    3.462560e+05   7474.000000   230.000000\n",
      "max    1.567118e+07  78140.000000  1600.000000\n"
     ]
    }
   ],
   "source": [
    "# Get statistics from the preprocessed DataFrame\n",
    "def get_video_statistics(df):\n",
    "    video_stats = {}\n",
    "    for _, row in df.iterrows():\n",
    "        words = row['preprocessed_content']  # Already a list, no need to split\n",
    "        video_stats[row['video_title']] = {\n",
    "            'total_words': len(words),\n",
    "            'unique_words': len(set(words))\n",
    "        }\n",
    "    return video_stats\n",
    "\n",
    "def get_channel_statistics(df):\n",
    "    channel_stats = {}\n",
    "    \n",
    "    # Group by channel\n",
    "    for channel_name, channel_group in df.groupby('channel_name'):\n",
    "        all_words = []\n",
    "        unique_words = set()\n",
    "        \n",
    "        for word_list in channel_group['preprocessed_content']:\n",
    "            all_words.extend(word_list)\n",
    "            unique_words.update(word_list)\n",
    "            \n",
    "        channel_stats[channel_name] = {\n",
    "            'total_words': len(all_words),\n",
    "            'unique_words': len(unique_words),\n",
    "            'video_count': len(channel_group)\n",
    "        }\n",
    "    return channel_stats\n",
    "\n",
    "def get_corpus_statistics(df):\n",
    "    \"\"\"Calculate statistics for the entire corpus\"\"\"\n",
    "    all_words = []\n",
    "    unique_words = set()\n",
    "    \n",
    "    for word_list in df['preprocessed_content']:\n",
    "        all_words.extend(word_list)\n",
    "        unique_words.update(word_list)\n",
    "    \n",
    "    return {\n",
    "        'total_words': len(all_words),\n",
    "        'unique_words': len(unique_words),\n",
    "        'total_videos': len(df),\n",
    "        'total_channels': len(df['channel_name'].unique())\n",
    "    }\n",
    "\n",
    "# Calculate statistics\n",
    "video_statistics = get_video_statistics(df_metadata_transcript)\n",
    "channel_statistics = get_channel_statistics(df_metadata_transcript)\n",
    "corpus_statistics = get_corpus_statistics(df_metadata_transcript)\n",
    "\n",
    "# Convert video statistics to DataFrame\n",
    "video_stats_df = pd.DataFrame.from_dict(video_statistics, orient='index')\n",
    "video_stats_df.index.name = 'video_title'\n",
    "video_stats_df = video_stats_df.reset_index()\n",
    "\n",
    "# Merge statistics with original DataFrame\n",
    "df_metadata_transcript = df_metadata_transcript.merge(\n",
    "    video_stats_df, \n",
    "    on='video_title', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate channel statistics DataFrame\n",
    "channel_stats_df = pd.DataFrame.from_dict(channel_statistics, orient='index')\n",
    "\n",
    "# Display results\n",
    "print(\"\\nCorpus-Level Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "for key, value in corpus_statistics.items():\n",
    "    print(f\"{key}: {value:,}\")\n",
    "\n",
    "print(\"\\nUpdated DataFrame with word statistics:\")\n",
    "print(df_metadata_transcript[['video_title', 'channel_name', 'total_words', 'unique_words']].head())\n",
    "\n",
    "print(\"\\nPer Channel Statistics:\")\n",
    "print(channel_stats_df.sort_values('total_words', ascending=False))\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(\"\\nVideo Level:\")\n",
    "print(df_metadata_transcript[['total_words', 'unique_words']].describe())\n",
    "print(\"\\nChannel Level:\")\n",
    "print(channel_stats_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the pre-processed data as a new .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV (existing code)\n",
    "df_metadata_transcript.to_csv('clean_metadata_transcript.csv', index=False)\n",
    "\n",
    "# Also save as pickle for faster loading and preserved data types\n",
    "df_metadata_transcript.to_pickle('clean_metadata_transcript.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
