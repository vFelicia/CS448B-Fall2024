{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "\n",
    "# Visualization basics\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Interactive components\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "# Analysis tools\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Display settings\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "# run a virtual environment of Python 3.9.0 .venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the pickle loading with CSV loading\n",
    "df_metadata_transcript = pd.read_csv('clean_metadata_transcript.csv')\n",
    "\n",
    "# If the preprocessed_content column contains string representations of lists\n",
    "# Convert it back to actual lists\n",
    "# df_metadata_transcript['preprocessed_content'] = df_metadata_transcript['preprocessed_content'].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're going to create a series of visualizations that allow us to better sift through the data and do our own analysis:\n",
    "\n",
    "## 1. Topical Focus -- Topic Distribution Dashboard\n",
    "Leverage the Topic Distribution Dashboard to reveal:\n",
    "* Channel specializations\n",
    "* Common themes across different teaching styles2\n",
    "* Educational approach variations\n",
    "\n",
    "## 2. Channel Relationships -- Log-Odds Ratio Comparison\n",
    "Utilize Log-Odds comparisons to demonstrate:\n",
    "* Teaching style differences\n",
    "* Target audience variations\n",
    "* Technical depth variations\n",
    "\n",
    "## 3. Educational Approaches -- NLP Metrics Channel Comparison\n",
    "Utilize TF-IDFs, Normalized TF-IDFs, LLR, and Fightin'Words to identify:\n",
    "* Teach style differences\n",
    "* Complexity level variations\n",
    "* Target audience adaptations\n",
    "\n",
    "## For preliminary results, we compare Black Girls Code (identity-oriented) against Code.org (identity-agnostic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Topic Distribution Dashboard\n",
    "The x-axis seems to pit \"Technical Content <-> Community Focus\" from left-to-right, suggestions a contrast between theoretical topics in CS versus practical application; the y-axis seems to contrast \"Beginner Topics <-> Advanced Topics\" from bottom to top. Unfortunately, BERTopic won't allow us to directly edit the axis labels for readability.\n",
    "\n",
    "We can see this in the comparison between BGC and code.org: it seems that BGC on the distance map trends towards the bottom-right while code.org trends towards the top-left. You can verify the patterns by looking at the table of topic terms on the right, and indeed we see that BGC is more communtiy focused than code.org whom seems to focus more on teaching computer science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for Coding with Mat\n",
      "Missing files for Computer World Kids\n",
      "Missing files for Low Level Learning\n",
      "Missing files for Coding with Mat\n",
      "Missing files for Computer World Kids\n",
      "Missing files for Low Level Learning\n",
      "\n",
      "Verifying AlvinBlox:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Black Girls Code:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Brackeys:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Bro Code:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Cave of Programming:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Clear Code:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Clever Programmer:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Code Monkey:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Code With Conner:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Code.org:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying CodeBeauty:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Codecademy:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying CodeMonkey - Coding Games for Kids:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying CodeWithChris:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Coding for kids:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Coding is for girls:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Coding Kids:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Coding with John:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Coding With Kids:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Coding Workshops for Kids - Online Coding Courses for Kids and Parents:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying CodingNepal:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Corey Schafer:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying CS Dojo:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying CS50 Made Easy with Rahul:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 4\n",
      "\n",
      "Verifying Easy Codes for Kids:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying First Code Academy:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying freeCodeCamp.org:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying GIRLS CODE TOO!:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Girls Who Code:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Girls Will Code:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying GirlsCodeIt:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying griffpatch:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Hackingtons Code School:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Jenny's Lectures CS IT:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Khan Academy Computing:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Kids Coding Playground:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Kids for Code:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying KidsCanCode:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Kodable:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Learn Computer Programming:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying LearnCode.academy:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying MrBrownCS:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying My CS:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying mycodeschool:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Programiz:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Programming For Beginners:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Programming Kids:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Programming with Mosh:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying ProgrammingKnowledge:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Scratch Team:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying ShawCode:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying STEMinGames - Beginner Programming:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying Tech With Tim:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying TechWorld with Nana:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying The Coding Train:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying thenewboston:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n",
      "\n",
      "Verifying w3schools.com:\n",
      "  Has topic_embeddings_: True\n",
      "  Has get_topic method: True\n",
      "  Has get_topic_freq method: True\n",
      "  Number of topics: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1cb87ade3e4b63ba9f0ff46a3fdfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Channels:', index=(0,), layout=Layout(height='100px', width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_channel_models(base_dir='./channel_topic_analysis'):\n",
    "    channel_models = {}\n",
    "    topic_distributions = {}\n",
    "    \n",
    "    if not os.path.exists(base_dir):\n",
    "        raise ValueError(f\"Directory {base_dir} does not exist\")\n",
    "        \n",
    "    for channel_dir in os.listdir(base_dir):\n",
    "        channel_path = os.path.join(base_dir, channel_dir)\n",
    "        if os.path.isdir(channel_path):\n",
    "            try:\n",
    "                model_path = os.path.join(channel_path, 'topic_model.pkl')\n",
    "                dist_path = os.path.join(channel_path, 'topic_distributions.pkl')\n",
    "                \n",
    "                if not os.path.exists(model_path) or not os.path.exists(dist_path):\n",
    "                    print(f\"Missing files for {channel_dir}\")\n",
    "                    continue\n",
    "                \n",
    "                # Add try-except specifically for model loading\n",
    "                try:\n",
    "                    with open(model_path, 'rb') as f:\n",
    "                        model = pickle.load(f)\n",
    "                    # Verify model has required attributes\n",
    "                    if not hasattr(model, 'topic_embeddings_'):\n",
    "                        print(f\"Invalid model format for {channel_dir}\")\n",
    "                        continue\n",
    "                    channel_models[channel_dir] = model\n",
    "                except Exception as e:\n",
    "                    print(f\"Model loading error for {channel_dir}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "                with open(dist_path, 'rb') as f:\n",
    "                    topic_distributions[channel_dir] = pickle.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {channel_dir}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not channel_models:\n",
    "        raise ValueError(\"No valid models found in directory\")\n",
    "        \n",
    "    return channel_models, topic_distributions\n",
    "\n",
    "# In your dashboard notebook:\n",
    "channel_models, channel_distributions = load_channel_models()\n",
    "# Then use these with your dashboard code\n",
    "\n",
    "def create_topic_distribution_dashboard(channel_models, topic_distributions, selected_channels=None, n_topics=10):\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Intertopic Distance Map', 'Topic Terms'),\n",
    "        specs=[[{'type': 'scatter'}, {'type': 'table'}]],\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    colors = px.colors.qualitative.Set3\n",
    "    combined_dist_df = pd.DataFrame()\n",
    "    \n",
    "    channels_to_process = ([selected_channels] if isinstance(selected_channels, str) \n",
    "                         else selected_channels if selected_channels \n",
    "                         else ['All'])\n",
    "    \n",
    "    for idx, channel in enumerate(channels_to_process):\n",
    "        model = channel_models[channel] if channel != 'All' else list(channel_models.values())[0]\n",
    "        \n",
    "        if hasattr(model, 'topic_embeddings_'):\n",
    "            coords = model.topic_embeddings_\n",
    "            n_topics = coords.shape[0]\n",
    "            perplexity = min(30, n_topics - 1)\n",
    "            \n",
    "            tsne = TSNE(\n",
    "                n_components=2,\n",
    "                random_state=42,\n",
    "                perplexity=max(perplexity, 1)\n",
    "            )\n",
    "            coords_2d = tsne.fit_transform(coords)\n",
    "            \n",
    "            # Generate meaningful topic labels\n",
    "            topic_labels = {}\n",
    "            for topic_id in range(len(coords)):\n",
    "                topic_words = model.get_topic(topic_id)\n",
    "                if hasattr(model, 'custom_labels_') and topic_id in model.custom_labels_:\n",
    "                    topic_labels[topic_id] = model.custom_labels_[topic_id]\n",
    "                else:\n",
    "                    # Create descriptive label from top words\n",
    "                    words = [word for word, _ in topic_words[:3]]\n",
    "                    topic_labels[topic_id] = f\"{' | '.join(words)}\"\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=coords_2d[:, 0],\n",
    "                    y=coords_2d[:, 1],\n",
    "                    mode='markers+text',\n",
    "                    text=[topic_labels[i] for i in range(len(coords))],\n",
    "                    textposition=\"top center\",\n",
    "                    name=channel,\n",
    "                    marker=dict(\n",
    "                        size=10,\n",
    "                        color=colors[idx % len(colors)],\n",
    "                        line=dict(width=1)\n",
    "                    ),\n",
    "                    hovertemplate='<b>%{text}</b><br>Channel: ' + channel + '<extra></extra>'\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "    \n",
    "    # Create combined topic terms table with meaningful labels\n",
    "    all_topics_terms = []\n",
    "    for channel in channels_to_process:\n",
    "        model = channel_models[channel] if channel != 'All' else list(channel_models.values())[0]\n",
    "        \n",
    "        for topic_id in range(len(model.get_topic_freq())):\n",
    "            try:\n",
    "                terms = model.get_topic(topic_id)\n",
    "                if isinstance(terms, list) and len(terms) > 0:\n",
    "                    # Get topic label\n",
    "                    if hasattr(model, 'custom_labels_') and topic_id in model.custom_labels_:\n",
    "                        topic_label = model.custom_labels_[topic_id]\n",
    "                    else:\n",
    "                        topic_label = f\"{', '.join([word for word, _ in terms[:3]])}\"\n",
    "                    \n",
    "                    terms_string = ', '.join([term for term, _ in terms[:5]])\n",
    "                    weight_string = ', '.join([f\"{weight:.3f}\" for _, weight in terms[:5]])\n",
    "                    channel_name = channel if channel != 'All' else 'Combined'\n",
    "                    all_topics_terms.append([\n",
    "                        f\"{channel_name} - {topic_label}\",\n",
    "                        terms_string,\n",
    "                        weight_string\n",
    "                    ])\n",
    "            except (TypeError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Table(\n",
    "            header=dict(\n",
    "                values=['Topic', 'Top Terms', 'Weights'],\n",
    "                font=dict(size=12, color='white'),\n",
    "                fill_color='rgb(55, 83, 109)'\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=list(zip(*all_topics_terms)),\n",
    "                font=dict(size=11),\n",
    "                align=['left'] * 3\n",
    "            )\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=1400,\n",
    "        showlegend=True,\n",
    "        legend_title_text=\"Channels\",\n",
    "        title_text=\"Channel Topic Comparison Dashboard\",\n",
    "        title_x=0.5,\n",
    "        template=\"plotly_white\",\n",
    "        margin=dict(t=100, b=50, l=50, r=50)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_interactive_dashboard(channel_models, topic_distributions):\n",
    "    if not channel_models:\n",
    "        raise ValueError(\"No channel models provided\")\n",
    "    \n",
    "    channel_options = list(channel_models.keys())\n",
    "    \n",
    "    # Create multi-select for channels\n",
    "    channel_selector = widgets.SelectMultiple(\n",
    "        options=['All'] + channel_options,\n",
    "        value=['All'],\n",
    "        description='Channels:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='50%', height='100px')\n",
    "    )\n",
    "    \n",
    "    # Get maximum number of topics\n",
    "    max_topics = min(20, max(len(model.get_topic_freq()) \n",
    "                    for model in channel_models.values()))\n",
    "    \n",
    "    interact(\n",
    "        lambda c: create_topic_distribution_dashboard(\n",
    "            channel_models,\n",
    "            topic_distributions,\n",
    "            None if 'All' in c else list(c)\n",
    "        ),\n",
    "        c=channel_selector\n",
    "    )\n",
    "\n",
    "def verify_models(channel_models):\n",
    "    for channel, model in channel_models.items():\n",
    "        print(f\"\\nVerifying {channel}:\")\n",
    "        print(f\"  Has topic_embeddings_: {hasattr(model, 'topic_embeddings_')}\")\n",
    "        print(f\"  Has get_topic method: {hasattr(model, 'get_topic')}\")\n",
    "        print(f\"  Has get_topic_freq method: {hasattr(model, 'get_topic_freq')}\")\n",
    "        if hasattr(model, 'topic_embeddings_'):\n",
    "            print(f\"  Number of topics: {len(model.topic_embeddings_)}\")\n",
    "\n",
    "# Verify before creating dashboard\n",
    "channel_models, topic_distributions = load_channel_models()\n",
    "verify_models(channel_models)\n",
    "create_interactive_dashboard(channel_models, topic_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Log-Odds Visualization\n",
    "More granular analysis of words most characteristic of a channel, between channels. It's interesting the BGC, compared to code.org, uniquely uses words like \"afro\" and \"afrotech\". Though I think because Log-Odds is drawing out the most characteristic words of a channel, it's also drawing out the most unique words. Some of these words are incredibly unique for their channel, and I think I'd have to watch the video associated with the word to understand the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67117683d8549c0af139e226c2423c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Channels:', index=(0,), layout=Layout(height='200px', width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_log_odds_data(directory='Log_Odds_Analysis'):\n",
    "    log_odds_results = {}\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('_log_odds_tfd.csv'):\n",
    "            channel_name = filename.replace('_log_odds_tfd.csv', '')\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # Read CSV with index as terms\n",
    "            df = pd.read_csv(file_path, index_col='term')\n",
    "            \n",
    "            log_odds_results[channel_name] = {\n",
    "                'log_odds': df['log_odds'].values,\n",
    "                'tfd': df['tfd'].values,\n",
    "                'terms': df.index.values  # Store actual terms\n",
    "            }\n",
    "    \n",
    "    return log_odds_results\n",
    "\n",
    "def create_log_odds_visualization(log_odds_results, n_terms=20):\n",
    "    # Generate colors automatically using a qualitative color scale\n",
    "    n_channels = len(log_odds_results)\n",
    "    colors = px.colors.qualitative.Set3[:n_channels]\n",
    "    \n",
    "    if n_channels > 12:\n",
    "        colors = px.colors.sample_colorscale('viridis', n_channels)\n",
    "    \n",
    "    channel_colors = dict(zip(log_odds_results.keys(), colors))\n",
    "\n",
    "    # Create 1x2 subplot layout for vertical orientation\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Channel Term Comparison', 'Top Distinctive Terms'),\n",
    "        specs=[[{'type': 'scatter'}, {'type': 'bar'}]],\n",
    "        horizontal_spacing=0.2  # Increased spacing between plots\n",
    "    )\n",
    "    \n",
    "    for channel, data in log_odds_results.items():\n",
    "        color = channel_colors.get(channel, '#666666')\n",
    "        df = pd.DataFrame({\n",
    "            'log_odds': data['log_odds'],\n",
    "            'tfd': data['tfd'],\n",
    "            'terms': data['terms']\n",
    "        })\n",
    "        \n",
    "        # Scatter plot\n",
    "        df_sorted = df.sort_values('log_odds', key=abs, ascending=False)\n",
    "        top_terms = df_sorted.head(n_terms)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=top_terms['tfd'],\n",
    "                y=top_terms['log_odds'],\n",
    "                mode='markers+text',\n",
    "                name=channel,\n",
    "                text=top_terms['terms'],\n",
    "                textposition=\"top center\",\n",
    "                marker=dict(size=10, color=color)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Bar chart\n",
    "        top_distinctive = df_sorted.head(10)\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=top_distinctive['log_odds'],\n",
    "                y=top_distinctive['terms'],\n",
    "                orientation='h',\n",
    "                name=f\"{channel} Top Terms\",\n",
    "                marker_color=color\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=1400,\n",
    "        showlegend=True,\n",
    "        title_text=\"Channel Content Analysis\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    \n",
    "    # Update axes labels\n",
    "    fig.update_xaxes(title_text=\"Term Frequency Distribution\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Log-Odds Ratio\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Log-Odds Ratio\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Terms\", row=1, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_interactive_log_odds_dashboard(log_odds_results):\n",
    "    instructions = widgets.HTML(\n",
    "        value=\"<p style='margin-left:15px; padding-top:5px'><i>Hold Shift to select multiple consecutive channels<br>or click individual channels to toggle selection</i></p>\"\n",
    "    )\n",
    "\n",
    "    channel_selector = widgets.SelectMultiple(\n",
    "        options=list(log_odds_results.keys()),\n",
    "        value=[list(log_odds_results.keys())[0]],\n",
    "        description='Channels:',\n",
    "        layout=widgets.Layout(width='250px', height='200px'),\n",
    "        rows=10,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    terms_slider = widgets.IntSlider(\n",
    "        value=20,\n",
    "        min=5,\n",
    "        max=50,\n",
    "        step=5,\n",
    "        description='Top Terms:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HBox([channel_selector, instructions]),\n",
    "        terms_slider\n",
    "    ])\n",
    "    \n",
    "    def update_viz(channels, n_terms):\n",
    "        selected_results = {k: log_odds_results[k] for k in channels}\n",
    "        return create_log_odds_visualization(selected_results, n_terms)\n",
    "    \n",
    "    interact(update_viz, channels=channel_selector, n_terms=terms_slider)\n",
    "\n",
    "# Add interactive controls\n",
    "def create_interactive_log_odds_dashboard(log_odds_results):\n",
    "    instructions = widgets.HTML(\n",
    "        value=\"<p style='margin-left:15px; padding-top:5px'><i>Hold Shift to select multiple consecutive channels<br>or click individual channels to toggle selection</i></p>\"\n",
    "    )\n",
    "\n",
    "    channel_selector = widgets.SelectMultiple(\n",
    "        options=list(log_odds_results.keys()),\n",
    "        value=[list(log_odds_results.keys())[0]],\n",
    "        description='Channels:',\n",
    "        layout=widgets.Layout(width='250px', height='200px'),\n",
    "        rows=10,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    terms_slider = widgets.IntSlider(\n",
    "        value=20,\n",
    "        min=5,\n",
    "        max=50,\n",
    "        step=5,\n",
    "        description='Top Terms:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HBox([channel_selector, instructions]),\n",
    "        terms_slider\n",
    "    ])\n",
    "    \n",
    "    def update_viz(channels, n_terms):\n",
    "        selected_results = {k: log_odds_results[k] for k in channels}\n",
    "        return create_log_odds_visualization(selected_results, n_terms)\n",
    "    \n",
    "    interact(update_viz, channels=channel_selector, n_terms=terms_slider)\n",
    "\n",
    "# Load the data and create the visualization\n",
    "log_odds_results = load_log_odds_data()\n",
    "create_interactive_log_odds_dashboard(log_odds_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: NLP Metrics Channel Comparison\n",
    "\n",
    "## Interesting Trends:\n",
    "\n",
    "### Log-Likelihood Ratio\n",
    "There is a strong focus on identity markers with the words “girl”, “black”, “woman”, and “afro” being amongst the top LLR-scored words.\n",
    "\n",
    "Code.org LLR scores produced words related to academics, specifically computer science education, with words like “computer”, “science”, “school”, and “education” being top words. BGC also has some of these terms, but it seems that they’re more characteristic for Code.org.\n",
    "\n",
    "### Fightin' Words\n",
    "By the z-scores, it looks like BGC compared to Code.org distinctively has terms relating to identity and empowerment (“black”, z=14.171; “girl”, z=14.051) and some technical programming words (“script”, z=7.644; “block”, z=7.869). \n",
    "\n",
    "If you switch the comparison to Channel 1: Code.org and Channel 2: BGC, there seems to be a strong emphasis on formal computer science education for Code.org(“computer”, z=-49.91; “student”, z=-46.431; “science”, z=-41.637; and “school”, z=-22.336)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a349a0e6a1c4dcf9058e0b48d8d57ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Channel 1', options=('Black Girls Code', 'Codecademy', 'Coding for…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # Try loading pickle first\n",
    "    df_metadata_transcript = pd.read_pickle('clean_metadata_transcript.pkl')\n",
    "except:\n",
    "    # If pickle fails, load CSV and convert preprocessed_content back to lists\n",
    "    df_metadata_transcript = pd.read_csv('clean_metadata_transcript.csv')\n",
    "    df_metadata_transcript['preprocessed_content'] = df_metadata_transcript['preprocessed_content'].apply(eval)\n",
    "\n",
    "# TF-IDF calculation function\n",
    "def calculate_tfidf_comparison(texts1, texts2):\n",
    "    # Join tokens back into strings\n",
    "    all_texts = [' '.join(text) for text in texts1 + texts2]\n",
    "    \n",
    "    # Calculate regular TF-IDF\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(all_texts)\n",
    "    \n",
    "    # Get average scores for each channel\n",
    "    n1 = len(texts1)\n",
    "    channel1_tfidf = np.mean(tfidf_matrix[:n1].toarray(), axis=0)\n",
    "    channel2_tfidf = np.mean(tfidf_matrix[n1:].toarray(), axis=0)\n",
    "    \n",
    "    results = []\n",
    "    for idx, term in enumerate(tfidf.get_feature_names_out()):\n",
    "        results.append({\n",
    "            'word': term,\n",
    "            'tfidf_diff': channel1_tfidf[idx] - channel2_tfidf[idx],\n",
    "            'channel1_tfidf': channel1_tfidf[idx],\n",
    "            'channel2_tfidf': channel2_tfidf[idx]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('tfidf_diff', ascending=False)\n",
    "\n",
    "def calculate_normalized_tfidf_comparison(texts1, texts2):\n",
    "    # Join tokens back into strings\n",
    "    all_texts = [' '.join(text) for text in texts1 + texts2]\n",
    "    \n",
    "    # Calculate normalized TF-IDF\n",
    "    tfidf_norm = TfidfVectorizer(norm='l1')\n",
    "    tfidf_norm_matrix = tfidf_norm.fit_transform(all_texts)\n",
    "    \n",
    "    # Get average scores for each channel\n",
    "    n1 = len(texts1)\n",
    "    channel1_norm = np.mean(tfidf_norm_matrix[:n1].toarray(), axis=0)\n",
    "    channel2_norm = np.mean(tfidf_norm_matrix[n1:].toarray(), axis=0)\n",
    "    \n",
    "    results = []\n",
    "    for idx, term in enumerate(tfidf_norm.get_feature_names_out()):\n",
    "        results.append({\n",
    "            'word': term,\n",
    "            'norm_tfidf_diff': channel1_norm[idx] - channel2_norm[idx],\n",
    "            'channel1_norm_tfidf': channel1_norm[idx],\n",
    "            'channel2_norm_tfidf': channel2_norm[idx]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('norm_tfidf_diff', ascending=False)\n",
    "\n",
    "# Normalized TF-IDF calculation function\n",
    "def normalize_sparse_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Normalize sparse matrix rows to sum to 1\n",
    "    \"\"\"\n",
    "    row_sums = np.array(matrix.sum(axis=1)).ravel()\n",
    "    row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "    row_indices, col_indices = matrix.nonzero()\n",
    "    matrix.data /= row_sums[row_indices]\n",
    "    return matrix\n",
    "\n",
    "def calculate_normalized_tfidf_comparison(texts1, texts2):\n",
    "    # Join tokens back into strings\n",
    "    all_texts = [' '.join(text) for text in texts1 + texts2]\n",
    "    \n",
    "    # Calculate TF-IDF with parameters matching our previous analysis\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        min_df=1,\n",
    "        max_df=1.0,\n",
    "        token_pattern=r'(?u)\\b\\w+\\b',\n",
    "        stop_words=None,\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # Normalize the matrix\n",
    "    normalized_matrix = normalize_sparse_matrix(tfidf_matrix)\n",
    "    \n",
    "    # Get average scores for each channel\n",
    "    n1 = len(texts1)\n",
    "    channel1_norm = np.mean(normalized_matrix[:n1].toarray(), axis=0)\n",
    "    channel2_norm = np.mean(normalized_matrix[n1:].toarray(), axis=0)\n",
    "    \n",
    "    results = []\n",
    "    for idx, term in enumerate(tfidf_vectorizer.get_feature_names_out()):\n",
    "        results.append({\n",
    "            'word': term,\n",
    "            'norm_tfidf_diff': channel1_norm[idx] - channel2_norm[idx],\n",
    "            'channel1_norm_tfidf': channel1_norm[idx],\n",
    "            'channel2_norm_tfidf': channel2_norm[idx]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('norm_tfidf_diff', ascending=False)\n",
    "\n",
    "# LLR calculation function\n",
    "def calculate_llr(count1, count2, n1, n2):\n",
    "    # Add small smoothing constant to prevent division by zero\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    e1 = n1 * (count1 + count2 + epsilon) / (n1 + n2)\n",
    "    e2 = n2 * (count1 + count2 + epsilon) / (n1 + n2)\n",
    "    \n",
    "    # Add epsilon to prevent log(0)\n",
    "    return 2 * (count1 * np.log((count1 + epsilon) / (e1 + epsilon)) + \n",
    "                count2 * np.log((count2 + epsilon) / (e2 + epsilon)))\n",
    "\n",
    "# Fighting Words calculation function\n",
    "def calculate_fighting_words(texts1, texts2, prior=0.01):\n",
    "    words1 = [word for text in texts1 for word in text]\n",
    "    words2 = [word for text in texts2 for word in text]\n",
    "    \n",
    "    counts1 = Counter(words1)\n",
    "    counts2 = Counter(words2)\n",
    "    \n",
    "    vocab = set(counts1.keys()) | set(counts2.keys())\n",
    "    \n",
    "    results = []\n",
    "    for word in vocab:\n",
    "        count1 = counts1[word]\n",
    "        count2 = counts2[word]\n",
    "        \n",
    "        p1 = (count1 + prior) / (len(words1) + 2 * prior)\n",
    "        p2 = (count2 + prior) / (len(words2) + 2 * prior)\n",
    "        \n",
    "        se = np.sqrt(p1 * (1 - p1) / len(words1) + p2 * (1 - p2) / len(words2))\n",
    "        z_score = (p1 - p2) / se\n",
    "        \n",
    "        results.append({\n",
    "            'word': word,\n",
    "            'z_score': z_score,\n",
    "            'count_channel1': count1,\n",
    "            'count_channel2': count2\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('z_score', ascending=False)\n",
    "\n",
    "# Comparison function\n",
    "def compare_channels(channel1, channel2, method='llr'):\n",
    "    texts1 = df_metadata_transcript[df_metadata_transcript['channel_name'] == channel1]['preprocessed_content'].tolist()\n",
    "    texts2 = df_metadata_transcript[df_metadata_transcript['channel_name'] == channel2]['preprocessed_content'].tolist()\n",
    "    \n",
    "    if method == 'tfidf':\n",
    "        return calculate_tfidf_comparison(texts1, texts2)\n",
    "    elif method == 'normalized_tfidf':\n",
    "        return calculate_normalized_tfidf_comparison(texts1, texts2)\n",
    "    elif method == 'llr':\n",
    "        words1 = [word for text in texts1 for word in text]\n",
    "        words2 = [word for text in texts2 for word in text]\n",
    "        \n",
    "        counts1 = Counter(words1)\n",
    "        counts2 = Counter(words2)\n",
    "        \n",
    "        results = []\n",
    "        for word in set(counts1) | set(counts2):\n",
    "            count1 = counts1[word]\n",
    "            count2 = counts2[word]\n",
    "            llr_score = calculate_llr(count1, count2, len(words1), len(words2))\n",
    "            results.append({\n",
    "                'word': word,\n",
    "                'llr_score': llr_score,\n",
    "                'count_channel1': count1,\n",
    "                'count_channel2': count2\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results).sort_values('llr_score', ascending=False)\n",
    "    else:\n",
    "        return calculate_fighting_words(texts1, texts2)\n",
    "\n",
    "# Update visualization function\n",
    "def create_comparison_dashboard():\n",
    "    def update_comparison(channel1, channel2, method='llr'):\n",
    "        # Map UI method names to function method names\n",
    "        method_mapping = {\n",
    "            'TF-IDF': 'tfidf',\n",
    "            'Normalized TF-IDF': 'normalized_tfidf',\n",
    "            'LLR': 'llr',\n",
    "            'Fighting Words': 'fighting_words'\n",
    "        }\n",
    "        \n",
    "        # Get the correct method key for the comparison function\n",
    "        method_key = method_mapping[method]\n",
    "        \n",
    "        # Get comparison data\n",
    "        comparison_data = compare_channels(channel1, channel2, method_key)\n",
    "        \n",
    "        # Map method names to score columns\n",
    "        score_column_map = {\n",
    "            'tfidf': 'tfidf_diff',\n",
    "            'normalized_tfidf': 'norm_tfidf_diff',\n",
    "            'llr': 'llr_score',\n",
    "            'fighting_words': 'z_score'\n",
    "        }\n",
    "        \n",
    "        count_col1_map = {\n",
    "            'tfidf': 'channel1_tfidf',\n",
    "            'normalized_tfidf': 'channel1_norm_tfidf',\n",
    "            'llr': 'count_channel1',\n",
    "            'fighting_words': 'count_channel1'\n",
    "        }\n",
    "        \n",
    "        count_col2_map = {\n",
    "            'tfidf': 'channel2_tfidf',\n",
    "            'normalized_tfidf': 'channel2_norm_tfidf',\n",
    "            'llr': 'count_channel2',\n",
    "            'fighting_words': 'count_channel2'\n",
    "        }\n",
    "        \n",
    "        # Get correct column names\n",
    "        score_column = score_column_map[method_key]\n",
    "        count_col1 = count_col1_map[method_key]\n",
    "        count_col2 = count_col2_map[method_key]\n",
    "        \n",
    "        fig = go.Figure(data=[\n",
    "            go.Table(\n",
    "                header=dict(\n",
    "                    values=['Word', f'{method} Score', \n",
    "                           f'{channel1} Score', f'{channel2} Score'],\n",
    "                    font=dict(size=12),\n",
    "                    align='left'\n",
    "                ),\n",
    "                cells=dict(\n",
    "                    values=[\n",
    "                        comparison_data['word'],\n",
    "                        comparison_data[score_column].round(3),\n",
    "                        comparison_data[count_col1].round(3),\n",
    "                        comparison_data[count_col2].round(3)\n",
    "                    ],\n",
    "                    font=dict(size=11),\n",
    "                    align='left'\n",
    "                )\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            width=1000,\n",
    "            title_text=f'{method} Comparison: {channel1} vs {channel2}'\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    # Create widgets with updated options\n",
    "    channels = df_metadata_transcript['channel_name'].unique()\n",
    "    \n",
    "    channel_selector1 = widgets.Dropdown(\n",
    "        options=channels,\n",
    "        description='Channel 1'\n",
    "    )\n",
    "    \n",
    "    channel_selector2 = widgets.Dropdown(\n",
    "        options=channels,\n",
    "        description='Channel 2'\n",
    "    )\n",
    "    \n",
    "    method_selector = widgets.RadioButtons(\n",
    "        options=['TF-IDF', 'Normalized TF-IDF', 'LLR', 'Fighting Words'],\n",
    "        description='Method'\n",
    "    )\n",
    "    \n",
    "    interact(\n",
    "        update_comparison,\n",
    "        channel1=channel_selector1,\n",
    "        channel2=channel_selector2,\n",
    "        method=method_selector\n",
    "    )\n",
    "\n",
    "# Run the dashboard\n",
    "create_comparison_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
